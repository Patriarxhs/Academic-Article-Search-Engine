[
{"Title": "Homophily and Specialization in Networks", "abs": ["In this paper, players contribute to two local public goods for which they have different tastes and sponsor costly links to enjoy the provision of others. In equilibrium, either there are several contributors specialized in public good provision or only two contributors who are not entirely specialized. Higher linking costs have a non-monotonic impact on welfare and polarization, as they affect who specializes in public good provision. When the available budget is small, subsidies should be given to players who already specialize in public good provision; otherwise, they should target only one player who specializes in public good provision."], "authors": "Patrick Allmis"},
{"Title": "Polynomial tau-functions of the n-th Sawada-Kotera hierarchy", "abs": ["We find all polynomial tau-functions of the n-th reduced BKP hierarchy (=n-th Sawada-Kotera hierarchy). The name comes from the fact that for n=3 the simplest equation of the hierarchy is the famous Sawada-Kotera equation."], "authors": "Victor Kac"},
{"Title": "Meta-Diversity Search in Complex Systems, A Recipe for Artificial Open-Endedness ?", "abs": ["Can we build an artificial system that would be able to generate endless surprises if ran \"forever\" in Minecraft? While there is not a single path toward solving that grand challenge, this article presents what we believe to be some working ingredients for the endless generation of novel increasingly complex artifacts in Minecraft. Our framework for an open-ended system includes two components: a complex system used to recursively grow and complexify artifacts over time, and a discovery algorithm that leverages the concept of meta-diversity search. Since complex systems have shown to enable the emergence of considerable complexity from set of simple rules, we believe them to be great candidates to generate all sort of artifacts in Minecraft. Yet, the space of possible artifacts that can be generated by these systems is often unknown, challenging to characterize and explore. Therefore automating the long-term discovery of novel and increasingly complex artifacts in these systems is an exciting research field. To approach these challenges, we formulate the problem of meta-diversity search where an artificial \"discovery assistant\" incrementally learns a diverse set of representations to characterize behaviors and searches to discover diverse patterns within each of them. A successful discovery assistant should continuously seek for novel sources of diversities while being able to quickly specialize the search toward a new unknown type of diversity. To implement those ideas in the Minecraft environment, we simulate an artificial \"chemistry\" system based on Lenia continuous cellular automaton for generating artifacts, as well as an artificial \"discovery assistant\" (called Holmes) for the artifact-discovery process. Holmes incrementally learns a hierarchy of modular representations to characterize divergent sources of diversity and uses a goal-based intrinsically-motivated exploration as the diversity search strategy."], "authors": "Mayalen Etcheverry"},
{"Title": "Production of Protons and Light Nuclei in Au+Au Collisions at $\\sqrt{s_{\\mathrm{NN}}}$ = 3 GeV with the STAR Detector", "abs": ["We report the systematic measurement of protons and light nuclei production in Au+Au collisions at $\\sqrt{s_{\\mathrm{NN}}}$ = 3 GeV by the STAR experiment at the Relativistic Heavy Ion Collider (RHIC). The transverse momentum ($p_{T}$) spectra of protons ($p$), deuterons ($d$), tritons ($t$), $^{3}\\mathrm{He}$, and $^{4}\\mathrm{He}$ are measured from mid-rapidity to target rapidity for different collision centralities. We present the rapidity and centrality dependence of particle yields ($dN/dy$), average transverse momentum ($\\langle p_{T}\\rangle$), yield ratios ($d/p$, $t/p$,$^{3}\\mathrm{He}/p$, $^{4}\\mathrm{He}/p$), as well as the coalescence parameters ($B_2$, $B_3$). The 4$\\pi$ yields for various particles are determined by utilizing the measured rapidity distributions, $dN/dy$. Furthermore, we present the energy, centrality, and rapidity dependence of the compound yield ratios ($N_{p} \\times N_{t} / N_{d}^{2}$) and compare them with various model calculations. The physics implications of those results on the production mechanism of light nuclei and on QCD phase structure are discussed."], "authors": "STAR Collaboration"},
{"Title": "Exploration of hadronization through heavy flavor production at the future Electron-Ion Collider", "abs": ["The future Electron-Ion Collider will utilize high-luminosity high-energy electron+proton ($e+p$) and electron+nucleus ($e+A$) collisions to solve several fundamental questions in the high energy nuclear physics field. Heavy flavor products play an important role in constraining the initial-state nucleon/nucleus parton distribution functions especially in the high and low Bjorken-x ($x_{BJ}$) region and exploring the final-state parton propagation and hadronization processes under different nuclear medium conditions. Latest simulation studies of heavy flavor hadron and jet measurements with the EIC project detector conceptual design will be discussed. The projected statistical accuracy of heavy flavor jet and heavy flavor hadron inside jet measurements in comparison with latest theoretical calculations will be presented."], "authors": "Xuan Li"},
{"Title": "Phenomenology of superheavy decaying dark matter from string theory", "abs": ["We study the phenomenology of superheavy decaying dark matter with mass around $10^{10}$ GeV which can arise in the low-energy limit of string compactifications. Generic features of string theory setups (such as high scale supersymmetry breaking and epochs of early matter domination driven by string moduli) can accommodate superheavy dark matter with the correct relic abundance. In addition, stringy instantons induce tiny $R$-parity violating couplings which make dark matter unstable with a lifetime well above the age of the Universe. Adopting a model-independent approach, we compute the flux and spectrum of high-energy gamma rays and neutrinos from three-body decays of superheavy dark matter and constrain its mass-lifetime plane with current observations and future experiments. We show that these bounds have only a mild dependence on the exact nature of neutralino dark matter and its decay channels. Applying these constraints to an explicit string model sets an upper bound of ${\\cal O}(0.1)$ on the string coupling, ensuring that the effective field theory is in the perturbative regime."], "authors": "Rouzbeh Allahverdi"},
{"Title": "Dynamical manifold dimensionality as characterization measure of chimera states in bursting neuronal networks", "abs": ["Methods that distinguish dynamical regimes in networks of active elements make it possible to design the dynamics of models of realistic networks. A particularly salient example is partial synchronization, which may play a pivotal role in elucidating the dynamics of biological neural networks. Such emergent partial synchronization in structurally homogeneous networks is commonly denoted as chimera states. While several methods for detecting chimeras in networks of spiking neurons have been proposed, these are less effective when applied to networks of bursting neurons. Here we introduce the correlation dimension as a novel approach to identifying dynamic network states. To assess the viability of this new method, we study a network of intrinsically Hindmarsh-Rose neurons with non-local connections. In comparison to other measures of chimera states, the correlation dimension effectively characterizes chimeras in burst neurons, whether the incoherence arises in spikes or bursts. The generality of dimensionality measures inherent in the correlation dimension renders this approach applicable to any dynamic system, facilitating the comparison of simulated and experimental data. We anticipate that this methodology will enable the tuning and simulation of when modelling intricate network processes, contributing to a deeper understanding of neural dynamics."], "authors": "Olesia Dogonasheva"},
{"Title": "Neutron Star in Quantised-space-time", "abs": ["We construct and analyze a model of neutron star in the $\\kappa$-deformed space-time. This is done by first deriving $\\kappa$-deformed generalization of the Einstein tensor, starting from the non-commutative generalization of the metric tensor. By generalising the energy-momentum tensor to the non-commutative space-time and exploiting the $\\kappa$-deformed dispersion relation, we then set up Einstein's field equations in the $\\kappa$-deformed space-time. As we adopt a realisation of the non-commutative coordinates in terms of the commutative coordinates and their derivatives, our model is constructed in terms of commutative variables. Now by treating the interior of the star to be a perfect fluid as in the commutative space-time, we investigate the modification to neutron star's mass due to non-commutativity of the space-time. We show that the non-commutativity of the space-time enhances the mass limit of the neutron star. Using recent observational limit on the upper bound on the mass of neutron stars, we find the deformation parameter to be $|a|\\sim 10^{-44}m$."], "authors": "Bhagya. R"},
{"Title": "Carroll Fermions", "abs": ["Using carefully chosen projections, we consider different Carroll limits of relativistic Dirac fermions in any spacetime dimensions. These limits define Carroll fermions of two types: electric and magnetic. The latter type transforms as a reducible but indecomposable representation of the Carroll group. We also build action principles for all Carroll fermions we introduce; in particular, in even dimensions we provide an action principle for a minimal magnetic Carroll fermion, having the same number of components as a Dirac spinor. We then explore the coupling of these fermions to magnetic Carroll gravity in both its first-order and second-order formulations."], "authors": "Eric A. Bergshoeff"},
{"Title": "Tidal effects and renormalization at fourth post-Minkowskian order", "abs": ["We determine the adiabatic tidal contributions to the radiation reacted momentum impulse $\\Delta p_i^\\mu$ and scattering angle $\\theta$ between two scattered massive bodies (neutron stars) at next-to-next-to-leading post-Minkowskian (PM) order. The state-of-the-art three-loop (4PM) worldline quantum field theory toolkit using dimensional regularization is employed to establish the classical observables. We encounter divergent terms in the gravito-electric and gravito-magnetic quadrupolar sectors necessitating the addition of post-adiabatic counterterms in this classical theory. This leads us to include also the leading post-adiabatic tidal contributions to the observables. The resulting renormalization group flow of the associated post-adiabatic Love numbers is established and shown to agree with a recent gravito-electric third post-Newtonian analysis in the non-relativistic limit."], "authors": "Gustav Uhre Jakobsen"},
{"Title": "Multiple Testing of Linear Forms for Noisy Matrix Completion", "abs": ["Many important tasks of large-scale recommender systems can be naturally cast as testing multiple linear forms for noisy matrix completion. These problems, however, present unique challenges because of the subtle bias-and-variance tradeoff of and an intricate dependence among the estimated entries induced by the low-rank structure. In this paper, we develop a general approach to overcome these difficulties by introducing new statistics for individual tests with sharp asymptotics both marginally and jointly, and utilizing them to control the false discovery rate (FDR) via a data splitting and symmetric aggregation scheme. We show that valid FDR control can be achieved with guaranteed power under nearly optimal sample size requirements using the proposed methodology. Extensive numerical simulations and real data examples are also presented to further illustrate its practical merits."], "authors": "Wanteng Ma"},
{"Title": "Inference on common trends in functional time series", "abs": ["This paper studies statistical inference on unit roots and cointegration for time series in a Hilbert space. We develop statistical inference on the number of common stochastic trends that are embedded in the time series, i.e., the dimension of the nonstationary subspace. We also consider hypotheses on the nonstationary subspace itself. The Hilbert space can be of an arbitrarily large dimension, and our methods remain asymptotically valid even when the time series of interest takes values in a subspace of possibly unknown dimension. This has wide applicability in practice; for example, in the case of cointegrated vector time series of finite dimension, in a high-dimensional factor model that includes a finite number of nonstationary factors, in the case of cointegrated curve-valued (or function-valued) time series, and nonstationary dynamic functional factor models. We include two empirical illustrations to the term structure of interest rates and labor market indices, respectively."], "authors": "Morten Ørregaard Nielsen"},
{"Title": "Two-photon absorption cross sections of pulsed entangled beams", "abs": ["Entangled two-photon absorption (ETPA) could form the basis of nonlinear quantum spectroscopy at very low photon fluxes, since, at sufficiently low photon fluxes, ETPA scales linearly with the photon flux. When different pairs start to overlap temporally, accidental coincidences are thought to give rise to a 'classical' quadratic scaling which dominates the signal at large photon fluxes and thus recovers a supposedly classical regime, where any quantum advantage is thought to be lost. Here we scrutinize this assumption and demonstrate that quantum-enhanced absorption cross sections can persist even to very large photon numbers. To this end, we use a minimal model for quantum light, which can interpolate continuously between the entangled pair and a high-photon-flux limit, to derive analytically ETPA cross sections and the intensity crossover regime. We investigate the interplay between spectral and spatial degrees of freedom, how linewidth broadening of the sample impacts the experimentally achievable enhancement."], "authors": "Frank Schlawin"},
{"Title": "Subspace methods for electronic structure simulations on quantum computers", "abs": ["Quantum subspace methods (QSMs) are a class of quantum computing algorithms where the time-independent Schrodinger equation for a quantum system is projected onto a subspace of the underlying Hilbert space. This projection transforms the Schrodinger equation into an eigenvalue problem determined by measurements carried out on a quantum device. The eigenvalue problem is then solved on a classical computer, yielding approximations to ground- and excited-state energies and wavefunctions. QSMs are examples of hybrid quantum-classical methods, where a quantum device supported by classical computational resources is employed to tackle a problem. QSMs are rapidly gaining traction as a strategy to simulate electronic wavefunctions on quantum computers, and thus their design, development, and application is a key research field at the interface between quantum computation and electronic structure. In this review, we provide a self-contained introduction to QSMs, with emphasis on their application to the electronic structure of molecules. We present the theoretical foundations and applications of QSMs, and we discuss their implementation on quantum hardware, illustrating the impact of noise on their performance."], "authors": "Mario Motta"},
{"Title": "Kerr-Schild double copy for Kundt spacetimes of any dimension", "abs": ["We show that vacuum type N Kundt spacetimes in an arbitrary dimension admit a Kerr-Schild (KS) double copy. This is mostly done in a coordinate-independent way using the higher-dimensional Newman-Penrose formalism. We also discuss two kinds of non-uniqueness of an electromagnetic field corresponding to a given KS metric (i.e., its single copy) - these originate, respectively, from the rescaling freedom in the KS vector and from the non-uniqueness of the splitting of the KS metric in the flat part and the KS part. In connection to this, we show that the subset of KS pp-waves admits both null and non-null electromagnetic single copies. Since vacuum type N Kundt spacetimes are universal solutions of virtually any higher-order gravities and null fields in such backgrounds are immune to higher-order electromagnetic corrections, the KS-Kundt double copy demonstrated in the present paper also applies to large classes of modified theories."], "authors": "Marcello Ortaggio"},
{"Title": "Functional Renormalization Group Study of Thermodynamic Geometry Around the Phase Transition of Quantum Chromodynamic", "abs": ["We investigate the thermodynamic geometry of the quark-meson model at finite temperature, $T$, and quark number chemical potential, $\\mu$. We extend previous works by the inclusion of fluctuations exploiting the functional renormalization group approach. We use recent developments to recast the flow equation into the form of an advection-diffusion equation. We adopt the local potential approximation for the effective average action. We focus on the thermodynamic curvature, $R$, in the $(\\mu,T)$ plane, in proximity of the chiral crossover, up to the critical point of the phase diagram. We find that the inclusion of fluctuations results in a smoother behavior of $R$ near the chiral crossover. Moreover, for small $\\mu$, $R$ remains negative, signaling the fact that bosonic fluctuations reduce the capability of the system to completely overcome the fermionic statistical repulsion of the quarks. We investigate in more detail the small $\\mu$ region by analyzing a system in which we artificially lower the pion mass, thus approaching the chiral limit in which the crossover is actually a second order phase transition. On the other hand, as $\\mu$ is increased and the critical point is approached, we find that $R$ is enhanced and a sign change occurs, in agreement with mean field studies. Hence, we completely support the picture that $R$ is sensitive to a crossover and a phase transition, and provides information about the effective behavior of the system at the phase transition."], "authors": "Fabrizio Murgana"},
{"Title": "Robustness of Quantum Chaos and Anomalous Relaxation in Open Quantum Circuits", "abs": ["Dissipation is a ubiquitous phenomenon in nature that affects the fate of chaotic quantum dynamics. To characterize the interplay between quantum chaos and dissipation in generic quantum many-body systems, we consider a minimal dissipative Floquet many-body system. We study the dissipative form factor (DFF), an extension of the spectral form factor to open quantum systems, of the random phase model in the presence of arbitrary one-site nonunitary gates (quantum channels). In the limit of large local Hilbert space dimension, we obtain an exact expression for the DFF averaged over the random unitary gates, with simple, closed-form expressions in the limit of large times. We find that, for long enough times, the system always relaxes (i.e., the DFF decays) with two distinctive regimes characterized by the presence or absence of gap closing. While the system can sustain a robust ramp for a long (but finite) time interval in the gap-closing regime, relaxation is ``assisted'' by quantum chaos in the regime where the gap remains nonzero. In the latter regime, we find that, if the thermodynamic limit is taken first, the gap does not close even in the dissipationless limit."], "authors": "Takato Yoshimura"},
{"Title": "Two band atomic superfluidity in the presence of orbital Feshbach resonance", "abs": ["We study superfluid properties of alkali-earth-like Fermi atomic systems in the presence of orbital Feshbach resonance. Using a two-band description of the ground state and excited state and a mean-field approximation of the intra-band atomic pairing, we investigate the phase transitions and crossover between superfluid/normal phases. Defining an effective scattering length by combining both inter-band and intra-band interactions, we derive closed form gap and number density equations for both ground state and excited state atomic bands. We find that our zero-temperature analytical results and finite-temperature numerical results indicate that the system can show smooth crossover between Bardeen, Cooper, and Schreifer (BCS) and Bose-Einstein Condensate (BEC) superfluidity for atoms in each band. In addition, we find that inter-band and intra-band interactions can induce quantum phase transitions between BCS/BEC superfluid states of atoms in one band to that of the other. We anticipate that our closed form analytical results can be used as a bench mark for future experimental and theoretical investigations and will have an impact on the current understanding of two-band superconductors such as MgB$_2$."], "authors": "Andrew Vincent"},
{"Title": "Theoretical Developments in Lattice Gauge Theory for Applications in Double-beta Decay Processes and Quantum Simulation", "abs": ["Double beta decays are rare nuclear processes that can occur in two modes: two-neutrino double beta decay, observed in the Standard Model, and neutrinoless double beta decay, a hypothetical process with profound implications for Particle Physics. To draw reliable conclusions from their experimental constraints, it is necessary to have accurate predictions of the underlying hadronic interactions described by quantum chromodynamics (QCD), a non-Abelian gauge theory with the symmetry group SU(3). QCD predictions require non-perturbative methods for calculating observables, and lattice QCD (LQCD), a numerical method based on QCD formulated on a finite space-time grid, is the only reliable first-principles technique for obtaining quantitative results. However, LQCD needs formal prescriptions to match numerical results with observables. This thesis provides such prescriptions for double beta decays using the finite volume effects in the LQCD framework. Matching relations that connect two-nucleon double beta decay amplitudes to quantities accessible via LQCD calculations, namely the nuclear matrix elements and two-nucleon energy spectra in a finite volume are provided. The impact of uncertainties is examined on the precision with which low-energy constants of the corresponding effective field theories can be determined from future LQCD calculations.", "Hamiltonian simulation of QCD is another non-perturbative method of solving QCD which can be more suitable in some cases than the conventional LQCD. The rise of tensor network methods and quantum simulation has made Hamiltonian simulation of lattice gauge theories (LGTs) a reality. Towards the goal of simulating QCD, a loop-string-hadron (LSH) formulation of an SU(3) LGT with matter in 1+1 dimensions is developed in this thesis, motivated by recent studies that showed the LSH formulation of an SU(2) LGT to be advantageous over other formulations."], "authors": "Saurabh V. Kadam"},
{"Title": "Analysis of the fusion mechanism in synthesis superheavy element 119 via $^{54}$Cr+$^{243}$Am reaction", "abs": ["The combined dinuclear system (DNS) and statistical model implanted in KEWPIE2 have been used to study the prospects for the synthesis of a superheavy element (SHE) with $Z=119$ in the $^{54}$Cr+$^{243}$Am fusion reaction. The method of calculation has been verified by description of the evaporation residue cross sections measured for the $^{48}$Ca+$^{243}$Am reaction. The calculated results of the partial and total cross sections for the complete fusion, quasifission, fast fission and evaporation residues formation for both reactions are discussed."], "authors": "B.M. Kayumov"},
{"Title": "Higher-order moments of the elliptic flow distribution in PbPb collisions at $\\sqrt{s_\\mathrm{NN}}$ = 5.02 TeV", "abs": ["The hydrodynamic flow-like behavior of charged hadrons in high-energy lead-lead collisions is studied through multiparticle correlations. The elliptic anisotropy values based on different orders of multiparticle cumulants, $v_{2}\\{2k\\}$, are measured up to the tenth order ($k$ = 5) as functions of the collision centrality at a nucleon-nucleon center-of-mass energy of $\\sqrt{s_\\mathrm{NN}}$ = 5.02 TeV. The data were recorded by the CMS experiment at the LHC and correspond to an integrated luminosity of 0.607 nb$^{-1}$. A hierarchy is observed between the coefficients, with $v_{2}\\{2\\} > v_{2}\\{4\\} \\gtrsim v_{2}\\{6\\} \\gtrsim v_{2}\\{8\\} \\gtrsim v_{2}\\{10\\}$. Based on these results, centrality-dependent moments for the fluctuation-driven event-by-event $v_{2}$ distribution are determined, including the skewness, kurtosis and, for the first time, superskewness. Assuming a hydrodynamic expansion of the produced medium, these moments directly probe the initial-state geometry in high-energy nucleus-nucleus collisions."], "authors": "CMS Collaboration"},
{"Title": "Optimal colliding energy for the synthesis of superheavy element $Z$=119", "abs": ["The evaporation residue (ER) cross section of 3n and 4n channels related to the synthesis of superheavy element (SHE) with the charge number $Z=119$ in the $^{51}$V+$^{248}$Cm reaction has been calculated by the dinuclear system (DNS) model as a sum of the partial cross sections of the corresponding channels. The angular momentum distribution of the compound nucleus is estimated by the dynamical trajectory calculations of the capture probability which is considered as the DNS formation probability. The fusion probability decreases by the increase of the DNS angular momentum due to its influence on the intrinsic fusion barrier $B_{\\rm fus}^*$. The range $\\alpha_2=60^{\\circ} ÷70^{\\circ}$ of the orientation angle of the axial symmetry axis of the deformed target nucleus $^{248}$Cm is favorable for the formation of the compound nucleus. The fusion probability decreases at around $\\alpha_2=90^{\\circ}$ since the number of the partial waves contributing to the capture decreases. Therefore, it is important to calculate the capture cross section dynamically. The 4n channel cross section of the SHE synthesis is larger than the 3n channel cross section maximum value of the ER cross section is 12.3 fb at $E_{\\rm c.m.}$=232 MeV."], "authors": "Avazbek Nasirov"},
{"Title": "Particle Identification at VAMOS++ with Machine Learning Techniques", "abs": ["Multi-nucleon transfer reaction between 136Xe beam and 198Pt target was performed using the VAMOS++ spectrometer at GANIL to study the structure of n-rich nuclei around N=126. Unambiguous charge state identification was obtained by combining two supervised machine learning methods, deep neural network (DNN) and positional correction using a gradient-boosting decision tree (GBDT). The new method reduced the complexity of the kinetic energy calibration and outperformed the conventional method, improving the charge state resolution by 8%"], "authors": "Y. Cho"},
{"Title": "Measurement of the jet mass and angularities in Pb-Pb collisions at 5.02 TeV with ALICE", "abs": ["Jet substructure observables provide powerful tools to search for new physics and test theoretical descriptions of perturbative and non-perturbative processes in QCD. In heavy-ion collisions, jet substructure observables are used to elucidate the structure and dynamics of the quark-gluon plasma. Jet mass is one such observable, which probes the virtuality of hard-scattered partons and their modified fragmentation. Additionally, generalized jet angularities provide a powerful tool for differential measurements of the jet shower and its modification, as two parameters vary the weight of the jet constituents' relative angle and $p_\\mathrm{T}$. Previous measurements of the jet mass and jet angularities have shown conflicting differences in comparison with models. To clarify these results, we present new measurements of the jet mass and jet angularities using an identical jet sample. The high-precision tracking system of ALICE enables these measurements over a broad range in $p_\\mathrm{T}$, with low-$p_\\mathrm{T}$ reach that is unique at the LHC. We report the generalized jet mass and jet angularities using charged-particle tracks in Pb-Pb collisions at $\\sqrt{s_\\mathrm{NN}} = 5.02$ TeV. Various jet angularity parameters are investigated for the jet resolution parameter $R = 0.2$. Results are compared to pp collisions and theoretical models."], "authors": "Ezra D. Lesser"},
{"Title": "Quantal effect on the opening angle distribution between the fission fragment's spins", "abs": ["Background: Several approaches are currently trying to understand the generation of angular momentum in the fission fragments. The microscopic TDDFT and statistical FREYA lead to different predictions concerning the opening angle distribution formed between the two spins in particular at 0 and 180 degrees. Purpose: This letter aims to investigate how the geometry and the quantum nature of spins impact the distribution of opening angles to understand what leads to different model predictions. Method: Various assumptions of K distribution (K=0, isotropic, isotropic with total K=0, and from TDFFT) are investigated in a quantum approach. These distributions are then compared to the classical limit using the Clebsch-Gordan coefficients in the limit of $\\hbar$ approaches zero. Results: It is shown that in all the schematic scenario the quantal distribution of opening angle lead to the expected behavior in the classical limit. The model shows that the quantal nature of the spins prevents the population of opening angles close to 0 and 180 degrees. The difference in opening angle in the 2D and isotropic 3D distribution is discussed and it is shown that the realistic TDFFT opening angle distribution presents an intermediate behavior between the two cases. Conclusions: The last comparison reveals two key differences between the two models' predictions: the quantal spins' nature in TDDFT and the assumption of zero K values in FREYA."], "authors": "Guillaume Scamps"},
{"Title": "Measurements of the lightest hypernucleus ($\\mathrm{^3_ΛH}$): progress and perspective", "abs": ["The hyperon-nucleon ($Y$-$N$) interaction is important for the description of the equation-of-state of high baryon density matter. Hypernuclei, the cluster object of nucleons and hyperons, serve as cornerstones of a full understanding of the $Y$-$N$ interaction. Recent measurements of the lightest known hypernucleus, the hypertriton's ($\\mathrm{^3_{\\Lambda}H}$) and anti-hypertriton's ($\\mathrm{^3_{\\bar{\\Lambda}}\\bar{H}}$) lifetime, mass and $\\Lambda$ separation energy have attracted interests on the subject. Its cross section and collective flow parameters have also been measured in heavy-ion collisions, which have revealed new features on its production mechanism. In this article we summarise recent measurements of $\\mathrm{^3_{\\Lambda}H}$, focusing on the heavy-ion collisions. We will discuss their implications for the $\\mathrm{^3_{\\Lambda}H}$ properties and the constrains on the $Y$-$N$ interaction models."], "authors": "Jinhui Chen"},
{"Title": "The Beta-decay Paul Trap Mk IV: Design and commissioning", "abs": ["The Beta-decay Paul Trap is an open-geometry, linear trap used to measure the decays of $^8$Li and $^8$B to search for a tensor contribution to the weak interaction. In the latest $^8$Li measurement of Burkey et al. (2022), $\\beta$ scattering was the dominant experimental systematic uncertainty. The Beta-decay Paul Trap Mk IV reduces the prevalence of $\\beta$ scattering by a factor of 4 through a redesigned electrode geometry and the use of glassy carbon and graphite as electrode materials. The trap has been constructed and successfully commissioned with $^8$Li in a new data campaign that collected 2.6 million triple coincidence events, an increase in statistics by 30% with 4 times less $\\beta$ scattering compared to the previous $^8$Li data set."], "authors": "L. Varriano"},
{"Title": "Measurement of forward charged hadron flow harmonics in peripheral PbPb collisions at $\\sqrt{s_{NN}}=5.02$ TeV with the LHCb detector", "abs": ["Flow harmonic coefficients, $v_n$, which are the key to studying the hydrodynamics of the quark-gluon plasma (QGP) created in heavy-ion collisions, have been measured in various collision systems, kinematic regions, and using various particle species. The study of flow harmonics in a wide pseudorapidity range is particularly valuable to understand the temperature dependence of the shear viscosity to entropy density ratio of the QGP. This paper presents the first LHCb results of the second- and the third-order flow harmonic coefficients of charged hadrons as a function of transverse momentum in the forward region, corresponding to pseudorapidities between 2.0 and 4.9, using the data collected from PbPb collisions in 2018 at a center-of-mass energy of $5.02$ TeV. The coefficients measured using the two-particle angular correlation analysis method are smaller than the central-pseudorapidity measurements at ALICE and ATLAS from the same collision system but share similar features."], "authors": "LHCb collaboration"},
{"Title": "Virtual Photons Shed Light on the Early Temperature of Dense QCD Matter", "abs": ["Dileptons produced during heavy-ion collisions represent a unique probe of the QCD phase diagram, and convey information about the state of the strongly interacting system at the moment their preceding off-shell photon is created. In this study, we compute thermal dilepton yields from Au+Au collisions performed at different beam energies, employing a (3+1)-dimensional dynamic framework combined with emission rates accurate at next-to-leading order in perturbation theory and which include baryon chemical potential dependencies. By comparing the effective temperature extracted from the thermal dilepton invariant mass spectrum with the average temperature of the fluid, we offer a robust quantitative validation of dileptons as effective probe of the early quark-gluon plasma stage."], "authors": "Jessica Churchill"},
{"Title": "Neutron Skins: Weak Elastic Scattering and Neutron Stars", "abs": ["The recently completed PREX-2 campaign - which measured the weak form factor of lead at an optimal momentum transfer - has confirmed that the neutron skin of lead is relatively large and has provided a precise determination of the interior baryon density of a heavy nucleus. In turn, the measured form factor can be related to various nuclear and neutron-star properties. Astrophysical observations by the NICER mission have benefited from improvements in flux, energy resolution, and notably, timing resolution. NICER has the capability to measure pulse profile data, which enables simultaneous mass-radius determinations. During the next decade, measurements in astrophysics, gravitational wave astronomy, and nuclear physics are expected to provide a wealth of more precise data. In this review we provide an overview of the current state of neutron skin measurements and offer insights into the prospects for the future."], "authors": "Juliette M. Mammei"},
{"Title": "Dilepton production at NLO and intermediate invariant-mass observables", "abs": ["The thermal QCD dilepton production rate is calculated at next-to-leading order in the strong coupling and at finite baryon chemical potential. The two-loop virtual photon self-energy is evaluated using finite temperature field theory and combined consistently with the self-energy in the Landau-Pomeranchuk-Migdal regime. We present new results for a dense baryonic plasma. The rates are then integrated using (3+1)-dimensional fluid-dynamical simulations calibrated to reproduce hadronic experimental results obtained at RHIC at energies ranging from those of the Beam Energy Scan to $\\sqrt{s_{_{\\rm NN}}} = 200$ GeV. We elaborate on the ability for dileptons to relay information about the plasma baryonic content and temperature."], "authors": "Jessica Churchill"},
{"Title": "CATLIFE (Complementary Arm for Target LIke FragmEnts): Spectrometer for Target like fragments at VAMOS++", "abs": ["The multi-nucleon transfer reaction between 136Xe beam and 198Pt target at the beam energy 7 MeV/u was studied using the large acceptance spectrometer VAMOS++ coupled with the newly installed second arm time-of-flight and delayed $\\gamma$-ray spectrometer CATLIFE (Complementary Arm for Target LIke FragmEnts). The CATLIFE detector is composed of a large area multi-wire proportional chamber and the EXOGAM HPGe clover detectors with an ion flight length of 1230 mm. Direct measurement of the target-like fragments (TLF) and the delayed $\\gamma$-rays from the isomeric state helps to improve TLF identification. The use of the velocity of TLFs and the delayed $\\gamma$-ray demonstrate the proof of principle and effectiveness of the new setup."], "authors": "Y. Son"},
{"Title": "Digital Transformation of High Voltage Isolation Control and Monitoring System for HVE-400 Ion Implanter", "abs": ["HVE-400 ion implanter is special ion implantation equipment for semiconductor materials boron and phosphorus doping. The ion source and extraction deflection system are at high voltage platform, while the corresponding control system is at ground voltage position. The control signals and measurement signals of various parameters at the high-voltage end need to be transmitted between ground voltage and high voltage through optical fibers to isolate high voltage. Upgrading is carried out due to the aging of the optical fiber transmission control and monitoring system, which cannot work stably. The transformation replaces the original distributed single-point control method with an advanced distributed centralized control method, and integrates all control and monitoring functions into an industrial control computer for digital operation and display. In the computer software, two kinds of automatic calculation of ion mass number are designed. After upgrading, the implanter high-voltage platform control and monitoring system features digitalization, centralized control, high reliability, strong anti-interference, fast communication speed, and easy operation."], "authors": "Chengbo Li"},
{"Title": "A multi-reflection time-of-flight mass spectrometer for the offline ion source of the PUMA experiment", "abs": ["The antiProton Unstable Matter Annihilation experiment (PUMA) at CERN aims at investigating the nucleon composition in the matter density tail of radioactive as well as stable isotopes by use of low-energy antiproton-nucleon annihilation processes. For this purpose, antiprotons provided by the Extra Low ENergy Antiproton (ELENA) facility will be trapped together with the ions of interest. While exotic ions will be obtained by the Isotope mass Separator On-Line DEvice (ISOLDE), stable ions will be delivered from an offline ion source setup designed for this purpose. This allows the proposed technique to be applied to a variety of stable nuclei and for reference measurements. For beam purification, the ion source setup includes a multi-reflection time-of-flight mass spectrometer (MR-ToF MS). Supported by SIMION simulations, an earlier MR-ToF MS design has been modified to meet the requirements of PUMA. During commissioning of the new MR-ToF device with Ar$^+$ ions, mass resolving powers in excess of 50,000 have been obtained after 150 revolutions, limited by the chopping of the continuous beam from an electron impact ionisation source."], "authors": "M. Schlaich"},
{"Title": "Collinear laser spectroscopy of highly charged ions produced with an electron beam ion source", "abs": ["Collinear laser spectroscopy has been performed on He-like C$^{4+}$ ions extracted from an electron beam ion source (EBIS). In order to determine the transition frequency with the highest-possible accuracy, the lineshape of the fluorescence response function was studied for pulsed and continuous ion extraction modes of the EBIS in order to optimize its symmetry and linewidth. We found that the best signal-to-noise ratio is obtained using the continuous beam mode for ion extraction. Applying frequency-comb-referenced collinear and anticollinear laser spectroscopy, we achieved a measurement accuracy of better than 2\\,MHz including statistical and systematic uncertainties. The origin and size of systematic uncertainties, as well as further applications for other isotopes and elements are discussed."], "authors": "Phillip Imgram"},
{"Title": "SIDDHARTA-2 apparatus for kaonic atoms research on the DA$Φ$NE collider", "abs": ["SIDDHARTA-2 represents a state-of-the-art experiment designed to perform dedicated measurements of kaonic atoms, which are particular exotic atom configurations composed of a negatively charged kaon and a nucleus. Investigating these atoms provides an exceptional tool to comprehend the strong interactions in the non-perturbative regime involving strangeness. The experiment is installed at the DA$\\Phi$NE electron-positron collider, of the INFN National Laboratory of Frascati (INFN-LNF) in Italy, aiming to perform the first-ever measurement of the 2p$\\rightarrow$1s X-ray transitions in kaonic deuterium, a crucial step towards determining the isospin-dependent antikaon-nucleon scattering lengths. Based on the experience gained with the previous SIDDHARTA experiment, which performed the most precise measurement of the kaonic hydrogen 2p$\\rightarrow$1s X-ray transitions, the present apparatus has been upgraded with innovative Silicon Drift Detectors (SDDs), distributed around a cryogenic gaseous target placed in a vacuum chamber at a short distance above the interaction region of the collider. We present a comprehensive description of the SIDDHARTA-2 setup including the optimization of its various components during the commissioning phase of the collider."], "authors": "F. Sirghi"},
{"Title": "Collinear Laser Spectroscopy of $2\\,{}^3\\!S_1 \\rightarrow 2\\,{}^3\\!P_{\\!J}$ transitions in helium-like $^{12}\\mathrm{C}^{4+}$", "abs": ["Transition frequencies and fine-structure splittings of the $2\\,{}^3\\!S_1 \\rightarrow 2\\,{}^3\\!P_{\\!J}$ transitions in helium-like $^{12}\\mathrm{C}^{4+}$ were measured by collinear laser spectroscopy on a 1-ppb level. Accuracy is increased by more than three orders of magnitude with respect to previous measurements, enabling tests of recent non-relativistic QED calculations including terms up to $m\\alpha^7$. Deviations between the theoretical and experimental values are within theoretical uncertainties and are ascribed to $m\\alpha^8$ and higher-order contributions in the series expansion of the NR-QED calculations. Finally, prospects for an all-optical charge radius determination of light isotopes are evaluated."], "authors": "Phillip Imgram"},
{"Title": "ANCs of the bound states of $^{16}$O deduced from elastic $α$-$^{12}$C scattering data", "abs": ["Asymptotic normalization coefficients (ANCs) of the $0_1^+$, $0_2^+$, $1_1^-$, $2_1^+$, $3_1^-$ ($l_{i th}^\\pi$) bound states of $^{16}$O are deduced from the phase shift data of elastic $\\alpha$-$^{12}$C scattering at low energies. $S$ matrices of elastic $\\alpha$-$^{12}$C scattering are constructed within cluster effective field theory (EFT), in which both bound and resonant states of $^{16}$O are considered. Parameters in the $S$ matrices are fitted to the precise phase shift data below the $p$-$^{15}$N breakup energy for the partial waves of $l=0,1,2,3,4,5,6$, and the ANCs are calculated by using the wave function normalization factors of $^{16}$O propagators for $l=0,1,2,3$. We review the values of ANCs, which are compared with other results in the literature, and discuss uncertainties of the ANCs obtained from the elastic $\\alpha$-$^{12}$C scattering data in cluster EFT."], "authors": "Shung-Ichi Ando"},
{"Title": "Common femtoscopic hadron-emission source in pp collisions at the LHC", "abs": ["The femtoscopic study of pairs of identical pions is particularly suited to investigate the effective source function of particle emission, due to the resulting Bose-Einstein correlation signal. In small collision systems at the LHC, pp in particular, the majority of the pions are produced in resonance decays, which significantly affect the profile and size of the source. In this work, we explicitly model this effect in order to extract the primordial source in pp collisions at $\\sqrt{s} = 13$ TeV from charged $\\pi$-$\\pi$ correlations measured by ALICE. We demonstrate that the assumption of a Gaussian primordial source is compatible with the data and that the effective source, resulting from modifications due to resonances, is approximately exponential, as found in previous measurements at the LHC. The universality of hadron emission in pp collisions is further investigated by applying the same methodology to characterize the primordial source of K-p pairs. The size of the primordial source is evaluated as a function of the transverse mass ($m_{\\rm T}$) of the pairs, leading to the observation of a common scaling for both $\\pi$-$\\pi$ and K-p, suggesting a collective effect. Further, the present results are compatible with the $m_{\\rm T}$ scaling of the p-p and p$-\\Lambda$ primordial source measured by ALICE in high multiplicity pp collisions, providing compelling evidence for the presence of a common emission source for all hadrons in small collision systems at the LHC. This will allow the determination of the source function for any hadron--hadron pairs with high precision, granting access to the properties of the possible final-state interaction among pairs of less abundantly produced hadrons, such as strange or charmed particles."], "authors": "ALICE Collaboration"},
{"Title": "Improved determination of the oscillator parameters in nuclei", "abs": ["The oscillator parameter in nuclei is refitted to reproduce the available charge radius data. As an important improvement, we include the Coulomb term evaluated within the assumption of a uniformly charged sphere, and take into account the symmetry effect induced by the difference between N and Z numbers in a straightforward manner using the conventional parameterization. The Coulomb interaction has repulsive effect, causing the wave functions to extend further toward the nucleus exterior, resulting in an effectively larger oscillator length parameter. The symmetry effect is attractive for protons in neutron-rich nuclei and for neutrons in proton-rich nuclei, and repulsive for the other cases. Therefore, three distinct oscillator parameters are determined: one for protons, one for neutrons, and one isospin-invariant version, which is obtained by subtracting the Coulomb and symmetry contributions. Additionally, we explore the direct fit of the harmonic oscillator wave functions to the eigenfunctions of the Hartree-Fock mean field using the Skyrme interaction. Generally, this method agrees well with the others for light nuclei, typically up to $^{40}$Ca. Beyond this nucleus, however, the results begin to diverge over the orbits chosen for the fit. Only the parameters values obtained for the last occupied states agree remarkably well with the conventional ones throughout the mass range under consideration."], "authors": "Latsamy Xayavong"},
{"Title": "Pion and kaon electromagnetic and gravitational form factors", "abs": ["A unified set of predictions for pion and kaon elastic electromagnetic and gravitational form factors is obtained using a symmetry-preserving truncation of each relevant quantum field equation. A key part of the study is a description of salient aspects of the dressed graviton + quark vertices. The calculations reveal that each meson's mass radius is smaller than its charge radius, matching available empirical inferences; and meson core pressures are commensurate with those in neutron stars. The analysis described herein paves the way for a direct calculation of nucleon gravitational form factors."], "authors": "Yin-Zhen Xu"},
{"Title": "Enhanced Dilepton production near the color superconducting phase and the QCD critical point", "abs": ["The dilepton production yields in relativistic heavy ion collisions are investigated along isentropic trajectories in the quark (Wigner) phase within the two-flavor Nambu-Jona-Lasinio model. An enhancement of the ultra-low energy dilepton yield in the vicinity of the color superconducting (CSC) phase and the QCD critical point (QCD-CP) is found, compared to the free quark gas. Furthermore, we have found a nontrivial structure in the beam energy dependence of the ultra-low energy dilepton yield. A local maximum and minimum of the dilepton yield as a function of entropy per baryon emerge when the trajectories are close to both locations of the CSC phase transition line and the QCD-CP. Only the maximum appears in the scenario without the CSC phase but with the QCD-CP. On the other hand, when only the CSC phase is considered, the dilepton yield monotonically increases as the beam energy decreases. These distinctive patterns could potentially serve as signals of the CSC phase and QCD-CP. In addition, it is found that the dilepton production yield and the location of the minimum strongly depend on the value of diquark coupling, suggesting the possibility that the value of the diquark coupling may be extracted from experimental data."], "authors": "Toru Nishimura"},
{"Title": "Impact of two-body currents on magnetic dipole moments of nuclei", "abs": ["We investigate the effects of two-body currents on magnetic dipole moments of medium-mass and heavy nuclei using the valence-space in-medium similarity renormalization group with chiral effective field theory interactions and currents. Focusing on near doubly magic nuclei from oxygen to bismuth, we have found that the leading two-body currents globally improve the agreement with experimental magnetic moments. Moreover, our results show the importance of multi-shell effects for $^{41}$Ca, which suggest that the $Z=N=20$ gap in $^{40}$Ca is not as robust as in $^{48}$Ca. The increasing contribution of two-body currents in heavier systems is explained by the operator structure of the center-of-mass dependent Sachs term."], "authors": "T. Miyagi"},
{"Title": "Spin dynamics in intermediate-energy heavy-ion collisions with rigorous angular momentum conservation", "abs": ["We have revisited the spin dynamics in intermediate-energy heavy-ion collisions based on the improved spin- and isospin-dependent Boltzmann-Uehling-Uhlenbeck transport model, particularly with the constraint of rigorous angular momentum conservation incorporated. We have studied the spin polarization of free nucleons and tritons/$^3$He as well as the spin alignment of deuterons, and predicted the flow splittings for their different spin states. We have also demonstrated that the spin-dependent potential may enhance dissipations and thus have a non-negligible effect on the spin-averaged transverse flow at low collision energies. When rigorous angular momentum conservation in each spin-dependent nucleon-nucleon collision is incorporated, it affects the overall dynamics, the flow, and also the spin polarization, while the effects of the spin-orbit potential on the spin-related observables are still appreciable. The well-developed SIBUU model could be further extended to include hyperons or vector mesons, or used as a hadronic afterburner for spin-related studies in relativistic heavy-ion collisions, with more inelastic channels incorporated in the future."], "authors": "Rong-Jun Liu"},
{"Title": "Strong Gravity Extruding Peaks in Speed of Sound Profiles of Massive Neutron Stars", "abs": ["The speed of sound squared (SSS) $s^2$ in massive neutron stars (NSs) characterizes not only the stiffness of supradense neutron-rich matter within but also equivalently properties of the curved geometry due to the strong-field gravity and matter-geometry coupling. A peaked density or radius profile of $s^2$ has been predicted for massive NSs using various NS Equation of State (EOS) models. However, the nature, cause, location and size of the peak in $s^2$ profiles are still very EOS model dependent. In this work, we investigate systematically $s^2$ profiles in massive NSs in a new approach that is independent of the nuclear EOS model and without any presumption about the NS structure or composition. In terms of the small quantities (reduced radius, the energy density and pressure scaled by their central values), we perform double-element perturbative expansions in solving perturbatively the scaled Tolman--Oppenheimer--Volkoff (TOV) equations and analyzing $s^2$ profiles from the Newtonian limit to the general relativistic (GR) case. The GR term in the TOV equations plays a twofold role: it compresses NS matter and modifies the pressure/energy density ratio from small values in Newtonian stars showing no $s^2$ peak to large ones for massive NSs possessing a peak in their $s^2$ profiles, and eventually takes away the peak in extremely compact/massive NSs approaching the causality limit. These features revealed from our analyses are universal as they are intrinsic properties of the GR stellar structure equations independent of the still very uncertain EOS of supradense neutron-rich matter in NSs."], "authors": "Bao-Jun Cai"},
{"Title": "Multiplicity dependence of charged-particle intra-jet properties in pp collisions at $\\sqrt{s}$ = 13 TeV", "abs": ["The first measurement of the multiplicity dependence of intra-jet properties of leading charged-particle jets in proton-proton (pp) collisions is reported. The mean charged-particle multiplicity and jet fragmentation distributions are measured in minimum-bias and high-multiplicity pp collisions at $\\sqrt{s}$ = 13 TeV using the ALICE detector. Jets are reconstructed from charged particles produced in the midrapidity region ($|\\eta| < 0.9$) using the sequential recombination anti-$k_{\\rm T}$ algorithm with jet resolution parameters $R$ = 0.2, 0.3, and 0.4 for the transverse momentum ($p_{\\rm T}$) interval 5$-$110 GeV/$c$. High-multiplicity events are selected by the forward V0 scintillator detectors. The mean charged-particle multiplicity inside the leading jet cone rises monotonically with increasing jet $p_{\\rm T}$ in qualitative agreement with previous measurements at lower energies. The distributions of jet fragmentation functions $z^{\\rm ch}$ and $\\xi^{\\rm ch}$ are measured for different jet-$p_{\\rm T}$ intervals. Jet-$p_{\\rm T}$ independent fragmentation of leading jets is observed for wider jets except at high- and low-$z^{\\rm ch}$. The observed \"hump-backed plateau\" structure in the $\\xi^{\\rm ch}$ distribution indicates suppression of low-$p_{\\rm T}$ particles. In high-multiplicity events, an enhancement of the fragmentation probability of low-$z^{\\rm ch}$ particles accompanied by a suppression of high-$z^{\\rm ch}$ particles is observed compared to minimum-bias events. This behavior becomes more prominent for low-$p_{\\rm T}$ jets with larger jet radius. The results are compared with predictions of QCD-inspired event generators, PYTHIA 8 with Monash 2013 tune and EPOS LHC. It is found that PYTHIA 8 qualitatively reproduces the jet modification in high-multiplicity events except at high jet $p_{\\rm T}$. These measurements provide important constraints to models of jet fragmentation."], "authors": "ALICE Collaboration"},
{"Title": "A Comprehensive Characterization of the Neutron Fields Produced by the Apollon Petawatt Laser", "abs": ["Since two decades, laser-driven neutron emissions are studied as they represent a complementary source to conventional neutron sources, with further more different characteristics (i.e. shorter bunch duration and higher number of neutrons per bunch). We report here a global, thorough characterization of the neutron fields produced at the Apollon laser facility using the secondary laser beam (F2). A Double Plasma Mirror (DPM) was used to improve the temporal contrast of the laser which delivers pulses of 24 fs duration, a mean on-target energy of ~10 J and up to 1 shot/min. The interaction of the laser with thin targets (few tens or hundreds of nm) in ultra-high conditions produced enhanced proton beams (up to 35 MeV), which were then used to generate neutrons via the pitcher-catcher technique. The characterization of these neutron emissions is presented, with results obtained from both simulations and measurements using several diagnostics (activation samples, bubble detectors and Time-of-Flight detectors), leading to a neutron yield of ~4.10^7 neutrons/shot. Similar neutron emissions were observed during shots with and without DPM, while fewer X-rays are produced when the DPM is used, making this tool interesting to adjust the neutrons/X-rays ratio for some applications like combined neutron/X-ray radiography."], "authors": "Ronan Lelièvre"},
{"Title": "The Data Acquisition System for Phase-III of the BeEST Experiment", "abs": ["The BeEST experiment is a precision laboratory search for physics beyond the standard model that measures the electron capture decay of $^7$Be implanted into superconducting tunnel junction (STJ) detectors. For Phase-III of the experiment, we constructed a continuously sampling data acquisition system to extract pulse shape and timing information from 16 STJ pixels offline. Four additional pixels are read out with a fast list-mode digitizer, and one with a nuclear MCA already used in the earlier limit-setting phases of the experiment. We present the performance of the data acquisition system and discuss the relative advantages of the different digitizers."], "authors": "C. Bray"},
{"Title": "Novel Cross Section Ratios as Possible Signals of Saturation in UPCs", "abs": ["We propose new cross section ratios in ultra-peripheral A$+$A and $p+$A collisions (UPCs) as a potential experimental signal of saturation physics. We consider the ratio $R_1$ of elastic vector meson photoproduction cross section to the inclusive hadron or jet photoproduction cross section. The ratio can be measured in the $\\gamma +$A and $\\gamma + p$ collisions taking place in the UPCs. We label the ratios $R_1 ({\\rm A})$ and $R_1 (p)$, respectively. Constructing the double ratio $R_{\\rm{UPC}} ({\\rm A}) = R_1 ({\\rm A})/R_1 (p)$, and performing a small-$x$ calculation both in the quasi-classical approximation and by including small-$x$ evolution, we observe that $R_{\\rm{UPC}} ({\\rm A})$ exhibits a markedly different dependence on the nuclear atomic number inside and outside the saturation region. This result indicates that $R_{\\rm{UPC}} ({\\rm A})$ and $R_1 ({\\rm A})$ measurements in UPCs may help in the experimental searches for the evidence of saturation physics."], "authors": "Yuri V. Kovchegov"},
{"Title": "Rapidity and Energy Dependences of Temperatures and Volume Extracted from Identified Charged Hadron Spectra in Proton-Proton Collisions at a Super Proton Synchrotron (SPS)", "abs": ["The standard (Bose-Einstein/Fermi-Dirac or Maxwell-Boltzmann) distribution from the relativistic ideal gas model is used to study the transverse momentum ($p_{T}$) spectra of identified charged hadrons ($\\pi^-$, $\\pi^+$, $K^-$, $K^+$, $\\bar p$, and $p$) with different rapidities produced in inelastic proton-proton ($pp$) collisions at the Super Proton Synchrotron (SPS). The experimental data measured by the NA61/SHINE Collaboration at the center-of-mass (c.m.) energies $\\sqrt{s}=6.3$, 7.7, 8.8, 12.3, and 17.3 GeV are fitted well by the distribution. It is shown that the effective temperature ($T_{eff}$ or $T$), kinetic freeze-out temperature ($T_{0}$), and initial temperature ($T_{i}$) decrease with the increase in rapidity and increase with the increase in c.m. energy. The kinetic freeze-out volume ($V$) extracted from the $\\pi^-$, $\\pi^+$, $K^-$, $K^+$, and $\\bar p$ spectra decreases with the rapidity and increase with the c.m. energy. The opposite tendency of $V$, extracted from the $p$ spectra, is observed to be increasing with the rapidity and decreasing with the c.m. energy due to the effect of leading protons."], "authors": "Pei-Pin Yang"},
{"Title": "Rapidity scan approach for net-baryon cumulants with a statistical thermal model", "abs": ["Utilizing rapidity-dependent measurements to map the QCD phase diagram provides a complementary approach to traditional beam energy-dependent measurements around midrapidity. The changing nature of thermodynamic properties of QCD matter along the beam axis in heavy-ion collisions at low collision energies both motivate and pose challenges for this method. In this study, we derive the analytical cumulant-generating function for subsystems within distinct rapidity windows, while accounting for global net-baryon charge conservation of the full system. Rapidity-dependent net-baryon cumulants are then calculated for a system exhibiting inhomogeneity along the beam axis, and their sensitivity to finite acceptances through changing rapidity bin widths is explored. We highlight the non-trivial behaviors exhibited by these cumulants, underscoring their importance in establishing a non-critical baseline for interpreting net-proton cumulants in the search for the QCD critical point. Finally, we discuss the implications of the rapidity scan for mapping the QCD phase diagram within the current context."], "authors": "Jianing Li"},
{"Title": "The magnetic dipole transition in $^{48}$Ca", "abs": ["The magnetic dipole transition strength $B(M1)$ of $^{48}$Ca is dominated by a single resonant state at an excitation energy of 10.23 MeV. Experiments disagree about $B(M1)$ and this impacts our understanding of spin flips in nuclei. We performed ab initio computations based on chiral effective field theory and found that $B(M1:0^+\\rightarrow1^+)$ lies in the range from $7.0$ to $10.2~\\mu_N^2$. This is consistent with a $(\\gamma,n)$ experiment but larger than results from $(e,e^\\prime)$ and $(p,p')$ scattering. Two-body currents yield no quenching of the $B(M1)$ strength and continuum effects reduce it by about 10%. For a validation of our approach, we computed magnetic moments in $^{47,49}$Ca and performed benchmark calculations in light nuclei."], "authors": "B. Acharya"},
{"Title": "Bottomonium-like tetraquarks in a chiral quark model", "abs": ["The low-lying bottomonium-like tetraquarks $b\\bar{b}q\\bar{q}$ $(q=u,\\,d,\\,s)$ with spin-parity $J^P=0^+$, $1^+$ and $2^+$, and isospin $I=0,\\,1$ or $\\frac{1}{2}$, are systematically investigated within the theoretical framework of real- and complex-scaling range of a chiral quark model, which has already been successfully applied in analysis of several multiquark systems. A complete four-body $S$-wave function, which includes meson-meson, diquark-antidiquark and K-type arrangements of quarks, along with all possible color configurations are considered. In the $b\\bar{b}q\\bar{q}$ $(q=u,\\,d)$ tetraquark system, we found resonance states of $B^{(*)} \\bar{B}^{(*)}$, $\\Upsilon\\omega$, $\\Upsilon\\rho$ and $\\eta_b \\rho$ nature with all possible $I(J^P)$ quantum numbers. Their masses are generally located in the energy range $11.0-11.3$ GeV and their widths are less than $10$ MeV. In addition, extremely narrow resonances, with two-meson strong decay widths less than $1.5$ MeV, are obtained in both $b\\bar{b}u\\bar{s}$ and $b\\bar{b}s\\bar{s}$ tetraquark systems. Particularly, four radial excitations of $\\Upsilon K^*$ and $\\eta_b K^*$ are found at $\\sim11.1$ GeV in $J^P=0^+$, $1^+$ and $2^+$ channels of $b\\bar{b}u\\bar{s}$ system. One $\\Upsilon(1S)\\phi(2S)$ resonance state is obtained at $11.28$ GeV in the $J^P=1^+$ sector."], "authors": "Gang Yang"},
{"Title": "The $\\mathbf{sQ\\bar{q}\\bar{q}}$ $\\mathbf{(q=u,\\,d;\\, Q=c,\\,b)}$ tetraquarks in the chiral quark model", "abs": ["The low-lying $sQ\\bar{q}\\bar{q}$ $(q=u,\\,d,\\, Q=c,\\,b)$ tetraquark states with $J^P=0^+$, $1^+$ and $2^+$, and in the isoscalar and isovector sectors, are systematically investigated in the framework of real- and complex-scaling range of a chiral quark model, whose parameters have been fixed in advance describing hadron, hadron-hadron and multiquark phenomenology, and thus all results presented here are pure predictions. Each tetraquark configuration, compatible with the quantum numbers studied, is taken into account; this includes meson-meson, diquark-antidiquark and K-type arrangements of quarks with all possible color wave functions in four-body sector. Among the different numerical techniques to solve the Schrödinger-like 4-body bound state equation, we use a variational method in which the trial wave function is expanded in complex-range Gaussian basis functions, because its simplicity and flexibility. Several compact bound states and narrow resonances are found in both charm-strange $cs\\bar{q}\\bar{q}$ and bottom-strange $bs\\bar{q}\\bar{q}$ tetraquark sectors, most of them as a product of the strong coupling between the different channels. The so-called $X_{0,1}(2900)$ signals, recently found by the LHCb collaboration, are unstable in our formalism with several candidates in the single-channel computations."], "authors": "Gang Yang"},
{"Title": "Charmoniumlike tetraquarks in a chiral quark model", "abs": ["The lowest-lying charmonium-like tetraquarks $c\\bar{c}q\\bar{q}$ $(q=u,\\,d)$ and $c\\bar{c}s\\bar{s}$, with spin-parity $J^P=0^+$, $1^+$ and $2^+$, and isospin $I=0$ and $1$, are systematically investigated within the theoretical framework of complex-scaling range for a chiral quark model that has already been successfully applied in former studies of various tetra- and penta-quark systems. A four-body $S$-wave configuration which includes meson-meson, diquark-antidiquark and K-type arrangements of quarks, along with all possible color wave functions, is comprehensively considered. Several narrow resonances are obtained in each tetraquark channel when a fully coupled-channel computation is performed. We tentatively assign theoretical states to experimentally reported charmonium-like signals such as $X(3872)$, $Z_c(3900)$, $X(3960)$, $X(4350)$, $X(4685)$ and $X(4700)$. They can be well identified as hadronic molecules; however, other exotic components which involve, for instance, hidden-color channels or diquark-antidiquark structures play a considerable role. Meanwhile, two resonances are obtained at $4.04$ GeV and $4.14$ GeV which may be compatible with experimental data in the energy interval $4.0-4.2$ GeV. Furthermore, the $X(3940)$ and $X(4630)$ may be identified as color compact tetraquark resonances. Finally, we also find few resonance states in the energy interval from $4.5$ GeV to $5.0$ GeV, which would be awaiting for discovery in future experiments."], "authors": "Gang Yang"},
{"Title": "The $\\mathbf{\\bar{q}q\\bar{s}Q}$ $\\mathbf{(q=u,\\,d;\\,Q=c,\\,b)}$ tetraquark system in a chiral quark model", "abs": ["Inspired by the experimentally reported $T_{c\\bar{s}}(2900)$ exotic states, the $S$-wave $\\bar{q}q\\bar{s}Q$ $(q=u,\\,d;\\,Q=c,\\,b)$ tetraquarks, with spin-parity $J^P=0^+$, $1^+$ and $2^+$, in both isoscalar and isovector sectors are systematically studied in a chiral quark model. The meson-meson, diquark-antidiquark and K-type arrangements of quarks, along with all possible color wave functions, are comprehensively considered. The four-body system is solved by means of a highly efficient computational approach, the Gaussian expansion method, along with a complex-scaling formulation of the problem to disentangle bound, resonance and scattering states. This theoretical framework has already been successfully applied in various tetra- and penta-quark systems. In the complete coupled-channel case, and within the complex-range formulation, several narrow resonances of $\\bar{q}q\\bar{s}c$ and $\\bar{q}q\\bar{s}b$ systems are obtained in each allowed $I(J^P)$-channels. Particularly, the $T_{c\\bar{s}}(2900)$ is well identified as a $I(J^P)=1(0^+)$ $\\bar{q}q\\bar{s}c$ tetraquark state with a dominant molecular structure. Meanwhile, more resonances in $\\bar{q}q\\bar{s}c$ and $\\bar{q}q\\bar{s}b$ systems are also obtained within the energy regions $2.4-3.4$ GeV and $5.7-6.7$ GeV, respectively. The predicted exotic states, which are an indication of a richer color structure when going towards multiquark systems beyond mesons and baryons, are expected to be confirmed in future high-energy particle and nuclear experiments."], "authors": "Gang Yang"},
{"Title": "FENDL: A library for fusion research and applications", "abs": ["The Fusion Evaluated Nuclear Data Library (FENDL) is a comprehensive and validated collection of nuclear cross section data coordinated by the International Atomic Energy Agency (IAEA) Nuclear Data Section (NDS). FENDL assembles the best nuclear data for fusion applications selected from available nuclear data libraries and has been under development for decades. FENDL contains sub-libraries for incident neutron, proton, and deuteron cross sections including general purpose and activation files used for particle transport and nuclide inventory calculations.", "We describe the history, selection of evaluations for the various sub-libraries (neutron, proton, deuteron) with the focus on transport and reactor dosimetry applications, the processing of the nuclear data for application codes, and the development of the TENDL-2017 library which is the currently recommended activation library for FENDL. We briefly describe the IAEA IRDFF library as the recommended library for dosimetry fusion applications. We also present work on validation of the neutron sub-library using a variety of fusion relevant computational and experimental benchmarks. A variety of cross section libraries are used for the validation work including FENDL-2.1, FENDL-3.1d, FENDL-3.2, ENDF/B-VIII.0, and JEFF-3.2 with the emphasis on the FENDL libraries. The results of the experimental validation showed that the performance of FENDL-3.2b is at least as good and in most cases better than FENDL-2.1.", "Future work will consider improved evaluations developed by the International Nuclear Data Evaluation Network (INDEN). Additional work will be needed to investigate differences in gas production in structural materials. Covariance matrices need to be updated to support the development of fusion technology. Additional validation work for high-energy neutrons, protons and deuterons, and the activation library will be needed."], "authors": "G. Schnabel"},
{"Title": "Pion distribution functions from low-order Mellin moments", "abs": ["Exploiting an evolution scheme for parton distribution functions (DFs) that is all-orders exact, contemporary lattice-QCD (lQCD) results for low-order Mellin moments of the pion valence quark DF are shown to be mutually consistent. The analysis introduces a means by which key odd moments can be obtained from the even moments in circumstances where only the latter are available. Combining these elements, one arrives at parameter-free lQCD-based predictions for the pointwise behaviour of pion valence, glue, and sea DFs, with sound uncertainty estimates. The behaviour of the pion DFs at large light-front momentum fraction, $x> 0.85$, is found to be consistent with QCD expectations and continuum analyses of pion structure functions, i.e., damping like $(1 -x)^{\\beta_{\\rm parton}}$, with $\\beta_{\\rm valence} \\approx 2.4$, $\\beta_{\\rm glue} \\approx 3.6$, $\\beta_{\\rm sea} \\approx 4.6$. It may be possible to test these predictions using data from forthcoming experiments."], "authors": "Ya Lu"},
{"Title": "Secondary beams at high-intensity electron accelerator facilities", "abs": ["The interaction of a high-current $O$(100~\\textmu A), medium energy $O$(10\\,GeV) electron beam with a thick target $O$(1m) produces an overwhelming shower of standard matter particles in addition to hypothetical Light Dark Matter particles. While most of the radiation (gamma, electron/positron, and neutron) is contained in the thick target, deep penetrating particles (muons, neutrinos, and light dark matter particles) propagate over a long distance, producing high-intense secondary beams. Using sophisticated Monte Carlo simulations based on FLUKA and GEANT4, we explored the characteristics of secondary muons and neutrinos and (hypothetical) dark scalar particles produced by the interaction of Jefferson Lab 11 GeV intense electron beam with the experimental Hall-A beam dump. Considering the possible beam energy upgrade, this study was repeated for a 20 GeV CEBAF beam."], "authors": "Marco Battaglieri"},
{"Title": "Observation of strangeness enhancement with charmed mesons in high-multiplicity $p\\mathrm{Pb}$ collisions at $\\sqrt {s_{\\mathrm{NN}}}=8.16\\,$TeV", "abs": ["The production of prompt $D^+_{s}$ and $D^+$ mesons is measured by the LHCb experiment in proton-lead ($p\\mathrm{Pb}$) collisions in both the forward ($1.5<y^*<4.0$) and backward ($-5.0<y^*<-2.5$) rapidity regions at a nucleon-nucleon center-of-mass energy of $\\sqrt {s_{\\mathrm{NN}}}=8.16\\,$TeV. The nuclear modification factors of both $D^+_{s}$ and $D^+$ mesons are determined as a function of transverse momentum, $p_{\\mathrm{T}}$, and rapidity. In addition, the $D^+_{s}$ to $D^+$ cross-section ratio is measured as a function of the charged particle multiplicity in the event. An enhanced $D^+_{s}$ to $D^+$ production in high-multiplicity events is observed for the whole measured $p_{\\mathrm{T}}$ range, in particular at low $p_{\\mathrm{T}}$ and backward rapidity, where the significance exceeds six standard deviations. This constitutes the first observation of strangeness enhancement in charm quark hadronization in high-multiplicity $p\\mathrm{Pb}$ collisions. The results are also qualitatively consistent with the presence of quark coalescence as an additional charm quark hadronization mechanism in high-multiplicity proton-lead collisions."], "authors": "LHCb collaboration"},
{"Title": "A new cleaner and higher rate techniques for anti-neutrino detection using Tungsten 183 Isotope", "abs": ["Low energy anti-neutrinos detected from reactors or other sources have typically used the conversion of an anti-neutrino on hydrogen, producing a positron and a free neutron. This neutron is subsequently captured on a secondary element with a large neutron capture cross section such as Gadolinium or Cadmium. We have studied the anti-neutrino conversion and suggest other elements that have a comparable cross section for anti-neutrino reactions. With most neutron captures on Gadolinium, it is possible to get two or three delayed gamma signals of known energy to occur. With today's fast electronics, this leads to the possibility of having a triple delayed coincidence using the positron annihilation on atomic shell electrons as the starting signal. We have also found an isotope of Tungsten, $^{183}$W that offers a large anti-neutrino interaction cross section of $1.19 \\times 10^{-46}$ m$^2$ and an anti-neutrino threshold energy of 2.094 MeV. This reaction makes a nuclear m1 excited state of $^{183}$Ta$^*$ that emits a signature secondary gamma pulse of 73 keV with a 107 ns half-life. This offers a new delayed coincidence technique that can be used to cleanly identify anti-neutrinos with less shielding with the added advantage of the anti-neutrino threshold shifting down to low energies."], "authors": "Jarred Novak"},
{"Title": "Light Nuclei Production in Au+Au Collisions at $\\sqrt{s_{NN}}=$ 3 GeV within Thermodynamical Approach: Bulk Properties and Collective Flow", "abs": ["We present results of simulations of light-nuclei production in Au+Au collisions at collision energy of $\\sqrt{s_{NN}}=$ 3 GeV within updated Three-fluid Hydrodynamics-based Event Simulator Extended by UrQMD (Ultra-relativistic Quantum Molecular Dynamics) final State interactions (THESEUS). The results are compared with recent STAR data. The light-nuclei production is treated within the thermodynamical approach on equal basis with hadrons. The only additional parameter related to the light nuclei is the energy density of late freeze-out that imitates afterburner stage of the collision because the light nuclei do not participate in the UrQMD evolution. It is found that the late freeze-out is preferable for deuterons, tritons, and $^3$He. Remarkably, the $^4$He observables are better reproduced with the standard freeze-out. This suggests that the $^4$He nuclei better survive in the afterburner stage because they are more spatially compact and tightly bound objects. This is an argument in favor of dynamical treatment of light nuclei. The simulations indicate that the collision dynamics is determined by the hadronic phase. The calculated results reveal not perfect but a good reproduction of the data on bulk observables and directed flow. The elliptic flow turns out to be more intricate."], "authors": "M. Kozhevnikova"},
{"Title": "Isolating perturbative QCD splittings in heavy-ion collisions", "abs": ["We define a new strategy to scan jet substructure in heavy-ion collisions. The scope is multifold: (i) test the dominance of vacuum jet dynamics at early times, (ii) capture the transition from coherent to incoherent jet energy loss, and (iii) study elastic scatterings in the medium, which are either hard and perturbative or soft and responsible for jet thermalisation. To achieve that, we analyse the angular distribution of the hardest splitting, $\\theta_{\\rm hard}$, above a transverse momentum scale, $k_t^{\\rm min}$, in high-$p_t$ jets. Sufficiently high values of $k_t^{\\rm min}$ target the regime in which the observable is uniquely determined by vacuum-like splittings and energy loss, leaving the jet substructure unmodified compared to proton-proton collisions. Decreasing $k_t^{\\rm min}$ enhances the sensitivity to the relation between energy loss and the intra-jet structure and, in particular, to observe signatures of colour decoherence at small angles. At wider angles it also becomes sensitive to hard elastic scatterings with the medium and, therefore, the perturbative regime of medium response. Choosing $k_t^{\\rm min}\\approx 0$ leads to order one effects of non-perturbative origin such as hadronisation and, potentially, soft scatterings responsible for jet thermalisation. We perform a comprehensive analysis of this observable with three state-of-the-art jet-quenching Monte Carlo event generators. Our study paves the way for defining jet observables in heavy-ion collisions dominated by perturbative QCD and thus calculable from first principles."], "authors": "Leticia Cunqueiro"},
{"Title": "Performance of new Kuraray wavelength-shifting fibers with short decay time", "abs": ["We measure the decay time and the attenuation length of newly developed wavelength-shifting fibers, YS series from Kuraray, which have fast response. Using a 405 nm laser, the decay times of the YS-2, 4, and 6 are measured to be $3.70 \\pm 0.04$ ns, $2.06 \\pm 0.03$ ns, and $1.50 \\pm 0.02$ ns, respectively. The decay time of Y-11 is measured to be $7.16 \\pm 0.09$ ns using the same system. All fibers are found to have similar attenuation lengths of more than 4 meters. When combined with the plastic scintillators EJ-200 and EJ-204, the YS series have better time resolution than Y-11, with light yields of 60-100% of Y-11."], "authors": "Shoma Kodama"},
{"Title": "Evolution of giant monopole resonance with triaxial deformation", "abs": ["Background: The isoscalar giant monopole resonance (ISGMR) splits into two peaks in prolately deformed nuclei. When a nucleus is triaxially deformed, a peak appears in the middle between the two peaks.", "Purpose: We investigate the mechanism of the appearance of the middle peak in the ISGMR in triaxial nuclei.", "Method: We perform the constrained Skyrme-Hartree-Fock-Bogoliubov (CHFB) calculation for arbitrary triaxial shapes in $^{100}$Mo. We calculate the strength functions of the isoscalar monopole (ISM) and IS quadrupole modes on the CHFB states. Furthermore, we investigate vibrations of matter distributions in $x$, $y$, and $z$ directions induced by the external ISM field, with the $z$ axis being the longest axis of the triaxial shape.", "Results: The middle peak in the ISM strength evolves from the triaxial degree $\\gamma=0^\\circ$ to $60^\\circ$. This is because the difference between the vibration in $x$ direction and that in $y$ direction is evident with an increase in $\\gamma$ and the quadrupole $K=2$ component of the induced density of the ISM at the middle peak increases as $\\gamma$ increases, where $K$ denotes the $z$ component of the angular momentum. This property is also obtained in the unperturbed ISM strength without the residual fields.", "Conclusions: The mixing between the monopole and quadrupole modes is primarily determined by the ground-state deformation. Therefore, the ISM strength of the middle peak becomes strong as the triaxial degree in the ground state increases."], "authors": "Kouhei Washiyama"},
{"Title": "Anticipations and Discoveries of the Heavy Hydrogen Isotopes, 1913-1939", "abs": ["Just as the chemical elements from hydrogen (Z = 1) to oganesson (Z = 118) once were discovered, so were the numerous isotopes. The histories of how the isotopes were discovered are less well known, but in a few cases they are as interesting and instructive as those of the elements figuring in the periodic table. Following an overview of criteria usually associated with the concept of discovery in general, this paper examines in detail the historical developments that led to the discoveries of deuterium and tritium and also, as a by-product, the helium-3 isotope. It also includes a brief section on the neutron, which in the 1920s, when it was still a hypothetical particle, was sometimes discussed together with the mass-2 and mass-3 hydrogen isotopes. The paper concludes with a discussion of priority questions relating to suggestions of the two heavy isotopes as well as to their actual discoveries."], "authors": "Helge Kragh"},
{"Title": "Exploring Photoproduction with the GlueX Experiment", "abs": ["The GlueX experiment at Jefferson Lab (Newport News, VA USA) is designed to explore the spectrum of mesons up to about 3 GeV. We present results on the production of light-quark resonances with linearly polarized photons. These results enhance our understanding of photoproduction mechanisms, which is valuable in subsequent searches for exotic hybrid mesons. Measurements of the J/psi photoproduction cross section at threshold are also presented."], "authors": "Matthew Shepherd"},
{"Title": "pynucastro 2.1: an update on the development of a python library for nuclear astrophysics", "abs": ["pynucastro is a python library that provides visualization and analyze techniques to classify, construct, and evaluate nuclear reaction rates and networks. It provides tools that allow users to determine the importance of each rate in the network, based on a specified list of thermodynamic properties. Additionally, pynucastro can output a network in C++ or python for use in simulation codes, include the AMReX-Astrophysics simulation suite. We describe the changes in pynucastro since the last major release, including new capabilities that allow users to generate reduced networks and thermodynamic tables for conditions in nuclear statistical equilibrium."], "authors": "Alexander Smith Clark"},
{"Title": "Transverse Energy-Energy Correlators in the Color-Glass Condensate at the Electron-Ion Collider", "abs": ["We investigate the transverse energy-energy correlators (TEEC) in the small-$x$ regime at the upcoming Electron-Ion Collider (EIC). Focusing on the back-to-back production of electron-hadron pairs in both $ep$ and $eA$ collisions, we establish a factorization theorem given in terms of the hard function, quark distributions, soft functions, and TEEC jet functions, where the gluon saturation effect is incorporated. Numerical results for TEEC in both $ep$ and $eA$ collisions are presented, together with the nuclear modification factor $R_A$. Our analysis reveals that TEEC observables in deep inelastic scattering provide a valuable approach for probing gluon saturation phenomena. Our findings underscore the significance of measuring TEEC at the EIC, emphasizing its efficacy in advancing our understanding of gluon saturation and nuclear modifications in high-energy collisions."], "authors": "Zhong-Bo Kang"},
{"Title": "Exotic nonaxial-octupole shapes in $N=184$ isotones from covariant density functional theories", "abs": ["The nonaxial octupole shape in some nuclei with $N = 184$, namely, $^{284}$Fm, $^{286}$No, $^{288}$Rf, and $^{290}$Sg, is investigated using covariant density functional theories. Employing the density-dependent point-coupling covariant density functional theory with the parameter set DD-PC1 in the particle-hole channel, it is found that the ground states of $^{284}$Fm, $^{286}$No, $^{288}$Rf, and $^{290}$Sg have pure nonaxial octupole shapes with deformation parameters $\\beta_{31} \\approx 0.08$ and $\\beta_{33} \\approx -0.01 \\sim -0.03$. The energy gain due to the $\\beta_{31}$ and $\\beta_{33}$ distortion is $\\sim$ 1 MeV. The occurrence of the nonaxial octupole correlations is mainly from the proton orbitals $1i_{13/2}$ and $2f_{7/2}$, which are close to the proton Fermi surface. The dependence of the nonaxial octupole effects on the form of the energy density functional and on the parameter set is also studied."], "authors": "Jie Zhao"},
{"Title": "Going Big for Phase III of the Project 8 Neutrino Mass Experiment", "abs": ["Project 8 is a next generation experiment aiming to directly measure the neutrino mass using the tritium endpoint method with a targeted sensitivity of 40 meV. Having established a new measuring technique, Cyclotron Radiation Emission Spectroscopy (CRES), the next development phase will demonstrate CRES on a large source volume, culminating in a pilot-scale CRES experiment with atomic tritium. A promising option is a mode-filtered, cylindrical, resonant cavity in which cyclotron radiation from magnetically trapped beta electrons only couples to the lowest eigenmode, maximizing effective volume and minimizing signal complexity. Recent progress in the experiment design, including a small scale cavity CRES proof-of-concept apparatus to demonstrate CRES in cavities and its scalability to large volumes are described."], "authors": "Juliana Stachurska"},
{"Title": "Variation of multi-Slater determinants in antisymmetrized molecular dynamics and its application to $^{10}$Be with various clustering", "abs": ["We propose a method to optimize the multi-Slater determinants of the antisymmetrized molecular dynamics (AMD) in the linear combination form and apply it to the neutron-rich $^{10}$Be nucleus. The individual Slater determinants and their weights in the superposition are determined simultaneously according to the variational principle of the energy of the total wave function. The multi-AMD basis states of $^{10}$Be show various cluster structures as well as the shell-model type. In the cluster configurations, different intercluster distances are superposed automatically indicating the role of the generator coordinates. We further introduce a procedure to obtain the configurations for the excited states imposing the orthogonal condition to the ground-state configurations. In the excited states of $^{10}$Be, the linear-chain-like structure is confirmed consisting of various clusters. The energy spectrum using the obtained basis states reproduces the experiments. The present framework can be the method to find the optimal multi-configuration for nuclear ground and excited states."], "authors": "Takayuki Myo"},
{"Title": "Coherent interactions of a fast proton with a short-range $NN$ correlation in the nucleus", "abs": ["Nuclear structure at short $NN$-distances is still poorly understood. In particular, the full quantum structure of the nucleus with a correlated $NN$-pair is a challenge to theory. So far, model descriptions have been limited to the average mean-field picture of the remaining nuclear system after removing the $NN$-pair. In the recent experiment of the BM@N Collaboration at JINR \\cite{Patsyuk:2021fju}, the reactions $^{12}\\mbox{C}(p,2pn_s)^{10}\\mbox{B}$ and $^{12}\\mbox{C}(p,2pp_s)^{10}\\mbox{Be}$ induced by the hard elastic $pp$ scattering were studied. Here, $n_s$ or $p_s$ denote the undetected slow nucleon in the rest frame of $^{12}\\mbox{C}$. In contrast to the previous experiments, the residual bound nucleus was also detected which requires a new level of theoretical understanding. In the present work, we apply the technique of fractional parentage coefficients of the translationally-invariant shell model (TISM) to calculate the spectroscopic amplitude of the system $NN-B$ where $B$ is the remaining nuclear system. The spectroscopic amplitude enters the full amplitude of a nuclear reaction. The relative $NN-B$ wave function is no longer a free parameter of the model but is uniquely related to the internal state of $B$. The interaction of the target proton with the $NN$-pair is considered in the impulse approximation. We also include the initial- and final state interactions of absorptive type as well as the single charge exchange processes. Our calculations are in a reasonable agreement with the BM@N data."], "authors": "A.B. Larionov"},
{"Title": "Dual-phase xenon time projection chambers for rare-event searches", "abs": ["In the past decade, dual-phase xenon time projection chambers (Xe-TPCs) have emerged as some of the most powerful detectors in the fields of astroparticle physics and rare-event searches. Developed primarily towards the direct detection of dark matter particles, experiments presently operating deep underground have reached target masses at the multi-tonne scale, energy thresholds around 1\\,keV and radioactivity-induced background rates similar to those from solar neutrinos. These unique properties, together with demonstrated stable operation over several years, allow for the exploration of new territory via high-sensitivity searches for a plethora of ultra-rare interactions. These include searches for particle dark matter, for second order weak decays, and the observation of astrophysical neutrinos. We first review some properties of xenon as a radiation detection medium and the operation principles of dual-phase Xe-TPCs together with their energy calibration and resolution. We then discuss the status of currently running experiments and of proposed next-generation projects, describing some of the technological challenges. We end by looking at their sensitivity to dark matter candidates, to second order weak decays and to solar and supernova neutrinos. Experiments based on dual-phase Xe-TPCs are difficult, and, like all good experiments, they are constantly pushed to their limits. Together with many other endeavours in astroparticle physics and cosmology they will continue to push at the borders of the unknown, hopefully to reveal profound new knowledge about our cosmos."], "authors": "Laura Baudis"},
{"Title": "Quick Guides for Use of the CompOSE Data Base", "abs": ["We present a combination of two quick guides aimed at summarizing relevant information about the CompOSE nuclear equation of state repository. The first is aimed at nuclear physicists and describes how to provide standard equation of state tables. The second quick guide is meant for users and describes the basic procedures to obtain customized tables with equation of state data. Several examples are included to help providers and users to understand and benefit from the CompOSE database."], "authors": "Veronica Dexheimer"},
{"Title": "Spreading widths of giant monopole resonance in the lead region: Random matrix approach", "abs": ["The microscopic calculation of the decay width of giant monopole resonance (GMR) anticipates the mixing of one-phonon states with configurations of increasing complexity. To this aim we develop the effective approach for description of monopole excited states that are obtained in the quasiparticle random phase approximation (QRPA), with regard of the coupling between one- and two-phonon states. Based on the QRPA one-phonon states, we generate the coupling and two-phonon states by means of the Gaussian orthogonal ensemble (GOE) distribution. Within our approach the spreading width of the GMRs in $^{204,206,208}$Pb are described by means of a random matrix approach on two energy scales. It is demonstrated that the main contribution into the decay of the GMR is determined by a small number of two-phonon states strongly coupled to low-energy surface vibrations. While a vast majority of the coupling matrix elements (that are small in value and following the GOE distribution) are responsible for the fine structure of the GMR spreading width. A remarkable agreement between the results of the full microscopic calculations (based on QRPA phonons coupled by means of the microscopic coupling matrix elements with calculated two-phonon states) with those of the developed approach confirms the vitality of the proposed ideas."], "authors": "N.N. Arsenyev"},
{"Title": "Dynamics of causal hydrodynamic fluctuations in an expanding system", "abs": ["We develop a framework of causal hydrodynamic fluctuations in one-dimensional expanding system performing linearisation of the hydrodynamic equations around the boost invariant solution. Through the description of space-time evolution of thermodynamic variables and flow velocity, we find a novel phenomenon that the structure of thermodynamic variables is almost frozen. We also show that two-particle correlation functions of final hadrons after freezeout are closely related with the mass of hadrons and properties of the medium such as viscosity, relaxation time and equation of state."], "authors": "Shin-ei Fujii"},
{"Title": "An extended Skyrme momentum dependent potential in asymmetric nuclear matter and transport models", "abs": ["Based on an extended Skyrme momentum-dependent interaction, we derive an isospin asymmetric equation of state, isospin dependent single particle potential and the Hamiltonian which can be used in the Boltzmann-Uehling-Uhlenbeck (BUU) model and the quantum molecular dynamics (QMD) model at the beam energy less than 1 GeV/u. As an example, we also present the results obtained with the extended Skyrme momentum-dependent interaction in the improved quantum molecular dynamics model (ImQMD), and the influence of the effective mass splitting on the isospin sensitive observables, i.e., the single and double neutron-to-proton ratios, are discussed again."], "authors": "Junping Yang"},
{"Title": "Estimate magnetic field strength in heavy-ion collisions via the direct photon elliptic flow", "abs": ["There must be electromagnetic fields created during high-energy heavy-ion collisions. As the quark-gluon plasma (QGP) starts to evolve hydrodynamically, although these fields may become weak comparing to the energy scales of the strong interaction, they are potentially important to some electromagnetic probes. In this work, we focus on the dissipative corrections in QGP due to the presence of a weak external magnetic field, and calculate accordingly the induced photon radiation in the framework of viscous hydrodynamics. By event-by-event hydrodynamical simulations, the experimentally measured direct photon elliptic flow can be well reproduced. Correspondingly, the direct photon elliptic flow implies a magnetic field strength around 0.1$m_\\pi^2 \\sim 10^{16}$ G. This is indeed a weak field in heavy-ion physics that is compatible to the theoretical predictions, however, it is still an ultra-strong magnetic field in nature."], "authors": "Jing-An Sun"},
{"Title": "Bayesian calibration of viscous anisotropic hydrodynamic (VAH) simulations of heavy-ion collisions", "abs": ["A Bayesian calibration, using experimental data from 2.76 $A$ TeV Pb-Pb collisions at the LHC, of a novel hybrid model is presented in which the usual pre-hydrodynamic and viscous relativistic fluid dynamic (vRFD) stages are replaced by a viscous anisotropic hydrodynamic (VAH) core that smoothly interpolates between the initial expansion-dominated, approximately boost-invariant longitudinally free-streaming and the subsequent collision-dominated (3+1)-dimensional standard vRFD stages. This model yields meaningful constraints for the temperature-dependent specific shear and bulk viscosities, $(\\eta/s)(T)$ and $(\\zeta/s)(T)$, for temperatures up to about $700$ MeV (i.e. over twice the range that could be explored with earlier models). With its best-fit model parameters the calibrated VAH model makes highly successful predictions for additional $p_T$-dependent observables for which high-quality experimental data are available that were not used for the model calibration."], "authors": "Ulrich Heinz"},
{"Title": "Coalescence sum rule and the electric charge- and strangeness-dependences of directed flow in heavy ion collisions", "abs": ["The rapidity-odd directed flows ($v_{\\rm 1}$) of identified hadrons are expected to follow the coalescence sum rule when the created matter is initially in parton degrees of freedom and then hadronizes through quark coalescence. A recent study has considered the $v_{\\rm 1}$ of produced hadrons that do not contain $u$ or $d$ constituent quarks. It has constructed multiple hadron sets with a small mass difference but given difference in electric charge $\\Delta q$ and strangeness $\\Delta S$ between the two sides, where a nonzero and increasing $\\Delta v_{\\rm 1}$ with $\\Delta q$ has been proposed to be a consequence of electromagnetic fields. In this study, we examine the consequence of coalescence sum rule on the $\\Delta v_{\\rm", "1}$ of the hadron sets in the absence of electromagnetic fields. We find that in general $\\Delta v_{\\rm 1} \\neq 0$ for a hadron set with nonzero $\\Delta q$ and/or $\\Delta S$ due to potential $v_{\\rm 1}$ differences between $\\bar u$ and $\\bar d$ and between $s$ and $\\bar s$ quarks. We further propose methods to extract the coefficients for the $\\Delta q$- and $\\Delta S$-dependences of the direct flow difference, where a nonzero constant term would indicate the breaking of the coalescence sum rule. The extraction methods are then demonstrated with transport model results."], "authors": "Kishora Nayak"},
{"Title": "Precision three-dimensional imaging of nuclei using recoil-free jets", "abs": ["In this study, we explore the azimuthal angle decorrelation of lepton-jet pairs in e-p and e-A collisions as a means for precision measurements of the three-dimensional structure of bound and free nucleons. Utilizing soft-collinear effective theory, we perform the first-ever resummation of this process in e-p collisions at NNLL accuracy using a recoil-free jet axis. Our results are validated against Pythia simulations. In e-A collisions, we address the complex interplay between three characteristic length scales: the medium length $L$, the mean free path of the energetic parton in the medium $\\lambda$, and the hadronization length $L_h$. We demonstrate that in the thin-dilute limit, where $L \\ll L_h$ and $L \\sim \\lambda$, this process can serve as a robust probe of the three-dimensional structure for bound nucleons. We conclude by offering predictions for future experiments at the Electron-Ion Collider within this limit."], "authors": "Shen Fang"},
{"Title": "Production of the $ΞN$ dibaryon as a weakly bound system in $pp$ collisions", "abs": ["The $\\Xi N$ interaction plays an important role in our understanding on the long-anticipated $H$-dibaryon. Recent lattice QCD calculations verified the attractive nature of the $\\Xi N$ interaction. On the other hand, whether it is strong enough to generate a bound state remains", "this work, assuming that it can generate a weakly bound state, we study the yields of the $\\Xi N$ dibaryon for different binding energies in $pp$ collisions at 7 TeV using the coalescence model and the transport model PACIAE. The yields are estimated first numerically and then analytically adopting a Yukawa-type wave function. In particular, we find that in the weak binding limit, there exists a universal relation between the yield and the binding energy, valid for $pp$ collisions."], "authors": "Tian-Chen Wu"},
{"Title": "Developing predictions for pion fragmentation functions", "abs": ["Exploiting crossing symmetry, the hadron scale pion valence quark distribution function is used to predict the kindred elementary valence quark fragmentation function (FF). This function defines the kernel of a quark jet fragmentation equation, which is solved to obtain the full pion FFs. After evolution to a scale typical of FF fits to data, the results for quark FFs are seen to compare favourably with such fits. However, the gluon FF is markedly different. Notably, although FF evolution equations do not themselves guarantee momentum conservation, inclusion of a gluon FF which, for four quark flavours, distributes roughly 11% of the total light-front momentum fraction, is sufficient to restore momentum conservation under evolution. Overall, significant uncertainty is attached to FFs determined via fits to data; hence, the features of the predictions described herein could potentially provide useful guidance for future such studies."], "authors": "H.-Y. Xing"},
{"Title": "Pushing the high count rate limits of scintillation detectors for challenging neutron-capture experiments", "abs": ["One of the critical aspects for the accurate determination of neutron capture cross sections when combining time-of-flight and total energy detector techniques is the characterization and control of systematic uncertainties associated to the measuring devices. In this work we explore the most conspicuous effects associated to harsh count rate conditions: dead-time and pile-up effects. Both effects, when not properly treated, can lead to large systematic uncertainties and bias in the determination of neutron cross sections. In the majority of neutron capture measurements carried out at the CERN n\\_TOF facility, the detectors of choice are the C$_{6}$D$_{6}$ liquid-based either in form of large-volume cells or recently commissioned sTED detector array, consisting of much smaller-volume modules. To account for the aforementioned effects, we introduce a Monte Carlo model for these detectors mimicking harsh count rate conditions similar to those happening at the CERN n\\_TOF 20~m fligth path vertical measuring station. The model parameters are extracted by comparison with the experimental data taken at the same facility during 2022 experimental campaign. We propose a novel methodology to consider both, dead-time and pile-up effects simultaneously for these fast detectors and check the applicability to experimental data from $^{197}$Au($n$,$\\gamma$), including the saturated 4.9~eV resonance which is an important component of normalization for neutron cross section measurements."], "authors": "J. Balibrea Correa"},
{"Title": "Study of bulk properties of the system formed in U+U collisions at $\\sqrt{s_{\\mathrm NN}}$ =~2.12~GeV using JAM model", "abs": ["The Lanzhou Cooling-Storage-Ring facility is set to conduct experiments involving Uranium-Uranium collisions at the center of mass energies ranging from 2.12 to 2.4 GeV. Our investigation is focused on various bulk observables, which include charged particle multiplicity ($N_{\\text{ch}}$), average transverse momentum ($\\langle p_{\\text{T}}\\rangle$), initial eccentricity ($\\epsilon_{n}$), and flow harmonics ($v_{n}$), for different orientations of U+U collisions within the range of $0^{\\circ} < \\theta < 120 ^{\\circ}$ at $\\sqrt{s_{\\mathrm NN}} = 2.12$ GeV ($p_{\\mathrm lab}$ = 500 MeV). Among the various collision configurations at this energy, the tip-tip scenario emerged with the highest average charged particle multiplicity, denoted as $\\langle N_{\\text{ch}} \\rangle$. Notably, both the second and third-order eccentricities, $\\epsilon_{2,3}$, revealed intricate patterns as they varied with impact parameter across distinct configurations. The tip-tip configuration displayed the most pronounced magnitude of rapidity-odd directed flow ($v_{1}$), whereas the body-body configuration exhibited the least pronounced magnitude. Concerning elliptic flow ($v_{2}$) near mid-rapidity ($\\eta < 1.0$), a negative sign is observed for all configurations except for the side-side exhibited a distinctly positive sign. Within the spectrum of configurations, the body-body scenario displayed the highest magnitude of $v_{2}$. For reaction plane correlated triangular flow ($v_{3}$), the body-body configuration emerged with the largest magnitude while the side-side exhibited the smallest magnitude. Our study seeks to establish a fundamental understanding of various U+U collision configurations in preparation for the forthcoming CEE experiment."], "authors": "Aswini Kumar Sahoo"},
{"Title": "The CeBrA demonstrator for particle-$γ$ coincidence experiments at the FSU Super-Enge Split-Pole Spectrograph", "abs": ["We report on a highly selective experimental setup for particle-$\\gamma$ coincidence experiments at the Super-Enge Split-Pole Spectrograph (SE-SPS) of the John D. Fox Superconducting Linear Accelerator Laboratory at Florida State University (FSU) using fast CeBr$_3$ scintillators for $\\gamma$-ray detection. Specifically, we report on the results of characterization tests for the first five CeBr$_3$ scintillation detectors of the CeBr$_3$ Array (CeBrA) with respect to energy resolution and timing characteristics. We also present results from the first particle-$\\gamma$ coincidence experiments successfully performed with the CeBrA demonstrator and the FSU SE-SPS. We show that with the new setup, $\\gamma$-decay branching ratios and particle-$\\gamma$ angular correlations can be measured very selectively using narrow excitation energy gates, which are possible thanks to the excellent particle energy resolution of the SE-SPS. In addition, we highlight that nuclear level lifetimes in the nanoseconds regime can be determined by measuring the time difference between particle detection with the SE-SPS focal-plane scintillator and $\\gamma$-ray detection with the fast CeBrA detectors. Selective excitation energy gates with the SE-SPS exclude any feeding contributions to these lifetimes."], "authors": "A.L. Conley"},
{"Title": "Hidden-charm pentaquarks with strangeness in a chiral quark model", "abs": ["The LHCb collaboration has recently announced the discovery of two hidden-charm pentaquark states with also strange quark content, $P_{cs}(4338)$ and $P_{cs}(4459)$; its analysis points towards having both hadrons isospin equal to zero and spin-parity quantum numbers $\\frac12^-$ and $\\frac32^-$, respectively. We perform herein a systematical investigation of the $qqsc\\bar{c}$ $(q=u,\\,d)$ system by means of a chiral quark model, along with a highly accurate computational method, the Gaussian expansion approach combined with the complex-scaling technique. Baryon-meson configurations in both singlet- and hidden-color channels are considered. The $P_{cs}(4338)$ and $P_{cs}(4459)$ signals can be well identified as molecular bound states with dominant components $\\Lambda J/\\psi$ $(60\\%)$ and $\\Xi_c D$ $(23\\%)$ for the lowest-energy case and $\\Xi_c D^*$ $(72\\%)$ for the highest-energy one. Besides, it seems that some narrow resonances can be also found in each allowed $I(J^P)$-channel in the energy region of $4.6-5.5$ GeV, except for the $1(\\frac12^-)$ where a shallow bound state with dominant $\\Xi^*_c D^*$ structure is obtained at $4673$ MeV with binding energy $E_B=-3$ MeV. These exotic states are expected to be confirmed in future high energy experiments."], "authors": "Gang Yang"},
{"Title": "Light-yield response of liquid scintillators using 2--6 MeV tagged neutrons", "abs": ["Knowledge of the neutron light-yield response is crucial to the understanding of scintillator-based neutron detectors. In this work, neutrons from 2--6 MeV have been used to study the scintillation light-yield response of the liquid scintillators NE 213A, EJ 305, EJ 331 and EJ 321P using event-by-event waveform digitization. Energy calibration was performed using a GEANT model to locate the edge positions of the Compton distributions produced by gamma-ray sources. The simulated light yield for neutrons from a PuBe source was compared to measured recoil proton distributions, where neutron energy was selected by time-of-flight. This resulted in an energy-dependent Birks parametrization to characterize the non-linear response to the lower energy neutrons. The NE 213A and EJ 305 results agree very well with existing data and are reproduced nicely by the simulation. New results for EJ 331 and EJ 321P, where the simulation also reproduces the data well, are presented."], "authors": "N. Mauritzson"},
{"Title": "Improving the Performance of Cryogenic Calorimeters with Nonlinear Multivariate Noise Cancellation Algorithms", "abs": ["State-of-the-art physics experiments require high-resolution, low-noise, and low-threshold detectors to achieve competitive scientific results. However, experimental environments invariably introduce sources of noise, such as electrical interference or microphonics. The sources of this environmental noise can often be monitored by adding specially designed \"auxiliary devices\" (e.g. microphones, accelerometers, seismometers, magnetometers, and antennae). A model can then be constructed to predict the detector noise based on the auxiliary device information, which can then be subtracted from the true detector signal. Here, we present a multivariate noise cancellation algorithm which can be used in a variety of settings to improve the performance of detectors using multiple auxiliary devices. To validate this approach, we apply it to simulated data to remove noise due to electromagnetic interference and microphonic vibrations. We then employ the algorithm to a cryogenic light detector in the laboratory and show an improvement in the detector performance. Finally, we motivate the use of nonlinear terms to better model vibrational contributions to the noise in thermal detectors. We show a further improvement in the performance of a particular channel of the CUORE detector when using the nonlinear algorithm in combination with optimal filtering techniques."], "authors": "Kenneth J. Vetter"},
{"Title": "Fraction of $χ_c$ decays in prompt $J/ψ$ production measured in pPb collisions at $\\sqrt{s_{NN}}=8.16$ TeV", "abs": ["The fraction of $\\chi_{c1}$ and $\\chi_{c2}$ decays in the prompt $J/\\psi$ yield, $F_{\\chi c}=\\sigma_{\\chi_c \\to J/\\psi}/\\sigma_{J/\\psi}$, is measured by the LHCb detector in pPb collisions at $\\sqrt{s_{NN}}=8.16$ TeV. The study covers the forward ($1.5<y^*<4.0$) and backward ($-5.0<y^*<-2.5$) rapidity regions, where $y^*$ is the $J/\\psi$ rapidity in the nucleon-nucleon center-of-mass system. Forward and backward rapidity samples correspond to integrated luminosities of 13.6 $\\pm$ 0.3 nb$^{-1}$ and 20.8 $\\pm$ 0.5 nb$^{-1}$, respectively. The result is presented as a function of the $J/\\psi$ transverse momentum $p_{T,J/\\psi}$ in the range 1$<p_{T, J/\\psi}<20$ GeV/$c$. The $F_{\\chi c}$ fraction at forward rapidity is compatible with the LHCb measurement performed in $pp$ collisions at $\\sqrt{s}=7$ TeV, whereas the result at backward rapidity is 2.4 $\\sigma$ larger than in the forward region for $1<p_{T, J/\\psi}<3$ GeV/$c$. The increase of $F_{\\chi c}$ at low $p_{T, J/\\psi}$ at backward rapidity is compatible with the suppression of the $\\psi$(2S) contribution to the prompt $J/\\psi$ yield. The lack of in-medium dissociation of $\\chi_c$ states observed in this study sets an upper limit of 180 MeV on the free energy available in these pPb collisions to dissociate or inhibit charmonium state formation."], "authors": "LHCb collaboration"},
{"Title": "Heating rate in a linear quadrupole trap", "abs": ["In radio-frequency trap, the temperature of ion ensembles converges towards a hot equilibrium due to radio-frequency heating. This effect is detrimental to the stability of trapped ensembles and is the justification of cooling. The intensity of this radio-frequency heating increases with the amplitude of the radio-frequency field $q_x$. Using an analytical empirical formula, we show that the lifetime of the ion ensemble $t_0$ under cold condition increases with $q_x$ according to a power law $t_0\\propto q_x^A$, and does not vary significantly for the several ion quantities $N$ tested. The temperature of the explosive onset $B$ decreases linearly with $q_x$. We also show that non-linear instabilities due to trapping parameters decreases $t_0$ and $B$, and produce a local increase of heating rate for certain temperature ranges."], "authors": "Adrien Poindron"},
{"Title": "Wehrl Entropy and Entanglement Complexity of Quantum Spin Systems", "abs": ["The Wehrl entropy of a quantum state is the entropy of the coherent-state distribution function (Husimi function), and is non-zero even for pure states. We investigate the Wehrl entropy for $N$ spin-1/2 particles with respect to SU(2)$^{\\otimes N}$ coherent states (i.e., the direct products of spin coherent states of each particle). We focus on: (1) The statistical interpretation of this Wehrl entropy. (2) The relationship between the Wehrl entropy and quantum entanglement. For (1), despite the coherent states not forming a group of orthonormal bases, we prove that the Wehrl entropy can still be interpreted as the entropy of a probability distribution with clear physical meaning. For (2), we numerically calculate the Wehrl entropy of various entangled pure states with particle number $2\\leq N\\leq 20$. Our results show that for the large-$N$ ($N\\gtrsim 10$) systems the Wehrl entropy of the highly chaotic entangled states are much larger than that of the regular ones (e.g., the GHZ state). These results, together with the fact that the Wehrl entropy is invariant under local unitary transformations, indicate that the Wehrl entropy can reflect the complexity of the quantum entanglement (entanglement complexity) of many-body pure states, as A. Sugita proposed directly from the definitions of the Husimi function and Wehrl entropy (Jour. Phys. A 36, 9081 (2003)). Furthermore, the Wehrl entropy per particle can serve as a quantitative description of this complexity. We further show that the many-body pure entangled states can be classified into three types, according to the behaviors of the Wehrl entropy per particle in the limit $N\\rightarrow\\infty$, with the states of each type having very different entanglement complexity."], "authors": "Chen Xu"},
{"Title": "Coupling trapped ions to a nanomechanical oscillator", "abs": ["Cold ions in traps are well-established, highly controllable quantum systems with a wide variety of applications in quantum information, precision spectroscopy, clocks and chemistry. Nanomechanical oscillators are used in advanced sensing applications and for exploring the border between classical and quantum physics. Here, we report on the implementation of a hybrid system combining a metallic nanowire with laser-cooled ions in a miniaturised ion trap. We demonstrate resonant and off-resonant coupling of the two systems and the coherent motional excitation of the ion by the mechanical drive of the nanowire. The present results open up avenues for mechanically manipulating the quantum motion of trapped ions, for the development of ion-mechanical hybrid quantum systems and for the sympathetic cooling of mechanical systems by trapped ions and vice versa."], "authors": "Moritz Weegen"},
{"Title": "Nonadiabatic conical intersection dynamics in the local diabatic representation with Strang splitting and Fourier basis", "abs": ["We develop and implement an exact conical intersection nonadiabatic wave packet dynamics method that combines the local diabatic representation, Strang splitting for the total molecular propagator, and discrete variable representation with uniform grids. By employing the local diabatic representation, this method captures all non-adiabatic effects, including nonadiabatic transitions, electronic coherences, and geometric phases. Moreover, it is free of singularities in the first and second derivative couplings, and does not require a smooth gauge of electronic wavefunction phase. We further show that in contrast to the adiabatic representation, the split-operator method can be directly applied to the full molecular propagator with the locally diabatic ansatz. The Fourier series, employed as the primitive nuclear basis functions, is universal and can be applied to all types of reactive coordinates. The combination of local diabatic representation, Strang splitting, and Fourier basis allows exact modeling of conical intersection quantum dynamics directly with adiabatic electronic states that can be obtained from standard electronic structure computations."], "authors": "Bing Gu"},
{"Title": "A continuous-wave and pulsed X-band electron spin resonance spectrometer operating in ultra-high vacuum for the study of low dimensional spin ensembles", "abs": ["We report the development of a continuous-wave and pulsed X-band electron spin resonance (ESR) spectrometer for the study of spins on ordered surfaces down to cryogenic temperatures. The spectrometer operates in ultra-high vacuum and utilizes a half-wavelength microstrip line resonator realized using epitaxially grown copper films on single crystal Al$_2$O$_3$ substrates. The one-dimensional microstrip line resonator exhibits a quality factor of more than 200 at room temperature, close to the upper limit determined by radiation losses. The surface characterizations of the copper strip of the resonator by atomic force microscope, low-energy electron diffraction, and scanning tunneling microscope show that the surface is atomically clean, flat, and single crystalline. Measuring the ESR spectrum at 15 K from a few nm thick molecular film of YPc$_2$, we find a continuous-wave ESR sensitivity of $6.5 \\cdot 10^{10}~\\text{spins}/\\text{G} \\cdot \\text{Hz}^{1/2}$ indicating that a signal-to-noise ratio of $7.7~\\text{G} \\cdot \\text{Hz}^{1/2}$ is expected from a monolayer of YPc$_2$ molecules. Advanced pulsed ESR experimental capabilities including dynamical decoupling and electron-nuclear double resonance are demonstrated using free radicals diluted in a glassy matrix."], "authors": "Franklin H. Cho"},
{"Title": "Titanium:Sapphire-on-insulator for broadband tunable lasers and high-power amplifiers on chip", "abs": ["Titanium:Sapphire (Ti:Sa) lasers have been essential for advancing fundamental research and technological applications. Ti:Sa lasers are unmatched in bandwidth and tuning range, yet their use is severely restricted due to their large size, cost, and need for high optical pump powers. Here, we demonstrate a monocrystalline Ti:Sa-on-insulator (Ti:SaOI) photonics platform which enables dramatic miniaturization, cost-reduction, and scalability of Ti:Sa technology. First, through fabrication of low-loss whispering gallery mode resonators, we realize a Ti:Sa laser operating with an ultra-low lasing threshold of 290 $\\mu$W. Then, through orders-of-magnitude improvement in mode confinement in Ti:SaOI waveguides, we realize the first integrated solid-state (i.e., non-semiconductor) optical amplifier operating below 1 $\\mu$m, with an ultra-wide bandwidth of 700 - 950 nm and peak gain of 64 dB/cm. We demonstrate unprecedented 17 dB distortion-free amplification of picosecond pulses to up to 2.3 nJ pulse energy, corresponding to a peak power of 1.0 kW. Finally, we demonstrate the first tunable integrated Ti:Sa laser, featuring narrow linewidths and a 24.7 THz tuning range, which, for the first time, can be pumped with low-cost, miniature, off-the-shelf green laser diodes. This opens doors to new modalities of Ti:Sa lasers (now occupying a footprint less than 0.15 mm$^2$), such as massively-scalable Ti:Sa laser array systems for a variety of applications. As a proof-of-concept demonstration, we employ a Ti:SaOI laser array as the sole optical control for a cavity quantum electrodynamics experiment with artificial atoms in silicon carbide. This work is a key step towards the democratization of Ti:Sa technology through a three orders-of-magnitude reduction in cost and footprint, as well as the introduction of solid-state broadband amplification of sub-micron wavelength light."], "authors": "Joshua Yang"},
{"Title": "Performance Analysis of Multi-Angle QAOA for p > 1", "abs": ["In this paper we consider the scalability of Multi-Angle QAOA with respect to the number of QAOA layers. We found that MA-QAOA is able to significantly reduce the depth of QAOA circuits, by a factor of up to 4 for the considered data sets. However, MA-QAOA is not optimal for minimization of the total QPU time. Different optimization initialization strategies are considered and compared for both QAOA and MA-QAOA. Among them, a new initialization strategy is suggested for MA-QAOA that is able to consistently and significantly outperform random initialization used in the previous studies."], "authors": "Igor Gaidai"},
{"Title": "A Pedestrian's Way to Baxter's Bethe Ansatz for the Periodic XYZ Chain", "abs": ["A chiral coordinate Bethe ansatz method is developed to study the periodic XYZ chain. We construct a set of chiral vectors with fixed number of kinks. All vectors are factorized and have simple structures. Under roots of unity conditions, the Hilbert space has an invariant subspace and our vectors form a basis of this subspace. We propose a Bethe ansatz solely based on the action of the Hamiltonian on the chiral vectors, avoiding the use of transfer matrix techniques. This allows to parameterize the expansion coefficients and derive the homogeneous Bethe ansatz equations whose solutions give the exact energies and eigenstates. Our analytic results agree with earlier approaches, notably by Baxter, and are supported by numerical calculations."], "authors": "Xin Zhang"},
{"Title": "Three-Wave Mixing Quantum-Limited Kinetic Inductance Parametric Amplifier operating at 6 Tesla and near 1 Kelvin", "abs": ["Parametric amplifiers play a crucial role in modern quantum technology by enabling the enhancement of weak signals with minimal added noise. Traditionally, Josephson junctions have been the primary choice for constructing parametric amplifiers. Nevertheless, high-kinetic inductance thin films have emerged as viable alternatives to engineer the necessary nonlinearity. In this work, we introduce and characterize a Kinetic Inductance Parametric Amplifier (KIPA) built using high-quality NbN superconducting thin films. The KIPA addresses some of the limitations of traditional Josephson-based parametric amplifiers, excelling in dynamic range, operational temperature, and magnetic field resilience. We demonstrate a quantum-limited amplification (> 20 dB) with a 20 MHz gain-bandwidth product, operational at fields up to 6 Tesla and temperatures as high as 850 mK. Harnessing kinetic inductance in NbN thin films, the KIPA emerges as a robust solution for quantum signal amplification, enhancing research possibilities in quantum information processing and low-temperature quantum experiments. Its magnetic field compatibility and quantum-limited performance at high temperatures make it an invaluable tool, promising new advancements in quantum research."], "authors": "Simone Frasca"},
{"Title": "Probing Off-diagonal Eigenstate Thermalization with Tensor Networks", "abs": ["Energy filter methods in combination with quantum simulation can efficiently access the properties of quantum many-body systems at finite energy densities [Lu et al. PRX Quantum 2, 020321 (2021)]. Classically simulating this algorithm with tensor networks can be used to investigate the microcanonical properties of large spin chains, as recently shown in [Yang et al. Phys. Rev. B 106, 024307 (2022)]. Here we extend this strategy to explore the properties of off-diagonal matrix elements of observables in the energy eigenbasis, fundamentally connected to the thermalization behavior and the eigenstate thermalization hypothesis. We test the method on integrable and non-integrable spin chains of up to 60 sites, much larger than accessible with exact diagonalization. Our results allow us to explore the scaling of the off-diagonal functions with the size and energy difference, and to establish quantitative differences between integrable and non-integrable cases"], "authors": "Maxine Luo"},
{"Title": "Ground-state entanglement spectrum of a generic model with nonlocal excitation-phonon coupling", "abs": ["While the concept of the entanglement spectrum has heretofore been utilized to address various many-body systems, the models describing an itinerant spinless-fermion excitation coupled to zero-dimensional bosons (e.g. dispersionless phonons) have as yet not received much attention in this regard. To fill this gap, the ground-state entanglement spectrum of a model that includes two of the most common types of short-ranged, nonlocal excitation-phonon interaction -- the Peierls- and breathing-mode couplings -- is numerically evaluated here. This model displays a sharp, level-crossing transition at a critical coupling strength, which signifies the change from a nondegenerate ground state at the quasimomentum $K_{\\textrm{gs}}=0$ to a twofold-degenerate one corresponding to a symmetric pair of nonzero quasimomenta. Another peculiarity of this model is that in the special case of equal Peierls- and breathing-mode coupling strengths the bare-excitation Bloch state with the quasimomentum $0$ or $\\pi$ is its exact eigenstate. Moreover, below a critical coupling strength this state is the ground state of the model. Thus, the sharp transition between a bare excitation and a heavily phonon-dressed (polaronic) one can be thought of as a transition between vanishing and finite entanglement. It is demonstrated here that the smallest ground-state entanglement-spectrum eigenvalue to a large extent mimics the behavior of the entanglement entropy itself and vanishes in this special case of the model; by contrast, all the remaining eigenvalues diverge in this case. The implications of excitation-phonon entanglement for $W$-state engineering in superconducting and neutral-atom-based qubit arrays serving as analog simulators of this model are also discussed."], "authors": "Vladimir M. Stojanovic"},
{"Title": "Provable bounds for noise-free expectation values computed from noisy samples", "abs": ["In this paper, we explore the impact of noise on quantum computing, particularly focusing on the challenges when sampling bit strings from noisy quantum computers as well as the implications for optimization and machine learning applications. We formally quantify the sampling overhead to extract good samples from noisy quantum computers and relate it to the layer fidelity, a metric to determine the performance of noisy quantum processors. Further, we show how this allows us to use the Conditional Value at Risk of noisy samples to determine provable bounds on noise-free expectation values. We discuss how to leverage these bounds for different algorithms and demonstrate our findings through experiments on a real quantum computer involving up to 127 qubits. The results show a strong alignment with theoretical predictions."], "authors": "Samantha V. Barron"},
{"Title": "Algebra of Nonlocal Boxes and the Collapse of Communication Complexity", "abs": ["Communication complexity quantifies how difficult it is for two distant computers to evaluate a function $f(X,Y)$ where the strings $X$ and $Y$ are distributed to the first and second computer, respectively and under the constraint of exchanging as few bits as possible. Surprisingly, some nonlocal boxes, which are resources shared by the two computers, are so powerful that they allow to collapse communication complexity, in the sense that any Boolean function $f$ can be correctly estimated with the exchange of only one bit of communication. The Popescu-Rohrlich (PR) box is an example of such a collapsing resource, but a comprehensive description of the set of collapsing nonlocal boxes remains elusive.", "In this work, we carry out an algebraic study of the structure of wirings connecting nonlocal boxes, thus defining the notion of the \"product of boxes\" $\\mathtt{P}\\boxtimes\\mathtt{Q}$, and we show related associativity and commutativity results. This gives rise to the notion of the \"orbit of a box\", unveiling surprising geometrical properties about the alignment and parallelism of distilled boxes. The power of this new framework is that it allows to prove previously-reported numerical intuitions concerning the best way to wire consecutive boxes, and to numerically and analytically recover recently-identified noisy PR boxes that collapse communication complexity for different types of noise models."], "authors": "Pierre Botteron"},
{"Title": "Generalized Quantum Singular Value Transformation", "abs": ["The quantum singular value transformation has revolutionised quantum algorithms. By applying a polynomial to an arbitrary matrix, it provides a unifying picture of quantum algorithms. However, polynomials are restricted to definite parity and real coefficients, and finding the circuit (the phase factors) has proven difficult in practice. Recent work has removed these restrictions and enabled faster computation of phase factors, yet only for unitary matrices. Here we propose two generalisations. The generalised quantum singular value transformation allows complex polynomials for arbitrary matrices. For Hermitian matrices, we propose the generalised quantum eigenvalue transformation that even allows polynomials of indefinite parity. While we find that the polynomial might have to be downscaled compared to the quantum singular value transformation, the higher expressivity of polynomials and faster computation of phase factors can sometimes result in advantages. The results are achieved with various block encoding (or projected unitary encoding) techniques, including qubitisation, Hermitianisation, and multiplication. We show how to multiply block-encoded matrices with only one extra qubit, and introduce measure-early multiplication to further avoid the extra qubit and decrease average circuit length."], "authors": "Christoph Sünderhauf"},
{"Title": "Low-Overhead Parallelisation of LCU via Commuting Operators", "abs": ["The Linear Combination of Unitaries (LCU) method is a powerful scheme for the block encoding of operators but suffers from high overheads. In this work, we discuss the parallelisation of LCU and in particular the SELECT subroutine of LCU based on partitioning of observables into groups of commuting operators, as well as the use of adaptive circuits and teleportation that allow us to perform required Clifford circuits in constant depth. We only require an $O(\\log n)$ factor increase in the number of qubits in order to produce a significant depth reduction, with evidence suggesting that for practical molecular Hamiltonians, the depth saving is $O(n)$, and calculate a depth saving of $20\\times$ for SELECT on a H$_2$O Hamiltonian, even though small problem sizes are the worst case for our scheme. We discuss the implications of our method in the fault-tolerant setting, noting that parallelisation reduces the $T$-depth by the same factor as the logical algorithm, without changing the $T$-count."], "authors": "Gregory Boyd"},
{"Title": "Exploiting Maximally Mixed States for Spectral Estimation by Time Evolution", "abs": ["We introduce a novel approach for estimating the spectrum of quantum many-body Hamiltonians, and more generally, of Hermitian operators, using quantum time evolution. In our approach we are evolving a maximally mixed state under the Hamiltonian of interest and collecting specific time-series measurements to estimate its spectrum. We demonstrate the advantage of our technique over currently used classical statistical sampling methods. We showcase our approach by experimentally estimating the spectral decomposition of a 2-qubit Heisenberg Hamiltonian on an IBM Quantum backend. For this purpose, we develop a hardware-efficient decomposition that controls $n$-qubit Pauli rotations against the physically closest qubit alongside expressing two-qubit rotations in terms of the native entangling interaction. This substantially reduced the accumulation of errors from noisy two-qubit operations in time evolution simulation protocols. We conclude by discussing the potential impact of our work and the future directions of research it opens."], "authors": "Kaelyn J. Ferris"},
{"Title": "Rectified Lorentz Force from Thermal Current Fluctuations", "abs": ["In a conducting medium held at finite temperature, free carriers are performing Brownian motion and generate fluctuating electromagnetic fields. We compute the averaged Lorentz force density that turns out nonzero in a thin sub-surface layer, pointing towards the surface, while vanishing in the bulk. This is an elementary example of rectified fluctuations, similar to the Casimir force or radiative heat transport. Our results also provide an experimental way to distinguish between the Drude and so-called plasma models."], "authors": "Carsten Henkel"},
{"Title": "Comparative Analysis of Phase Noise for different configurations of Bragg lattice for an Atomic Gravimeter with Bose-Einstein Condensate", "abs": ["We perform a comparative study of the phase noise induced in the lasers used for Bragg diffraction in a Bose-Einstein condensate-based quantum gravimeter where the Bragg beams are generated using two different configurations. In one of the configurations, the Bragg beams that form the moving optical lattice are generated using two different acousto-optic modulators. In the second configuration, the Bragg beams are generated using a single acousto-optic modulator carrying two phase-locked frequencies. The second configuration shows a suppression of phase noise by a factor of 4.7 times in the frequency band upto 10 $kHz$, the primary source of noise, which is the background acoustic noise picked up by optical components and the optical table. We report a sensitivity of 99.7 $\\mu Gal/\\sqrt Hz$ for an interferometric time of 10 $ms$."], "authors": "Pranab Dutta"},
{"Title": "Qubits, entangled states, and quantum gates realized on a set of classical pendulums", "abs": ["Here we show that the concepts behind such terms as entanglement, qubits, quantum gates, quantum error corrections, unitary time evolution etc., which are usually ascribed to quantum systems, can be adequately realized on a set of coupled classical pendulums."], "authors": "Alexey V. Nenashev"},
{"Title": "Partial-wave projection of the one-particle exchange in three-body scattering amplitudes", "abs": ["As the study of three-hadron physics from lattice QCD matures, it is necessary to develop proper analysis tools in order to reliably study a variety of phenomena, including resonance spectroscopy and nuclear structure. Reconstructing the three-particle scattering amplitude requires solving integral equations, which can be written in terms of data-constrained dynamical functions and physical on-shell quantities. The driving term in these equations is the so-called one-particle exchange, which leads to a kinematic divergence for particles on-mass-shell. A vital component in defining three-particle amplitudes with definite parity and total angular momentum, which are used in spectroscopic studies, is to project the one-particle exchange into definite partial waves. We present a general procedure to construct exact analytic partial wave projections of the one-particle exchange contribution for any system composed of three spinless hadrons. Our result allows one full control over the analytic structure of the projection, which we explore for some low-lying partial waves with applications to three pions."], "authors": "Andrew W. Jackura"},
{"Title": "Quantum Schwarzschild geometry in effective-field-theory models of gravity", "abs": ["The Schwarzschild geometry is investigated within the context of effective-field-theory models of gravity. Starting from its harmonic-coordinate expression, we derive the metric in standard coordinates by keeping the leading one-loop quantum contributions in their most general form. We examine the metric horizons and the nature of the hypersurfaces having constant radius; furthermore, a possible energy-extraction process which violates the null energy condition is described, and both timelike and null geodesics are studied. Our analysis shows that there is no choice of the sign of the constant parameter embodying the quantum correction to the metric which leaves all the features of the classical Schwarzschild solution almost unaffected."], "authors": "Emmanuele Battista"},
{"Title": "Secular growths and their relation to equilibrium states in perturbative QFT", "abs": ["In the perturbative treatment of interacting quantum field theories, if the interaction Lagrangian changes adiabatically in a finite interval of time, secular growths may appear in the truncated perturbative series also when the interaction Lagrangian density is returned to be constant. If this happens, the perturbative approach does not furnish reliable results in the evaluation of scattering amplitudes or expectation values. In this paper we show that these effects can be avoided for adiabatically switched-on interactions, if the spatial support of the interaction is compact and if the background state is suitably chosen. We start considering equilibrium background states and show that, when thermalisation occurs (interaction Lagrangian of spatial compact support), secular effects are avoided. Furthermore, no secular effects pop up if the limit where the Lagrangian is supported everywhere in space is taken after thermalisation (large time limit), in contrast to the reversed order. This result is generalized showing that if the interaction Lagrangian is spatially compact, secular growths are avoided for generic background states which are only invariant under time translation and to states whose explicit dependence of time is not too strong. Finally, as an example, we apply the presented theorems to study a complex scalar and a Dirac field in a classical external electromagnetic potential, on a background KMS state, to manifest that a spatially compact supported interaction does not give rise to secular growths."], "authors": "Stefano Galanda"},
{"Title": "Glueballs in $N_f=1$ QCD", "abs": ["We present an evaluation of the glueball spectrum for configurations produced with $N_f=1$ dynamical fermions as a function of the $m_{\\rm PCAC}$ mass. We obtained masses of states that fall into the irreducible representations of the octahedral group of rotations in combination with the quantum numbers of charge conjugation $C$ and parity $P$. Due to the low signal to noise ratio, practically, we can only extract masses for the irreducible representations $R^{PC}=$ $A_1^{++}$, $E^{++}$, $T_2^{++}$ as well as $A_1^{-+}$. We make use of the Generalized Eigenvalue Problem (GEVP) with an operator basis consisting only of gluonic operators. Throughout this work we are aiming towards the identification of the effects of light dynamical quarks on the glueball spectrum and how this compares to the statistically more precise spectrum of SU(3) pure gauge theory. We used large gauge ensembles which consist of ${\\sim {~\\cal O}}(10 {\\rm K})$ configurations. Our findings demonstrate that the low-lying spectrum of the scalar, tensor as well as pseudo-scalar glueballs receive negligible contributions from the inclusion of $N_f=1$ dynamical fermions."], "authors": "Andreas Athenodorou"},
{"Title": "White Paper and Roadmap for Quantum Gravity Phenomenology in the Multi-Messenger Era", "abs": ["The unification of quantum mechanics and general relativity has long been elusive. Only recently have empirical predictions of various possible theories of quantum gravity been put to test. The dawn of multi-messenger high-energy astrophysics has been tremendously beneficial, as it allows us to study particles with much higher energies and travelling much longer distances than possible in terrestrial experiments, but more progress is needed on several fronts.", "A thorough appraisal of current strategies and experimental frameworks, regarding quantum gravity phenomenology, is provided here. Our aim is twofold: a description of tentative multimessenger explorations, plus a focus on future detection experiments.", "As the outlook of the network of researchers that formed through the COST Action CA18108 \"Quantum gravity phenomenology in the multi-messenger approach (QG-MM)\", in this work we give an overview of the desiderata that future theoretical frameworks, observational facilities, and data-sharing policies should satisfy in order to advance the cause of quantum gravity phenomenology."], "authors": "R. Alves Batista"},
{"Title": "The effective potential of composite operator in the first order region of QCD phase transition", "abs": ["We propose a method to compute the effective potential of QCD from gap equations by introducing the homotopy transformation between solutions of the equation of motion. Via this method, the effective potential can be obtained beyond the bare vertex approximation, which then generalizes the Cornwall, Jackiw and Tomboulis (CJT) effective potential for bilocal composite operators. Moreover, the extended effective potential is set to be a function of self energy instead of the composite operator, which is the key point to make the potential bounded from below as for the auxiliary field (AF) Potential. We then apply the effective potential in the coexistence region where there exists at least two solutions, for instance, in vacuum with small current quark mass, and the first order phase transition region in finite temperature and chemical potential, which provides the in-medium behavior of the latent heat and false vacuum energy."], "authors": "Hui-wen Zheng"},
{"Title": "$τ$SPECT: A spin-flip loaded magnetic ultracold neutron trap for a determination of the neutron lifetime", "abs": ["The confinement of ultracold neutrons (UCNs) in a three dimensional magnetic field gradient trap allows for a measurement of the free neutron lifetime with superior control over spurious loss channels and can provide a large kinetic energy acceptance to enhance statistical sensitivity. In this paper, we present the first successful implementation of a pulsed spin-flip based loading scheme for a three-dimensional magnetic UCN trap. The measurements with the $\\tau$SPECT experiment were performed at the pulsed UCN source of the research reactor TRIGA Mainz. We report on detailed investigations of major systematic effects influencing the neutron storage time, statistically limited by the size of the recorded data set. The extracted neutron storage time constant of $\\tau = 859(16)\\mathrm{s}$ is compatible with, but not to be interpreted as, a measurement of the free neutron lifetime."], "authors": "J. Auler"},
{"Title": "Polarized fragmenting jet functions in Inclusive and Exclusive Jet Production", "abs": ["In this work, we present a complete theoretical framework for analyzing the distribution of polarized hadrons within jets, with and without measuring the transverse momentum relative to the standard jet axis. Using soft-collinear effective theory (SCET), we derive the factorization and provide the theoretical calculation of both semi-inclusive and exclusive fragmenting jet functions (FJFs) under longitudinal and transverse polarization. With the polarized FJFs, one gains access to a variety of new observables that can be used for extracting both collinear and transverse momentum dependent parton distribution functions (PDFs) and fragmentation functions (FFs). As examples, we provide numerical results for the spin asymmetry $A_{TU,T}^{\\cos(\\phi _S - \\hat{\\phi}_{S_h})}$ from polarized semi-inclusive hadron-in-jet production in polarized $pp$ collisions at RHIC kinematics, where a transversely polarized quark would lead to the transverse spin of the final-state hadron inside the jet and is thus sensitive to the transversity fragmentation functions. Similarly, another spin asymmetry, $A_{TU, L}^{\\cos(\\phi _q - \\phi _{S})}$ from polarized exclusive hadron-in-jet production in polarized $ep$ collisions at EIC kinematics would allow us to access the helicity fragmentation functions. These observables demonstrate promising potential in investigating transverse momentum dependent PDFs and FFs and are worthwhile for further measurements."], "authors": "Zhong-Bo Kang"},
{"Title": "Shell-model study for $^{204-210}$Tl isotopes and core excitations across the $Z = 82$ and $N = 126$ shell gaps", "abs": ["In the present work, the $^{204-210}$Tl isotopes have been investigated by performing large-scale shell-model calculations, including configurations allowing both neutron and proton core excitations across the $Z$ = 82 and $N$ = 126 shell gaps. Inspired by the recent high-spin experimental data, the structure of Tl isotopes has been studied for a considerably large model space. The KHHE interaction has been used for $^{204-206}$Tl isotopes, KHH7B interaction for $^{204-210}$Tl isotopes, and additionally KHM3Y interaction has been used for $^{208}$Tl isotope. The core excitation has been performed using the KHH7B and KHM3Y interactions. The level spectra of $^{204-210}$Tl isotopes are comprehensively described and explained by multi-nucleon couplings of single-particle-hole orbitals within the valence space and by core excitations across $^{208}$Pb core. The well-known isomeric states are analyzed in terms of the shell model configurations."], "authors": "Bharti Bhoy"},
{"Title": "Measuring the Electric and Magnetic Form Factors of Protons and Antiprotons at small $Q^2$ and the charge radii of hadrons", "abs": ["Charge radii of hadrons are back in the focus since precision spectroscopic measurements in muonic hydrogen revealed a proton charge radius considerably smaller than generally accepted ever since R.~Hofstaedter's pioneering experiments. Recent experimental results also point to an underestimation of systematic uncertainties in most previous measurements. A new method was thus proposed by AMBER at CERN using elastic scattering by very high energy muons using an active hydrogen target. With a simplified setup we may resume elastic scattering of $\\pi$ and K mesons on electrons in inverse kinematics, and, for the first time, probe antiprotons with few percent precision for their charge radius. Applying this method also for protons allows a separation of $G_E^p(Q^2)$ and $G_M^p(Q^2)$ down to $Q^2=10^{-3}(GeV/c)^2$."], "authors": "Stephan Paul"},
{"Title": "Nuclear PDFs After the First Decade of LHC Data", "abs": ["We present a review of the conceptual basis, present knowledge and recent progress in the field of global analysis of nuclear parton distribution functions (PDFs). After introducing the theoretical foundations and methodological approaches for the extraction of nuclear PDFs from experimental data, we discuss how different measurements in fixed-target and collider experiments provide increasingly precise constraints on various aspects of nuclear PDFs, including shadowing, antishadowing, the EMC effect, Fermi motion, flavor separation, deuteron binding, target-mass and other higher-twist effects. Particular emphasis is given to measurements carried out in proton-lead collisions at the Large Hadron Collider, which have revolutionized the global analysis during the past decade. These measurements include electroweak-boson, jet, light-hadron, and heavy-flavor observables. Finally, we outline the expected impact of the future Electron Ion Collider and discuss the role and interplay of nuclear PDFs with other branches of nuclear, particle and astroparticle physics."], "authors": "M. Klasen"},
{"Title": "Superallowed nuclear beta decays and precision tests of the Standard Model", "abs": ["For many decades, the main source of information on the top-left corner element of the Cabibbo-Kobayashi-Maskawa quark mixing matrix $V_{ud}$ were superallowed nuclear beta decays with an impressive 0.01\\% precision. This precision, apart from experimental data, relies on theoretical calculations in which nuclear structure-dependent effects and uncertainties play a prime role. This review is dedicated to a thorough reassessment of all ingredients that enter the extraction of the value of $V_{ud}$ from experimental data. We tried to keep balance between historical retrospect and new developments, many of which occurred in just five past years. They have not yet been reviewed in a complete manner, not least because new results are a-coming. This review aims at filling this gap and offers an in-depth yet accessible summary of all recent developments."], "authors": "Mikhail Gorchtein"},
{"Title": "The $p^\\uparrow$ and $^3$He$^\\uparrow$ beam polarization measurements at the RHIC and future EIC using the Polarized Atomic Hydrogen Gas Jet Target", "abs": ["At the Relativistic Heavy-Ion Collider (RHIC), the Polarized Atomic Hydrogen Gas Jet Target polarimeter (HJET) is employed for the precise measurement of the absolute transverse (vertical) polarization of proton beams, achieving low systematic uncertainties of approximately $\\sigma^\\text{syst}_P/P\\leq0.5\\%$. The acquired experimental data not only facilitated the determination of single $A_\\text{N}(t)$ and double $A_\\text{NN}(t)$ spin analyzing powers for 100 and 255 GeV proton beams but also revealed a non-zero Pomeron spin-flip contribution through a Regge fit. Preliminary results obtained for forward inelastic $p^{\\uparrow}p$ and elastic $p^{\\uparrow}A$ analyzing powers will be discussed. The success of HJET at RHIC suggests its potential application for proton beam polarimetry at the upcoming Electron-Ion Collider (EIC), aiming for an accuracy of 1\\%. Moreover, the provided analysis indicates that the RHIC HJET target can serve as a tool for the precision calibration, with the required accuracy, of the $^3$He ($h$) beam polarization at the EIC."], "authors": "Andrei Poblaguev"},
{"Title": "First results of evaporation residue cross-section measurements of $^{32}$S+$^{208}$Pb system", "abs": ["The dynamics of heavy ion-induced reactions play a critical role in forming super heavy elements (SHE), and one clear signature of the SHE formation is the evaporation residue (ER). In our pursuit of SHE, we present the heaviest element populated in India for ER cross-section measurements. These are the first-ever measurements of the Evaporation Residue (ER) cross-sections for the nuclear reactions between $^{32}$S and $^{208}$Pb. These measurements were conducted above the Coulomb barrier at four distinct beam energies in the laboratory frame, ranging from 176 to 191 MeV at the pelletron Linac facility at the Inter-University Accelerator Centre (IUAC), New Delhi. The Hybrid Recoil Mass Analyzer (HYRA) in a gas-filled mode was employed for these experiments. The obtained range of ER cross-sections enriches our knowledge and helps advance the field of heavy ion-induced reactions, especially in the context of super heavy element formation."], "authors": "R. Sariyal"},
{"Title": "Study of proton-unbound states in $^{24}{\\rm Al}$ relevant for the $^{23}{\\rm Mg}(p,γ)$ reaction in novae", "abs": ["Background: The nucleosynthesis of several proton-rich nuclei is determined by radiative proton-capture reactions on unstable nuclei in nova explosions. One such reaction is $^{23}{\\rm Mg}(p,\\gamma)^{24}{\\rm Al}$, which links the NeNa and MgAl cycles in oxygen-neon (ONe) novae.", "Purpose: To extract $^{23}{\\rm Mg}(p,\\gamma)^{24}{\\rm Al}$ resonance strengths from a study of proton-unbound states in $^{24}{\\rm Al}$, produced via the $^{24}$Mg($^{3}$He,$t$) reaction.", "Methods: A beam of $^3 {\\rm He}^{2+}$ ions at 50.7 MeV was used to produce the states of interest in $^{24}$Al. Proton-triton angular correlations were measured with a $K=600$ QDD magnetic spectrometer and a silicon detector array, located at iThemba LABS, South Africa.", "Results: We measured the excitation energies of the four lowest proton-unbound states in $^{24}$Al and place lower-limits on $\\Gamma_p/\\Gamma$ values for these four states. Together with USD-C shell-model calculations of partial gamma widths, the experimental data are also used to determine resonance strengths for the three lowest $^{23}{\\rm Mg}(p,\\gamma)^{24}{\\rm Al}$ resonances.", "Conclusions: The energy of the dominant first $^{23}{\\rm Mg}(p,\\gamma)$ resonance is determined to be $E_{r} = 481.4 \\pm 1.1$ keV, with a resonance strength $\\omega \\gamma = 18 \\pm 6$ meV."], "authors": "E. C. Vyfers"},
{"Title": "The Giant Pairing Vibration in Heavy Nuclei: Present Status and Future Studies", "abs": ["The Giant Pairing Vibration, a two-nucleon collective mode originating from the second shell above the Fermi surface, has long been predicted and expected to be strongly populated in two-nucleon transfer reactions with cross sections similar to those of the normal Pairing Vibration. Recent experiments have provided evidence for this mode in $^{14,15}$C but, despite sensitive studies, it has not been definitively identified either in Sn or Pb nuclei where pairing correlations are known to play a crucial role near their ground states. In this paper we review the basic theoretical concepts of this \"elusive\" state and the status of experimental searches in heavy nuclei. We discuss the hindrance effects due to Q-value mismatch and the use of weakly-bound projectiles as a way to overcome the limitations of the (p,t) and (t,p) reactions. We also discuss the role of the continuum and conclude with some possible future developments."], "authors": "M. Assié"},
{"Title": "Overview of the experimental quest for the giant pairing vibration", "abs": ["The search for the giant pairing vibration (GPV) has a long standing history since the 1970's when it was predicted. First experimental measurements focused on (p,t) transfer reactions in the heavy nuclei and did not show convincing evidence. The discovery of a signal compatible with the GPV in the light carbon isotopes has renewed the interest for the GPV. It triggered new theoretical models showing that the GPV in the heavy nuclei might be too wide or too melted to be observed and triggered new experiments with radioactive probes based on ($^{6}$He,$^{4}$He) transfer."], "authors": "M. Assié"},
{"Title": "Systematics of the low-energy electric dipole strength in the Sn isotopic chain", "abs": ["We present a systematic study of the mass dependence of the low-energy electric dipole strength (LEDS) in Sn isotopes in the range $ A = 111 - 124$ based on data obtained with the Oslo method and with relativistic Coulomb excitation in forward-angle ($p,p^\\prime$) scattering. The combined data cover an energy range of $2 - 20$ MeV which permits, with minimal assumptions, a decomposition of the total strength into the contribution from the low-energy tail of the isovector giant dipole resonance (IVGDR) and possible resonance-like structures on top of it. In all cases, a resonance peaked at about 8.3 MeV is observed, exhausting an approximately constant fraction of the Thomas-Reiche-Kuhn (TRK) sum rule with a local maximum at $^{120}$Sn which might be related to shell structure effects. For heavier isotopes ($A \\geq 118$) a consistent description of the data requires the inclusion of a second resonance centered at 6.5 MeV, representing the isovector response of the pygmy dipole resonance (PDR). Its strength corresponds to a small fraction of the total LEDS only and shows an approximately linear dependence on mass number. The experimental results are also compared to ab initio-based microscopic calculations to investigate the importance of an inclusion of quasiparticle vibration coupling (qPVC) for a realistic description of the LEDS."], "authors": "M. Markova"},
{"Title": "Measurement of fragment-correlated $γ$-ray emission from $^{252}$Cf(sf)", "abs": ["This paper presents recent experimental results on the yield of prompt fission $\\gamma$ rays from the spontaneous fission of $^{252}$Cf. We use an ionization chamber to tag fission events and measure the masses and kinetic energies of the fission fragments and trans-stilbene organic scintillators to measure the neutrons and $\\gamma$ rays emitted by the fission fragments. The combination of the ionization chamber and trans-stilbene scintillators allows us to determine the properties of neutrons and $\\gamma$ rays in coincidence with the fragments. The yield of $\\gamma$ rays is known to be influenced by the angular momenta (AM) of the fission fragments. We present new experimental evidence that indicates that the total $\\gamma$-ray multiplicity, i.e., the sum of both fragments' emission, saturates at sufficiently high internal fragment excitation energies. We also observe distinct behaviors for the yield of $\\gamma$ rays from the light and heavy fragment, which for certain mass and total kinetic energy (TKE) regions are weakly or anti-correlated, indicating the presence of complex AM generation modes. We also observed a mass- and TKE-dependent anisotropy of the $\\gamma$ rays, which challenges and expands on the conventional notion that the fragments' AM are always aligned perpendicularly to the fission axis. Moreover, the dependence of the anisotropy on mass and TKE indicates a dependence of these properties on the specific fission channels, thus providing an insight into the deformations and dynamics in fission and their connection with experimentally observable quantities."], "authors": "Stefano Marin"},
{"Title": "Emergence of long-range angular correlations in low-multiplicity proton-proton collisions", "abs": ["This Letter presents the measurement of near-side associated per-trigger yields, denoted ridge yields, from the analysis of angular correlations of charged hadrons in proton-proton collisions at $\\sqrt{s}$ = 13 TeV. Long-range ridge yields are extracted for pairs of charged particles with a pseudorapidity difference of $1.4 < |\\Delta\\eta| < 1.8$ and a transverse momentum of $1 < p_{\\rm T} < 2$ GeV/$c$, as a function of the charged-particle multiplicity measured at midrapidity. This study extends the measurements of the ridge yield to the low multiplicity region, where in hadronic collisions it is typically conjectured that a strongly-interacting medium is unlikely to be formed. The precision of the new results allows for the first direct quantitative comparison with the results obtained in $\\mathrm {e^{+}e^{-}}$ collisions at $\\sqrt{s}$ = 91 GeV, where initial-state effects such as pre-equilibrium dynamics and collision geometry are not expected to play a role. In the multiplicity range where the $\\mathrm {e^{+}e^{-}}$ results have good precision, the measured ridge yields in pp collisions are substantially larger than the limits set in $\\mathrm {e^{+}e^{-}}$ annihilations. Consequently, the findings presented in this Letter suggest that the processes involved in $\\mathrm {e^{+}e^{-}}$ annihilations do not contribute significantly to the emergence of long-range correlations in pp collisions."], "authors": "ALICE Collaboration"},
{"Title": "Fission of 215Fr studied with gamma spectroscopic methods", "abs": ["Background: Asymmetric fission is known to occur in two regions, the actinides and sub-lead, and is dependent on the fissioning system excitation energy. Experimental evidence in the sub-lead region show that this mode is surprisingly persistent with increasing energy and its origin is not fully understood.", "Purpose: To experimentally study the fusion-fission reaction of $^{215}$Fr at moderate excitation energy and determine previously unknown independent fission yields and other properties.", "Method: The compound nucleus was formed in the reaction $^{18}$O + $^{197}$Au. The prompt gamma-rays emitted during the reaction were measured with the high efficiency and high granularity $\\nu$-ball2 spectrometer. Independent fission yields of even-even nuclei were determined by detecting triple-gamma cascades in the fission fragments.", "Results: The observed yields, although dominated by a symmetric peak, show maxima for heavy fragment of $Z \\approx 54-56$, which is consistent with the known results in the actinide region but unexpected for the nuclide of interest, and at the studied excitation energy.", "Conclusions: The mode of asymmetric fission is present even at relatively high excitation energies in the system studied. This observation matches experimental findings in the sub-lead region, contrary to the actinides, and so far there is no well-developed explanation of this phenomenon."], "authors": "K. Miernik"},
{"Title": "Exclusive $J/ψ$, $ψ(2s)$, and $e^{+}e^{-}$ pair production in Au$+$Au ultra-peripheral collisions at RHIC", "abs": ["Measurements of exclusive $J/\\psi$, $\\psi(2s)$, and electron-positron ($e^{+}e^{-}$) pair photoproduction in Au$+$Au ultra-peripheral collisions are reported by the STAR experiment at $\\sqrt{s_{_\\mathrm{NN}}}=200~\\rm{GeV}$. We report several first measurements at the Relativistic Heavy-Ion Collider, which are i) $J/\\psi$ photoproduction with large momentum transfer up to $2.2~\\rm{(GeV/c)^{2}}$, ii) coherent $J/\\psi$ photoproduction associated with neutron emissions from nuclear breakup, iii) the rapidity dependence of incoherent $J/\\psi$ photoproduction, iv) the $\\psi(2s)$ photoproduction cross section at mid-rapidity, and v) $e^{+}e^{-}$ pair photoproduction up to high invariant mass of 6 $\\rm{GeV/c^2}$. For measurement ii), the coherent $J/\\psi$ total cross section of $\\gamma^{\\ast} + \\rm{Au} \\rightarrow J/\\psi + \\rm{Au}$ as a function of the center-of-mass energy $W_{\\rm{\\gamma* N}}$ has been obtained without photon energy ambiguities. The data are quantitatively compared with the Monte Carlo models STARlight, Sartre, BeAGLE, and theoretical calculations of gluon saturation with color glass condensate, nuclear shadowing with leading twist approximation, Quantum Electrodynamics, and the Next-to-Leading Order perturbative QCD. At the photon-nucleon center-of-mass energy of 25.0 GeV, the coherent and incoherent $J/\\psi$ cross sections of Au nuclei are found to be $71\\pm10\\%$ and $36\\pm7\\%$, respectively, of that of free protons. These data provide an important experimental constraint for nuclear parton distribution functions and a unique opportunity to advance the understanding of the nuclear modification effect at the top RHIC energy."], "authors": "STAR Collaboration"},
{"Title": "Observation of strong nuclear suppression in exclusive $J/ψ$ photoproduction in Au$+$Au ultra-peripheral collisions at RHIC", "abs": ["We report a measurement of exclusive $J/\\psi$ photoproduction in Au$+$Au ultra-peripheral collisions at $\\sqrt{s_{_\\mathrm{NN}}}=200$ GeV using the STAR detector. For the first time, i) the rapidity correlation between $J/\\psi$ photoproduction and neutron emission from nuclear breakups has been experimentally measured; ii) nuclear suppression factors are measured for both the coherent and incoherent $J/\\psi$ production. At photon-nucleon center-of-mass energy of 25.0 GeV, the coherent and incoherent $J/\\psi$ cross sections of Au nuclei are found to be $71\\pm10\\%$ and $36\\pm7\\%$, respectively, of that of free protons. The stronger suppression observed in the incoherent production provides a new experimental handle to study the initial-state parton density in heavy nuclei. Data are compared with theoretical models quantitatively."], "authors": "STAR Collaboration"},
{"Title": "Measurements of chemical potentials in Pb-Pb collisions at $\\sqrt{s_{\\rm NN}} = 5.02$ TeV", "abs": ["This Letter presents the most precise measurement to date of the matter/antimatter imbalance at midrapidity in Pb-Pb collisions at a center-of-mass energy per nucleon pair $\\sqrt{s_{\\rm NN}} = 5.02$ TeV. Using the Statistical Hadronization framework, it is possible to obtain the value of the electric charge and baryon chemical potentials, $\\mu_Q=-0.18\\pm0.90$ MeV and $\\mu_B=0.71\\pm0.45$ MeV, with unprecedented precision. A centrality-differential study of the antiparticle-to-particle yield ratios of charged pions, protons, $\\Omega$-baryons, and light (hyper)nuclei is performed. These results indicate that the system created in Pb-Pb collisions at the LHC is on average baryon-free and electrically neutral at midrapidity."], "authors": "ALICE Collaboration"},
{"Title": "Validation of the $^{10}\\mathrm{Be}$ Ground-State Molecular Structure Using $^{10}\\mathrm{Be}(p,pα)^{6}\\mathrm{He}$ Triple Differential Reaction Cross-Section Measurements", "abs": ["The cluster structure of the neutron-rich isotope $^{10}$Be has been probed via the $(p,p\\alpha)$ reaction at 150 MeV/nucleon in inverse kinematics and in quasifree conditions. The populated states of $^{6}$He residues were investigated through missing mass spectroscopy. The triple differential cross-section for the ground-state transition was extracted for quasifree angle pairs ($\\theta_{p}$, $\\theta_{\\alpha}$) and compared to distorted-wave impulse approximation reaction calculations performed in a microscopic framework using successively the Tohsaki-Horiuchi-Schuck-Röpke product wave-function and the wave-function deduced from Antisymmetrized Molecular Dynamics calculations. The remarkable agreement between calculated and measured cross-sections in both shape and magnitude validates the molecular structure description of the $^{10}$Be ground-state, configured as an $\\alpha$-$\\alpha$ core with two valence neutrons occupying $\\pi$-type molecular orbitals."], "authors": "P. J. Li"},
{"Title": "Photoproduction of K$^{+}$K$^{-}$ pairs in ultra-peripheral collisions", "abs": ["K$^{+}$K$^{-}$ pairs may be produced in photonuclear collisions, either from the decays of photoproduced $\\phi (1020)$ mesons, or directly as non-resonant K$^{+}$K$^{-}$ pairs. Measurements of K$^{+}$K$^{-}$ photoproduction probe the couplings between the $\\phi (1020)$ and charged kaons with photons and nuclear targets. We present the first measurement of coherent photoproduction of K$^{+}$K$^{-}$ pairs on lead ions in ultra-peripheral collisions using the ALICE detector, including the first investigation of direct K$^{+}$K$^{-}$ production. There is significant K$^{+}$K$^{-}$ production at low transverse momentum, consistent with coherent photoproduction on lead targets. In the mass range $1.1 < M_{\\rm{KK}} < 1.4$ GeV/$c^2$ above the $\\phi (1020)$ resonance, for rapidity $|y_{\\rm{KK}}|<0.8$ and $p_{\\rm T,KK} < 0.1$ GeV/$c$, the measured coherent photoproduction cross section is $\\mathrm{d}\\sigma/\\mathrm{d}y$ = 3.37 $\\pm\\ 0.61$ (stat.) $\\pm\\ 0.15 $ (syst.) mb. The centre-of-mass energy per nucleon of the photon-nucleus (Pb) system $W_{\\gamma \\mathrm{Pb, n}}$ ranges from 33 to 188 GeV, far higher than previous measurements on heavy-nucleus targets. The cross section is larger than expected for $\\phi (1020)$ photoproduction alone. The mass spectrum is fit to a cocktail consisting of $\\phi (1020)$ decays, direct K$^{+}$K$^{-}$ photoproduction, and interference between the two. The confidence regions for the amplitude and relative phase angle for direct K$^{+}$K$^{-}$ photoproduction are presented."], "authors": "ALICE Collaboration"},
{"Title": "Observation of abnormal suppression of $\\mathrm{f}_{0}$(980) production in p$-$Pb collisions at $\\sqrt{s_{\\rm NN}}$ = 5.02 TeV", "abs": ["The dependence of $\\mathrm{f}_{0}$(980) production on the final-state charged-particle multiplicity in p$-$Pb collisions at $\\sqrt{s_{\\mathrm{NN}}} = 5.02$ TeV is reported. The production of $\\mathrm{f}_{0}$(980) is measured with the ALICE detector via the $\\mathrm{f}_0 (980) \\rightarrow \\pi^{+}\\pi^{-}$ decay channel in a midrapidity region of $-0.5<y<0$. Particle yield ratios of $\\mathrm{f}_{0}$(980) to $\\pi$ and $\\mathrm{K}^{*}$(892)$^{0}$ are found to be decreasing with increasing charged-particle multiplicity. The magnitude of the suppression of the $\\mathrm{f}_{0}$(980)/$\\pi$ and $\\mathrm{f}_{0}$(980)/$\\mathrm{K}^{*}$(892)$^{0}$ yield ratios is found to be dependent on the transverse momentum $p_{\\mathrm{T}}$, suggesting different mechanisms responsible for the measured effects. Furthermore, the nuclear modification factor $Q_{\\mathrm{pPb}}$ of $\\mathrm{f}_{0}$(980) is measured in various multiplicity ranges. The $Q_{\\mathrm{pPb}}$ shows a strong suppression of the $\\mathrm{f}_{0}$(980) production in the $p_{\\mathrm{T}}$ region up to about 4 GeV/$c$. The results on the particle yield ratios and $Q_{\\mathrm{pPb}}$ for $\\mathrm{f}_{0}$(980) may help to understand the late hadronic phase in p$-$Pb collisions and the nature of the internal structure of $\\mathrm{f}_{0}$(980) particle."], "authors": "ALICE Collaboration"},
{"Title": "Measurement of (anti)alpha production in central Pb-Pb collisions at $\\sqrt{s_{\\rm NN}}$ = 5.02 TeV", "abs": ["In this letter, measurements of (anti)alpha production in central (0$-$10%) Pb$-$Pb collisions at a center-of-mass energy per nucleon$-$nucleon pair of $\\sqrt{s_{\\rm NN}}$ = 5.02 TeV are presented, including the first measurement of an antialpha transverse-momentum spectrum. Owing to its large mass, (anti)alpha production yields and transverse-momentum spectra are of particular interest because they provide a stringent test of particle production models. The averaged antialpha and alpha spectrum is included into a common blast-wave fit with lighter particles, indicating that the (anti)alpha also participates in the collective expansion of the medium created in the collision. A blast-wave fit including only protons, (anti)alpha, and other light nuclei results in a similar flow velocity as the fit that includes all particles. A similar flow velocity, but a significantly larger kinetic freeze-out temperature is obtained when only protons and light nuclei are included in the fit. The coalescence parameter $B_4$ is well described by calculations from a statistical hadronization model but significantly underestimated by calculations assuming nucleus formation via coalescence of nucleons. Similarly, the (anti)alpha-to-proton ratio is well described by the statistical hadronization model. On the other hand, coalescence calculations including approaches with different implementations of the (anti)alpha substructure tend to underestimate the data."], "authors": "ALICE Collaboration"},
{"Title": "Generation of Robust Entanglement in Plasmonically Coupled Quantum Dots Driven by Quantum Squeezed Light", "abs": ["Our cavity quantum electrodynamics calculations demonstrate generation of steady-state entanglement between a plasmonically coupled pair of quantum dots by using single-mode squeezed light source. We show that strong coupling of plasmons to the incoming light source and the pairwise nature of squeezed photon generation enable the formation of entanglement between the initially unexcited quantum dots. The entanglement of quantum dots, measured as concurrence, can be improved replacing a pulsed source of light to continuous pumping of squeezed photons. Unlike previously introduced schemes the concurrence is robust against variations in the system parameters. Specifically, the generation of entanglement does not rely on fine tuning of plasmon quantum dot coupling. This work provides a new perspective for robust entangled state preparation in open quantum systems."], "authors": "Sina Soleimanikahnoj"},
{"Title": "Low spin spectroscopy of neutron-rich 43,44,45Cl via β and (β}n decay", "abs": ["{\\beta} decay of neutron-rich isotopes 43,45 S,studied at the National Superconducting Cyclotron Laboratory is reported here. {\\beta} delayed {\\gamma} transitions were detected by an array of 16 clover detectors surrounding the Beta Counting Station which consists of a 40x40 Double Sided Silicon Strip Detector followed by a Single Sided Silicon Strip Detector. {\\beta} decay half-lives have been extracted for 43,45 S by correlating implants and decays in the pixelated implant detector with further coincidence with {\\gamma} transitions in the daughter nucleus. The level structure of 43,45 Cl is expanded by the addition of 20 new {\\gamma} transitions in 43Cl and 8 in 45 Cl with the observation of core excited negative-parity states for the first time. For 45 S decay, a large fraction of the {\\beta} decay strength goes to delayed neutron emission populating states in 44 Cl which are also presented. Comparison of experimental observations is made to detailed shell-model calculations using the SDPFSDG-MU interaction to highlight the role of the diminished N = 28 neutron shell gap and the near degeneracy of the proton s 1/2 and d 3/2 orbitals on the structure of the neutron-rich Cl isotopes. The current work also provides further support to a ground state spin-parity assignment of 3/2 + in 45 Cl."], "authors": "V. Tripathi"},
{"Title": "Two Results in the Quantum Theory of Measurements", "abs": ["Two theorems with applications to the quantum theory of measurements are stated and proven. The first one clarifies and amends von Neumann's Measurement Postulate used in the Copenhagen interpretation of quantum mechanics. The second one clarifies the relationship between ``events'' and ``measurements'' and the meaning of measurements in the $ETH$-Approach to quantum mechanics."], "authors": "Simone Del Vecchio"},
{"Title": "Optical coherence and spin population dynamics in $^{171}$Yb$^{3+}$:Y$_2$SiO$_5$ single crystals", "abs": ["$^{171}$Yb$^{3+}$-doped Y$_2$SiO$_5$ crystals are a promising platform for optical quantum memories in long-distance quantum communications. The relevance of this material lies in $^{171}$Yb long optical and spin coherence times, along with a large hyperfine splitting, enabling long quantum storage over large bandwidths. Mechanisms affecting the optical decoherence are however not precisely known, especially since low-temperature measurements have so far focused on the 2 to 4 K range. In this work, we performed two- and three-pulse photon echoes and spectral hole burning to determine optical homogeneous linewidths in two 171 Yb:YSO crystals doped at 2 and 10 ppm. Experiments were performed in the 40 mK to 18 K temperature range, leading to linewidths between 320 Hz, among the narrowest reported for rare-earth ions, and several MHz. Our results show that above 6 K the homogeneous linewidth is mainly due to an elastic two-phonon process which results in a slow broadening with temperature, the homogeneous linewidth reaching only 25 kHz at 10 K. At lower temperatures, interactions with $^{89}$Yb nuclear spin-flips, paramagnetic defects or impurities, and also Yb-Yb interactions for the higher concentrated crystal, are likely the main limiting factor to the homogeneous linewidth. In particular, we conclude that the direct effect of spin and optical excited state lifetime is a minor contribution to optical decoherence in the whole temperature range studied. Our results indicate possible paths and regimes for further decreasing the homogeneous linewidths or maintaining narrow lines at higher $^{171}$Yb concentration."], "authors": "Federico Chiossi"},
{"Title": "Two new non-equivalent three-qubit CHSH games", "abs": ["In this paper, we generalize to three players the well-known CHSH quantum game. To do so, we consider all possible 3 variables Boolean functions and search among them which ones correspond to a game scenario with a quantum advantage (for a given entangled state). In particular we provide two new three players quantum games where, in one case, the best quantum strategy is obtained when the players share a $GHZ$ state, while in the other one the players have a better advantage when they use a $W$ state as their quantum resource. To illustrate our findings we implement our game scenarios on an online quantum computer and prove experimentally the advantage of the corresponding quantum resource for each game."], "authors": "Hamza Jaffali"},
{"Title": "Thermometry with a Dissipative Heavy Impurity", "abs": ["Improving the measurement precision of low temperature is significant in fundamental science and advanced quantum technology application. However, the measurement precision of temperature $T$ usually diverges as $T$ tends to 0. Here, by utilizing a heavy impurity to measure the temperature of a Bose gas, we obtain the Landau bound to precision $\\delta^2 T\\propto T^2$ to avoid the divergence. Moreover, when the initial momentum of the heavy impurity is fixed and non-zero, the measurement precision can be $\\delta^2 T\\propto T^3$ to break the Landau bound. We derive the momentum distribution of the heavy impurity at any moment and obtain the optimal measurement precision of the temperature by calculating the Fisher information. As a result, we find that enhancing the expectation value of the initial momentum can help to improve the measurement precision. In addition, the momentum measurement is the optimal measurement of the temperature in the case of that the initial momentum is fixed and not equal to 0. The kinetic energy measurement is the optimal measurement in the case of that the expectation value of the initial momentum is 0. Finally, we obtain that the temperatures of two Bose gases can be measured simultaneously. The simultaneous measurement precision is proportional to $T^2$ when two temperatures are close to $T$."], "authors": "Dong Xie"},
{"Title": "Quantum Speed Limits based on Schatten norms", "abs": ["We present two families of quantum speed limits (QSLs) for finite-dimensional quantum systems undergoing a general physical process. These QSLs were obtained using Schatten $\\alpha$-norms, firstly exploiting the geometric features of the space of quantum states endowed with some inner product, and secondly employing the Holder's inequality for matrix norms. In particular, for the case of single-qubit states, we find that the geometric QSL is independent of the Schatten norm chosen, thus revealing a universality behavior of such quantifiers. Furthermore, we provide a comparison of these quantum speed limits with existing paradigmatic QSLs in literature, thus showing that the latter results represent particular cases of a general class of QSLs related to Schatten $\\alpha$-norms. Noteworthy, we address necessary and sufficient conditions for the tightness of the quantum speed limit that mostly depends on the populations and quantum coherences of the evolved single-qubit state, and also present a geometric interpretation for these set of conditions. Finally, we compare the two QSL obtained for the dynamics of single-qubit states, also presenting an inequality between them that has a clear geometrical meaning."], "authors": "Alberto J. B. Rosal"},
{"Title": "Control of a single-photon router via an extra cavity", "abs": ["Controllable single-photon routing plays an important role in quantum networks. We investigate single-photon scattering in two one-dimensional (1D) waveguides by a three-level emitter with a cascade configuration, which is a dipole coupled to an extra cavity. The tunneling path for the transmission of a single photon is switched by whether the extra cavity contains photons. For the setup, the Autler-Townes splitting is modulated by the extra cavity, in which the transmission valley (reflection range) width is tunable in terms of the number of photons in the extra cavity. Our investigation will be beneficial to single-photon routing in quantum networks using quantifiable photon numbers in an extra cavity."], "authors": "Yike Luo"},
{"Title": "Absolute separability witnesses for symmetric multiqubit states", "abs": ["The persistent separability of certain quantum states, known as symmetric absolutely separable (SAS), under symmetry-preserving global unitary transformations is of key significance in the context of quantum resources for bosonic systems. In this work, we develop criteria for detecting SAS states of any number of qubits. Our approach is based on the Glauber-Sudarshan $P$ representation for finite-dimensional quantum systems. We introduce three families of SAS witnesses, one linear and two non-linear in the state $\\rho$, formulated respectively as an algebraic inequality or a quadratic optimization problem. These witnesses are capable of identifying more SAS states than previously known counterparts. We also explore the geometric properties of the subsets of SAS states detected by our witnesses, shedding light on their distinctions."], "authors": "Eduardo Serrano-Ensástiga"},
{"Title": "Subsystem eigenstate thermalization hypothesis for translation invariant systems", "abs": ["The eigenstate thermalization hypothesis for translation invariant quantum spin systems has been proved recently by using random matrices. In this paper, we study the stronger subsystem version of eigenstate thermalization hypothesis for translation invariant quantum systems without referring to random matrices. By showing the small upper bounds on the quantum variance or the Belavkin-Staszewski relative entropy, we prove the subsystem eigenstate thermalization hypothesis for translation invariant quantum systems in an elementary way."], "authors": "Zhiqiang Huang"},
{"Title": "Dynamics of a quantum system interacting with non-Gaussian baths: Poisson noise master equation", "abs": ["Quantum systems are unavoidably open to their surrounding degrees of freedom. The theory of open quantum systems is thus crucial to understanding the fluctuations, dissipation, and decoherence of a quantum system of interest. Typically, the bath is modeled as an ensemble of harmonic oscillators, which yields Gaussian statistics of the bath influence on the quantum systems. However, there are also phenomena in which the bath consists of two-state systems, spins, or anharmonic oscillators; therefore, the non-Gaussian properties of the bath become important. Nevertheless, a theoretical framework to describe quantum systems under the influence of such non-Gaussian baths is not well established. Here, we develop a theory describing quantum dissipative systems affected by Poisson noise properties of the bath as Poisson noise is fundamental in describing non-Gaussian white noises. In contrast to past studies that modeled the bath as a classical stochastic noise source producing only pure dephasing, we introduce a quantum bath model that allows for the consistent description of dissipative quantum systems. The property of the constructed bath model is consistent with the Poisson noise properties when the bath correlation time is short and the bath interacts with the quantum system strongly but discretely. The obtained results reveal non-Gaussian bath effects in the white noise regime, and they provide an essential step toward describing open quantum dynamics under the influence of generic non-Gaussian baths. Our findings can be used to design baths with non-Gaussian properties for dissipative quantum state engineering in quantum information science, as well as to explore non-Gaussian bath effects in biophysical chemistry and condensed matter physics."], "authors": "Ken Funo"},
{"Title": "Impact of Data Augmentation on QCNNs", "abs": ["In recent years, Classical Convolutional Neural Networks (CNNs) have been applied for image recognition successfully. Quantum Convolutional Neural Networks (QCNNs) are proposed as a novel generalization to CNNs by using quantum mechanisms. The quantum mechanisms lead to an efficient training process in QCNNs by reducing the size of input from $N$ to $log_2N$. This paper implements and compares both CNNs and QCNNs by testing losses and prediction accuracy on three commonly used datasets. The datasets include the MNIST hand-written digits, Fashion MNIST and cat/dog face images. Additionally, data augmentation (DA), a technique commonly used in CNNs to improve the performance of classification by generating similar images based on original inputs, is also implemented in QCNNs. Surprisingly, the results showed that data augmentation didn't improve QCNNs performance. The reasons and logic behind this result are discussed, hoping to expand our understanding of Quantum machine learning theory."], "authors": "Leting Zhouli"},
{"Title": "Quantum Kernel t-Distributed Stochastic Neighbor Embedding", "abs": ["Data visualization is important in understanding the characteristics of data that are difficult to see directly. It is used to visualize loss landscapes and optimization trajectories to analyze optimization performance. Popular optimization analysis is performed by visualizing a loss landscape around the reached local or global minimum using principal component analysis. However, this visualization depends on the variational parameters of a quantum circuit rather than quantum states, which makes it difficult to understand the mechanism of optimization process through the property of quantum states. Here, we propose a quantum data visualization method using quantum kernels, which enables us to offer fast and highly accurate visualization of quantum states. In our numerical experiments, we visualize hand-written digits dataset and apply $k$-nearest neighbor algorithm to the low-dimensional data to quantitatively evaluate our proposed method compared with a classical kernel method. As a result, our proposed method achieves comparable accuracy to the state-of-the-art classical kernel method, meaning that the proposed visualization method based on quantum machine learning does not degrade the separability of the input higher dimensional data. Furthermore, we visualize the optimization trajectories of finding the ground states of transverse field Ising model and successfully find the trajectory characteristics. Since quantum states are higher dimensional objects that can only be seen via observables, our visualization method, which inherits the similarity of quantum data, would be useful in understanding the behavior of quantum circuits and algorithms."], "authors": "Yoshiaki Kawase"},
{"Title": "Sharp Thresholds Imply Circuit Lower Bounds: from random 2-SAT to Planted Clique", "abs": ["We show that sharp thresholds for Boolean functions directly imply average-case circuit lower bounds. More formally we show that any Boolean function exhibiting a sharp enough threshold at \\emph{arbitrary} critical density cannot be computed by Boolean circuits of bounded depth and polynomial size.", "Our general result implies new average-case bounded depth circuit lower bounds in a variety of settings.", "(a) ($k$-cliques) For $k=\\Theta(n)$, we prove that any circuit of depth $d$ deciding the presence of a size $k$ clique in a random graph requires exponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is the first average-case exponential size lower bound for bounded depth (not necessarily monotone) circuits solving the fundamental $k$-clique problem (for any $k=k_n$).", "(b)(random 2-SAT) We prove that any circuit of depth $d$ deciding the satisfiability of a random 2-SAT formula requires exponential-in-$n^{\\Theta(1/d)}$ size. To the best of our knowledge, this is the first bounded depth circuit lower bound for random $k$-SAT for any value of $k \\geq 2.$ Our results also provide the first rigorous lower bound in agreement with a conjectured, but debated, ``computational hardness'' of random $k$-SAT around its satisfiability threshold.", "(c)(Statistical estimation -- planted $k$-clique) Over the recent years, multiple statistical estimation problems have also been proven to exhibit a ``statistical'' sharp threshold, called the All-or-Nothing (AoN) phenomenon. We show that AoN also implies circuit lower bounds for statistical problems. As a simple corollary of that, we prove that any circuit of depth $d$ that solves to information-theoretic optimality a ``dense'' variant of the celebrated planted $k$-clique problem requires exponential-in-$n^{\\Theta(1/d)}$ size."], "authors": "David Gamarnik"},
{"Title": "Complexity-theoretic foundations of BosonSampling with a linear number of modes", "abs": ["BosonSampling is the leading candidate for demonstrating quantum computational advantage in photonic systems. While we have recently seen many impressive experimental demonstrations, there is still a formidable distance between the complexity-theoretic hardness arguments and current experiments. One of the largest gaps involves the ratio of photons to modes: all current hardness evidence assumes a \"high-mode\" regime in which the number of linear optical modes scales at least quadratically in the number of photons. By contrast, current experiments operate in a \"low-mode\" regime with a linear number of modes. In this paper we bridge this gap, bringing the hardness evidence for the low-mode experiments to the same level as had been previously established for the high-mode regime. This involves proving a new worst-to-average-case reduction for computing the Permanent that is robust to large numbers of row repetitions and also to distributions over matrices with correlated entries."], "authors": "Adam Bouland"},
{"Title": "Efficient Pauli channel estimation with logarithmic quantum memory", "abs": ["Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\\epsilon$. Prior work (Chen et al., 2022) proved no-go theorems for this task in the practical regime where one has a limited amount of quantum memory, e.g. any protocol with $\\le 0.99n$ ancilla qubits of quantum memory must make exponentially many measurements, provided it is non-concatenating. Such protocols can only interact with the channel by repeatedly preparing a state, passing it through the channel, and measuring immediately afterward.", "This left open a natural question: does the lower bound hold even for general protocols, i.e. ones which chain together many queries to the channel, interleaved with arbitrary data-processing channels, before measuring? Surprisingly, in this work we show the opposite: there is a protocol that can estimate the eigenvalues of a Pauli channel to error $\\epsilon$ using only $O(\\log n/\\epsilon^2)$ ancilla qubits and $\\tilde{O}(n^2/\\epsilon^2)$ measurements. In contrast, we show that any protocol with zero ancilla, even a concatenating one, must make $\\Omega(2^n/\\epsilon^2)$ measurements, which is tight.", "Our results imply, to our knowledge, the first quantum learning task where logarithmically many qubits of quantum memory suffice for an exponential statistical advantage."], "authors": "Sitan Chen"},
{"Title": "Skipper: Improving the Reach and Fidelity of Quantum Annealers by Skipping Long Chains", "abs": ["Quantum Annealers (QAs) operate as single-instruction machines, lacking a SWAP operation to overcome limited qubit connectivity. Consequently, multiple physical qubits are chained to form a program qubit with higher connectivity, resulting in a drastically diminished effective QA capacity by up to 33x. We observe that in QAs: (a) chain lengths exhibit a power-law distribution, a few dominant chains holding substantially more qubits than others; and (b) about 25% of physical qubits remain unused, getting isolated between these chains. We propose Skipper, a software technique that enhances the capacity and fidelity of QAs by skipping dominant chains and substituting their program qubit with two readout results. Using a 5761-qubit QA, we demonstrate that Skipper can tackle up to 59% (Avg. 28%) larger problems when eleven chains are skipped. Additionally, Skipper can improve QA fidelity by up to 44% (Avg. 33%) when cutting five chains (32 runs). Users can specify up to eleven chain cuts in Skipper, necessitating about 2,000 distinct quantum executable runs. To mitigate this, we introduce Skipper-G, a greedy scheme that skips sub-problems less likely to hold the global optimum, executing a maximum of 23 quantum executables with eleven chain trims. Skipper-G can boost QA fidelity by up to 41% (Avg. 29%) when cutting five chains (11 runs)."], "authors": "Ramin Ayanzadeh"},
{"Title": "Quantum Multiple Kernel Learning in Financial Classification Tasks", "abs": ["Financial services is a prospect industry where unlocked near-term quantum utility could yield profitable potential, and, in particular, quantum machine learning algorithms could potentially benefit businesses by improving the quality of predictive models. Quantum kernel methods have demonstrated success in financial, binary classification tasks, like fraud detection, and avoid issues found in variational quantum machine learning approaches. However, choosing a suitable quantum kernel for a classical dataset remains a challenge. We propose a hybrid, quantum multiple kernel learning (QMKL) methodology that can improve classification quality over a single kernel approach. We test the robustness of QMKL on several financially relevant datasets using both fidelity and projected quantum kernel approaches. We further demonstrate QMKL on quantum hardware using an error mitigation pipeline and show the benefits of QMKL in the large qubit regime."], "authors": "Shungo Miyabe"},
{"Title": "A Policy Gradient Method for Confounded POMDPs", "abs": ["In this paper, we propose a policy gradient method for confounded partially observable Markov decision processes (POMDPs) with continuous state and observation spaces in the offline setting. We first establish a novel identification result to non-parametrically estimate any history-dependent policy gradient under POMDPs using the offline data. The identification enables us to solve a sequence of conditional moment restrictions and adopt the min-max learning procedure with general function approximation for estimating the policy gradient. We then provide a finite-sample non-asymptotic bound for estimating the gradient uniformly over a pre-specified policy class in terms of the sample size, length of horizon, concentratability coefficient and the measure of ill-posedness in solving the conditional moment restrictions. Lastly, by deploying the proposed gradient estimation in the gradient ascent algorithm, we show the global convergence of the proposed algorithm in finding the history-dependent optimal policy under some technical conditions. To the best of our knowledge, this is the first work studying the policy gradient method for POMDPs under the offline setting."], "authors": "Mao Hong"},
{"Title": "On Learning the Optimal Regularization Parameter in Inverse Problems", "abs": ["Selecting the best regularization parameter in inverse problems is a classical and yet challenging problem. Recently, data-driven approaches have become popular to tackle this challenge. These approaches are appealing since they do require less a priori knowledge, but their theoretical analysis is limited. In this paper, we propose and study a statistical machine learning approach, based on empirical risk minimization. Our main contribution is a theoretical analysis, showing that, provided with enough data, this approach can reach sharp rates while being essentially adaptive to the noise and smoothness of the problem. Numerical simulations corroborate and illustrate the theoretical findings. Our results are a step towards grounding theoretically data-driven approaches to inverse problems."], "authors": "Jonathan Chirinos Rodriguez"},
{"Title": "First-order coherent quantum Zeno dynamics and its appearance in tight-binding chains", "abs": ["The coherent quantum Zeno dynamics (QZD) is a special unitary time evolution in which a quantum population transition gets constrained in a subspace of the entire Hilbert space. We show that coherent QZD can be categorized by orders for the first time, where only the zeroth-order type has been well investigated. In this paper, we focus on the little-known first-order coherent QZD (FC-QZD). We also construct some chain-like systems described by the tight-binding model which establishes FC-QZD in the form of a surprisingly nonlocal end-to-end population transition."], "authors": "Yuhan Mei"},
{"Title": "Sparse Projected Averaged Regression for High-Dimensional Data", "abs": ["We examine the linear regression problem in a challenging high-dimensional setting with correlated predictors to explain and predict relevant quantities, with explicitly allowing the regression coefficient to vary from sparse to dense. Most classical high-dimensional regression estimators require some degree of sparsity. We discuss the more recent concepts of variable screening and random projection as computationally fast dimension reduction tools, and propose a new random projection matrix tailored to the linear regression problem with a theoretical bound on the gain in expected prediction error over conventional random projections.", "Around this new random projection, we built the Sparse Projected Averaged Regression (SPAR) method combining probabilistic variable screening steps with the random projection steps to obtain an ensemble of small linear models. In difference to existing methods, we introduce a thresholding parameter to obtain some degree of sparsity.", "In extensive simulations and two real data applications we guide through the elements of this method and compare prediction and variable selection performance to various competitors. For prediction, our method performs at least as good as the best competitors in most settings with a high number of truly active variables, while variable selection remains a hard task for all methods in high dimensions."], "authors": "Roman Parzer"},
{"Title": "On the spectrum of the screened Coulomb potential $V(r)=-r^{-1}e^{-C/r}$", "abs": ["We analyse recent contradictory results and conclusions about the spectrum of the screened Coulomb potential $V(r)=-r^{-1}e^{-C/r}$. The well known Hellmann-Feynman theorem shows that all the bound states of the Coulomb potential ($C=0$) remain bounded as $C$ increases. We derive a simple approximate analytical expression for the eigenvalues for sufficiently small values of the screening parameter $C$ and an approximate asymptotic expression for the asymptotic behaviour of the s-state eigenvalues when $C\\rightarrow \\infty $. Present results are expected to resolve the discrepancy about the spectrum of the quantum-mechanical model just mentioned."], "authors": "Francisco M. Fernández"},
{"Title": "Binary perceptrons capacity via fully lifted random duality theory", "abs": ["We study the statistical capacity of the classical binary perceptrons with general thresholds $\\kappa$. After recognizing the connection between the capacity and the bilinearly indexed (bli) random processes, we utilize a recent progress in studying such processes to characterize the capacity. In particular, we rely on \\emph{fully lifted} random duality theory (fl RDT) established in \\cite{Stojnicflrdt23} to create a general framework for studying the perceptrons' capacities. Successful underlying numerical evaluations are required for the framework (and ultimately the entire fl RDT machinery) to become fully practically operational. We present results obtained in that directions and uncover that the capacity characterizations are achieved on the second (first non-trivial) level of \\emph{stationarized} full lifting. The obtained results \\emph{exactly} match the replica symmetry breaking predictions obtained through statistical physics replica methods in \\cite{KraMez89}. Most notably, for the famous zero-threshold scenario, $\\kappa=0$, we uncover the well known $\\alpha\\approx0.8330786$ scaled capacity."], "authors": "Mihailo Stojnic"},
{"Title": "The spectrum of the Laplacian on closed manifolds and the heat asymptotics near cones", "abs": ["Let $\\mathcal{M}$ be a smooth, closed and connected manifold of dimension $n\\in\\mathbb{N}$, endowed with a Riemannian metric $g$. Moreover, let $\\mathcal{B}$ be an $(n+1)$-dimensional compact manifold with boundary equal to $\\mathcal{M}$. Endow $\\mathcal{B}$ with a Riemannian metric $h$ such that, in local coordinates $(x,y)\\in [0,1)\\times \\mathcal{M}$ on the collar part of the boundary, it admits the warped product form $h=dx^{2}+x^{2}g(y)$. We consider the homogeneous heat equation on $(\\mathcal{B},h)$ and find an arbitrary long asymptotic expansion of the solutions with respect to $x$ near $0$. It turns out that the spectrum of the Laplacian on $(\\mathcal{M},g)$ determines explicitly the above asymptotic expansion and vice versa."], "authors": "Nikolaos Roidos"},
{"Title": "Qutrit codes within representations of SU(3)", "abs": ["We describe a quantum error-detecting and error-correcting code embedded within irreducible representations of SU(3). These logical qutrits inherit the He(3) symmetries induced by the representation, while protecting against small SU(3) displacements. We explore the general methodology for finding codes from structure-inducing representations of groups, together with symmetries inherited from finite subgroups, extending the case of spin representations of SU(2)."], "authors": "Xzavier Herbert"},
{"Title": "Shelukhin's Hofer distance and a symplectic cohomology barcode for contactomorphisms", "abs": ["This paper constructs a persistence module of Floer cohomology groups associated to a contactomorphism of the ideal boundary of a Liouville manifold. The barcode (or, bottleneck) distance between the persistence modules is bounded from above by Shelukhin's Hofer distance. Moreover, the barcode is supported (i.e., has spectrum) on the lengths of translated points of the contactomorphism. We use this structure to prove various existence results for translated points and to construct spectral invariants for contactomorphisms which are monotone with respect to positive paths and continuous with respect to Shelukhin's Hofer distance. While this paper was nearing completion, the author was made aware of similar upcoming work by Djordjević, Uljarević, Zhang."], "authors": "Dylan Cant"},
{"Title": "Studying Hopfield models via fully lifted random duality theory", "abs": ["Relying on a recent progress made in studying bilinearly indexed (bli) random processes in \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23}, the main foundational principles of fully lifted random duality theory (fl RDT) were established in \\cite{Stojnicflrdt23}. We here study famous Hopfield models and show that their statistical behavior can be characterized via the fl RDT. Due to a nestedly lifted nature, the resulting characterizations and, therefore, the whole analytical machinery that produces them, become fully operational only if one can successfully conduct underlying numerical evaluations. After conducting such evaluations for both positive and negative Hopfield models, we observe a remarkably fast convergence of the fl RDT mechanism. Namely, for the so-called square case, the fourth decimal precision is achieved already on the third (second non-trivial) level of lifting (3-sfl RDT) for the positive and on the fourth (third non-trivial) level of lifting (4-sfl RDT) for the corresponding negative model. In particular, we obtain the scaled ground state free energy $\\approx 1.7788$ for the positive and $\\approx 0.3279$ for the negative model."], "authors": "Mihailo Stojnic"},
{"Title": "Physics-informed dynamic mode decomposition (piDMD)", "abs": ["In this work, we demonstrate how physical principles -- such as symmetries, invariances, and conservation laws -- can be integrated into the dynamic mode decomposition (DMD). DMD is a widely-used data analysis technique that extracts low-rank modal structures and dynamics from high-dimensional measurements. However, DMD frequently produces models that are sensitive to noise, fail to generalize outside the training data, and violate basic physical laws. Our physics-informed DMD (piDMD) optimization, which may be formulated as a Procrustes problem, restricts the family of admissible models to a matrix manifold that respects the physical structure of the system. We focus on five fundamental physical principles -- conservation, self-adjointness, localization, causality, and shift-invariance -- and derive several closed-form solutions and efficient algorithms for the corresponding piDMD optimizations. With fewer degrees of freedom, piDMD models are less prone to overfitting, require less training data, and are often less computationally expensive to build than standard DMD models. We demonstrate piDMD on a range of challenging problems in the physical sciences, including energy-preserving fluid flow, travelling-wave systems, the Schrödinger equation, solute advection-diffusion, a system with causal dynamics, and three-dimensional transitional channel flow. In each case, piDMD significantly outperforms standard DMD in metrics such as spectral identification, state prediction, and estimation of optimal forcings and responses."], "authors": "Peter J. Baddoo"},
{"Title": "Markovian Embeddings of Non-Markovian Quantum Systems: Coupled Stochastic and Quantum Master Equations for Non-Markovian Quantum Systems", "abs": ["Quantum Markov models are employed ubiquitously in quantum physics and in quantum information theory due to their relative simplicity and analytical tractability. In particular, these models are known to give accurate approximations for a wide range of quantum optical and mesoscopic systems. However, in general, the validity of the Markov approximation entails assumptions regarding properties of the system of interest and its environment, which may not be satisfied or accurate in arbitrary physical systems. Therefore, developing useful modelling tools for general non-Markovian quantum systems for which the Markov approximation is inappropriate or deficient is an undertaking of significant importance. This work considers non-Markovian principal quantum systems that can be embedded in a larger Markovian quantum system with one or more compound baths consisting of an auxiliary quantum system and a quantum white noise field, and derives a set of coupled stochastic and quantum master equations for embedded non-Markovian quantum systems. The case of a purely Hamiltonian coupling between the principal and auxiliary systems as a closed system without coupling to white noises is included as a special case. The results are expected to be of interest for (open-loop and feedback) control of continuous-time non-Markovian systems and studying reduced models for numerical simulation of such systems. They may also shed more light on the general structure of continuous-time non-Markovian quantum systems."], "authors": "H. I. Nurdin"},
{"Title": "Fully lifted random duality theory", "abs": ["We study a generic class of \\emph{random optimization problems} (rops) and their typical behavior. The foundational aspects of the random duality theory (RDT), associated with rops, were discussed in \\cite{StojnicRegRndDlt10}, where it was shown that one can often infer rops' behavior even without actually solving them. Moreover, \\cite{StojnicRegRndDlt10} uncovered that various quantities relevant to rops (including, for example, their typical objective values) can be determined (in a large dimensional context) even completely analytically. The key observation was that the \\emph{strong deterministic duality} implies the, so-called, \\emph{strong random duality} and therefore the full exactness of the analytical RDT characterizations. Here, we attack precisely those scenarios where the strong deterministic duality is not necessarily present and connect them to the recent progress made in studying bilinearly indexed (bli) random processes in \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23}. In particular, utilizing a fully lifted (fl) interpolating comparison mechanism introduced in \\cite{Stojnicnflgscompyx23}, we establish corresponding \\emph{fully lifted} RDT (fl RDT). We then rely on a stationarized fl interpolation realization introduced in \\cite{Stojnicsflgscompyx23} to obtain complete \\emph{statitionarized} fl RDT (sfl RDT). A few well known problems are then discussed as illustrations of a wide range of practical applications implied by the generality of the considered rops."], "authors": "Mihailo Stojnic"},
{"Title": "Modern Koopman Theory for Dynamical Systems", "abs": ["The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to reduce Koopman theory to practice in real-world applications. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of applications. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems."], "authors": "Steven L. Brunton"},
{"Title": "Dynamical Magic Transitions in Monitored Clifford+T Circuits", "abs": ["The classical simulation of highly-entangling quantum dynamics is conjectured to be generically hard. Thus, recently discovered measurement-induced transitions between highly entangling and low-entanglement dynamics are phase transitions in classical simulability. Here, we study simulability transitions beyond entanglement: noting that some highly-entangling dynamics (e.g., integrable systems or Clifford circuits) are easy to classically simulate, thus requiring \"magic\"--a subtle form of quantum resource--to achieve computational hardness, we ask how the dynamics of magic competes with measurements. We study the resulting \"dynamical magic transitions\" focusing on random monitored Clifford circuits doped by T gates (injecting magic). We identify dynamical \"stabilizer-purification\"--the collapse of a superposition of stabilizer states by measurements--as the mechanism driving this transition. We find cases where transitions in magic and entanglement coincide, but also others with a magic and simulability transition in a highly (volume-law) entangled phase. In establishing our results, we use Pauli-based computation, a scheme distilling the quantum essence of the dynamics to a magic state register subject to mutually commuting measurements. We link stabilizer-purification to \"magic fragmentation\" wherein these measurements separate into disjoint, O(1)-weight blocks, and relate this to the spread of magic in the original circuit becoming arrested."], "authors": "M. Bejan"},
{"Title": "The Functional Average Treatment Effect", "abs": ["This paper establishes the functional average as an important estimand for causal inference. The significance of the estimand lies in its robustness against traditional issues of confounding. We prove that this robustness holds even when the probability distribution of the outcome, conditional on treatment or some other vector of adjusting variables, differs almost arbitrarily from its counterfactual analogue. This paper also examines possible estimators of the functional average, including the sample mid-range, and proposes a new type of bootstrap for robust statistical inference: the Hoeffding bootstrap. After this, the paper explores a new class of variables, the $\\mathcal{U}$ class of variables, that simplifies the estimation of functional averages. This class of variables is also used to establish mean exchangeability in some cases and to provide the results of elementary statistical procedures, such as linear regression and the analysis of variance, with causal interpretations. Simulation evidence is provided. The methods of this paper are also applied to a National Health and Nutrition Survey data set to investigate the causal effect of exercise on the blood pressure of adult smokers."], "authors": "Shane Sparkes"},
{"Title": "The Multiverse of Dynamic Mode Decomposition Algorithms", "abs": ["Dynamic Mode Decomposition (DMD) is a popular data-driven analysis technique used to decompose complex, nonlinear systems into a set of modes, revealing underlying patterns and dynamics through spectral analysis. This review presents a comprehensive and pedagogical examination of DMD, emphasizing the role of Koopman operators in transforming complex nonlinear dynamics into a linear framework. A distinctive feature of this review is its focus on the relationship between DMD and the spectral properties of Koopman operators, with particular emphasis on the theory and practice of DMD algorithms for spectral computations. We explore the diverse \"multiverse\" of DMD methods, categorized into three main areas: linear regression-based methods, Galerkin approximations, and structure-preserving techniques. Each category is studied for its unique contributions and challenges, providing a detailed overview of significant algorithms and their applications as outlined in Table 1. We include a MATLAB package with examples and applications to enhance the practical understanding of these methods. This review serves as both a practical guide and a theoretical reference for various DMD methods, accessible to both experts and newcomers, and enabling readers to delve into their areas of interest in the expansive field of DMD."], "authors": "Matthew J. Colbrook"},
{"Title": "Adiabatic-Passage Based Parameter Setting Method for Quantum Approximate Optimization Algorithm on 3-SAT Problem", "abs": ["The quantum approximate optimization algorithm (QAOA) shows great computational potential on combinatorial optimization problems. It is a promising algorithm on near-term quantum devices, but one of the difficulty in application of QAOA is the complexity of parameter setting. In this paper, an adiabatic-passage based parameter setting method is proposed and applied to 3-SAT. And in simulation, the optimization cost is significantly reduced, approximately between sublinear to logarithmic on the depth $p$ of QAOA. The efficiency of this method mainly stems from two aspects, one is the problem-oriented preprocessing of Hamiltonian, and the other is the parameter space adjustment based on the continuity of adiabatic passage. Firstly, a random model for 3-SAT is provided and the problem Hamiltonian of this model is designed as a random matrix. Based on the statistical property of randomized Hamiltonian, the Hamiltonian of QAOA is preprocessed and the parameter setting is seperated from the overal property of the problem. As a result, a good initialization can be obtained. Secondly, the optimal adiabatic passage is introduced and actrually, the QAOA can be regarded as the parameterization of adiabatic passage and the optimization as the search of the optimal adiabatic passage. Based on this, the adiabatic passage is parameterized as another parameter space with better continuity and the adiabatic-passage based parameter setting method is proposed."], "authors": "Mingyou Wu"},
{"Title": "On random pairwise comparisons matrices and their geometry", "abs": ["We describe a framework for random pairwise comparisons matrices, inspired by selected constructions releted to the so called inconsistency reduction of pairwise comparisons (PC) matrices. In to build up structures on random pairwise comparisons matrices, the set up for (deterministic) PC matrices for non-reciprocal PC matrices is completed. The extension of basic concepts such as inconsistency indexes and geometric mean method are extended to random pairwise comparisons matrices and completed by new notions which seem useful to us. Two procedures for (random) inconsistency reduction are sketched, based on well-known existing objects, and a fiber bundle-like decomposition of random pairwise comparisons is proposed."], "authors": "Jean-Pierre Magnot"},
{"Title": "On two-dimensional Dirac operators with $δ$-shell interactions supported on unbounded curves with straight ends", "abs": ["In this paper we study the self-adjointness and spectral properties of two-dimensional Dirac operators with electrostatic, Lorentz scalar, and anomalous magnetic $\\delta$-shell interactions with constant weights that are supported on a smooth unbounded curve that is straight outside a compact set and whose ends are rays that are not parallel to each other. For all possible combinations of interaction strengths we describe the self-adjoint realizations and compute their essential spectra. Moreover, we prove in different situations the existence of geometrically induced discrete eigenvalues."], "authors": "Jussi Behrndt"},
{"Title": "Topological 5d $\\mathcal {N} = 2$ Gauge Theory: Novel Floer Homologies, their Dualities, and an $A_\\infty$-category of Three-Manifolds", "abs": ["We show how one can define novel gauge-theoretic Floer homologies of four, three and two-manifolds from the physics of a certain topologically-twisted 5d ${\\cal N}=2$ gauge theory via its supersymmetric quantum mechanics interpretation. They are associated with Vafa-Witten, Hitchin and complexified BF configurations on the four, three and two-manifolds, respectively. We also show how one can define novel symplectic Floer homologies of Hitchin spaces, which in turn will allow us to derive novel Atiyah-Floer correspondences that relate our gauge-theoretic Floer homologies to symplectic intersection Floer homologies of Higgs bundles. Furthermore, topological invariance and 5d \"S-duality\" suggest a web of relations and a Langlands duality amongst these novel Floer homologies and their loop/toroidal group generalizations. Last but not least, via a 2d gauged Landau-Ginzburg model interpretation of the 5d theory, we derive, from the soliton string theory that it defines and the 5d partition function, a Fukaya-Seidel type $A_\\infty$-category of Hitchin configurations on three-manifolds and its Atiyah-Floer correspondence. Our work therefore furnishes purely physical realizations and generalizations of the mathematical conjectures and constructions of Haydys [1], Wang [2] and Abouzaid-Manolescu [3], and more."], "authors": "Arif Er"},
{"Title": "Photo-induced charge carrier dynamics in a semiconductor-based ion trap investigated via motion-sensitive qubit transitions", "abs": ["Ion trap systems built upon microfabricated chips have emerged as a promising platform for quantum computing to achieve reproducible and scalable structures. However, photo-induced charging of materials in such chips can generate undesired stray electric fields that disrupt the quantum state of the ion, limiting high-fidelity quantum control essential for practical quantum computing. While crude understanding of the phenomena has been gained heuristically over the past years, explanations for the microscopic mechanism of photo-generated charge carrier dynamics remains largely elusive. Here, we present a photo-induced charging model for semiconductors, whose verification is enabled by a systematic interaction between trapped ions and photo-induced stray fields from exposed silicon surfaces in our chip. We use motion-sensitive qubit transitions to directly characterize the stray field and analyze its effect on the quantum dynamics of the trapped ion. In contrast to incoherent errors arising from the thermal motion of the ion, coherent errors are induced by the stray field, whose effect is significantly imprinted during the quantum control of the ion. These errors are investigated in depth and methods to mitigate them are discussed. Finally, we extend the implications of our study to other photo-induced charging mechanisms prevalent in ion traps."], "authors": "Woojun Lee"},
{"Title": "Canonical generating function on Legendrian submanifolds on the one-jet bundle", "abs": ["In the present paper, we formulate a contact analogue on the one-jet bundle $J^1B$ of Weinstein's observation which reads the classical action functional on the cotangent bundle is a generating function of any Hamiltonian isotope of the zero section. We do this by identifying the correct action functional which is defined on the space of Hamiltonian-translated (piecewise smooth) horizontal curves of the contact distribution, which we call the Carnot path space. Then we give a canonical construction of the Legendrian generating function which is the Legendrian counterpart of Laudenbach-Sikorav's canonical construction of the generating function of Hamiltonian isotope of the zero section on the cotangent bundle which utilizes a finite dimensional approximation of the action functional.", "Motivated by this construction, we develop a Floer theoretic construction of spectral invariants for the Legendrian submanifolds in the sequel [OY] which is the contact analog to the construction given in [Oh97, Oh99] for the Lagrangian submanifolds in the cotangent bundle."], "authors": "Yong-Geun Oh"},
{"Title": "Open Gromov-Witten theory for cohomologically incompressible Lagrangians", "abs": ["This paper classifies separated bounding pairs for Lagrangian submanifolds that are homologically trivial inside the ambient space, under the assumption that restriction on cohomology from the ambient space to the Lagrangian is surjective. As an application, open Gromov-Witten invariants are defined under the above assumptions. When the Lagrangian is the fixed locus of an anti-symplectic involution, the surjectivity assumption can be somewhat relaxed while the classifying space needs to be modified."], "authors": "Sara B. Tukachinsky"},
{"Title": "From Euclidean field theory to hyperkähler Floer theory via regularized polysymplectic geometry", "abs": ["Hamiltonian Floer theory plays an important role for finding periodic solutions of Hamilton's equation, which can be seen as generalization of Newton's equation. Generalizing Newton's equation to Laplace's equation with non-linearity, we show that this role is taken over by the hyperkähler Floer theory of Hohloch, Noetzel, and Salamon. Apart from establishing $C^0$-bounds in order to be able to deal with noncompact hyperkähler manifolds, the core ingredient is a regularization scheme for the polysymplectic formalism due to Bridges, which allows us to link Euclidean field theory with hyperkähler Floer theory. As a concrete result, we prove a cuplength estimate."], "authors": "Ronen Brilleslijper"},
{"Title": "On the variational treatment of a class of double-well oscillators", "abs": ["We compare the well known Rayleigh-Ritz variational method (RRVM) with a recently proposed approach based on supersymmetric quantum mechanics and the Gram-Schmidt orthogonalization method (SSQMGS). We apply both procedures to a particular class of double-well harmonic oscillators that had been conveniently chosen for the application of the latter approach. The RRVM eigenvalues converge smoothly from above providing much more accurate results with less computational effort. Present results show that the unproved SSQMGS upper bounds do not hold."], "authors": "Francisco M. Fernández"},
{"Title": "Extensible positive loops and vanishing of symplectic cohomology", "abs": ["The symplectic cohomology of certain symplectic manifolds $W$ with non-compact ends modelled on the positive symplectization of a compact contact manifold $Y$ is shown to vanish whenever there is a positive loop of contactomorphisms of $Y$ which extends to a loop of Hamiltonian diffeomorphisms of $W$. An open string version of this result is also proved: the wrapped Floer cohomology of a Lagrangian $L$ with ideal Legendrian boundary $\\Lambda$ is shown to vanish if there is a positive loop $\\Lambda_{t}$ based at $\\Lambda$ which extends to an exact loop of Lagrangians based at $L$. Various examples of such loops are considered. Applications include the construction of exotic compactly supported symplectomorphisms and exotic fillings of $\\Lambda$."], "authors": "Dylan Cant"},
{"Title": "Projective symmetries of three-dimensional TQFTs", "abs": ["Quantum field theory has various projective characteristics which are captured by what are called anomalies. This paper explores this idea in the context of fully-extended three-dimensional topological quantum field theories (TQFTs).", "Given a three-dimensional TQFT (valued in the Morita 3-category of fusion categories), the anomaly identified herein is an obstruction to gauging a naturally occurring orthogonal group of symmetries, i.e. we study 't Hooft anomalies. In other words, the orthogonal group almost acts: There is a lack of coherence at the top level. This lack of coherence is captured by a \"higher (central) extension\" of the orthogonal group, obtained via a modification of the obstruction theory of Etingof-Nikshych-Ostrik-Meir [ENO10]. This extension tautologically acts on the given TQFT/fusion category, and this precisely classifies a projective (equivalently anomalous) TQFT. We explain the sense in which this is an analogue of the classical spin representation. This is an instance of a phenomenon emphasized by Freed [Fre23]: Quantum theory is projective.", "In the appendices we establish a general relationship between the language of projectivity/anomalies and the language of topological symmetries. We also identify a universal anomaly associated with any theory which is appropriately \"simple\"."], "authors": "Jackson Van Dyke"},
{"Title": "Symmetries of quantization of finite groupoids", "abs": ["This paper proves certain facts concerning the equivariance of quantization of pi-finite spaces. We argue that these facts establish an analogy between this quantization procedure and the geometric quantization of a symplectic vector space. Specifically, we observe that symmetries of a given polarization/Lagrangian always induce coherent symmetries of the quantization. On the other hand, symmetries of the entire phase space a priori only induce projective symmetries. For certain three-dimensional theories, this projectivity appears via a twice-categorified analogue of Blattner-Kostant-Sternberg kernels in geometric quantization and the associated integral transforms."], "authors": "Jackson Van Dyke"},
{"Title": "An explicit formula for the zeros of the Riemann zeta function", "abs": ["We present an explicit formula for a weighted sum over the zeros of the Riemann zeta function. This weighted sum is evaluated in terms of a sum over the prime numbers, weighted with help of the Hermite polynomials. From the explicit formula presented in this note, it follows that prime numbers determine the distribution of the zeros of the Riemann zeta function. In fact, it is possible to compute the zeros of the zeta function without actually using this function."], "authors": "Eugenio P Balanzario"},
{"Title": "$\\mathbb{A}^1$-Brouwer degrees in Macaulay2", "abs": ["We describe the Macaulay2 package \"A1BrouwerDegrees\" for computing local and global $\\mathbb{A}^1$-Brouwer degrees and studying symmetric bilinear forms over a field."], "authors": "Nikita Borisov"},
{"Title": "Constant Sum Partition of $\\{1,2,...,n\\}$ Into Subsets With Prescribed Orders", "abs": ["Studies on partition of $I_n$ = $\\{1, 2, . . . , n\\}$ into subsets $S_1, S_2, . . . , S_x$ so far considered with prescribed sum of the elements in each subset. In this paper, we study constant sum partitions $\\{S_1,S_2,...,S_x\\}$ of $I_n$ with prescribed $|S_i|$, $1 \\leq i \\leq x$. Theorem \\ref{thm 2.3} is the main result which gives a necessary and sufficient condition for a partition set $\\{S_1,S_2,\\ldots, S_x\\}$ of $I_n$ with prescribed $|S_i|$ to be a constant sum partition of $I_n$, $1 \\leq i \\leq x$ and $n > x \\geq 2$. We state its applications in graph theory and also define {\\em constant sum partition permutation} or {\\em magic partition permutation} of $I_n$. A partition $\\{S_1,S_2,\\cdots,S_x\\}$ of $I_n$ is a {\\em constant sum partition of $I_n$} if $\\sum_{j\\in S_i}{j}$ is a constant for every $i$, $1 \\leq i \\leq x$."], "authors": "V. Vilfred Kamalappan"},
{"Title": "Star colouring and locally constrained graph homomorphisms", "abs": ["Dvořák, Mohar and Šámal (J. Graph Theory, 2013) proved that for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ admits a locally bijective homomorphism to the cube $Q_3$. We generalise this result as follows: for $p\\geq 2$, a $K_{1,p+1}$-free $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ admits a locally bijective homomorphism to a fixed $2p$-regular graph named $G_{2p}$. We also prove the following: (i) for $p\\geq 2$, a $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ has an orientation $\\vec{G}$ that admits an out-neighbourhood bijective homomorphism to a fixed orientation $\\vec{G_{2p}}$ of $G2p$; (ii) for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ is bipartite and distance-two 4-colourable; and (iii) it is NP-complete to check whether a planar 4-regular 3-connected graph is 4-star colourable."], "authors": "Shalu M. A."},
{"Title": "Uniform estimates for a fully discrete scheme integrating the linear heat equation on a bounded interval with pure Neumann boundary conditions", "abs": ["This manuscript deals with the analysis of numerical methods for the full discretization (in time and space) of the linear heat equation with Neumann boundary conditions, and it provides the reader with error estimates that are uniform in time. First, we consider the homogeneous equation with homogeneous Neumann boundary conditions over a finite interval. Using finite differences in space and the Euler method in time, we prove that our method is of order 1 in space, uniformly in time, under a classical CFL condition, and despite its lack of consistency at the boundaries. Second, we consider the nonhomogeneous equation with nonhomogeneous Neumann boundary conditions over a finite interval. Using a tailored similar scheme, we prove that our method is also of order 1 in space, uniformly in time, under a classical CFL condition. We indicate how this numerical method allows for a new way to compute steady states of such equations when they exist. We conclude by several numerical experiments to illustrate the sharpness and relevance of our theoretical results, as well as to examine situations that do not meet the hypotheses of our theoretical results, and to illustrate how our results extend to higher dimensions."], "authors": "Guillaume Dujardin"},
{"Title": "Combinatorial decompositions for deformed or decorated classes of maps", "abs": ["The perturbative expansion of tensorial field theories in Feynman graphs can be interpreted as weighted generating series of some piecewise linear varieties. This simple fact establishes a link between two a priori distinct fields: the combinatorics of discrete manifolds on one hand and tensorial field theories on the other hand. In this thesis, we study different aspects revolving around this connection between combinatorics and field theory. First, we consider constellations model, which generalize maps and their algebraic properties. This makes them suited to probe the b-deformation, a deformation of the algebra of symmetric functions. We will study the constraints satisfied by the generating series of cubical b-deformed constellations. Second, we analyze the double scaling limit of particular tensor models of order 3. For tensor of order greater than two, the nature of the 1/N-expansion is qualitatively different from the matrix case of order 2. In particular, only the leading order graphs are fully characterized. Despite this fact, it is possible to identify graphs of subleading orders contributing to the double scaling limit by implementing the scheme decomposition for Feynman graphs of these theories. An analysis of the singularity of the schemes then allows us to give a complete characterization of the graphs contributing to the double scaling limit. Finally, we investigate a particular link between a tensor and a vector field theory which both admit a melonic limit. Namely, we will show that we can obtain the vectorial Amit-Roginski model by considering perturbations around a classical solution of the Boulatov model, a tensorial theory. We give sufficient conditions on the classical solution so that the effective action for the perturbation around this solution takes the form of the Amit-Roginski action."], "authors": "Victor Nador"},
{"Title": "IEEE 802.11be Network Throughput Optimization with Multi-Link Operation and AP Coordination", "abs": ["IEEE 802.11be (Wi-Fi 7) introduces a new concept called multi-link operation (MLO) which allows multiple Wi-Fi interfaces in different bands (2.4, 5, and 6 GHz) to work together to increase network throughput, reduce latency, and improve spectrum reuse efficiency in dense overlapping networks. To make the most of MLO, a new intelligent resource allocation is needed. This paper proposes a model to align MLO and access point (AP) coordination in 11be. To maximize network throughput, a network topology optimization problem is formulated for MLO with AP coordination, which is solved by exploiting the totally unimodular property of the bipartite graph formed by the connection between AP and station (STA) in Wi-Fi networks. Subsequently, a proportional fairness algorithm is applied for radio link allocation, network throughput optimization considering the channel condition, and the fairness of the multi-link device (MLD) data rate. The performance of the proposed algorithm on two main MLO implementations - multi-mink multi-radio (MLMR) with simultaneous transmission and reception (STR), and the interplay between multiple nodes employing them are evaluated through cross-layer (PHY-MAC) data rate simulation with PHY abstraction."], "authors": "Lyutianyang Zhang"},
{"Title": "Explicit representations and Azumaya loci of skein algebras of small surfaces", "abs": ["We construct finite dimensional representations of the Kauffman bracket skein algebra of the one-punctured torus and four-punctured sphere at all roots of unity. The representations are given by explicit formulas. They all have dimensions equal to the PI degrees of the skein algebras, and they realize all classical shadows. We then use the reducibility of these representations to determine the Azumaya loci. In particular, the Azumaya loci of these surfaces contain the smooth loci of the classical shadow varieties, with equality in the case of the one-punctured torus and proper containment in the case of the four-punctured sphere."], "authors": "Tao Yu"},
{"Title": "Self-similarity of Communities of the ABCD Model", "abs": ["The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster and can be investigated analytically.", "In this paper, we show that the ABCD model exhibits some interesting self-similar behaviour, namely, the degree distribution of ground-truth communities is asymptotically the same as the degree distribution of the whole graph (appropriately normalized based on their sizes). As a result, we can not only estimate the number of edges induced by each community but also the number of self-loops and multi-edges generated during the process. Understanding these quantities is important as (a) rewiring self-loops and multi-edges to keep the graph simple is an expensive part of the algorithm, and (b) every rewiring causes the underlying configuration models to deviate slightly from uniform simple graphs on their corresponding degree sequences."], "authors": "Jordan Barrett"},
{"Title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs", "abs": ["Data-driven machine learning approaches are being increasingly used to solve partial differential equations (PDEs). They have shown particularly striking successes when training an operator, which takes as input a PDE in some family, and outputs its solution. However, the architectural design space, especially given structural knowledge of the PDE family of interest, is still poorly understood. We seek to remedy this gap by studying the benefits of weight-tied neural network architectures for steady-state PDEs. To achieve this, we first demonstrate that the solution of most steady-state PDEs can be expressed as a fixed point of a non-linear operator. Motivated by this observation, we propose FNO-DEQ, a deep equilibrium variant of the FNO architecture that directly solves for the solution of a steady-state PDE as the infinite-depth fixed point of an implicit operator layer using a black-box root solver and differentiates analytically through this fixed point resulting in $\\mathcal{O}(1)$ training memory. Our experiments indicate that FNO-DEQ-based architectures outperform FNO-based baselines with $4\\times$ the number of parameters in predicting the solution to steady-state PDEs such as Darcy Flow and steady-state incompressible Navier-Stokes. Finally, we show FNO-DEQ is more robust when trained with datasets with more noisy observations than the FNO-based baselines, demonstrating the benefits of using appropriate inductive biases in architectural design for different neural network based PDE solvers. Further, we show a universal approximation result that demonstrates that FNO-DEQ can approximate the solution to any steady-state PDE that can be written as a fixed point equation."], "authors": "Tanya Marwah"},
{"Title": "On the Interplay Between Stepsize Tuning and Progressive Sharpening", "abs": ["Recent empirical work has revealed an intriguing property of deep learning models by which the sharpness (largest eigenvalue of the Hessian) increases throughout optimization until it stabilizes around a critical value at which the optimizer operates at the edge of stability, given a fixed stepsize (Coehn et al, 2022). We investigate empirically how the sharpness evolves when using stepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the stepsize along the iterations to local quantities such as, implicitly, the sharpness itself. We find that the surprisingly poor performance of a classical Armijo linesearch may be well explained by its tendency to ever-increase the sharpness of the objective in the full or large batch regimes. On the other hand, we observe that Polyak stepsizes operate generally at the edge of stability or even slightly beyond, while outperforming its Armijo and constant stepsizes counterparts. We conclude with an analysis that suggests unlocking stepsize tuners requires an understanding of the joint dynamics of the step size and the sharpness."], "authors": "Vincent Roulet"},
{"Title": "What a twist cell experiment tells about a quartic twist theory for chromonics", "abs": ["The elastic theory of chromonic liquid crystals is not completely established. We know, for example, that for anomalously low twist constants (needed for chromonics) the classical Oseen- Frank theory may entail paradoxical consequences when applied to describe the equilibrium shapes of droplets surrounded by an isotropic phase: contrary to experimental evidence, they are predicted to dissolve in a plethora of unstable smaller droplets. We proposed a quartic twist theory that prevents such an instability from happening. Here we apply this theory to the data of an experiment devised to measure the planar anchoring strength at the plates bounding a twist cell filled with a chromonic liquid crystal; these data had before been interpreted within the Oseen-Frank theory. We show that the quartic twist theory affords a slightly better agreement with the experimental data, while delivering a larger value for the anchoring strength."], "authors": "Silvia Paparini"},
{"Title": "The theoretical limits of biometry", "abs": ["Biometry has proved its capability in terms of recognition accuracy. Now, it is widely used for automated border control with the biometric passport, to unlock a smartphone or a computer with a fingerprint or a face recognition algorithm. While identity verification is widely democratized, pure identification with no additional clues is still a work in progress. The identification difficulty depends on the population size, as the larger the group is, the larger the confusion risk. For collision prevention, biometric traits must be sufficiently distinguishable to scale to considerable groups, and algorithms should be able to capture their differences accurately.", "Most biometric works are purely experimental, and it is impossible to extrapolate the results to a smaller or a larger group. In this work, we propose a theoretical analysis of the distinguishability problem, which governs the error rates of biometric systems. We demonstrate simple relationships between the population size and the number of independent bits necessary to prevent collision in the presence of noise. This work provides the lowest lower bound for memory requirements. The results are very encouraging, as the biometry of the whole Earth population can fit in a regular disk, leaving some space for noise and redundancy."], "authors": "Gaëlle Candel"},
{"Title": "Transport Equation based Physics Informed Neural Network to predict the Yield Strength of Architected Materials", "abs": ["In this research, the application of the Physics-Informed Neural Network (PINN) model is explored to solve transport equation-based Partial Differential Equations (PDEs). The primary objective is to analyze the impact of different activation functions incorporated within the PINN model on its predictive performance, specifically assessing the Mean Squared Error (MSE) and Mean Absolute Error (MAE). The dataset used in the study consists of a varied set of input parameters related to strut diameter, unit cell size, and the corresponding yield stress values. Through this investigation the aim is to understand the effectiveness of the PINN model and the significance of choosing appropriate activation functions for solving complex PDEs in real-world applications. The outcomes suggest that the choice of activation function may have minimal influence on the model's predictive accuracy for this particular problem. The PINN model showcases exceptional generalization capabilities, indicating its capacity to avoid overfitting with the provided dataset. The research underscores the importance of striking a balance between performance and computational efficiency while selecting an activation function for specific real-world applications. These valuable findings contribute to advancing the understanding and potential adoption of PINN as an effective tool for solving challenging PDEs in diverse scientific and engineering domains."], "authors": "Akshansh Mishra"},
{"Title": "New polyconvolution product for Fourier-cosine and Laplace integral operators and their applications", "abs": ["The goal of this paper is to introduce the notion of polyconvolution for Fourier-cosine, Laplace integral operators, and its applications. The structure of this polyconvolution operator and associated integral transforms are investigated in detail. The Watson-type theorem is given, to establish necessary and sufficient conditions for this operator to be isometric isomorphism (unitary) on $L_2 (\\mathbb{R}_+)$, and to get its inverse represented in the conjugate symmetric form. The correlation between the existence of polyconvolution with some weighted spaces is shown, and Young's type theorem, as well as the norm-inequalities in weighted space, are also obtained. As applications, we investigate the solvability of a class of Toeplitz plus Hankel type integral equations and linear Barbashin's equations with the help of factorization identities of such polyconvolution. Several examples are provided to illustrate the obtained results to ensure their validity and applicability."], "authors": "Trinh Tuan"},
{"Title": "Global properties of Higgs bundle moduli spaces", "abs": ["The moduli spaces for Higgs bundles associated to real Lie groups and a closed Riemann surface have multiple connected components. This survey provides a compendium of results concerning the counting of these components in cases where the Lie group is a real forms of a complex simple Lie group. In some cases the components can be described quite explicitly."], "authors": "Steven Bradlow"},
{"Title": "Mean Curvature Flow from Conical Singularities", "abs": ["We prove Ilmanen's resolution of point singularities conjecture by establishing short-time smoothness of the level set flow of a smooth hypersurface with isolated conical singularities. This shows how the mean curvature flow evolves through asymptotically conical singularities and resolves a particular case of Ilmanen's strict genus reduction conjecture.", "Precisely, we prove that the level set flow of a smooth hypersurface $M^n\\subset \\mathbb{R}^{n+1}$, $2\\leq n\\leq 6$, with an isolated conical singularity is modeled on the level set flow of the cone. In particular, the flow fattens (instantaneously) if and only if the level set flow of the cone fattens."], "authors": "Otis Chodosh"},
{"Title": "On absolutely friendly measures on $\\mathbb{Q}_S^d$", "abs": ["In this paper, we extend the work of Pollington and Velani in \\cite{PV} to an $S$-arithmetic set-up, where $S$ is a finite set of valuations of $\\mathbb{Q}$. In particular, for an `absolutely friendly' measure supported on a compact set in $\\mathbb{Q}_S^d$, we give a summation condition on approximating function $\\psi$ such that $\\mu$ almost no point in the compact set is $\\psi$ approximable. The crucial ingredient is a version of the simplex lemma that we prove dynamically."], "authors": "Shreyasi Datta"},
{"Title": "Operadic categories and 2-Segal sets", "abs": ["If $X$ is a 2-Segal set, then the edgewise subdivision of $X$ admits a factorization system coming from upper and lower décalage. Using the correspondence between 2-Segal sets and unary operadic categories satisfying the blow-up axiom, the edgewise subdivision of $X$ is interpreted as an enlargement of the associated operadic category, where fiber inclusions have been adjoined."], "authors": "Philip Hackney"},
{"Title": "Simple Braids Tend toward Positive Entropy", "abs": ["A simple braid is a positive braid in which any two strands cross at most once. We prove that as $n \\to \\infty$, the proportion of simple braids on $n$ strands that have positive topological entropy tends toward $100\\%$. In particular, such braids must be pseudo-Anosov or reducible with a pseudo-Anosov component. Our proof involves a method of reduction from simple braids to non-simple $3$-strand braids that may be of independent interest."], "authors": "Luke Robitaille"},
{"Title": "Computing Networks Enabled Semantic Communications", "abs": ["Semantic communication has shown great potential in boosting the effectiveness and reliability of communications. However, its systems to date are mostly enabled by deep learning, which requires demanding computing resources. This article proposes a framework for the computing networks enabled semantic communication system, aiming to offer sufficient computing resources for semantic processing and transmission. Key techniques including semantic sampling and reconstruction, semantic-channel coding, semantic-aware resource allocation and optimization are introduced based on the cloud-edge-end computing coordination. Two use cases are demonstrated to show advantages of the proposed framework. The article concludes with several future research directions."], "authors": "Zhijin Qin"},
{"Title": "How do correlations shape the landscape of information?", "abs": ["We explore a few common models on how correlations affect information. The main model considered is the Shannon mutual information $I(S:R_1,\\cdots, R_i)$ over distributions with marginals $P_{S,R_i}$ fixed for each $i$, with the analogy in which $S$ is the stimulus and $R_i$'s are neurons. We work out basic models in details, using algebro-geometric tools to write down discriminants that separate distributions with distinct qualitative behaviours in the probability simplex into toric chambers and evaluate the volumes of them algebraically. As a byproduct, we provide direct translation between a decomposition of mutual information inspired by a series expansion and one from partial information decomposition (PID) problems, characterising the synergistic terms of the former. We hope this paper serves for communication between communities especially mathematics and theoretical neuroscience on the topic.", "KEYWORDS: information theory, algebraic statistics, mathematical neuroscience, partial information decomposition"], "authors": "Ching-Peng Huang"},
{"Title": "Transitions of bifurcation diagrams of a forced heteroclinic cycle", "abs": ["A family of periodic perturbations of an attracting robust heteroclinic cycle defined on the two-sphere is studied by reducing the analysis to that of a one-parameter family of maps on a circle. The set of zeros of the family forms a bifurcation diagram on the cylinder. The different bifurcation diagrams and the transitions between them are obtained as the strength of attraction of the cycle and the amplitude of the periodic perturbation vary. When the cycle is weakly attracting further transitions are found giving rise to a frequency locked invariant torus and to a frequency locked suspended horseshoe, arising from heteroclinic tangencies in the family of maps. We determine a threshold in the cycle's attraction strength above which there are no other transitions in the bifurcation diagrams. Above this threshold and as the period of the perturbation decreases, frequency locked periodic solutions with arbitrarily long periods bifurcate from the cycle."], "authors": "Isabel S. Labouriau"},
{"Title": "Approximation Bounds for Model Reduction on Polynomially Mapped Manifolds", "abs": ["For projection-based linear-subspace model order reduction (MOR), it is well known that the Kolmogorov n-width describes the best-possible error for a reduced order model (ROM) of size n. In this paper, we provide approximation bounds for ROMs on polynomially mapped manifolds. In particular, we show that the approximation bounds depend on the polynomial degree p of the mapping function as well as on the linear Kolmogorov n-width for the underlying problem. This results in a Kolmogorov (n, p)-width, which describes a lower bound for the best-possible error for a ROM on polynomially mapped manifolds of polynomial degree p and reduced size n."], "authors": "Patrick Buchfink"},
{"Title": "Convolution identities for divisor sums and modular forms", "abs": ["We prove exact identities for convolution sums of divisor functions of the form $\\sum_{n_1 \\in \\mathbb{Z} \\smallsetminus \\{0,n\\}}\\varphi(n_1,n-n_1)\\sigma_{2m_1}(n_1)\\sigma_{2m_2}(n-n_1)$ where $\\varphi(n_1,n_2)$ is a Laurent polynomial with logarithms for which the sum is absolutely convergent. Such identities are motivated by computations in string theory and prove and generalize a conjecture of Chester, Green, Pufu, Wang, and Wen from \\cite{CGPWW}. Originally, it was suspected that such sums, suitably extended to $n_1\\in\\{0,n\\}$ should vanish, but in this paper we find that in general they give Fourier coefficients of holomorphic cusp forms."], "authors": "Ksenia Fedosova"},
{"Title": "Tight-minimal dichotomies in Banach spaces", "abs": ["We extend the methods used by V. Ferenczi and Ch. Rosendal to obtain the `third dichotomy' in the program of classification of Banach spaces up to subspaces, in order to prove that a Banach space E with an admissible system of blocks with admissible set A, contains an infinite dimensional subspace with a basis which is either A-tight or A-minimal. In this setting we obtain, in particular, dichotomies regarding subsequences of a basis, and as a corollary, we show that every normalized basic sequence has a subsequence which either satisfies a tightness property or is spreading. Other dichotomies between notions of minimality and tightness are demonstrated, and the Ferenczi-Godefroy interpretation of tightness in terms of Baire category is extended to this new context."], "authors": "Alejandra C. Cáceres-Rigo"},
{"Title": "A fast and accurate domain-decomposition nonlinear manifold reduced order model", "abs": ["This paper integrates nonlinear-manifold reduced order models (NM-ROMs) with domain decomposition (DD). NM-ROMs approximate the FOM state in a nonlinear-manifold by training a shallow, sparse autoencoder using FOM snapshot data. These NM-ROMs can be advantageous over linear-subspace ROMs (LS-ROMs) for problems with slowly decaying Kolmogorov $n$-width. However, the number of NM-ROM parameters that need to trained scales with the size of the FOM. Moreover, for \"extreme-scale\" problems, the storage of high-dimensional FOM snapshots alone can make ROM training expensive. To alleviate the training cost, this paper applies DD to the FOM, computes NM-ROMs on each subdomain, and couples them to obtain a global NM-ROM. This approach has several advantages: Subdomain NM-ROMs can be trained in parallel, each involve fewer parameters to be trained than global NM-ROMs, require smaller subdomain FOM dimensional training data, and training of subdomain NM-ROMs can tailor them to subdomain-specific features of the FOM. The shallow, sparse architecture of the autoencoder used in each subdomain NM-ROM allows application of hyper-reduction (HR), reducing the complexity caused by nonlinearity and yielding computational speedup of the NM-ROM. This paper provides the first application of NM-ROM (with HR) to a DD problem. In particular, it details an algebraic DD formulation of the FOM, trains a NM-ROM with HR for each subdomain, and develops a sequential quadratic programming (SQP) solver to evaluate the coupled global NM-ROM. Theoretical convergence results for the SQP method and a priori and a posteriori error estimates for the DD NM-ROM with HR are provided. The proposed DD NM-ROM with HR approach is numerically compared to a DD LS-ROM with HR on 2D steady-state Burgers' equation, showing an order of magnitude improvement in accuracy of the proposed DD NM-ROM over the DD LS-ROM."], "authors": "Alejandro N. Diaz"},
{"Title": "Nonlinear-manifold reduced order models with domain decomposition", "abs": ["A nonlinear-manifold reduced order model (NM-ROM) is a great way of incorporating underlying physics principles into a neural network-based data-driven approach. We combine NM-ROMs with domain decomposition (DD) for efficient computation. NM-ROMs offer benefits over linear-subspace ROMs (LS-ROMs) but can be costly to train due to parameter scaling with the full-order model (FOM) size. To address this, we employ DD on the FOM, compute subdomain NM-ROMs, and then merge them into a global NM-ROM. This approach has multiple advantages: parallel training of subdomain NM-ROMs, fewer parameters than global NM-ROMs, and adaptability to subdomain-specific FOM features. Each subdomain NM-ROM uses a shallow, sparse autoencoder, enabling hyper-reduction (HR) for improved computational speed. In this paper, we detail an algebraic DD formulation for the FOM, train HR-equipped NM-ROMs for subdomains, and numerically compare them to DD LS-ROMs with HR. Results show a significant accuracy boost, on the order of magnitude, for the proposed DD NM-ROMs over DD LS-ROMs in solving the 2D steady-state Burgers' equation."], "authors": "Alejandro N. Diaz"},
{"Title": "Thick points of 4D critical branching Brownian motion", "abs": ["We study the thick points of branching Brownian motion and branching random walk with a critical branching mechanism, focusing on the critical dimension $d = 4$. We determine the exponent governing the probability to hit a small ball with an exceptionally high number of pioneers, showing that this has a second-order transition between an exponential phase and a stretched-exponential phase at an explicit value ($a = 2$) of the thickness parameter $a$. We apply the outputs of this analysis to prove that the associated set of thick points $\\mathcal{T}(a)$ has dimension $(4-a)_+$, so that there is a change in behaviour at $a=4$ but not at $a = 2$ in this case. Along the way, we obtain related results for the nonpositive solutions of a boundary value problem associated to the semilinear PDE $\\Delta v = v^2$ and develop a strong coupling between tree-indexed random walk and tree-indexed Brownian motion that allows us to deduce analogues of some of our results in the discrete case.", "We also obtain in each dimension $d\\geq 1$ an infinite-order asymptotic expansion for the probability that critical branching Brownian motion hits a distant unit ball, finding that this expansion is convergent when $d\\neq 4$ and divergent when $d=4$. This reveals a novel, dimension-dependent critical exponent governing the higher-order terms of the expansion, which we compute in every dimension."], "authors": "Nathanaël Berestycki"},
{"Title": "Computing 1-Periodic Persistent Homology with Finite Windows", "abs": ["Let $K$ be a periodic cell complex endowed with a covering $q:K\\to G$ where $G$ is a finite quotient space of equivalence classes under translations acting on $K$. We assume $G$ is embedded in a space whose homotopy type is a $d$-torus for some $d$, which introduces \"toroidal cycles\" in $G$ which do not lift to cycles in $K$ by $q$ . We study the behaviour of toroidal and non-toroidal cycles for the case $K$ is 1-periodic, i.e. $G=K/\\mathbb{Z}$ for some free action of $\\mathbb{Z}$ on $K$. We show that toroidal cycles can be entirely classified by endomorphisms on the homology of unit cells of $K$, and moreover that toroidal cycles have a sense of unimodality when studying the persistent homology of $G$."], "authors": "Adam Onus"},
{"Title": "On the Periodicity of Singular Vectors and the Holomorphic Block-Circulant SVD on the Unit Circumference", "abs": ["We investigate the singular value decomposition of a rectangular matrix that is analytic on the complex unit circumference, which occurs, e.g., with the matrix of transfer functions representing a broadband multiple-input multiple-output channel. Our analysis is based on the Puiseux series expansion of the eigenvalue decomposition of analytic para-Hermitian matrices on the complex unit circumference. We study the case in which the rectangular matrix does not admit a full analytic singular value factorization, either due to partly multiplexed systems or to sign ambiguity. We show how to find an SVD factorization in the ring of Puiseux series where each singular value and the associated singular vectors present the same period and multiplexing structure, and we prove that it is always possible to find an analytic pseudo-circulant factorization, meaning that any arbitrary arrangements of multiplexed systems can be converted into a parallel form. In particular, one can show that the sign ambiguity can be overcome by allowing non-real holomorphic singular values."], "authors": "Giovanni Barbarino"},
{"Title": "Moments of the Poisson distribution of order $k$", "abs": ["The factorial moments of the standard Poisson distribution are well known and are simple, but the raw moments are considered to be more complicated (Touchard polynomials). The present note presents a recurrence relation and an explicit combinatorial sum for the raw moments of the Poisson distribution of order $k$. Unlike the standard Poisson distribution (the case $k=1$), for $k>1$ the structure of the raw and factorial moments have many similarities and the raw moments are not more complicated (formally, at least) than the factorial moments. We remark briefly on the central moments (i.e.~moments centered on the mean) of the Poisson distribution of order $k$."], "authors": "S. R. Mane"},
{"Title": "Rigidity Results for large displacement quotients of mapping class groups", "abs": ["We consider quotients of mapping class groups of orientable, finite type surfaces by subgroups whose action on the curve graph has large displacement. This class includes quotients by the normal closure of a pseudo-Anosov element, the mapping class group itself, and in view of forthcoming work of Abbott, Berlyne, Ng, and Rasmussen, also random quotients. First, we show that every automorphism of the corresponding quotient of the curve graph is induced by a mapping class, thus generalising Ivanov's Theorem about automorphisms of the curve graph. Then we use this to prove quasi-isometric rigidity under additional assumptions, satisfied by all aforementioned quotients. In the process, we clarify a proof of quasi-isometric rigidity of mapping class groups by Behrstock, Hagen, and Sisto. Finally, we show that the outer automorphisms groups of our quotients, as well as their abstract commensurators, are \"the smallest possible\"."], "authors": "Giorgio Mangioni"},
{"Title": "Dimension de Heitmann des treillis distributifs et des anneaux commutatifs", "abs": ["We study a notion of dimension which was introduced by R. Heitmann in his remarkable paper in 1984, and also a related notion, implicit in the proofs in his paper. We develop these notions in the general framework of distributive lattices and spectral spaces. We obtain in this way constructive versions of important theorems in commutative algebra, with simpler proofs than the classical ones, and some new results."], "authors": "Thierry Coquand"},
{"Title": "Heitman dimension of distributive lattices and commutative rings", "abs": ["This paper is the English translation of the first 4 sections of the article \"Thierry Coquand, Henri Lombardi, and Claude Quitté. Dimension de Heitmann des treillis distributifs et des anneaux commutatifs. Publications Mathématiques de l'Université de Franche-Comté, Besançon. Algèbre et théorie des nombres. (2006)\", after some corrections.", "Sections 5-7 of the original article are treated a bit more simply in the book \"Henri Lombardi and Claude Quitté. Commutative algebra: constructive methods. Finite projective modules. Algebra and applications, 20, Springer, Dordrecht, 2015.\"", "We study the notion of dimension introduced by Heitmann in his remarkable article \"Raymond Heitmann. Generating non-Noetherian modules efficiently, Mich. Math. J., 31, (1084)\" as well as a related notion, only implicit in his proofs. We first develop this within the general framework of the theory of distributive lattices and spectral spaces.", "Keywords: Constructive mathematics, distributive lattice, Heyting algebra, spectral space, Zariski lattice, Zariski spectrum, Krull dimension, maximal spectrum, Heitmann lattice, Heitmann spectrum, Heitmann dimensions.", "MSC: 13C15, 03F65, 13A15, 13E05"], "authors": "Thierry Coquand"},
{"Title": "Quasi-F-split and Hodge-Witt", "abs": ["We study an analogy between quasi-F-split and Hodge-Witt. In particular, we show that the fiber product of an F-split scheme and a quasi-F-split scheme is quasi-F-split and, in converse, if the fiber product is quasi-F-split then one of the factors is F-split and the other is quasi-F-split. This is an analogy of Ekedahl's theorem, which says the fiber product of an ordinary scheme and a Hodge-Witt scheme is Hodge Witt and if the product is Hodge-Witt then one of the factors is ordinary and the other is Hodge-Witt. As an application, we show that, for any prime p, there is a klt Fano fourfold in characteristic p which is not quasi-F-split."], "authors": "Fuetaro Yobuko"},
{"Title": "Minimal rank factorizations of polynomial matrices", "abs": ["We investigate rank revealing factorizations of rank deficient $m \\times n$ polynomial matrices $P(\\lambda)$ into products of three, $P(\\lambda) = L(\\lambda) E(\\lambda) R(\\lambda)$, or two, $P(\\lambda) = L(\\lambda) R(\\lambda)$, polynomial matrices. Among all possible factorizations of these types, we focus on those for which $L(\\lambda)$ and/or $R(\\lambda)$ is a minimal basis, since they allow us to relate easily the degree of $P(\\lambda)$ with some degree properties of the factors. We call these factorizations minimal rank factorizations. Motivated by the well-known fact that, generically, rank deficient polynomial matrices over the complex field do not have eigenvalues, we pay particular attention to the properties of the minimal rank factorizations of polynomial matrices without eigenvalues. We carefully analyze the degree properties of generic minimal rank factorizations in the set of complex $m \\times n$ polynomial matrices with normal rank at most $r$ and degree at most $d$, and we prove that they are of the form $L(\\lambda) R(\\lambda)$, where the degrees of the $r$ columns of $L(\\lambda)$ differ at most by one, the degrees of the $r$ rows of $R(\\lambda)$ differ at most by one, and, for each $i=1, \\ldots, r$, the sum of the degrees of the $i$th column of $L(\\lambda)$ and of the $i$th row of $R(\\lambda)$ is equal to $d$. Finally, we show how these sets of polynomial matrices with generic factorizations are related to the sets of polynomial matrices with generic eigenstructures."], "authors": "Andrii Dmytryshyn"},
{"Title": "A transform pair for bounded convex planar domains", "abs": ["A new transform pair which can be used to solve mixed boundary value problems for Laplace's equation and the complex Helmholtz equation in bounded convex planar domains is presented. This work is an extension of Crowdy (2015, CMFT, 15, 655--687) where new transform techniques were developed for boundary value problems for Laplace's equation in circular domains. The key ingredient of the method is the analysis of the so called global relation which provides a coupling of integral transforms of the given boundary data and of the unknown boundary values. Three problems which involve mixed boundary conditions are solved in detail, as well as numerically implemented, to illustrate how to apply the new approach."], "authors": "Jesse Hulse"},
{"Title": "$L^p -L^q$ boundedness of Fourier multipliers on quantum Euclidean spaces", "abs": ["In this paper, we study Fourier multipliers on quantum Euclidean spaces and obtain results on their $L^p -L^q$ boundedness. On the way to get these results, we prove Paley, Hausdorff-Young, Hausdorff-Young-Paley, and Hardy-Littlewood inequalities on the quantum Euclidean space. As applications, we establish the $L^p -L^q$ estimate for the heat semigroup and Sobolev embedding theorem on quantum Euclidean spaces. We also obtain quantum analogues of logarithmic Sobolev and Nash type inequalities."], "authors": "M. Ruzhansky"},
{"Title": "Edge-covering plane-filling curves on grid colorings: a pedestrian approach", "abs": ["We describe families of plane-filling curves on any edge-to-edge tiling of the plane with regular polygons and finitely many classes of edges. It is shown how to partition the minimal number of edge classes from the group G of symmetries of the tiling into refined colorings of the tiling, corresponding to finite subgroups of G. All of these colorings correspond to families of plane-filling curves which we call curve-sets. Our exposition is driven by illustrated examples."], "authors": "Jörg Arndt"},
{"Title": "Categories of impartial rulegraphs and gamegraphs", "abs": ["The traditional mathematical model for an impartial combinatorial game is defined recursively as a set of the options of the game, where the options are games themselves. We propose a model called gamegraph, together with its generalization rulegraph, based on the natural description of a game as a digraph where the vertices are positions and the arrows represent possible moves. Such digraphs form a category where the morphisms are option preserving maps. We study several versions of this category. Our development includes congruence relations, quotients, and isomorphism theorems and is analogous to the corresponding notions in universal algebra. The quotient by the maximum congruence relation produces an object that is essentially equivalent to the traditional model. After the development of the general theory, we count the number of non-isomorphic gamegraphs and rulegraphs by formal birthday and the number of positions."], "authors": "Bojan Bašić"},
{"Title": "Distributed Asynchronous Discrete-Time Feedback Optimization", "abs": ["In this article, we present an algorithm that drives the outputs of a network of agents to jointly track the solutions of time-varying optimization problems in a way that is robust to asynchrony in the agents' operations. We consider three operations that can be asynchronous: (1) computations of control inputs, (2) measurements of network outputs, and (3) communications of agents' inputs and outputs. We first show that our algorithm converges to the solution of a time-invariant feedback optimization problem in linear time. Next, we show that our algorithm drives outputs to track the solution of time-varying feedback optimization problems within a bounded error dependent upon the movement of the minimizers and degree of asynchrony in a way that we make precise. These convergence results are extended to quantify agents' asymptotic behavior as the length of their time horizon approaches infinity. Then, to ensure satisfactory network performance, we specify the timing of agents' operations relative to changes in the objective function that ensure a desired error bound. Numerical experiments confirm these developments and show the success of our distributed feedback optimization algorithm under asynchrony."], "authors": "Gabriel Behrendt"},
{"Title": "Neural networks for the approximation of Euler's elastica", "abs": ["Euler's elastica is a classical model of flexible slender structures, relevant in many industrial applications. Static equilibrium equations can be derived via a variational principle. The accurate approximation of solutions of this problem can be challenging due to nonlinearity and constraints. We here present two neural network based approaches for the simulation of this Euler's elastica. Starting from a data set of solutions of the discretised static equilibria, we train the neural networks to produce solutions for unseen boundary conditions. We present a $\\textit{discrete}$ approach learning discrete solutions from the discrete data. We then consider a $\\textit{continuous}$ approach using the same training data set, but learning continuous solutions to the problem. We present numerical evidence that the proposed neural networks can effectively approximate configurations of the planar Euler's elastica for a range of different boundary conditions."], "authors": "Elena Celledoni"},
{"Title": "One to beat them all: \"RYU'' -- a unifying framework for the construction of safe balls", "abs": ["In this paper, we put forth a novel framework (named ``RYU'') for the construction of ``safe'' balls, i.e. regions that provably contain the dual solution of a target optimization problem. We concentrate on the standard setup where the cost function is the sum of two terms: a closed, proper, convex Lipschitz-smooth function and a closed, proper, convex function. The RYU framework is shown to generalize or improve upon all the results proposed in the last decade for the considered family of optimization problems."], "authors": "Thu-Le Tran"},
{"Title": "Numerical computation of the stress concentration between closely located stiff inclusions of general shapes", "abs": ["When two stiff inclusions are closely located, the gradient of the solution may become arbitrarily large as the distance between two inclusions tends to zero. Since blow-up of the gradient occurs in the narrow region, fine meshes should be required to compute the gradient. Thus, it is a challenging problem to numerically compute the gradient. Recent studies have shown that the major singularity can be extracted in an explicit way, so it suffices to compute the residual term for which only regular meshes are required. In this paper, we show through numerical simulations that the characterization of the singular term method can be efficiently used for the computation of the gradient when two strongly convex stiff domains of general shapes are closely located."], "authors": "Xiaofei Li"},
{"Title": "Extremal graphs without long paths and a given graph", "abs": ["For a family of graphs $\\mathcal{F}$, the Turán number $ex(n,\\mathcal{F})$ is the maximum number of edges in an $n$-vertex graph containing no member of $\\mathcal{F}$ as a subgraph. The maximum number of edges in an $n$-vertex connected graph containing no member of $\\mathcal{F}$ as a subgraph is denoted by $ex_{conn}(n,\\mathcal{F})$. Let $P_k$ be the path on $k$ vertices and $H$ be a graph with chromatic number more than $2$. Katona and Xiao [Extremal graphs without long paths and large cliques, European J. Combin., 2023 103807] posed the following conjecture: Suppose that the chromatic number of $H$ is more than $2$. Then $ex\\big(n,\\{H,P_k\\}\\big)=n\\max\\big\\{\\big\\lfloor \\frac{k}{2}\\big\\rfloor-1,\\frac{ex(k-1,H)}{k-1}\\big\\}+O_k(1)$. In this paper, we determine the exact value of $ex_{conn}\\big(n,\\{P_k,H\\}\\big)$ for sufficiently large $n$. Moreover, we obtain asymptotical result for $ex\\big(n,\\{P_k,H\\}\\big)$, which solves the conjecture proposed by Katona and Xiao."], "authors": "Yichong Liu"},
{"Title": "Semilinear wave inequalities with double damping and potential terms on Riemannian Manifolds", "abs": ["We study a semilinear wave inequality with double damping on a complete noncompact Riemannian manifold. The considered problem involves a potential function $V$ depending on the space variable in front of the power nonlinearity and an inhomogeneous term $W$ depending on both time and space variables. Namely, we establish sufficient conditions for the nonexistence of weak solutions in both cases: $W\\equiv 0$ and $W\\not\\equiv 0$. The obtained conditions depend on the parameters of the problem as well as the geometry of the manifold. Some special cases of manifolds, and of $V$ and $W$ are discussed in detail."], "authors": "Mohamed Jleli"},
{"Title": "Stability for the logarithmic Hardy-Littlewood-Sobolev Inequality with application to the Keller-Segel system", "abs": ["We apply a duality method to prove an optimal stability theorem for the logarithmic Hardy-Littlewood-Sobolev inequality, and we apply it to the estimation of the rate of approach to equilibrium for the critical mass Keller-Segel system."], "authors": "Eric A. Carlen"},
{"Title": "Stopper vs. singular-controller games with degenerate diffusions", "abs": ["We study zero-sum stochastic games between a singular controller and a stopper when the (state-dependent) diffusion matrix of the underlying controlled diffusion process is degenerate. In particular, we show the existence of a value for the game and determine an optimal strategy for the stopper. The degeneracy of the dynamics prevents the use of analytical methods based on solution in Sobolev spaces of suitable variational problems. Therefore we adopt a probabilistic approach based on a perturbation of the underlying diffusion modulated by a parameter $\\gamma>0$. For each $\\gamma>0$ the approximating game is non-degenerate and admits a value $u^\\gamma$ and an optimal strategy $\\tau^\\gamma_*$ for the stopper. Letting $\\gamma\\to 0$ we prove convergence of $u^\\gamma$ to a function $v$, which identifies the value of the original game. We also construct explicitly optimal stopping times $\\theta^\\gamma_*$ for $u^\\gamma$, related but not equal to $\\tau^\\gamma_*$, which converge almost surely to an optimal stopping time $\\theta_*$ for the game with degenerate dynamics."], "authors": "Andrea Bovo"},
{"Title": "Massey iterated products and closed geodesics", "abs": ["In this paper, we show that the existence of two sequences of Massey iterated product containing zero in the cohomology of a 1-connected CW complex of finite type $X$ directly bears on the unbounded growth of the Betti numbers of the free loop space of $X$."], "authors": "Bitjong Ndombol"},
{"Title": "The continuum limit of higher-order Follow-the-Leader models", "abs": ["We study a generalized Follow-the-Leader model where the driver considers the position of an arbitrary but finite number of vehicles ahead, as well as the position of the vehicle directly behind the driver. It is proved that this model converges to the classical Lighthill-Whitham-Richards model for traffic flow when traffic becomes dense. This also underscores the robustness of the Lighthill-Whitham-Richards model."], "authors": "Helge Holden"},
{"Title": "Monotone duality of interacting particle systems", "abs": ["In his paper from 1986 Gray developed a theory of dual processes for attractive spin systems. Based on his work Sturm and Swart systematically investigated monotonicity-based pathwise dualities for Markov processes in general and interacting particle systems in particular. In this paper we only consider monotone interacting particle systems whose state space is the Cartesian product of countably many copies of a finite set. For this class of processes Sturm and Swart only showed the well-definedness of their dual processes if started from finite initial states. This paper closes this gap and shows how to construct a well-defined pathwise dual process of a monotone interacting particle system that can also be started from an infinite initial state. This then allows us to study invariant laws of the dual process and connect them to properties of the original interacting particle system."], "authors": "Jan Niklas Latz"},
{"Title": "The sub-Riemannian X-ray Transform on H-type groups: Fourier-Slice Theorems and Injectivity sets", "abs": ["We continue the development of X-ray tomography in sub-Riemannian geometry. Using the Fourier Transform adapted to the group structure, we generalize the Fourier Slice Theorem to the class of H-type groups. The Fourier Slice Theorem expresses the X-ray transform as the composition of a Fourier restriction and multiplication operator. We compute the spectral resolution for the resulting operator-valued multiplier, which we use to show that an integrable function on an H-type group is determined by its integrals over sub-Riemannian geodesics. We also relate the support of the X-ray transform $If$ to the support of $f$ in frequency space. These results given explicit answers to the injectivity question in a class of geometries with an abundance of conjugate points."], "authors": "Steven Flynn"},
{"Title": "Symmetric functions in noncommuting variables in superspace", "abs": ["In 2004, Rosas and Sagan developed the theory of symmetric functions in noncommuting variables, achieving results analogous to classical symmetric functions. On the other hand, in 2004, Desrosiers, Lapointe and Mathieu introduced the theory of symmetric functions in superspace, which involve both commuting and anticommuting variables, extending the classic theory. Here, we introduce symmetric functions in noncommuting variables in superspace. We define the classical symmetric functions in noncommuting variables to superspace: monomials, power sums, elementaries and complete homogeneous, which generalize both the ones studied by Rosas and Sagan and the ones studied by Desrosiers, Lapointe and Mathieu. We also define Schur--type functions in noncommuting variables in superspace."], "authors": "Diego Arcis"},
{"Title": "Killing vector fields on semi-Riemannian product manifolds", "abs": ["Hano's theorem states that the space of Killing vector fields of a complete simply connected Riemannian manifold is isomorphic to the direct sum of the Killing vector fields of the factors in its de Rham decomposition. We prove a generalisation of this theorem to manifolds with indefinite metrics that requires an assumption on the factors, and show by example why this assumption is needed."], "authors": "Federico Costanza"},
{"Title": "A geometric $C_2$-equivariant Bézout Theorem", "abs": ["Classically, Bézout's theorem says that an intersection of hypersurfaces in a projective space is rationally equivalent to a number of copies of a smaller projective space, the number depending on the degrees of the hypersurfaces. We give a generalization of that result to the context of $C_2$-equivariant hypersurfaces in $C_2$-equivariant linear projective space, expressing the intersection as a linear combination of equivariant Schubert varieties."], "authors": "Steven R. Costenoble"},
{"Title": "Dense, irregular, yet always graphic $3$-uniform hypergraph degree sequences", "abs": ["A $3$-uniform hypergraph is a generalization of simple graphs where each hyperedge is a subset of vertices of size $3$. The degree of a vertex in a hypergraph is the number of hyperedges incident with it. The degree sequence of a hypergraph is the sequence of the degrees of its vertices. The degree sequence problem for $3$-uniform hypergraphs is to decide if a $3$-uniform hypergraph exists with a prescribed degree sequence. Such a hypergraph is called a realization. Recently, Deza \\emph{et al.} proved that the degree sequence problem for $3$-uniform hypergraphs is NP-complete. Some special cases are easy; however, polynomial algorithms have been known so far only for some very restricted degree sequences. The main result of our research is the following. If all degrees are between $\\frac{2n^2}{63}+O(n)$ and $\\frac{5n^2}{63}-O(n)$ in a degree sequence $D$, further, the number of vertices is at least $45$, and the degree sum can be divided by $3$, then $D$ has a $3$-uniform hypergraph realization. Our proof is constructive and in fact, it constructs a hypergraph realization in polynomial time for any degree sequence satisfying the properties mentioned above. To our knowledge, this is the first polynomial running time algorithm to construct a $3$-uniform hypergraph realization of a highly irregular and dense degree sequence."], "authors": "Runze Li"},
{"Title": "Injectivity of the genus 1 Kudla-Millson lift on locally symmetric spaces", "abs": ["Let $L$ be an even indefinite lattice. We show that if $L$ splits off a hyperbolic plane and a scaled hyperbolic plane, then the Kudla-Millson lift of genus $1$ associated to $L$ is injective. Our result includes as special cases all previously known injectivity results on the whole space of elliptic cusp forms available in the literature. In particular, we also consider the Funke-Millson twist of the lift. Further, we provide geometric applications on locally symmetric spaces of orthogonal type."], "authors": "Ingmar Metzler"},
{"Title": "Breakdown of Hölder Continuity for 2D Euler Equation in the Propagation of Loglog Vortex", "abs": ["Drivas-Elgindi-La \\cite{Drivas-Propagation} showed that when a radial loglog vortex is perturbed with bounded function, the solution maintains its structure all time, i.e., the solution can be written in the form of moving loglog vortex with bounded correction term. In this paper, we show that if the loglog vortex is perturbed with Hölder continuous function, then the solution loses its structure instantaneously: The solution could not be written in the form of loglog vortex with Hölder continuous correction term whose norm is uniformly bounded in time interval $[0,T]$ for any $T>0$. This breakdown of Hölder continuity still occurs even when the perturbation is smooth."], "authors": "Woohyu Jeon"},
{"Title": "On the Divisibility of Degrees of Representations of Lie Algebras", "abs": ["Let $\\mathfrak g$ be a reductive Lie algebra, and $m$ a positive integer. There is a natural density of irreducible representations of $\\mathfrak g$, whose degrees are not divisible by $m$. For $\\mathfrak g=\\mathfrak{gl}_n$, this density decays exponentially to $0$ as $n \\to \\infty$. Similar results hold for simple Lie algebras and Lie groups, and there are versions for self-dual and orthogonal representations."], "authors": "Varun Shah"},
{"Title": "Completion of two-parameter period maps by nilpotent orbits", "abs": ["We show that every two-parameter period map admits a Kato--Nakayama--Usui completion to a morphism of log manifolds."], "authors": "Haohua Deng"},
{"Title": "Limit theorems for empirical measures of interacting quantum systems in Wasserstein space", "abs": ["We prove fundamental properties of empirical measures induced by measurements performed on quantum $N$-body systems. More precisely, we consider measurements performed on the ground state of an interacting, trapped Bose gase in the Gross--Pitaevskii regime, known to exhibit Bose--Einstein condensation. For the corresponding empirical measure, we prove a weak law of large numbers with limit induced by the condensate wave function and characterize the fluctuations around through an appropriate central limit theorem."], "authors": "Lorenzo Portinale"},
{"Title": "A Preconditioned Interior Point Method for Support Vector Machines Using an ANOVA-Decomposition and NFFT-Based Matrix-Vector Products", "abs": ["In this paper we consider the numerical solution to the soft-margin support vector machine optimization problem. This problem is typically solved using the SMO algorithm, given the high computational complexity of traditional optimization algorithms when dealing with large-scale kernel matrices. In this work, we propose employing an NFFT-accelerated matrix-vector product using an ANOVA decomposition for the feature space that is used within an interior point method for the overall optimization problem. As this method requires the solution of a linear system of saddle point form we suggest a preconditioning approach that is based on low-rank approximations of the kernel matrix together with a Krylov subspace solver. We compare the accuracy of the ANOVA-based kernel with the default LIBSVM implementation. We investigate the performance of the different preconditioners as well as the accuracy of the ANOVA kernel on several large-scale datasets."], "authors": "Theresa Wagner"},
{"Title": "A note on the primitive cohomology lattice of a projective surface", "abs": ["The isometry class of the intersection form of a compact complex surface can be easily determined from complex-analytic invariants. For projective surfaces the primitive lattice is another naturally occurring lattice. The goal of this note is to show that it can be determined from the intersection lattice and the self-intersection of a primitive ample class, at least when the primitive lattice is indefinite. Examples include the Godeaux surfaces, the Kunev surface and a specific Horikawa surface. There are also some results concerning (negative) definite primitive lattices, especially for canonically polarized surfaces of general type."], "authors": "Chris Peters"},
{"Title": "On invariants of multiplexed virtual links", "abs": ["For a virtual knot $K$ and an integer $r$ with $r\\geq2$, we introduce a method of constructing an $r$-component virtual link $L(K;r)$, which we call the $r$-multiplexing of $K$. Every invariant of $L(K;r)$ is an invariant of $K$. We give a way of calculating three kinds of invariants of $L(K;r)$ using invariants of $K$. As an application of our method, we also show that Manturov's virtual $n$-colorings for $K$ can be interpreted as certain classical $n$-colorings for $L(K;2)$."], "authors": "Kodai Wada"},
{"Title": "Quantization of locally compact groups associated with essentially bijective $1$-cocycles", "abs": ["Given an extension $0\\to V\\to G\\to Q\\to1$ of locally compact groups, with $V$ abelian, and a compatible essentially bijective $1$-cocycle $\\eta\\colon Q\\to\\hat V$, we define a dual unitary $2$-cocycle on $G$ and show that the associated deformation of $\\hat G$ is a cocycle bicrossed product defined by a matched pair of subgroups of $Q\\ltimes\\hat V$. We also discuss an interpretation of our construction from the point of view of Kac cohomology for matched pairs.", "Our setup generalizes that of Etingof and Gelaki for finite groups and its extension due to Ben David and Ginosar, as well as our earlier work on locally compact groups satisfying the dual orbit condition. In particular, we get a locally compact quantum group from every involutive nondegenerate set-theoretical solution of the Yang--Baxter equation, or more generally, from every brace structure.", "On the technical side, the key new points are constructions of an irreducible projective representation of $G$ on $L^2(Q)$ and a unitary quantization map $L^2(G)\\to{\\rm HS}(L^2(Q))$ of Kohn--Nirenberg type."], "authors": "Pierre Bieliavsky"},
{"Title": "Parametric Distributionally Robust Optimisation Models for Budgeted Multi-period Newsvendor Problems", "abs": ["In this paper, we consider a static, multi-period newsvendor model under a budget constraint. In the case where the true demand distribution is known, we develop a heuristic algorithm to solve the problem. By comparing this algorithm with off-the-shelf solvers, we show that it generates near-optimal solutions in a short time. We then consider a scenario in which limited information on the demand distribution is available. It is assumed, however, that the true demand distribution lies within some given family of distributions and that samples can be obtained from it. We consider the cases of normal and Poisson demands. For each case, we show that using maximum likelihood estimates in place of the true parameters can lead to poor estimates of the true cost associated with an order quantity. Hence, we make use of likelihood inference to develop confidence sets for the true parameters. These are used as ambiguity sets in a distributionally robust model, where we enforce that the worst-case distribution lies in the same family as the true distribution. We solve these models by discretising the ambiguity set and reformulating them as piecewise linear models. We show that these models quickly become large as the ambiguity set grows, resulting in long computation times. To overcome this, we propose a heuristic cutting surface algorithm that exploits theoretical properties of the objective function to reduce the size of the ambiguity set. We illustrate that our cutting surface algorithm solves orders of magnitude faster than the piecewise linear model, while generating very near-optimal solutions."], "authors": "Ben Black"},
{"Title": "Tree universality in positional games", "abs": ["In this paper we consider positional games where the winning sets are tree universal graphs. Specifically, we show that in the unbiased Maker-Breaker game on the complete graph $K_n$, Maker has a strategy to occupy a graph which contains copies of all spanning trees with maximum degree at most $cn/\\log(n)$, for a suitable constant $c$ and $n$ being large enough. We also prove an analogous result for Waiter-Client games. Both of our results show that the building player can play at least as good as suggested by the random graph intuition. Moreover, they improve on a special case of earlier results by Johannsen, Krivelevich, and Samotij as well as Han and Yang for Maker-Breaker games."], "authors": "Grzegorz Adamski"},
{"Title": "Atiyah sequences of braided Lie algebras and their splittings", "abs": ["Associated with an equivariant noncommutative principal bundle we give an Atiyah sequence of braided derivations whose splittings give connections on the bundle. Vertical braided derivations act as infinitesimal gauge transformations on connections. For the $SU(2)$-principal bundle over the sphere $S^{4}_\\theta$ an equivariant splitting of the Atiyah sequence recovers the instanton connection. An infinitesimal action of the braided conformal Lie algebra $so_\\theta(5,1)$ yields a five parameter family of splittings. On the principal $SO_\\theta(2n,\\mathbb{R})$-bundle of orthonormal frames over the sphere $S^{2n}_\\theta$, the splitting of the sequence leads to the Levi-Civita connection for the `round' metric on the $S^{2n}_\\theta$. The corresponding Riemannian geometry of $S^{2n}_\\theta$ is worked out."], "authors": "Paolo Aschieri"},
{"Title": "Optimal complexity of goal-oriented adaptive FEM for nonsymmetric linear elliptic PDEs", "abs": ["We analyze a goal-oriented adaptive algorithm that aims to efficiently compute the quantity of interest $G(u^\\star)$ with a linear goal functional $G$ and the solution $u^\\star$ to a general second-order nonsymmetric linear elliptic partial differential equation. The current state of the analysis of iterative algebraic solvers for nonsymmetric systems lacks the contraction property in the norms that are prescribed by the functional analytic setting. This seemingly prevents their application in the optimality analysis of goal-oriented adaptivity. As a remedy, this paper proposes a goal-oriented adaptive iteratively symmetrized finite element method (GOAISFEM). It employs a nested loop with a contractive symmetrization procedure, e.g., the Zarantonello iteration, and a contractive algebraic solver, e.g., an optimal multigrid solver. The various iterative procedures require well-designed stopping criteria such that the adaptive algorithm can effectively steer the local mesh refinement and the computation of the inexact discrete approximations. The main results consist of full linear convergence of the proposed adaptive algorithm and the proof of optimal convergence rates with respect to both degrees of freedom and total computational cost (i.e., optimal complexity). Numerical experiments confirm the theoretical results and investigate the selection of the parameters."], "authors": "Philipp Bringmann"},
{"Title": "Degenerate Schr{ö}dinger-Kirchhoff $(p, N)$-Laplacian problem With singular Trudinger-Moser nonlinearity in $\\mathbb{R}^N$", "abs": ["In this paper, we deal with the existence of nontrivial nonnegative solutions for a $(p, N)$-Laplacian Schr{ö}dinger-Kirchhoff problem in $\\mathbb{R}^N$ with singular exponential nonlinearity. The main features of the paper are the $(p, N)$ growth of the elliptic operators, the double lack of compactness, and the fact that the Kirchhoff function is of degenerate type. To establish the existence results, we use the mountain pass theorem, the Ekeland variational principle, the singular Trudinger-Moser inequality, and a completely new Brézis-Lieb type lemma for singular exponential nonlinearity."], "authors": "Deepak Kumar Mahanta"},
{"Title": "Glued lattices are better quantizers than $K_{12}$", "abs": ["40 years ago, Conway and Sloane proposed using the highly symmetrical Coxeter-Todd lattice $K_{12}$ for quantization, and estimated its second moment. Since then, all published lists identify $K_{12}$ as the best 12-dimensional lattice quantizer. Surprisingly, $K_{12}$ is not optimal: we construct two new 12-dimensional lattices with lower normalized second moments. The new lattices are obtained by gluing together 6-dimensional lattices."], "authors": "Erik Agrell"},
{"Title": "Normalized solutions for nonautonomous Schrödinger-Poisson equations", "abs": ["In this paper, we study the existence of normalized solutions for the nonautonomous Schrödinger-Poisson equations \\begin{equation}\\nonumber -\\Delta u+\\lambda u +\\left(\\vert x \\vert ^{-1} * \\vert u \\vert ^{2} \\right) u=A(x)|u|^{p-2}u,\\quad \\text{in}~\\R^3, \\end{equation} where $\\lambda\\in\\R$, $A \\in L^\\infty(\\R^3)$ satisfies some mild conditions. Due to the nonconstant potential $A$, we use Pohozaev manifold to recover the compactness for a minimizing sequence. For $p\\in (2,3)$, $p\\in(3,\\frac{10}{3})$ and $p\\in(\\frac{10}{3}, 6)$, we adopt different analytical techniques to overcome the difficulties due to the presence of three terms in the corresponding energy functional which scale differently, respectively."], "authors": "Yating Xu"},
{"Title": "Maximum principles for the fractional p-Laplacian and symmetry of solutions", "abs": ["In this paper, we consider nonlinear equations involving the fractional p-Laplacian $$ (-\\lap)_p^s u(x)) \\equiv C_{n,s,p} PV \\int_{\\mathbb{R}^n} \\frac{|u(x)-u(y)|^{p-2}[u(x)-u(y)]}{|x-z|^{n+ps}} dz= f(x,u).$$", "We prove a {\\em maximum principle for anti-symmetric functions} and obtain other key ingredients for carrying on the method of moving planes, such as {\\em a key boundary estimate lemma}. Then we establish radial symmetry and monotonicity for positive solutions to semilinear equations involving the fractional p-Laplacian in a unit ball and in the whole space. We believe that the methods developed here can be applied to a variety of problems involving nonlinear nonlocal operators."], "authors": "Wenxiong Chen"},
{"Title": "Maximum principles for nonlinear integro-differential equations and symmetry of solutions", "abs": ["In this paper, we study the semilinear integro-differential equations \\begin{equation*} \\mathcal{L}_{K}u(x)\\equiv C_n\\text{P.V.}\\int_{\\R^n}\\left(u(x)-u(y)\\right)K(x-y)dy=f(x,u), \\end{equation*} and the full nonlinear integro-differential equations \\begin{equation*} F_{G,K}u(x)\\equiv C_n\\text{P.V.}\\int_{\\R^n}G(u(x)-u(y))K(x-y)dy=f(x,u), \\end{equation*} where $K(\\cdot)$ is a symmetric jumping kernel and $K(\\cdot)\\geq C|\\cdot|^{-n-\\alpha}$, $G(\\cdot)$ is some nonlinear function without non-degenerate condition. We adopt the direct method of moving planes to study the symmetry and monotonicity of solutions for the integro-differential equations, and investigate the limit of some non-local operators $\\mathcal{L}_{K}$ as $\\alpha\\to2.$ Our results extended some results obtained in \\cite{CL} and \\cite{CLLG}."], "authors": "Huxiao Luo"},
{"Title": "An overpartition analogue of Bressoud conjecture for even moduli", "abs": ["In 1980, Bressoud conjectured a combinatorial identity $A_j=B_j$ for $j=0$ or $1$. In this paper, we introduce a new partition function $\\overline{B}_0$ which can be viewed as an overpartition analogue of the partition function $B_0$. An overpartition is a partition such that the last occurrence of a part can be overlined. We build a bijection to get a relationship between $\\overline{B}_0$ and $B_1$, based on which an overpartition analogue of Bressoud's conjecture for $j=0$ is obtained."], "authors": "Y.H. Chen"},
{"Title": "A global branch approach to normalized solutions for the Schrödinger equation", "abs": ["We study the existence, non-existence and multiplicity of prescribed mass positive solutions to a Schrödinger equation of the form \\begin{equation*} -\\Delta u+\\lambda u=g(u), \\quad u \\in H^1(\\mathbb{R}^N), \\, N \\geq 1. \\end{equation*} Our approach permits to handle in a unified way nonlinearities $g(s)$ which are either mass subcritical, mass critical or mass supercritical. Among its main ingredients is the study of the asymptotic behaviors of the positive solutions as $\\lambda\\rightarrow 0^+$ or $\\lambda\\rightarrow +\\infty$ and the existence of an unbounded continuum of solutions in $(0, + \\infty) \\times H^1(\\mathbb{R}^N)$."], "authors": "Louis Jeanjean"},
{"Title": "Uniqueness and nondegeneracy of ground states for the Schrödinger-Newton equation with power nonlinearity", "abs": ["In this article, we study the Schrödinger-Newton equation \\begin{equation} -\\Delta u+\\lambda u=\\frac{1}{4\\pi}\\left(\\frac{1}{|x|}\\star u^{2}\\right)u+|u|^{q-2}u \\quad \\text{in}~\\mathbb{R}^3, \\end{equation} where $\\lambda\\in\\mathbb{R}_+$, $q\\in (2,3)\\cup(3, 6)$. By investigating limit profiles of ground states as $\\lambda\\to0^+$ or $\\lambda\\to+\\infty$, we prove the uniqueness of ground states. By the action of the linearized eqaution with respect to decomposition into spherical harmonics, we obtain the nondegeneracy of ground states."], "authors": "Huxiao Luo"},
{"Title": "Lih Wang and Dittert Conjectures on Permanents", "abs": ["Let $\\Omega_n$ denote the set of all doubly stochastic matrices of order $n$. Lih and Wang conjectured that for $n\\geq3$, per$(tJ_n+(1-t)A)\\leq t $per$J_n+(1-t)$per$A$, for all $A\\in\\Omega_n$ and all $t \\in [0.5,1]$, where $J_n$ is the $n \\times n$ matrix with each entry equal to $\\frac{1}{n}$. This conjecture was proved partially for $n \\leq 5$. \\\\ \\indent Let $K_n$ denote the set of non-negative $n\\times n$ matrices whose elements have sum $n$. Let $\\phi$ be a real valued function defined on $K_n$ by $\\phi(X)=\\prod_{i=1}^{n}r_i+\\prod_{j=1}^{n}c_j$ - per$X$ for $X\\in K_n$ with row sum vector $(r_1,r_2,...r_n)$ and column sum vector $(c_1,c_2,...c_n)$. A matrix $A\\in K_n$ is called a $\\phi$-maximizing matrix if $\\phi(A)\\geq \\phi(X)$ for all $X\\in K_n$. Dittert conjectured that $J_n$ is the unique $\\phi$-maximizing matrix on $K_n$. Sinkhorn proved the conjecture for $n=2$ and Hwang proved it for $n=3$. \\\\ \\indent In this paper, we prove the Lih and Wang conjecture for $n=6$ and Dittert conjecture for $n=4$."], "authors": "Divya.K.U"},
{"Title": "Low-rank-modified Galerkin methods for the Lyapunov equation", "abs": ["Of all the possible projection methods for solving large-scale Lyapunov matrix equations, Galerkin approaches remain much more popular than Petrov-Galerkin ones. This is mainly due to the different nature of the projected problems stemming from these two families of methods. While a Galerkin approach leads to the solution of a low-dimensional matrix equation per iteration, a matrix least-squares problem needs to be solved per iteration in a Petrov-Galerkin setting. The significant computational cost of these least-squares problems has steered researchers towards Galerkin methods in spite of the appealing minimization properties of Petrov-Galerkin schemes. In this paper we introduce a framework that allows for modifying the Galerkin approach by low-rank, additive corrections to the projected matrix equation problem with the two-fold goal of attaining monotonic convergence rates similar to those of Petrov-Galerkin schemes while maintaining essentially the same computational cost of the original Galerkin method. We analyze the well-posedness of our framework and determine possible scenarios where we expect the residual norm attained by two low-rank-modified variants to behave similarly to the one computed by a Petrov-Galerkin technique. A panel of diverse numerical examples shows the behavior and potential of our new approach."], "authors": "Kathryn Lund"},
{"Title": "Growth Diagrams for Schubert RSK", "abs": ["Motivated by classical combinatorial Schubert calculus on the Grassmannian, Huang--Pylyavskyy introduced a generalized theory of Robinson-Schensted-Knuth (RSK) correspondence for studying Schubert calculus on the complete flag variety via insertion algorithms. The inputs of the correspondence are certain biwords, the insertion objects are bumpless pipe dreams, and the recording objects are certain chains in Bruhat order. In particular, they defined plactic biwords and showed that classical Knuth relations can be generalized to plactic biwords. In this paper, we give an analogue of Fomin's growth diagrams for this generalized RSK correspondence on plactic biwords. We show that this growth diagram recovers the bijection between pipe dreams and bumpless pipe dreams of Gao--Huang."], "authors": "Daoji Huang"},
{"Title": "A large family of strongly regular graphs with small Weisfeiler-Leman dimension", "abs": ["In 2002, D. Fon-Der-Flaass constructed a prolific family of strongly regular graphs. In this paper, we prove that for infinitely many natural numbers $n$, this family contains $n^{\\Omega(n^{2/3})}$ strongly regular $n$-vertex graphs $X$ with the same parameters, which satisfy the following condition: an isomorphism between $X$ and any other graph can be verified by the $4$-dimensional Weisfeiler-Leman algorithm."], "authors": "Jinzhuan Cai"},
{"Title": "The colored Jones polynomial of the figure-eight knot and an $\\operatorname{SL}(2;\\mathbb{R})$-representation", "abs": ["We study the asymptotic behavior of the $N$-dimensional colored Jones polynomial of the figure-eight knot, evaluated at $\\exp\\bigl((u+2p\\pi\\sqrt{-1})/N\\bigr)$ as $N$ tends to infinity, where $u>\\operatorname{arccosh}(3/2)$ is a real number and $p\\ge1$ is an integer. It turns out that it corresponds to an $\\operatorname{SL}(2;\\mathbb{R})$ representation of the fundamental group of the knot complement. Moreover, it defines the adjoint Reidemeister torsion and the Chern--Simons invariant associated with the representation."], "authors": "Hitoshi Murakami"},
{"Title": "Convolution algebras of double groupoids and strict 2-groups", "abs": ["Double groupoids are a type of higher groupoid structure that can arise when one has two distinct groupoid products on the same set of arrows. A particularly important example of such structures is the irrational torus and, more generally, strict 2-groups. Groupoid structures give rise to convolution operations on the space of arrows. Therefore, a double groupoid comes equipped with two product operations on the space of functions. In this article we investigate in what sense these two convolution operations are compatible. We use the representation theory of compact Lie groups to get insight into a certain class of 2-groups."], "authors": "Angel Roman"},
{"Title": "Propagation of chaos in path spaces via information theory", "abs": ["We study the mean-field limit of the stochastic interacting particle systems via tools from information theory. The key in our method is that, after applying the data processing inequality, one only needs to handle independent copies of solutions to the mean-field McKean stochastic differential equations, which then allows one to apply the law of large numbers. Our result on the propagation of chaos in path space is valid for both first and second order interacting particle systems; in particular, for the latter one our convergence rate is independent of the particle mass and also only linear in time. Our framework is different from current approaches in literature and could provide new insight for the study of interacting particle systems."], "authors": "Lei Li"},
{"Title": "On Novel Fixed-Point-Type Iterations with Structure-Preserving Doubling Algorithms for Stochastic Continuous-time Algebraic Riccati equations", "abs": ["In this paper we mainly propose efficient and reliable numerical algorithms for solving stochastic continuous-time algebraic Riccati equations (SCARE) typically arising from the differential statedependent Riccati equation technique from the 3D missile/target engagement, the F16 aircraft flight control and the quadrotor optimal control etc. To this end, we develop a fixed point (FP)-type iteration with solving a CARE by the structure-preserving doubling algorithm (SDA) at each iterative step, called FP-CARE SDA. We prove that either the FP-CARE SDA is monotonically nondecreasing or nonincreasing, and is R-linearly convergent, with the zero initial matrix or a special initial matrix satisfying some assumptions. The FP-CARE SDA (FPC) algorithm can be regarded as a robust initial step to produce a good initial matrix, and then the modified Newton (mNT) method can be used by solving the corresponding Lyapunov equation with SDA (FPC-mNT-Lyap SDA). Numerical experiments show that the FPC-mNT-Lyap SDA algorithm outperforms the other existing algorithms."], "authors": "Tsung-Ming Huang"},
{"Title": "A Framework for Solving Parabolic Partial Differential Equations on Discrete Domains", "abs": ["We introduce a framework for solving a class of parabolic partial differential equations on triangle mesh surfaces, including the Hamilton-Jacobi equation and the Fokker-Planck equation. PDE in this class often have nonlinear or stiff terms that cannot be resolved with standard methods on curved triangle meshes. To address this challenge, we leverage a splitting integrator combined with a convex optimization step to solve these PDE. Our machinery can be used to compute entropic approximation of optimal transport distances on geometric domains, overcoming the numerical limitations of the state-of-the-art method. In addition, we demonstrate the versatility of our method on a number of linear and nonlinear PDE that appear in diffusion and front propagation tasks in geometry processing."], "authors": "Leticia Mattos Da Silva"},
{"Title": "Simple homotopy types of even dimensional manifolds", "abs": ["We study the difference between simple homotopy equivalence and homotopy equivalence for closed manifolds of dimension $n \\geq$ 4. Given a closed $n$-manifold, we characterise the set of simple homotopy types of $n$-manifolds within its homotopy type in terms of algebraic $K$-theory, the surgery obstruction map, and the homotopy automorphisms of the manifold. We use this to construct the first examples, for all $n \\ge$ 4 even, of closed $n$-manifolds that are homotopy equivalent but not simple homotopy equivalent. In fact, we construct infinite families with pairwise the same properties, and our examples can be taken to be smooth for $n \\geq$ 6.", "We also show that, for $n \\ge 4$ even, orientable examples with fundamental group $C_\\infty \\times C_m$ exist if and only if $m$=4,8,9,12,15,16,18 or $\\ge$ 20. The proof involves analysing the obstructions which arise using integral representation theory and class numbers of cyclotomic fields. More generally, we consider the classification of the fundamental groups $G$ for which such examples exist. For $n \\ge$ 12 even, we show that examples exist for any finitely presented $G$ such that the involution on the Whitehead group $\\text{Wh}(G)$ is nontrivial. The key ingredient of the proof is a formula for the Whitehead torsion of a homotopy equivalence between doubles of thickenings."], "authors": "Csaba Nagy"},
{"Title": "New formula for the prepotentials associated with Hurwitz-Frobenius manifolds and generalized WDVV equations", "abs": ["We consider the Hurwitz spaces of ramified coverings of $\\mathbb{P}^1$ with prescribed ramification profile over the point at infinity. By means of a particular symmetric bidifferential on a compact Riemann surface, we introduce quasi-homogeneous differentials. By following Dubrovin, we construct on Hurwitz spaces a family of Frobenius manifold structures associated with the quasi-homogeneous differentials. We explicitly derive new generating formulas for the corresponding prepotentials. This produces quasi-homogeneous solutions to the following generalized WDVV associativity equations: $F_i\\eta^{-1}F_j=F_j\\eta^{-1}F_i$, where the invertible constant matrix $\\eta$ is a linear combination of the matrices $F_j$. In particular, our approach provides another look at Dubrovin's construction of semi-simple Hurwitz-Frobenius manifolds and establishes an alternative practical method to calculate their primary free energy functions. As applications, we use our formalism to obtain various explicit quasi-homogeneous solutions to the WDVV equations in genus zero and one and give a new proof of Ramanujan's differential equations for Eisenstein series."], "authors": "Chaabane Rejeb"},
{"Title": "A Polynomial Ring Connecting Central Binomial Coefficients and Gould's Sequence", "abs": ["We uncover a new connection between two well-known combinatorial sequences by passing through a specially constructed polynomial ring. We construct a ring $\\mathbb{Z}[a,b,c,\\ldots]$ where variables satisfy rules like $a^2 = 2a + b$, and show how expanding $(1+a)^n$ in our ring produces the central binomial coefficients $\\binom{2n}{n}$ when evaluated at $a=b=c=\\cdots=1$. Further, reducing the coefficients modulo $2$ prior to evaluation yields Gould's sequence. A method for computation of the binomial transforms of these sequences using our polynomial ring is also described. This creative linking of algebraic and combinatorial concepts is enabled by the design of our polynomial ring. By developing recursive rules mirroring sequence definitions, this structure enables manipulating sequences algebraically through polynomial expansion."], "authors": "Joseph M. Shunia"},
{"Title": "A Simple Formula for Binomial Coefficients Revealed Through Polynomial Encoding", "abs": ["We provide a detailed derivation of a new formula for binomial coefficients by harnessing an underexplored property of polynomial encoding. The formula, $\\binom{n}{k} = \\left\\lfloor\\frac{(1 + 2^{n})^{n}}{2^{n k}}\\right\\rfloor \\bmod{2^{n}}$, is valid for $n > 0$ and $0 \\leq k \\leq n$. We relate this formula to existing mathematical methods via Kronecker substitution. To showcase the versatility of our approach, we also apply it to multinomials. A baseline computational complexity analysis identifies opportunities for optimization. We conclude by positing an open problem concerning the efficient computation of $\\binom{n}{k}$ modulo $n$ using our formula."], "authors": "Joseph M. Shunia"},
{"Title": "An equivalent criteria for irrationality of $ζ(5)$", "abs": ["Defining a Beukers [1] like integral for $\\zeta(5)$ as \\begin{equation*} I_n:=\\int_{(0,1)^5}\\frac{(1-x_3)^n(1-x_4)^n P_n(x_1)P_n(x_2)}{1-(1-x_1x_2x_3x_4)x_5} \\ dx_1dx_2dx_3dx_4dx_5 \\end{equation*} we prove that for each $n\\in\\mathbb{N}$ \\begin{equation*} I_n= \\frac{p_n\\zeta(5)+q_n\\zeta(4)+r_n\\zeta(3)+s_n}{d_n^5} \\end{equation*} where $p_n,q_n,r_n,s_n$ are integers and $d_n=\\text{lcm}(1,2,...,n)$. We prove that the following are equivalent:", "1. $q_n\\zeta(4)+r_n\\zeta(3)-d_n^5 I_n\\notin\\mathbb{Z}$ for each natural number $n$.", "2. $q_n\\zeta(4)+r_n\\zeta(3)-d_n^5 I_n\\notin\\mathbb{Z}$ for infinitely many natural number $n$.", "3. $\\zeta(5)$ is irrational."], "authors": "Shekhar Suman"},
{"Title": "A note on Apery's constant is transcendental", "abs": ["Beuker's [2] considers the following integral $$ \\int_{0}^{1}\\int_{0}^{1} \\frac{-\\log xy}{1-xy} P_n(x)P_n(y)\\ dx dy$$If $d_n=\\text{LCM}(1,2,...,n)$, then $$", "0<\\frac{|A_n+B_n\\zeta(3)|}{d_n^3}<2(\\sqrt{2}-1)^{4n} \\zeta(3) $$ for some $A_n,B_n\\in\\mathbb{Z}$. We establish that if Apery's constant is algebraic then the above inequality fails to be true. This proves that $\\zeta(3)$ is"], "authors": "Shekhar Suman"},
{"Title": "On irrationality of Euler's constant and related asymptotic formulas", "abs": ["By defining $$I_n:=\\int_{0}^{1}\\int_{0}^{1} \\frac{(x(1-x)y(1-y))^n}{(1-xy)(-\\log xy)}\\ dx dy$$ Sondow (see [2]) proved that $$I_n=\\binom{2n}{n} \\gamma+L_n-A_n$$ We prove asymptotic formula for $L_n$ and $A_n$ as $n\\to\\infty$, $$ L_n=\\binom{2n}{n}\\left(\\log \\left( {\\frac{3n}{2}} \\right) +\\mathcal{O}\\!\\left( {\\frac{1}{n}} \\right)\\right)$$ and $$A_n\\sim\\frac{4^n}{\\sqrt{\\pi n}}\\left(\\gamma+\\ln\\frac32+\\ln n\\right)$$ Using the sufficient condition for irrationality criteria of Euler's constant due to Sondow, we prove that $\\gamma$ is irrational."], "authors": "Shekhar Suman"},
{"Title": "The Existence the Solution of Nonlinear Discrete Schemes and Convergence of a Linearized Iterative Method for time-dependent PNP Equations", "abs": ["We establish the existence theory of several commonly used finite element (FE) nonlinear fully discrete solutions, and the convergence theory of a linearized iteration. First, it is shown for standard FE, SUPG and edge-averaged method respectively that the stiffness matrix is a column M-matrix under certain conditions, and then the existence theory of these three FE nonlinear fully discrete solutions is presented by using Brouwer's fixed point theorem. Second, the contraction of a commonly used linearized iterative method-Gummel iteration is proven, and then the convergence theory is established for the iteration. At last, a numerical experiment is shown to verifies the theories."], "authors": "Yang Liu"},
{"Title": "Formula of boundary crossing probabilities by the Girsanov theorem", "abs": ["A formula for the probability that a Wiener process with stochastic drift process and random variance crosses a one-sided stochastic boundary process in a finite time interval is derived. This formula is obtained by the Girsanov theorem when considering an equivalent probability measure where the boundary is constant equal to its starting value and the drift is null. We assume that the drift minus the deviation of the boundary from its starting value divided by the standard deviation is absolutely continuous and that its derivative satisfies Novikov's condition. Since the formula is not completely explicit, we also give an explicit formula based on one theoretical approximation. We also derive a formula in the two-sided boundary case when the difference between the deviation of each boundary from their starting value is linear."], "authors": "Yoann Potiron"},
{"Title": "Explicit formula of boundary crossing probabilities for continuous local martingales to constant boundary", "abs": ["An explicit formula for the probability that a continuous local martingale crosses a one or two-sided random constant boundary in a finite time interval is derived. We obtain that the boundary crossing probability of a continuous local martingale to a constant boundary is equal to the boundary crossing probability of a standard Wiener process to a constant boundary up to a time change of quadratic variation value. This relies on the constancy of the boundary and the Dambis, Dubins-Schwarz theorem for continuous local martingale. The main idea of the proof is the scale invariant property of the time-changed Wiener process and thus the scale invariant property of the first-passage time."], "authors": "Yoann Potiron"},
{"Title": "On the residual nilpotence of generalized free products of groups", "abs": ["Let $G$ be the generalized free product of two groups with an amalgamated subgroup. We propose an approach that allows one to use results on the residual $p$-finiteness of $G$ for proving that this generalized free product is residually a finite nilpotent group or residually a finite metanilpotent group. This approach can be applied under most of the conditions on the amalgamated subgroup that allow the study of residual $p$-finiteness. Namely, we consider the cases where the amalgamated subgroup is a) periodic, b) locally cyclic, c) central in one of the free factors, d) normal in both free factors, or e) is a retract of one of the free factors. In each of these cases, we give certain necessary and sufficient conditions for $G$ to be residually a) a finite nilpotent group, b) a finite metanilpotent group."], "authors": "E. V. Sokolov"},
{"Title": "The shift orbits of the graded Kronecker modules", "abs": ["The Kronecker modules (or matrix pencils) are the representations of the n-Kronecker quiver K(n) (the quiver with two vertices, namely a sink and a source, and n arrows) over some fixed field. The universal cover of K(n) is the n-regular tree with bipartite orientation.", "The paper deals with the representations of the n-regular tree with bipartite orientation (thus with graded Kronecker modules). The simultaneous Bernstein-Gelfand-Ponomarev reflection at all sinks will be called the shift functor, and we consider the orbits under this shift functor. Whereas the length of a regular module growths exponentially when we apply the shift functor repeatedly, the radius of such a module growths just linearly.", "To any regular shift orbit, we attach a positive integer r (the minimal radius of the sink modules in the orbit) and the path in T(n) which starts at the center p of the sink modules in the orbit and ends at the center q of the source modules in the orbit. If r is even, then p has to be a sink, otherwise a source. We call this path the center path of the orbit (since the center of any module in the orbit lies on this path). If the center path of a shift orbit has length b, then the orbit contains precisely b flow modules, the remaining modules are sink modules and source modules. We use this division in order to index the regular graded Kronecker modules in a coherent way. Conversely, we show that given a positive integer r and a path in T(n) (starting at a sink iff r is even), there are regular shift orbits with these invariants."], "authors": "Claus Michael Ringel"},
{"Title": "Middle terms of AR-sequences of graded Kronecker modules", "abs": ["Let $(T(n),\\Omega)$ be the covering of the generalized Kronecker quiver $K(n)$, where $\\Omega$ is a bipartite orientation. Then there exists a reflection functor $\\sigma$ on the category $\\mod(T(n),\\Omega)$. Suppose that $0\\rightarrow X\\rightarrow Y\\rightarrow Z\\rightarrow 0$ is an AR-sequence in the regular component $\\mathcal{D}$ of $\\mod(T(n),\\Omega)$, and $b(Z)$ is the number of flow modules in the $\\sigma$-orbit of $Z$. Then the middle term $Y$ is a sink (source or flow) module if and only if $\\sigma Z$ is a sink (source or flow) module. Moreover, their radii and centers satisfy $r(Y)=r(\\sigma Z)+1$ and $C(Y)=C(\\sigma Z)$."], "authors": "Jie Liu"},
{"Title": "Unreachability of $\\bf{Γ_{2n+1,m}}$", "abs": ["We find bounds for the maximal length of a sequence of distinct $\\bf{\\Gamma_{2n+1,m}}$-sets under $AD$ and show there is no sequence of distinct $\\bf{\\Gamma_{2n+1}}$-sets of length $\\bf{\\delta^1_{2n+3}}$. As a special case, there is no sequence of distinct $\\bf{\\Gamma_{1,m}}$-sets of length $\\aleph_{m+2}$. These are the optimal results for the pointclasses $\\bf{\\Gamma_{2n+1}}$ and $\\bf{\\Gamma_{1,m}}$."], "authors": "Derek Levinson"},
{"Title": "Stochastic forward-backward-half forward splitting algorithm with variance reduction", "abs": ["In this paper, we present a stochastic forward-backward-half forward splitting algorithm with variance reduction for solving the structured monotone inclusion problem composed of a maximally monotone operator, a maximally monotone and Lipschitz continuous operator and a cocoercive operator. By defining a Lyapunov function, we establish the almost sure convergence of the proposed algorithm, and obtain the linear convergence when one of the maximally monotone operators is strongly monotone. Numerical examples are provided to show the performance of the proposed algorithm."], "authors": "Liqian Qin"},
{"Title": "On the Riemann integrability of the norm of a path in normed spaces", "abs": ["A useful result is that if a bounded complex-valued path is Riemann-integrable, then its modulus is also Riemann-integrable. The extension of this last result to bounded paths taking values in a normed space is affirmed, as being true, in [3]. However, we show that if a bounded path taking values in a normed space is barely Riemann-integrable, then it is not really guaranteed that the norm of this path is also Riemann-integrable."], "authors": "Borys Álvarez-Samaniego"},
{"Title": "Note on approximation of truncated Baskakov operators by Fuzzy numbers", "abs": ["In this paper, we firstly introduce nonlinear truncated Baskakov operators on compact intervals and obtain some direct theorems. Also, we give the approximation of fuzzy numbers by truncated nonlinear Baskakov operators."], "authors": "Ecem Acar"},
{"Title": "The minimum number of peeling sequences of a point set", "abs": ["Let $P$ be a set of $n$ points in $\\mathbb{R}^d$, in general position. We remove all of them one by one, in each step erasing one vertex of the convex hull of the current remaining set. Let $g_d(P)$ denote the number of different removal orders we can attain while erasing all points of $P$ this way, and let $g_d(n)$ be the \\emph{minimum} of $g_d(P)$ over all $n$-element point sets $P\\subset \\mathbb{R}^d$. Dumitrescu and Tóth showed that $g_d(n)=O((d+1)^{(d+1)^2n})$.", "We substantially improve their bound, by proving that $g_d(n)= O((d+d\\ln{(d)})^{(2+\\frac{(d-1)}{\\lfloor d\\ln{d}\\rfloor})n})$. It follows that, for any $\\epsilon>0$, there exist sufficiently high dimensional point sets $P\\subset \\mathbb{R}^d$ with $g_d(P)\\leq O(d^{(2+\\epsilon)n})$. This almost closes the gap between the upper bound and the best-known lower bound $(d+1)^n$."], "authors": "Dániel Gábor Simon"},
{"Title": "Betti graphs and atomization of Puiseux monoids", "abs": ["Let $M$ be a Puiseux monoid, that is, a monoid consisting of nonnegative rationals (under addition). A nonzero element of $M$ is called an atom if its only decomposition as a sum of two elements in $M$ is the trivial decomposition (i.e., one of the summands is $0$), while a nonzero element $b \\in M$ is called atomic if it can be expressed as a sum of finitely many atoms allowing repetitions: this formal sum of atoms is called an (additive) factorization of $b$. The monoid $M$ is called atomic if every nonzero element of $M$ is atomic. In this paper, we study factorizations in atomic Puiseux monoids through the lens of their associated Betti graphs. The Betti graph of $b \\in M$ is the graph whose vertices are the factorizations of $b$ with edges between factorizations that share at least one atom. Betti graphs have been useful in the literature to understand several factorization invariants in the more general class of atomic monoids."], "authors": "Scott T. Chapman"},
{"Title": "Cofiltrations of spanning trees in multiparameter persistent homology", "abs": ["Given a multiparameter filtration of simplicial complexes, we consider the problem of explicitly constructing generators for the multipersistent homology groups with arbitrary PID coefficients. We propose the use of spanning trees as a tool to identify such generators by introducing a condition for persistent spanning trees, which is accompanied by an existence result for cofiltrations consisting of spanning trees. We also introduce a generalization of spanning trees, called spanning complexes, for dimensions higher than one, and we establish their existence as a first step towards this direction."], "authors": "Fritz Grimpen"},
{"Title": "W-volume for planar domains with circular boundary", "abs": ["We extend the notion of Epstein maps to conformal metrics on submanifolds of the unit sphere $\\mathbb{S}^n=\\partial_\\infty\\mathbb{H}^{n+1}$. Using this construction for curves in $\\mathbb{S}^2$, we define the W-volume for conformal metrics on domains in $\\overline{\\mathbb{C}}=\\mathbb{S}^2$ with round circles as boundaries. We show that the W-volume is a realization in $\\mathbb{H}^3$ of the determinant of the Laplacian. We use this and work of Osgood, Phillips and Sarnak to show that a classical Schottky uniformization of a genus g Riemann surface has renormalized volume bounded by $(6g-8)\\pi$, and by $-2\\pi$ under further assumptions. This gives a partial answer to a question of Maldacena. We also then provide a $\\mathbb{H}^3$ realization of the Loewner energy of a $C^{2,\\alpha}$ Jordan curve."], "authors": "Jeffrey Brock"},
{"Title": "Super Kähler structures on the complex Abelian Lie supergroups", "abs": ["We consider a real Abelian Lie supergroup G acting on its complexification M, equipped with a G-invariant super Kähler form. We extend the scheme of classical geometric quantization to this setting and construct a unitary G-representation. We show that the occurrences of its irreducible subrepresentations are governed by the image of the moment map of the super Kähler form. As an application, we construct a Gelfand model of G, namely a unitary G-representation in which every unitary irreducible representation occurs exactly once."], "authors": "Meng-Kiat Chuah"},
{"Title": "Sobolev improvements on sharp Rellich inequalities", "abs": ["There are two Rellich inequalities for the bilaplacian, that is for $\\int (\\Delta u)^2dx$, the one involving $|\\nabla u|$ and the other involving $|u|$ at the RHS. In this article we consider these inequalities with sharp constants and obtain sharp Sobolev-type improvements. More precisely, in our first result we improve the Rellich inequality with $|\\nabla u|$ obtained recently by Cazacu in dimensions $n=3,4$ by a sharp Sobolev term thus complementing existing results for the case $n\\geq 5$. In the second theorem the sharp constant of the Sobolev improvement for the Rellich inequality with $|u|$ is obtained."], "authors": "Gerassimos Barbatis"},
{"Title": "Inertial (self-)collisions of viscoelastic solids with Lipschitz boundaries", "abs": ["We continue our study, started in", ", of (self-)collisions of viscoelastic solids in an inertial regime. We show existence of weak solutions with a corresponding contact force measure in the case of solids with only Lipschitz-regular boundaries. This necessitates a careful study of different concepts of tangent and normal cones and the role these play both in the proofs and in the formulation of the problem itself. Consistent with our previous approach, we study contact without resorting to penalization, i.e. by only relying on a strict non-interpenetration condition. Additionally, we improve the strategies of our previous proof, eliminating the need for regularization terms across all levels of approximation."], "authors": "Antonín Češík"},
{"Title": "Every Elementary Graph is Chromatic Choosable", "abs": ["Elementary graphs are graphs whose edges can be colored using two colors in such a way that the edges in any induced $P_3$ get distinct colors. They constitute a subclass of the class of claw-free perfect graphs. In this paper, we show that for any elementary graph, its list chromatic number and chromatic number are equal."], "authors": "Nandana K Vasudevan"},
{"Title": "Polygraphs: From Rewriting to Higher Categories", "abs": ["Polygraphs are a higher-dimensional generalization of the notion of directed graph. Based on those as unifying concept, this monograph on polygraphs revisits the theory of rewriting in the context of strict higher categories, adopting the abstract point of view offered by homotopical algebra. The first half explores the theory of polygraphs in low dimensions and its applications to the computation of the coherence of algebraic structures. It is meant to be progressive, with little requirements on the background of the reader, apart from basic category theory, and is illustrated with algorithmic computations on algebraic structures. The second half introduces and studies the general notion of n-polygraph, dealing with the homotopy theory of those. It constructs the folk model structure on the category of strict higher categories and exhibits polygraphs as cofibrant objects. This allows extending to higher dimensional structures the coherence results developed in the first half."], "authors": "Dimitri Ara"},
{"Title": "A multivariate version of Polya-Carlson theorem", "abs": ["Polya-Carlson theorem asserts that if a power series with integer coefficients and convergence radius 1 can be extended holomorphically out of the unit disc, it must represent a rational function. In this note, we give a generalization of this result to multivariate case and give an application to rationality theorem about D-finite power series."], "authors": "Tianlong Yu"},
{"Title": "Integral representations and zeros of the Lommel function and the hypergeometric $_1F_2$ function", "abs": ["We give different integral representations of the Lommel function $s_{\\mu,\\nu}(z)$ involving trigonometric and hypergeometric $_1F_1$ functions. By using classical results of Polya, we give the distribution of the zeros of $s_{\\mu,\\nu}(z)$ for certain regions in the plane $(\\mu,\\nu)$. Further, thanks to a well known relation between the functions $s_{\\mu,\\nu}(z)$ and the hypergeometric $ _1F_2$ function, we describe the distribution of the zeros of $_1F_2$ for specific values of its parameters."], "authors": "Federico Zullo"},
{"Title": "Divides with cusps and symmetric links", "abs": ["A Divide with cusps is the image of a proper generic immersion from finite intervals and circles into a 2-disk which allows to have cusps. A divide with cusps is the generalization of the notion of the divide which is introduced by A'Campo. From a divide with cusps, we can define the associated link in $S^3$. In this paper, we give the characterization of the link in $S^3$ which can be described as the associated link of a divide with cusps. In particular, we prove that every strongly invertible link and $2$-periodic link can be described as the link of a divide with cusps."], "authors": "Sakumi Sugawara"},
{"Title": "Diophantine transference principle over function fields", "abs": ["We study the Diophantine transference principle over function fields. By adapting the approach of Beresnevich and Velani to the function field set-up, we extend many results from homogeneous Diophantine approximation to the realm of inhomogeneous Diophantine approximation over function fields. This also yields the inhomogeneous Baker-Sprindzuk conjecture over function fields as a consequence. Furthermore, we prove the upper bounds for the general non-extremal scenario."], "authors": "Sourav Das"},
{"Title": "On 2-bisections and monochromatic edges in claw-free cubic multigraphs", "abs": ["A $k$-bisection of a multigraph $G$ is a partition of its vertex set into two parts of the same cardinality such that every component of each part has at most $k$ vertices. Cui and Liu shown that every claw-free cubic multigraph contains a $2$-bisection, while Eom and Ozeki constructed specific $2$-bisections with bounded number of monochromatic edges. Their bound is the best possible for claw-free cubic simple graphs. In this note, we extend the latter result to the larger family of claw-free cubic multigraphs"], "authors": "Federico Romaniello"},
{"Title": "Parabolic subgroups in characteristics two and three", "abs": ["This text brings to an end the classification of non-reduced parabolic subgroups in positive characteristic, especially two and three: they are all obtained as intersections of parabolics having maximal reduced part. We prove this result and deduce a few geometric consequences on rational projective homogeneous varieties."], "authors": "Matilde Maccan"},
{"Title": "About universality of large deviation principles for conjugacy invariant permutations", "abs": ["We prove the universality of the large deviations for  conjugacy invariant permutations with few cycles. As an application,  we establish the universality of large deviation at speeds $n$ and $\\sqrt{n}$ for the length of monotone subsequences in conjugacy invariant permutations, with a  sharp control over the total number of cycles. This universality class includes the well-known Ewens measures."], "authors": "Alice Guionnet"},
{"Title": "Intertwining operators in the Takeda-Wood isomorphism", "abs": ["Over any non-Archimedean local field of characteristic not equal to $2$, Takeda and Wood constructed types for the two blocks containing the even and odd Weil representations of the metaplectic group $\\tilde{G}$, and identified the resulting Hecke algebras $H_\\psi^{\\pm}$ with the Iwahori-Hecke algebras of odd orthogonal groups $G^{\\pm}$ of the same rank. We describe normalized parabolic induction and Jacquet modules in terms of Hecke modules using a suitable variant of Bushnell-Kutzko theory. Furthermore, we match the standard intertwining operators of $\\tilde{G}$ and $G^{\\pm}$ by proving a variant of Gindikin-Karpelevich formula for $\\tilde{G}$. As an application, we describe the behavior of normalized intertwining operators of $\\tilde{G}$ in these blocks under Aubert involution, reducing everything to the $G^{\\pm}$ side. This is mainly motivated by Arthur's local intertwining relations."], "authors": "Fei Chen"},
{"Title": "Dynamics of a diffusive predator-prey system with fear effect in advective environments", "abs": ["We explore a diffusive predator-prey system that incorporates the fear effect in advective environments. Firstly, we analyze the eigenvalue problem and the adjoint operator, considering Constant-Flux and Dirichlet (CF/D) boundary conditions, as well as Free-Flow (FF) boundary conditions. Our investigation focuses on determining the direction and stability of spatial Hopf bifurcation, with the generation delay $\\tau$ serving as the bifurcation parameter. Additionally, we examine the influence of both linear and Holling-II functional responses on the dynamics of the model. Through these analyses, we aim to gain a better understanding of the intricate relationship between advection, predation, and prey response in this system."], "authors": "Daifeng Duan"},
{"Title": "Inverse-Optimization-Based Uncertainty Set for Robust Linear Optimization", "abs": ["We consider solving linear optimization (LO) problems with uncertain objective coefficients. For such problems, we often employ robust optimization (RO) approaches by introducing an uncertainty set for the unknown coefficients. Typical RO approaches require observations or prior knowledge of the unknown coefficient to define an appropriate uncertainty set. However, such information may not always be available in practice. In this study, we propose a novel uncertainty set for robust linear optimization (RLO) problems without prior knowledge of the unknown coefficients. Instead, we assume to have data of known constraint parameters and corresponding optimal solutions. Specifically, we derive an explicit form of the uncertainty set as a polytope by applying techniques of inverse optimization (IO). We prove that the RLO problem with the proposed uncertainty set can be equivalently reformulated as an LO problem. Numerical experiments show that the RO approach with the proposed uncertainty set outperforms classical IO in terms of performance stability."], "authors": "Ayaka Ueta"},
{"Title": "Optimal Reverse-Complement-Duplication Error-Correcting Codes", "abs": ["Motivated by DNA storage in living organisms and inspired by biological mutation processes, this study explores the reverse-complement string-duplication system. We commence our investigation by introducing an optimal $q$-ary reverse-complement-duplication code construction for duplication length $1$ and any number of duplications, achieving a size of $\\Theta(q^n)$.", "Subsequently, we establish a fundamental limitation, proving that for duplication lengths greater than $1$, all reverse-complement-duplication codes correcting any number of duplications possess a size of $o(q^n)$. Further, we present a construction of reverse-complement-duplication codes with a duplication length of $2$, demonstrating a redundancy of at most $\\log_q(n/2) + \\log_q(\\log_q(n)+1) + 2 + \\log_q(3)$. Finally, we contribute an explicit construction for $q$-ary codes addressing a single classical tandem duplication for any $k$. The redundancy of these codes is $\\log_q(n/k) + 1 + (k-1)\\log_q(\\log_q(2n/k)+1)$."], "authors": "Lev Yohananov"},
{"Title": "Embeddings of infinite-dimensional spaces in the sets of norm-attaining Lipschitz functions", "abs": ["Motivated by the result of Dantas et. al. (2023) that there exist metric spaces for which the set of strongly norm-attaining Lipschitz functions does not contain an isometric copy of $c_0$, we introduce and study a weaker notion of norm-attainment for Lipschitz functions called the pointwise norm-attainment. As a main result, we show that for every infinite metric space $M$, there exists a metric space $M_0 \\subseteq M$ such that the set of pointwise norm-attaining Lipschitz functions on $M_0$ contains an isometric copy of $c_0$. We also observe that there are countable metric spaces $M$ for which the set of pointwise norm-attaining Lipschitz functions contains an isometric copy of $\\ell_\\infty$, which is a result that does not hold for the set of strongly norm-attaining Lipschitz functions. Several new results on $c_0$-embedding and $\\ell_1$-embedding into the set of strongly norm-attaining Lipschitz functions are presented as well. In particular, we show that if $M$ is a subset of an $\\mathbb{R}$-tree containing all the branching points, then the set of strongly norm-attaining Lipschitz functions contains $c_0$ isometrically. As a related result, we provide an example of metric space $M$ for which the set of norm-attaining functionals on the Lipschitz-free space over $M$ cannot contain an isometric copy of $c_0$. Finally, we compare the concept of pointwise norm-attainment with the several different kinds of norm-attainment from the literature."], "authors": "Geunsu Choi"},
{"Title": "The Collatz map in polynomial rings and in completions", "abs": ["We study an analogue of the Collatz map in the polynomial ring $R[x]$, where $R$ is an arbitrary commutative ring. We prove that if $R$ is of positive characteristic, then every polynomial in $R[x]$ is eventually periodic with respect to this map. This extends previous works of the authors and of Hicks, Mullen, Yucas and Zavislak, who studied the Collatz map on $\\mathbb{F}_p[x]$ and $\\mathbb{F}_2[x]$, respectively. We also consider the Collatz map on the ring of formal power series $R[[x]]$, characterize the eventually periodic series in this ring, and, if $R$ is finite, give formulas for the number of cycles induced by the Collatz map, of any given length. We provide similar formulas for the original Collatz map defined on the ring $\\mathbb{Z}_2$ of $2$-adic integers, extending previous results of Lagarias."], "authors": "Angelot Behajaina"},
{"Title": "Sample path MDP for the current and the tagged particle in the SSEP", "abs": ["We prove sample path moderate deviation principles (MDP) for the current and the tagged particle in the symmetric simple exclusion process, which extends the results in \\cite{xue2023moderate}, where the MDP was only proved at any fixed time."], "authors": "Xiaofeng Xue"},
{"Title": "On the automorphism group of a distance-regular graph", "abs": ["The motion of a graph is the minimal degree of its full automorphism group. Babai conjectured that the motion of a primitive distance-regular graph on $n$ vertices of diameter greater than two is at least $n/C$ for some universal constant $C > 0$, unless the graph is a Johnson or Hamming graph. We prove that the motion of a distance-regular graph of diameter $d \\geq 3$ on $n$ vertices is at least $Cn/(\\log n)^6$ for some universal constant $C > 0$, unless it is a Johnson, a Hamming or a crown graph. This follows using an improvement of an earlier result by Kivva who gave a lower bound on motion of the form $n/c_d$, where $c_d$ depends exponentially on $d$. As a corollary we derive a quasipolynomial upper bound for the automorphism group of a primitive distance-regular graph acting edge-transitively on the graph and on its distance-2 graph. The proofs use elementary combinatorial arguments and do not depend on the classification of finite simple groups."], "authors": "László Pyber"},
{"Title": "A new approach for the implementation of contact line motion based on the phase-filed lattice Boltzmann method", "abs": ["This paper proposes a new strategy to implement the free-energy based wetting boundary condition within the phase-field lattice Boltzmann method. The greatest advantage of the proposed method is that the implementation of contact line motion can be significantly simplified while still maintaining good accuracy. For this purpose, the liquid-solid free energy is treated as a part of the chemical potential instead of the boundary condition, thus avoiding complicated interpolations with irregular geometries. Several numerical testing cases including the droplet spreading processes on the idea flat, inclined and curved boundaries are conducted, and the results demonstrate that the proposed method has good ability and satisfactory accuracy to simulate contact line motions."], "authors": "Long Ju"},
{"Title": "The upper bound of the spectral radius for the hypergraphs without Berge-graphs", "abs": ["The spectral analogue of the Turán type problem for hypergraphs is to determine the maximum spectral radius for the hypergraphs of order $n$ that do not contain a given hypergraph. For the hypergraphs among the set of the connected linear $3$-uniform hypergraphs on $n$ vertices without the Berge-$C_l$, we present two upper bounds for their spectral radius and $\\alpha$-spectral radius, which are related to $n$,$l$ and $\\alpha$, where $C_l$ is a cycle of length $l$ with $l\\geqslant 5$, $n\\geqslant 3$ and $0 \\leqslant \\alpha<1$. Let $B_s$ be an $s$-book with $s\\geqslant2$ and $K_{s,t}$ be a complete bipartite graph with two parts of size $s$ and $t$, respectively, where $s,t \\geqslant 1$. For the hypergraphs among the set of the connected linear $k$-uniform hypergraphs on $n$ vertices without the Berge-$\\{B_s, K_{2,t}\\}$, we derive two upper bounds for their spectral radius and $\\alpha$-spectral radius, which depend on $n$, $k$, $s$, and $\\alpha$, where $n$,$k\\geqslant 3$,$s\\geqslant 2$,$1\\leqslant t\\leqslant \\frac{1}{2}(6k^2-15k+10)(s-1)+1$, and $0\\leqslant \\alpha <1$."], "authors": "Wen-Huan Wang"},
{"Title": "Unbounded Donoho-Stark-Elad-Bruckstein-Ricaud-Torrésani Uncertainty Principles", "abs": ["Let $(\\Omega, \\mu)$, $(\\Delta, \\nu)$ be measure spaces and $p=1$ or $p=\\infty$. Let $(\\{f_\\alpha\\}_{\\alpha\\in \\Omega}, \\{\\tau_\\alpha\\}_{\\alpha\\in \\Omega})$ and $(\\{g_\\beta\\}_{\\beta\\in \\Delta}, \\{\\omega_\\beta\\}_{\\beta\\in \\Delta})$ be unbounded continuous p-Schauder frames for a Banach space $\\mathcal{X}$. Then for every $x \\in ( \\mathcal{D}(\\theta_f) \\cap\\mathcal{D}(\\theta_g))\\setminus\\{0\\}$, we show that \\begin{align}\\label{UB}", "(1) \\quad \\quad \\quad \\quad \\mu(\\operatorname{supp}(\\theta_f x))\\nu(\\operatorname{supp}(\\theta_g x)) \\geq \\frac{1}{\\left(\\displaystyle\\sup_{\\alpha \\in \\Omega, \\beta \\in \\Delta}|f_\\alpha(\\omega_\\beta)|\\right)\\left(\\displaystyle\\sup_{\\alpha \\in \\Omega , \\beta \\in \\Delta}|g_\\beta(\\tau_\\alpha)|\\right)}, \\end{align} where \\begin{align*} &\\theta_f:\\mathcal{D}(\\theta_f) \\ni x \\mapsto \\theta_fx \\in \\mathcal{L}^p(\\Omega, \\mu); \\quad \\theta_fx: \\Omega \\ni \\alpha \\mapsto (\\theta_fx) (\\alpha):= f_\\alpha (x) \\in \\mathbb{K},\\\\ &\\theta_g: \\mathcal{D}(\\theta_g) \\ni x \\mapsto \\theta_gx \\in \\mathcal{L}^p(\\Delta, \\nu); \\quad \\theta_gx: \\Delta \\ni \\beta \\mapsto (\\theta_gx) (\\beta):= g_\\beta (x) \\in \\mathbb{K}. \\end{align*} We call Inequality (1) as \\textbf{Unbounded Donoho-Stark-Elad-Bruckstein-Ricaud-Torrésani Uncertainty Principle}. Along with recent \\textbf{Functional Continuous Uncertainty Principle} [", "], Inequality (1) also improves Ricaud-Torrésani uncertainty principle [IEEE Trans. Inform. Theory, 2013]. In particular, it improves Elad-Bruckstein uncertainty principle [IEEE Trans. Inform. Theory, 2002] and Donoho-Stark uncertainty principle [SIAM J. Appl. Math., 1989]."], "authors": "K. Mahesh Krishna"},
{"Title": "Matrix representations of linear transformations on bicomplex space", "abs": ["An algebraic investigation on bicomplex numbers is carried out here. Particularly matrices and linear maps defined on them are discussed. A new kind of cartesian product, referred to as an idempotent product, is introduced and studied. The elements of this space are linear maps of a special form. These linear maps are examined with respect to usual notions like kernel, range, and singularity. Their matrix representation is also discussed."], "authors": "Anjali"},
{"Title": "WENO based adaptive image zooming algorithm", "abs": ["Image zooming or upsampling is a widely used tool in image processing and an essential step in many algorithms. Upsampling increases the number of pixels and introduces new information into the image, which can lead to numerical effects such as ringing artifacts, aliasing effects, and blurring of the image. In this paper, we propose an efficient polynomial interpolation algorithm based on the WENO algorithm for image upsampling that provides high accuracy in smooth regions, preserves edges and reduces aliasing effects. Although this is not the first application of WENO interpolation for image resampling, it is designed to have comparable complexity and memory load with better image quality than the separable WENO algorithm.", "We show that the algorithm performs equally well on smooth 2D functions, artificial pixel art, and real digital images. Comparison with similar methods on test images shows good results on standard metrics and also provides visually satisfactory results. Moreover, the low complexity of the algorithm is ensured by a small local approximation stencil and the appropriate choice of smoothness indicators."], "authors": "Bojan Crnković"},
{"Title": "Multi-Axis and Multi-Vector Gradient Estimations: Using Multi-Sampled Complex Unit Vectors to Estimate Gradients of Real Functions", "abs": ["In this preliminary study, we provide two methods for estimating the gradients of functions of real value. Both methods are built on derivative estimations that are calculated using the standard method or the Squire-Trapp method for any given direction. Gradients are computed as the average of derivatives in uniformly sampled directions. The first method uses a uniformly distributed set of axes that consists of orthogonal unit vectors that span the space. The second method only uses a uniformly distributed set of unit vectors. Both methods essentially minimize the error through an average of estimations to cancel error terms. Both methods are essentially a conceptual generalization of the method used to estimate normal fractal surfaces."], "authors": "Ergun Akleman"},
{"Title": "Dagger groups and $p$-adic distribution algebras", "abs": ["Let $(G,\\omega)$ be a $p$-saturated group and $K/\\mathbb{Q}_p$ a finite extension. In this paper we introduce the space of $K$-valued overconvergent functions $\\mathcal{C}^\\dagger(G,K)$. In the process we promote the rigid analytic group attached to $(G,\\omega)$ in a previous work of the first two authors to a dagger group. A main result of this article is that under certain assumptions (satisfied for example when $G$ is a uniform pro-$p$ group) the distribution algebra $D^\\dagger(G,K)$, i.e. the strong dual of $\\mathcal{C}^\\dagger(G,K)$, is a Fréchet-Stein algebra in the sense of Schneider and Teitelbaum.", "In the last section we introduce overconvergent representations and show that there is an anti-equivalence of categories between overconvergent $G$-representations of compact type and continuous $D^\\dagger(G, K)$-modules on nuclear Fréchet spaces. This is analogous to the anti-equivalence between locally analytic representations and modules over the locally analytic distribution algebra as proved by Schneider and Teitelbaum."], "authors": "Aranya Lahiri"},
{"Title": "Cascaded Channel Decoupling Based Solution for RIS Regulation Matrix", "abs": ["This article presents a novel solution for reconfigurable intelligent surfaces (RISs) based on cascaded channel decoupling. The proposed mechanism simplifies the RIS regulation matrix, by decomposing the electromagnetic wave regulation process into two sub-processes: virtual receiving response and virtual regular transmission, which leads to the decoupling of the RIS cascaded channel. This article further discusses the concrete implementation of the proposed channel decoupling mechanism in two scenarios of single-user access and multi-user access, and gives the corresponding detailed scheme. The numerical simulation results demonstrate that the proposed channel decoupling scheme is a low-complexity and effective solution for resolving the RIS regulation matrix."], "authors": "Yajun Zhao"},
{"Title": "Topological equivalence in the infinity of a planar vector field and its principal part defined through Newton polytope", "abs": ["Given a planar polynomial vector field $X$ with a fixed Newton polytope $\\mathcal{P}$, we prove (under some non degeneracy conditions) that the monomials associated to the upper boundary of $\\mathcal{P}$ determine (under topological equivalence) the phase portrait of $X$ in a neighbourhood of boundary of the Poincaré--Lyapunov disk. This result can be seen as a version of the well known result of Berezovskaya, Brunella and Miari for the dynamics at the infinity, We also discuss the effect of the Poincaré--Lyapunov compactification on the Newton polytope."], "authors": "Thais Maria Dalbelo"},
{"Title": "Notes on Bolyai's 'Appendix'", "abs": ["This paper aims to provide an explanatory edition of Bolyai's 'Appendix Demonstrating the Absolute Science of Space', first published in 1832. In this treatise Bolyai began by extending neutral (or 'absolute') geometry by deriving a number of theorems which are independent of Euclid's parallel postulate. Then, while retaining Euclid first four postulates, he explored the consequences of replacing the parallel postulate with a different assumption, that through a given point not on a given straight line, more than than one straight line can be drawn which does not intersect the given line. On this basis Bolyai developed a non-Euclidean geometry nowadays called hyperbolic geometry.", "The English translation of Bolyai's text is reprinted in the paper, with explanatory notes provided at the end of each section. Some of the theorems are discussed in detail, with a particular focus on those in which Bolyai derived the trigonometric identities of the hyperbolic plane and on his astonishing quadrature of the circle. Bolyai's terse style of exposition can be quite challenging, so I have tried to fill in some of the mathematical details which he chose to omit, either through lack of space or simply because he thought them to obvious too include."], "authors": "Steven Rose"},
{"Title": "Interpolation and Extrapolation Statements equivalent to the Riemann Hypothesis", "abs": ["The goal of this paper is twofold; on one hand we wish to present some statements that can be formulated in terms of Interpolation theory which are equivalent to the truth or the falseness of the Riemann Hypothesis, on the other hand we will use a key result of the Jawerth-Milman extrapolation to improve on a well-known criterion by Beurling and Nyman for the Riemann Hypothesis giving sharper sufficient conditions to the celebrated hypothesis."], "authors": "Álvaro Corvalán"},
{"Title": "Minimal genus Seifert surface for 11 crossing alternating knots", "abs": ["Kakimizu complexes have been found for several classes of links. O.Kakimizu found the Kakimizu complexes of knots with crossing number less than or equal to 10. Hatcher and Thurston found the 0-skeleton of the Kakimizu complex of 2-bridge links. Sakuma later generalized the result for special arborescent links and found the Kakimizu complexes for the same. Jessica Banks gave a complete proof of results announced by Hirasawa and Sakuma, describing explicitly the Kakimizu complexes of non-split, prime special alternating links. The Kakimizu complexes of prime, non-split alternating links have finite number of vertices. In this paper we compute the Kakimizu complexes for all $11$ crossing prime, alternating knots, explicitly describing each of them. For most knots and links we use known algorithms. The rest of the Kakimizu complexes were found by using Murasugi sums and sutured manifold theory developed by Gabai, Scharlemann, Kakimizu and others."], "authors": "Neetal Neel"},
{"Title": "Egorov ideals", "abs": ["We study Egorov ideals, that is ideals on $\\omega$ for which the Egorov's theorem for ideal versions of pointwise and uniform convergences holds. We show that a non-pathological $\\bf{\\Sigma^0_2}$ ideal is Egorov if and only if it is countably generated. In particular, up to isomorphism, there are only three non-pathological $\\bf{\\Sigma^0_2}$ Egorov ideals. On the other hand, we construct $2^\\omega$ pairwise non-isomorphic Borel Egorov ideals. Moreover, we characterize when a product of ideals is Egorov."], "authors": "Adam Kwela"},
{"Title": "On The Convergence of the Variational Iteration Method Applied to Variable Coefficient Klein-Gordon Problems", "abs": ["In this paper, we give a formulation of the variational iteration method that makes it suitable for the analysis of the solutions of Klein-Gordon equations with variable coefficients. We particularly study a Klein-Gordon problem which has solutions in terms of Airy functions. We prove that the sequence of approximate solutions generated by the variational iteration method for such Klein-Gordon equation converges to Airy functions."], "authors": "Shohreh Gholizadeh Siahmazgi"},
{"Title": "Taut foliations, braid positivity, and unknot detection", "abs": ["We study positive braid knots (the knots in the three-sphere realized as positive braid closures) through the lens of the L-space conjecture. This conjecture predicts that if $K$ is a non-trivial positive braid knot, then for all $r < 2g(K)-1$, the 3-manifold obtained via $r$-framed Dehn surgery along $K$ admits a taut foliation. Our main result provides some positive evidence towards this conjecture: we construct taut foliations in such manifolds whenever $r<g(K)+1$. As an application, we produce a novel braid positivity obstruction for cable knots by proving that the $(n,\\pm 1)$-cable of a knot $K$ is braid positive if and only if $K$ is the unknot. We also present some curious examples demonstrating the limitations of our construction; these examples can also be viewed as providing some negative evidence towards the L-space conjecture. Finally, we apply our main result to produce taut foliations in some splicings of knot exteriors."], "authors": "Siddhi Krishna"},
{"Title": "SISO Decoding of Z4 Linear Kerdock and Preparata Codes", "abs": ["Some nonlinear codes, such as Kerdock and Preparata codes, can be represented as binary images under the Gray map of linear codes over rings. This paper introduces MAP decoding of Kerdock and Preparata codes by working with their quaternary representation (linear codes over Z4 ) with the complexity of O(N2log2N), where N is the code length in Z4. A sub-optimal bitwise APP decoder with good error-correcting performance and complexity of O(Nlog2N) that is constructed using the decoder lifting technique is also introduced. This APP decoder extends upon the original lifting decoder by working with likelihoods instead of hard decisions and is not limited to Kerdock and Preparata code families. Simulations show that our novel decoders significantly outperform several popular decoders in terms of error rate."], "authors": "Aleksandar Minja"},
{"Title": "Finite generation of fundamental groups for manifolds with nonnegative Ricci curvature and almost $k$-polar at infinity", "abs": ["In this article, we prove that the fundamental group of a complete open manifold $M$ with nonnegative Ricci curvature is finitely generated, if the Riemannian universal cover $\\tilde M$ satisfies almost $k$-polar at infinity."], "authors": "Hongzhi Huang"},
{"Title": "Projected exponential methods for stiff dynamical low-rank approximation problems", "abs": ["The numerical integration of stiff equations is a challenging problem that needs to be approached by specialized numerical methods. Exponential integrators form a popular class of such methods since they are provably robust to stiffness and have been successfully applied to a variety of problems. The dynamical low- \\rank approximation is a recent technique for solving high-dimensional differential equations by means of low-rank approximations. However, the domain is lacking numerical methods for stiff equations since existing methods are either not robust-to-stiffness or have unreasonably large hidden constants. In this paper, we focus on solving large-scale stiff matrix differential equations with a Sylvester-like structure, that admit good low-rank approximations. We propose two new methods that have good convergence properties, small memory footprint and that are fast to compute. The theoretical analysis shows that the new methods have order one and two, respectively. We also propose a practical implementation based on Krylov techniques. The approximation error is analyzed, leading to a priori error bounds and, therefore, a mean for choosing the size of the Krylov space. Numerical experiments are performed on several examples, confirming the theory and showing good speedup in comparison to existing techniques."], "authors": "Benjamin Carrel"},
{"Title": "Fibered 3-manifolds with unique incompressible surfaces", "abs": ["We present a family $M_g$ of fibered hyperbolic 3-manifolds whose fibre $F_g$ is the unique connected incompressible surface and the genus $g \\geq 2$ of $F_g$ can be arbitrary. This answers a question of Agol."], "authors": "Tommaso Cremaschi"},
{"Title": "Commutators and crossed modules of color Hopf algebras", "abs": ["In a previous paper we showed that the category of cocommutative color Hopf algebras is semi-abelian in case the group $G$ is abelian and finitely generated and the characteristic of the base field is different from 2 (not needed if $G$ is finite of odd cardinality). Here we describe the commutator of cocommutative color Hopf algebras and we explain the Hall's criterion for nilpotence and the Zassenhaus Lemma. Furthermore, we introduce the category of color Hopf crossed modules and we explicitly show that this is equivalent to the category of internal crossed modules in the category of cocommutative color Hopf algebras and to the category of simplicial cocommutative color Hopf algebras with Moore complex of length 1."], "authors": "Andrea Sciandra"},
{"Title": "Sub-signature operators and the Dabrowski-Sitarz-Zalecki type theorems for manifolds with boundary", "abs": ["In this paper, we define the spectral Einstein functional associated with the sub-signature operator for manifolds with boundary. Motivated by the spectral Einstein functional and the sub-signature operator, we relate them to the noncommutative residue for manifolds with boundary. And we give the proof of the Dabrowski-Sitarz-Zalecki type theorems for the spectral Einstein functional associated with the sub-signature operator on 4-dimensional manifolds with boundary."], "authors": "Hongfeng Li"},
{"Title": "Conformal perturbations of dirac operators and general Kastler-Kalau-Walze type theorems for even dimensional manifolds with boundary", "abs": ["In this paper, we establish the proof of general Kastler-Kalau-Walze type theorems for conformal perturbations of dirac Operators on even dimensional compact manifolds with (respectively without) boundary."], "authors": "Sining Wei"},
{"Title": "The operator $\\sqrt{-1}\\widehat{c}(V)(d+δ)$ and the Kastler-Kalau-Walze type theorems", "abs": ["In this paper, we obtain two Lichnerowicz type formulas for the operators $\\sqrt{-1}\\widehat{c}(V)(d+\\delta)$ and $-\\sqrt{-1}(d+\\delta)\\widehat{c}(V)$. And we give the proof of Kastler-Kalau-Walze type theorems for the operators $\\sqrt{-1}\\widehat{c}(V)(d+\\delta)$ and $-\\sqrt{-1}(d+\\delta)\\widehat{c}(V)$ on 3,4-dimensional oriented compact manifolds with (resp.without) boundary."], "authors": "Tong Wu"},
{"Title": "The general Kastler-Kalau-Walze type theorem and the Dabrowski-Sitarz-Zalecki type theorem for odd dimensional manifold with boundary", "abs": ["In this paper, we give the proof of the general Kastler-Kalau-Walze type theorem and the Dabrowski-Sitarz-Zalecki type theorem on odd dimensional compact manifolds with boundary."], "authors": "Tong Wu"},
{"Title": "The general Dabrowski-Sitarz-Zalecki type theorem for odd dimensional manifolds with boundary II", "abs": ["In [19], a general Dabrowski-Sitarz-Zalecki type theorem for odd dimensional manifolds with boundary was proved. In this paper, we give the proof of the another general Dabrowski-Sitarz-Zalecki type theorem for the spectral Einstein functional associated with the Dirac operator on odd dimensional manifolds with boundary."], "authors": "Hongfeng Li"},
{"Title": "On the Benjamin and related equations", "abs": ["We consider in this paper various theoretical and numerical issues on classical one dimensional models of internal waves with surface tension.They concern the Cauchy problem, including the long time dynamic, localized solitons or multisolitons, the soliton resolution property. We survey known results, present a few new ones together with open questions and conjectures motivated by numerical simulations.", "A major issue is to emphasize the differences of the qualitative behavior of solutions with those of the same equations without the capillary term."], "authors": "C. Klein"},
{"Title": "The Hodge-Dirac operator and Dabrowski-Sitarz-Zalecki type theorems for manifolds with boundary", "abs": ["In [10], Dabrowski etc. gave spectral Einstein bilinear functionals of differential forms for the Hodge-Dirac operator $d+\\delta$ on an oriented even-dimensional Riemannian manifold. In this paper, we generalize the results of Dabrowski etc. to the cases of 4 dimensional oriented Riemannian manifolds with boundary. Furthermore, we give the proof of Dabrowski-Sitarz-Zalecki type theorems associated with the Hodge-Dirac operator for manifolds with boundary."], "authors": "Tong Wu"},
{"Title": "Cubic surface bundles and the Brauer group", "abs": ["In this note we define a subgroup $H^i_{nr,\\pi}$ of unramified cohomology group $H^i_{nr}$ of a fibration $\\pi:X\\to S$. This subgroup can be used efficiently in refined specialization arguments and allows to detect the failure of stable rationality of a variety specializing to $X$. We compute $H^2_{nr, \\pi}$ systematically for many cubic surface bundles $\\pi:X\\to S$ over a smooth projective rational surface over an algebraically closed field: we give a combinatorial formula in terms of components of the discriminant divisor of $\\pi$."], "authors": "Alena Pirutka"},
{"Title": "The Stochastic Dynamic Post-Disaster Inventory Allocation Problem with Trucks and UAVs", "abs": ["Humanitarian logistics operations face increasing difficulties due to rising demands for aid in disaster areas. This paper investigates the dynamic allocation of scarce relief supplies across multiple affected districts over time. It introduces a novel stochastic dynamic post-disaster inventory allocation problem with trucks and unmanned aerial vehicles delivering relief goods under uncertain supply and demand. The relevance of this humanitarian logistics problem lies in the importance of considering the inter-temporal social impact of deliveries. We achieve this by incorporating deprivation costs when allocating scarce supplies. Furthermore, we consider the inherent uncertainties of disaster areas and the potential use of cargo UAVs to enhance operational efficiency. This study proposes two anticipatory solution methods based on approximate dynamic programming, specifically decomposed linear value function approximation and neural network value function approximation to effectively manage uncertainties in the dynamic allocation process. We compare DL-VFA and NN-VFA with various state-of-the-art methods (exact re-optimization, PPO) and results show a 6-8% improvement compared to the best benchmarks. NN-VFA provides the best performance and captures nonlinearities in the problem, whereas DL-VFA shows excellent scalability against a minor performance loss. The experiments reveal that consideration of deprivation costs results in improved allocation of scarce supplies both across affected districts and over time. Finally, results show that deploying UAVs can play a crucial role in the allocation of relief goods, especially in the first stages after a disaster. The use of UAVs reduces transportation- and deprivation costs together by 16-20% and reduces maximum deprivation times by 19-40%, while maintaining similar levels of demand coverage, showcasing efficient and effective operations."], "authors": "Robert van Steenbergen"},
{"Title": "Scalar curvature and volume entropy of hyperbolic 3-manifolds", "abs": ["We show that any closed hyperbolic 3-manifold M admits a Riemannian metric with scalar curvature at least -6, but with volume entropy strictly larger than 2. In particular, this construction gives counterexamples to a conjecture of I. Agol, P. Storm and W. Thurston."], "authors": "Demetre Kazaras"},
{"Title": "Positive solutions to semilinear Dirichlet problems with general boundary data", "abs": ["We give a probabilistic representation of the solution to a semilinear elliptic Dirichlet problem with general (discontinuous) boundary data. The boundary behaviour of the solution is in the sense of the controlled convergence initiated by A. Cornea. Uniqueness results for the solution are also provided."], "authors": "Lucian Beznea"},
{"Title": "Asymptotic-preserving gyrokinetic implicit particle-orbit integrator for arbitrary electromagnetic fields", "abs": ["We extend the asymptotic preserving and energy conserving time integrator for charged-particle motion developed in [Ricketson & Chacón, JCP, 2020] to include finite Larmor-radius (FLR) effects in the presence of electric-field length-scales comparable to the particle gyro-radius (the gyro-kinetic limit). We introduce two modifications to the earlier scheme. The first is the explicit gyro-averaging of the electric field at the half time-step, along with an analogous modification to the current deposition, which we show preserves total energy conservation in implicit PIC schemes. The number of gyrophase samples is chosen adaptively, ensuring proper averaging for large timesteps, and the recovery of full-orbit dynamics in the small time-step limit. The second modification is an alternating large and small time-step strategy that ensures the particle trajectory samples gyrophases evenly. We show that this strategy relaxes the time-step restrictions on the scheme, allowing even larger speed-ups than previously achievable. We demonstrate the new method with several single-particle motion tests in a variety of electromagnetic field configurations featuring gyro-scale variation in the electric field. The results demonstrate the advertised ability to capture FLR effects accurately even when significantly stepping over the gyration time-scale."], "authors": "Lee Ricketson"},
{"Title": "Message-Passing on Hypergraphs: Detectability, Phase Transitions and Higher-Order Information", "abs": ["Hypergraphs are widely adopted tools to examine systems with higher-order interactions. Despite recent advancements in methods for community detection in these systems, we still lack a theoretical analysis of their detectability limits. Here, we derive closed-form bounds for community detection in hypergraphs. Using a Message-Passing formulation, we demonstrate that detectability depends on hypergraphs' structural properties, such as the distribution of hyperedge sizes or their assortativity. Our formulation enables a characterization of the entropy of a hypergraph in relation to that of its clique expansion, showing that community detection is enhanced when hyperedges highly overlap on pairs of nodes. We develop an efficient Message-Passing algorithm to learn communities and model parameters on large systems. Additionally, we devise an exact sampling routine to generate synthetic data from our probabilistic model. With these methods, we numerically investigate the boundaries of community detection in synthetic datasets, and extract communities from real systems. Our results extend the understanding of the limits of community detection in hypergraphs and introduce flexible mathematical tools to study systems with higher-order interactions."], "authors": "Nicolò Ruggeri"},
{"Title": "Applicability of Blockchain Technology in Avionics Systems", "abs": ["Blockchain technology, within its fast widespread and superiority demonstrated by recent studies, can be also used as an informatic tool for solving various aviation problems. Aviation electronics (avionics) systems stand out as the application area of informatics methods in solving aviation problems or providing different capabilities to aircrafts. Avionics systems are electronic systems used in air and space vehicles for many purposes such as surveillance, navigation and communication. In this study, the applicability of blockchain technology as a new approach in the development of avionics systems is discussed, and in this regard, a method inspired by the previously implemented applications in electronic flight systems is proposed to help evaluate the applicability of this technology in new avionics system designs. The potential of blockchain for solving the problems especially in basic services, communication, navigation and flight management systems; the problem structures for which application of this technology would be a reliable solution; and the superiority and inferiority of its use in avionic systems are explained. A guiding paper is proposed for aviation engineers/experts to make a decision on applying blockchain into avionics systems."], "authors": "Harun Celik"},
{"Title": "Practical Path-based Bayesian Optimization", "abs": ["There has been a surge in interest in data-driven experimental design with applications to chemical engineering and drug manufacturing. Bayesian optimization (BO) has proven to be adaptable to such cases, since we can model the reactions of interest as expensive black-box functions. Sometimes, the cost of this black-box functions can be separated into two parts: (a) the cost of the experiment itself, and (b) the cost of changing the input parameters. In this short paper, we extend the SnAKe algorithm to deal with both types of costs simultaneously. We further propose extensions to the case of a maximum allowable input change, as well as to the multi-objective setting."], "authors": "Jose Pablo Folch"},
{"Title": "Future of Bianchi I magnetic cosmologies with kinetic matter", "abs": ["We show under the assumption of small data that solutions to the Einstein-Vlasov system with a pure magnetic field and Bianchi I symmetry isotropise and tend to dust solutions. We also obtain the decay rates for the main variables. This generalises part of the work [V.~G.~LeBlanc, Classical Quantum Gravity 14, 2281-2301 (1997)] concerning the future behaviour of orthogonal perfect fluids with a linear equation of state in the presence of a magnetic field to the Vlasov case."], "authors": "Ho Lee"},
{"Title": "Phase Transitions, Spontaneous Symmetry Breaking, and Goldstone's Theorem", "abs": ["Some important rigorous results on phase transitions accompanied by the spontaneous breaking of symmetries in statistical mechanics and relativistic quantum field theory are reviewed. Basic ideas, mainly inspired by quantum field theory, underlying the proofs of some of these results are sketched. The Goldstone theorem is proven, and the Mermin-Wagner-Hohenberg theorem concerning the absence of continuous symmetry breaking in one and two dimensions is recalled. Comments concerning rigorous results on the Kosterlitz-Thouless transition in the two-dimensional classical XY model are made."], "authors": "Jürg Fröhlich"},
{"Title": "Interior Point Constrained Reinforcement Learning with Global Convergence Guarantees", "abs": ["We consider discounted infinite horizon constrained Markov decision processes (CMDPs) where the goal is to find an optimal policy that maximizes the expected cumulative reward subject to expected cumulative constraints. Motivated by the application of CMDPs in online learning of safety-critical systems, we focus on developing an algorithm that ensures constraint satisfaction during learning. To this end, we develop a zeroth-order interior point approach based on the log barrier function of the CMDP. Under the commonly assumed conditions of Fisher non-degeneracy and bounded transfer error of the policy parameterization, we establish the theoretical properties of the algorithm. In particular, in contrast to existing CMDP approaches that ensure policy feasibility only upon convergence, our algorithm guarantees feasibility of the policies during the learning process and converges to the optimal policy with a sample complexity of $O(\\varepsilon^{-6})$. In comparison to the state-of-the-art policy gradient-based algorithm, C-NPG-PDA, our algorithm requires an additional $O(\\varepsilon^{-2})$ samples to ensure policy feasibility during learning with same Fisher-non-degenerate parameterization."], "authors": "Tingting Ni"},
{"Title": "Slotted Aloha for Optical Wireless Communications in Internet of Underwater Things", "abs": ["In this work, we design and analyse a Slotted ALOHA (SA) solution for Optical Wireless Communication (OWC)-based Internet of Underwater Things (IoUT). In the proposed system, user devices exchange data with an access point (AP) which exploits the capture effect. The space spanned by the IoUT nodes is three-dimensional, i.e., users are located in half-sphere centered at the AP placed at the bottom of a floating object at the water surface level. The analytical expressions for the system throughput and reliability expressed in terms of the outage probability are derived. Based on the simulated signal-to-noise-and-interference-ratio statistics and derived analytical expressions, we present numerical results that investigate the trade-off between the system performance and the IoUT system parameters, such as the number of users, activation probability and type of water medium. The presented conclusions provide valuable insights into the design of an SA-based solution for IoUT communications."], "authors": "Milica Petkovic"},
{"Title": "Consensus group decision making under model uncertainty with a view towards environmental policy making", "abs": ["In this paper we propose a consensus group decision making scheme under model uncertainty consisting of an iterative two-stage procedure and based on the concept of Fréchet barycenter. Each step consists of two stages: the agents first update their position in the opinion metric space by a local barycenter characterized by the agents' immediate interactions and then a moderator makes a proposal in terms of a global barycenter, checking for consensus at each step. In cases of large heterogeneous groups the procedure can be complemented by an auxiliary initial homogenization step, consisting of a clustering procedure in opinion space, leading to large homogeneous groups for which the aforementioned procedure will be applied.", "The scheme is illustrated in examples motivated from environmental economics."], "authors": "Phoebe Koundouri"},
{"Title": "Geodesic slice sampling on Riemannian manifolds", "abs": ["We propose a theoretically justified and practically applicable slice sampling based Markov chain Monte Carlo (MCMC) method for approximate sampling from probability measures on Riemannian manifolds.", "The latter naturally arise as posterior distributions in Bayesian inference of matrix-valued parameters,", "for example belonging to either the Stiefel or the Grassmann manifold.", "Our method, called geodesic slice sampling, is reversible with respect to the distribution of interest, and", "generalizes Hit-and-run slice sampling on $\\mathbb{R}^{d}$ to Riemannian manifolds by using geodesics instead of straight lines.", "We demonstrate the robustness of our sampler's performance compared to other MCMC methods dealing with manifold valued distributions through extensive numerical experiments, on both synthetic and real data.", "In particular, we illustrate its remarkable ability to cope with anisotropic target densities,", "without using gradient information and preconditioning."], "authors": "Alain Durmus"},
{"Title": "Green Edge AI: A Contemporary Survey", "abs": ["Artificial intelligence (AI) technologies have emerged as pivotal enablers across a multitude of industries, including consumer electronics, healthcare, and manufacturing, largely due to their resurgence over the past decade. The transformative power of AI is primarily derived from the utilization of deep neural networks (DNNs), which require extensive data for training and substantial computational resources for processing. Consequently, DNN models are typically trained and deployed on resource-rich cloud servers. However, due to potential latency issues associated with cloud communications, deep learning (DL) workflows are increasingly being transitioned to wireless edge networks near end-user devices (EUDs). This shift is designed to support latency-sensitive applications and has given rise to a new paradigm of edge AI, which will play a critical role in upcoming 6G networks to support ubiquitous AI applications. Despite its potential, edge AI faces substantial challenges, mostly due to the dichotomy between the resource limitations of wireless edge networks and the resource-intensive nature of DL. Specifically, the acquisition of large-scale data, as well as the training and inference processes of DNNs, can rapidly deplete the battery energy of EUDs. This necessitates an energy-conscious approach to edge AI to ensure both optimal and sustainable performance. In this paper, we present a contemporary survey on green edge AI. We commence by analyzing the principal energy consumption components of edge AI systems to identify the fundamental design principles of green edge AI. Guided by these principles, we then explore energy-efficient design methodologies for the three critical tasks in edge AI systems, including training data acquisition, edge training, and edge inference. Finally, we underscore potential future research directions to further enhance the energy efficiency of edge AI."], "authors": "Yuyi Mao"},
{"Title": "Multiple Control Functionals for Interconnected Time-Delay Systems", "abs": ["Safety is essential for autonomous systems, in particular for interconnected systems in which the interactions among subsystems are involved. Motivated by the recent interest in cyber-physical and interconnected autonomous systems, we address the safe stabilization problem of interconnected systems with time delays. We propose multiple control Lyapunov and barrier functionals for the stabilization and safety control problems, respectively. In order to investigate the safe stabilization control problem, the proposed multiple control functionals are combined together via two methods: the optimization-based method and the sliding mode based method. The resulting controllers can be of either explicit or implicit forms, both of which ensure the safe stabilization objective of the whole system. The derived results are illustrated via a reach-avoid problem of multi-robot systems."], "authors": "Zhuo-Rui Pan"},
{"Title": "The K-theory of the conjugation action", "abs": ["In 1999, Brylinski and Zhang computed the complex equivariant K-theory of the conjugation self-action of a compact, connected Lie group with torsion-free fundamental group. In this note we show it is possible to do so in under a page."], "authors": "Jeffrey D. Carlson"},
{"Title": "Constructive Representation of Functions in $N$-Dimensional Sobolev Space", "abs": ["We propose a new representation of functions in Sobolev spaces on an $N$-dimensional hyper-rectangle, expressing such functions in terms of their admissible derivatives, evaluated along lower-boundaries of the domain. These boundary values are either finite-dimensional or exist in the space $L_2$ of square-integrable functions -- free of the continuity constraints inherent to Sobolev space. Moreover, we show that the map from this space of boundary values to the Sobolev space is given by an integral operator with polynomial kernel, and we prove that this map is invertible. Using this result, we propose a method for polynomial approximation of functions in Sobolev space, reconstructing such an approximation from polynomial projections of the boundary values. We prove that this approximation is optimal with respect to a discrete-continuous Sobolev norm, and show through numerical examples that it exhibits better convergence behavior than direct projection of the function. Finally, we show that this approach may also be adapted to use a basis of step functions, to construct accurate piecewise polynomial approximations that do not suffer from e.g. Gibbs phenomenon."], "authors": "Declan S. Jagt"},
{"Title": "A finite element method for stochastic diffusion equations using fluctuating hydrodynamics", "abs": ["We present a finite element approach for diffusion problems with thermal fluctuations based on a fluctuating hydrodynamics model. The governing transport equations are stochastic partial differential equations with a fluctuating forcing term. We propose a discrete formulation of the stochastic forcing term that has the correct covariance matrix up to a standard discretization error. Furthermore, to obtain a numerical solution with spatial correlations that converge to those of the continuum equation, we derive a linear mapping to transform the finite element solution into an equivalent discrete solution that is free from the artificial correlations introduced by the spatial discretization. The method is validated by applying it to two diffusion problems: a second-order diffusion equation and a fourth-order diffusion equation. The theoretical (continuum) solution to the first case presents spatially decorrelated fluctuations, while the second case presents fluctuations correlated over a finite length. In both cases, the numerical solution presents a structure factor that approximates well the continuum one."], "authors": "P. Martínez-Lera"},
{"Title": "A new numerical technique based on Chelyshkov polynomials for solving two-dimensional stochastic Itô-Volterra Fredholm integral equation", "abs": ["In this paper, a two-dimensional operational matrix method based on Chelyshkov polynomials is implemented to numerically solve the two-dimensional stochastic Itô-Volterra Fredholm integral equations. These equations arise in several problems such as an exponential population growth model with several independent white noise sources. In this paper a new stochastic operational matrix has been derived first time ever by using Chelyshkov polynomials. After that, the operational matrices are used to transform the Itô-Volterra Fredholm integral equation into a system of linear algebraic equations by using Newton cotes nodes as collocation point that can be easily solved. Furthermore, the convergence and error bound of the suggested method are well established. In order to illustrate the effectiveness, plausibility, reliability, and applicability of the existing technique, two typical examples have been presented."], "authors": "S. Saha Ray"},
{"Title": "A constructive approach for investigating the stability of incommensurate fractional differential systems", "abs": ["This paper is devoted to studying the asymptotic behaviour of solutions to generalized non-commensurate fractional systems. To this end, we first consider fractional systems with rational orders and introduce a criterion that is necessary and sufficient to ensure the stability of such systems. Next, from the fractional-order pseudospectrum definition proposed by Šanca et al., we formulate the concept of a rational approximation for the fractional spectrum of a noncommensurate fractional systems with general, not necessarily rational, orders. Our first important new contribution is to show the equivalence between the fractional spectrum of a noncommensurate linear system and its rational approximation. With this result in hand, we use ideas developed in our earlier work to demonstrate the stability of an equilibrium point to nonlinear systems in arbitrary finite-dimensional spaces. A second novel aspect of our work is the fact that the approach is constructive. Finally, we give numerical simulations to illustrate the merit of the proposed theoretical results."], "authors": "Kai Diethelm"},
{"Title": "On the $\\ell_0$ Isoperimetric Coefficient of Measurable Sets", "abs": ["In this paper we prove that the $\\ell_0$ isoperimetric coefficient for any axis-aligned cubes, $\\psi_{\\mathcal{C}}$, is $\\Theta(n^{-1/2})$ and that the isoperimetric coefficient for any measurable body $K$, $\\psi_K$, is of order $O(n^{-1/2})$. As a corollary we deduce that axis-aligned cubes essentially \"maximize\" the $\\ell_0$ isoperimetric coefficient: There exists a positive constant $q > 0$ such that $\\psi_K \\leq q \\cdot \\psi_{\\mathcal{C}}$, whenever $\\mathcal{C}$ is an axis-aligned cube and $K$ is any measurable set. Lastly, we give immediate applications of our results to the mixing time of Coordinate-Hit-and-Run for sampling points uniformly from convex bodies."], "authors": "Manuel Fernandez V"},
{"Title": "A class of fractional differential equations via power non-local and non-singular kernels: existence, uniqueness and numerical approximations", "abs": ["We prove a useful formula and new properties for the recently introduced power fractional calculus with non-local and non-singular kernels. In particular, we prove a new version of Gronwall's inequality involving the power fractional integral; and we establish existence and uniqueness results for nonlinear power fractional differential equations using fixed point techniques. Moreover, based on Lagrange polynomial interpolation, we develop a new explicit numerical method in order to approximate the solutions of a rich class of fractional differential equations. The approximation error of the proposed numerical scheme is analyzed. For illustrative purposes, we apply our method to a fractional differential equation for which the exact solution is computed, as well as to a nonlinear problem for which no exact solution is known. The numerical simulations show that the proposed method is very efficient, highly accurate and converges quickly."], "authors": "Hanaa Zitane"},
{"Title": "Multi-fidelity uncertainty quantification for homogenization problems in structure-property relationships from crystal plasticity finite elements", "abs": ["Crystal plasticity finite element method (CPFEM) has been an integrated computational materials engineering (ICME) workhorse to study materials behaviors and structure-property relationships for the last few decades. These relations are mappings from the microstructure space to the materials properties space. Due to the stochastic and random nature of microstructures, there is always some uncertainty associated with materials properties, for example, in homogenized stress-strain curves. For critical applications with strong reliability needs, it is often desirable to quantify the microstructure-induced uncertainty in the context of structure-property relationships. However, this uncertainty quantification (UQ) problem often incurs a large computational cost because many statistically equivalent representative volume elements (SERVEs) are needed. In this paper, we apply a multi-level Monte Carlo (MLMC) method to CPFEM to study the uncertainty in stress-strain curves, given an ensemble of SERVEs at multiple mesh resolutions. By using the information at coarse meshes, we show that it is possible to approximate the response at fine meshes with a much reduced computational cost. We focus on problems where the model output is multi-dimensional, which requires us to track multiple quantities of interest (QoIs) at the same time. Our numerical results show that MLMC can accelerate UQ tasks around 2.23x, compared to the classical Monte Carlo (MC) method, which is widely known as the ensemble average in the CPFEM literature."], "authors": "Anh Tran"},
{"Title": "The Bivariate Normal Integral via Owen's T Function as a Modified Euler's Arctangent Series", "abs": ["The Owen's T function is presented in four new ways, one of them as a series similar to the Euler's arctangent series divided by $2\\pi$, which is its majorant series. All possibilities enable numerically stable and fast convergent computation of the bivariate normal integral with simple recursion. When tested $\\Phi_\\varrho^2(x,y)$ computation on a random sample of one million parameter triplets with uniformly distributed components and using double precision arithmetic, the maximum absolute error was $3.45\\cdot 10^{-16}$. In additional testing, focusing on cases with correlation coefficients close to one in absolute value, when the computation may be very sensitive to small rounding errors, the accuracy was retained. In rare potentially critical cases, a simple adjustment to the computation procedure was performed - one potentially critical computation was replaced with two equivalent non-critical ones. All new series are suitable for vector and high-precision computation, assuming they are supplemented with appropriate efficient and accurate computation of the arctangent and standard normal cumulative distribution functions. They are implemented by the R package Phi2rho, available on CRAN. Its functions allow vector arguments and are ready to work with the Rmpfr package, which enables the use of arbitrary precision instead of double precision numbers. A special test with up to 1024-bit precision computation is also presented."], "authors": "Janez Komelj"},
{"Title": "Efficient calculation of the integral equation for simulating 2D TE scattering in a homogeneous medium using the Ewald method and a Gabor frame discretization", "abs": ["We utilize the domain integral equation formulation to simulate two-dimensional transverse electric scattering in a homogeneous medium and a summation of modulated Gaussian functions to approximate the dual Gabor window. Then we apply Ewald Green function transformation to separate the integrals related to x and z in the integral equation, which produce Gaussian functions. These Gaussian functions in the integrands can be integrated analytically, which greatly simplifies the calculation process. Finally, we discuss the convergence and the selection of the Ewald splitting parameter E."], "authors": "Xinyang Lua"},
{"Title": "A generalized character associated to element orders", "abs": ["Let $G$ be a finite group. We study the generalized character defined by $\\Xi(g)=|G|o(g)$, for $g\\in G$, which is closely related to a function that has been very studied recently from a group theoretical point of view."], "authors": "Alexander Moretó"},
{"Title": "Space-Time Decomposition of Kalman Filter", "abs": ["We present an innovative interpretation of Kalman Filter (KF, for short) combining the ideas of Schwarz Domain Decomposition (DD) and Parallel in Time (PinT) approaches. Thereafter we call it DD-KF. In contrast to standard DD approaches which are already incorporated in KF and other state estimation models, implementing a straightforward data parallelism inside the loop over time, DD-KF ab-initio partitions the whole model, including filter equations and dynamic model along both space and time directions/steps. As a consequence, we get local KFs reproducing the original filter at smaller dimensions on local domains. Also, sub problems could be solved in parallel. In order to enforce the matching of local solutions on overlapping regions, and then to achieve the same global solution of KF, local KFs are slightly modified by adding a correction term keeping track of contributions of adjacent subdomains to overlapping regions. Such a correction term balances localization errors along overlapping regions, acting as a regularization constraint on local solutions. Furthermore, such a localization excludes remote observations from each analyzed location improving the conditioning of the error covariance matrices. As dynamic model we consider Shallow Water equations which can be regarded a consistent tool to get a proof of concept of the reliability assessment of DD-KF in monitoring and forecasting of weather systems and ocean currents"], "authors": "Luisa D'Amore"},
{"Title": "NumCalc: An open source BEM code for solving acoustic scattering problems", "abs": ["The calculation of the acoustic field in or around objects is an important task in acoustic engineering. To numerically solve this task, the boundary element method (BEM) is a commonly used method especially for infinite domains. The open source tool Mesh2HRTF and its BEM core NumCalc provide users with a collection of free software for acoustic simulations without the need of having an in-depth knowledge into numerical methods. However, we feel that users should have a basic understanding with respect to the methods behind the software they are using. We are convinced that this basic understanding helps in avoiding common mistakes and also helps to understand the requirements to use the software. To provide this background is the first motivation for this paper. A second motivation for this paper is to demonstrate the accuracy of NumCalc when solving benchmark problems. Thus, users can get an idea about the accuracy they can expect when using NumCalc as well as the memory and CPU requirements of NumCalc. A third motivation for this paper is to give users detailed information about some parts of the actual implementation that are usually not mentioned in literature, e.g., the specific version of the fast multipole method and its clustering process or how to use frequency-dependent admittance boundary conditions."], "authors": "Wolfgang Kreuzer"},
{"Title": "The Discontinuity Group of a Locally Bounded Homomorphism of a Lie Group into a Lie Group Is Commutative", "abs": ["We prove that the discontinuity group of every locally bounded homomorphism of a Lie group into a Lie group is not only compact and connected, which is known, but is also commutative."], "authors": "A. I. Shtern"},
{"Title": "Primordial Black Holes and Higgs Vacuum Decay", "abs": ["Phase transitions are part of everyday life, yet are also believed to be part of the history of our universe, where the nature of particle interactions change as the universe settles into its vacuum state. The discovery of the Higgs, and measurement of its mass suggests that our vacuum may not be entirely stable, and that a further phase transition could take place. This article is based on a talk in the Oldenberg Series, and reviews how we find the probability of these phase transitions, discussing past work on how black holes can dramatically change the result! Apart from a brief update at the end, this article mostly follows the content of the talk."], "authors": "Ruth Gregory"},
{"Title": "Analyticity results for the cumulants in a random matrix model", "abs": ["The generating function of the cumulants in random matrix models, as well as the cumulants themselves, can be expanded as asymptotic (divergent) series indexed by maps. While at fixed genus the sums over maps converge, the sums over genera do not. In this paper we obtain alternative expansions both for the generating function and for the cumulants that cure this problem. We provide explicit and convergent expansions for the cumulants, for the remainders of their perturbative expansion (in the size of the maps) and for the remainders of their topological expansion (in the genus of the maps). We show that any cumulant is an analytic function inside a cardioid domain in the complex plane and we prove that any cumulant is Borel summable at the origin."], "authors": "Razvan Gurau"},
{"Title": "Variational Loop Vertex Expansion", "abs": ["Loop Vertex Expansion (LVE) was developed for the construction of QFT models with local and non-local interactions. Using LVE, one can prove the analyticity in the finite cardioid-like domain in the complex plain of the coupling constant of the free energies and cumulants of various vector, matrix, or tensor-type models. Here, applying the idea of choosing the initial approximation depending on the coupling constant, we construct the analytic continuation of the free energy of the quartic matrix model beyond the standard LVE cardioid over the branch cut and for arbitrary large couplings."], "authors": "Vasily Sazonov"},
{"Title": "Motivic coaction and single-valued map of polylogarithms from zeta generators", "abs": ["We introduce a new Lie-algebraic approach to explicitly construct the motivic coaction and single-valued map of multiple polylogarithms in any number of variables. In both cases, the appearance of multiple zeta values is controlled by conjugating generating series of polylogarithms with Lie-algebra generators associated with odd zeta values. Our reformulation of earlier constructions of coactions and single-valued polylogarithms preserves choices of fibration bases, exposes the correlation between multiple zeta values of different depths and paves the way for generalizations beyond genus zero."], "authors": "Hadleigh Frost"},
{"Title": "Tau-functions beyond the group elements", "abs": ["Matrix elements in different representations are connected by quadratic relations. If matrix elements are those of a $\\textit{group element}$, i.e. satisfying the property $\\Delta(X) = X\\otimes X$, then their generating functions obey bilinear Hirota equations and hence are named $\\tau$-functions. However, dealing with group elements is not always easy, especially for non-commutative algebras of functions, and this slows down the development of $\\tau$-function theory and the study of integrability properties of non-perturbative functional integrals. A simple way out is to use arbitrary elements of the universal enveloping algebra, and not just the group elements. Then the Hirota equations appear to interrelate a whole system of generating functions, which one may call $\\textit{generalized}$ $\\tau$-functions. It was recently demonstrated that this idea can be applicable even to a somewhat sophisticated case of the quantum toroidal algebra. We consider a number of simpler examples, including ordinary and quantum groups, to explain how the method works and what kind of solutions one can obtain."], "authors": "A. Mironov"},
{"Title": "Localisation of the Third Way Theory", "abs": ["The following is a master thesis centered around the concept of localisation and the Third Way Theory. This thesis discusses various aspects of supersymmetric localisation in one and three dimensions, and contains original results with regards to the Third Way Theory. It starts off with the Witten index for a one-dimensional supersymmetric system and derives various aspects through localisation. After this, the thesis moves on to the Third Way Theory. First, it offers a review of the Third Way Theory, a deformation of topologically massive Yang-Mills theory in three dimensions. Then it moves on to original results. These include a supersymmetrisation of the Third Way Theory and consequently a localisation of the Third Way Theory, which is to say, a method of deriving non-perturbative results."], "authors": "Dimitri Kanakaris Decavel"},
{"Title": "Twist-3 Generalized Parton Distribution for the Proton from Basis Light-Front Quantization", "abs": ["We investigate the twist-3 generalized parton distributions (GPDs) for the valence quarks of the proton within the basis light-front quantization (BLFQ) framework. We first solve for the mass spectra and light-front waved functions (LFWFs) in the leading Fock sector using an effective Hamiltonian. Using the LFWFs we then calculate the twist-3 GPDs via the overlap representation. By taking the forward limit, we also get the twist-3 parton distribution functions (PDFs), and discuss their properties. Our prediction for the twist-3 scalar PDF agrees well with the CLAS experimental extractions."], "authors": "Ziqi Zhang"},
{"Title": "Near mass-shell double boxes", "abs": ["Two-loop multi-leg form factors in off-shell kinematics require knowledge of planar and nonplanar double box Feynman diagrams with massless internal propagators. These are complicated functions of Mandelstam variables and external particle virtualities. The latter serve as regulators of infrared divergences, thus making these observables finite in four space-time dimensions. In this paper, we use the method of canonical differential equations for calculation of (non)planar double box integrals in the near mass-shell kinematical regime, i.e., where virtualities of external particles are much smaller than the Mandelstam variables involved. We deduce a basis of master integrals with uniform transcendental weight based on the analysis of leading singularities by means of the Baikov representation as well as an array of complementary techniques. We dub the former asymptotically canonical since it is valid in the near mass-shell limit of interest. We iteratively solve resulting differential equations up to weight four in terms of multiple polylogarithms."], "authors": "A.V. Belitsky"},
{"Title": "On the structure of wave functions in complex Chern-Simons theory", "abs": ["We study the structure of wave functions in complex Chern-Simons theory on the complement of a hyperbolic knot, emphasizing the similarities with the topological string/spectral theory correspondence. We first conjecture a hidden integrality structure in the holomorphic blocks and show that this structure guarantees the cancellation of potential singularities in the full non-perturbative wave function at rational values of the coupling constant. We then develop various techniques to determine the wave function at such rational points. Finally, we illustrate our conjectures and obtain explicit results in the examples of the figure-eight and the three-twist knots. In the case of the figure-eight knot, we also perform a direct evaluation of the state integral in the rational case and observe that the resulting wave function has the features of the ground state for a quantum mirror curve."], "authors": "Marcos Mariño"},
{"Title": "Quantifying chaos and randomness in magnetar bursts", "abs": ["In this study, we explore the dynamical stability of magnetar bursts within the context of the chaos-randomness phase space for the first time, aiming to uncover unique behaviors compared to various astrophysical transients, including fast radio bursts (FRBs). We analyze burst energy time series data from active magnetar sources SGR J1550-5418 and SGR J1935+2154, focusing on burst arrival time and energy differences between consecutive events. We find a distinct separation in the time domain, where magnetar bursts exhibit significantly lower randomness compared to FRBs, solar flares, and earthquakes, with a slightly higher degree of chaos. In the energy domain, magnetar bursts exhibit a broad consistency with other phenomena, primarily due to the wide distribution of chaos-randomness observed across different bursts and sources. Intriguingly, contrary to expectations from the FRB-magnetar connection, the arrival time patterns of magnetar bursts in our analysis do not exhibit significant proximity to repeating FRBs in the chaos-randomness plane. This finding may challenge the hypothesis that FRBs are associated with typical magnetar bursts but indirectly supports the evidence that FRBs may primarily be linked to special magnetar bursts like peculiar X-ray bursts from SGR J1935+2154 observed simultaneously with Galactic FRB 200428."], "authors": "Shotaro Yamasaki"},
{"Title": "Edge modes, extended TQFT, and measurement based quantum computation", "abs": ["Quantum teleportation can be used to define a notion of parallel transport which characterizes the entanglement structure of a quantum state \\cite{Czech:2018kvg}. This suggests one can formulate a gauge theory of entanglement. In \\cite{Wong:2022mnv}, it was explained that measurement based quantum computation in one dimension can be understood in term of such a gauge theory (MBQC). In this work, we give an alternative formulation of this \n\"entanglement gauge theory\" as an extended topological field theory. This formulation gives a alternative perspective on the relation between the circuit model and MBQC. In addition, it provides an interpretation of MBQC in terms of the extended Hilbert space construction in gauge theories, in which the entanglement edge modes play the role of the logical qubit."], "authors": "Gabriel Wong"},
{"Title": "The environmental dependence of Spitzer dusty Supernovae", "abs": ["Thanks to the mid-infrared capability offered by Spitzer, systematic searches of dust in SNe have been carried out over the past decade. Studies have revealed the presence of a substantial amount of dust over a broad range of SN subtypes. How normal SNe present mid-IR excess at later time and turn out to be dusty SNe can be affected by several factors, such as mass-loss history and envelope structure of progenitors and their explosion environment. All these can be combined and related to their environmental properties. A systematic analysis of SNe that exploded under a dusty environment could be of critical importance to measure the properties of the dust-veiled exploding stars, and whether such an intense dust production process is associated with the local environment. In this work, we firstly use the IFS data to study the environmental properties of dusty SNe compared to those of normal ones, and analyze correlations between the environmental properties and their dust parameters. We find that dusty SNe have a larger proportion located at higher SFR regions compared to the normal types. The occurrence of dusty SNe is less dependent on metallicity, with the oxygen abundance spanning from subsolar to oversolar metallicity. We also find the host extinction of dusty SNe scatters a lot, with about 40% of dusty SN located at extremely low extinction environments, and another 30% of them with considerably high host extinction of E(B-V)>0.6 mag."], "authors": "Lin Xiao"},
{"Title": "New Continuum Observations of the Andromeda galaxy M31 with FAST", "abs": ["We present a new total intensity image of M31 at 1.248 GHz, observed with the Five-hundred-meter Aperture Spherical radio telescope (FAST) with an angular resolution of 4 arcmin and a sensitivity of about 16 mK. The new FAST image clearly reveals weak emission outside the ring due to its high sensitivity on large-scale structures. We derive a scale length of 2.7 kpc for the cosmic ray electrons and find that the cosmic ray electrons propagate mainly through diffusion by comparing the scale length at 4.8 GHz. The spectral index of the total intensity varies along the ring, which can be attributed to the variation of the spectra of synchrotron emission. This variation is likely caused by the change of star formation rates along the ring. We find that the azimuthal profile of the non-thermal emission can be interpreted by an axisymmetric large-scale magnetic field with varying pitch angle along the ring, indicating a complicated magnetic field configuration in M31."], "authors": "Wenjun Zhang"},
{"Title": "Merger rate of supermassive primordial black hole binaries", "abs": ["The probability that the primordial black hole (PBH) binaries formed in the early Universe can be affected by the Hubble expansion of background, which is non-negligible when the number density of PBHs is very low (it is actually this case for supermassive PBHs). In this paper, taking into account the effect of cosmic expansion on the comoving distance of PBH pairs, we worked out the merger rate of PBHs with any extended mass function. The torques by all PBHs and linear density perturbations are also considered. It is found that the merger rate of PBH, $M\\gtrsim 10^6M_\\odot$, binaries is significantly lower for $f_\\text{pbh}\\lesssim 0.01$ than expected."], "authors": "Hai-Long Huang"},
{"Title": "Three-Dimensional Reconstruction of Weak-Lensing Mass Maps with a Sparsity Prior. II. Weighing Triaxial Cluster Halos", "abs": ["Continuing work presented in Li et al. (2021), we performed a series of tests to our high-resolution three-dimensional mass map reconstruction algorithm \\splinv{}. We test the mass reconstruction accuracy against realistic mock catalogs generated using shear field produced by triaxial halos with the inner density profile of $\\rho \\propto r^{-1}$ and of $\\rho \\propto r^{-1.5}$. The galaxy shape noise is modeled based on the Year-1 Subaru Hyper Suprime-Cam (HSC) Survey. After reviewing mathematical details of our algorithm and dark matter halo models, we determine an optimal value of the coefficient of the adaptive LASSO regression penalty term for single halo reconstruction. We successfully measure halo masses for massive triaxial halos; the mass determination accuracy is 5 percent for halos with $M = 10^{14.6}~M_\\odot$ at $0.0625\\leq z \\leq 0.2425$, and 5 percent for those with $10^{14.8}~M_\\odot$ at $0.0625\\leq z \\leq 0.4675$, and 20 percent for $M= 10^{15.0} ~M_\\odot$ and $M=10^{15.2}~M_\\odot$ in the redshift range $0.0625\\leq z \\leq 0.4675$. The redshift estimate accuracy is consistently below $\\Delta z /z \\leq 0.05$ for the above halo masses in the range $0.1525\\leq z \\leq 0.4675$. We also demonstrate that the orientation of triaxial halos and systematic error in our halo model do not affect reconstruction result significantly. Finally, we present results from reconstruction of mass distribution using shear catalogs produced by multiple halos, to show \\splinv{}'s capability using realistic shear maps from ongoing and future galaxy surveys."], "authors": "Shouzhuo Yang"},
{"Title": "Automated Evaluation of Environmental Coupling for Advanced LIGO Gravitational Wave Detections", "abs": ["The extreme sensitivity required for direct observation of gravitational waves by the Advanced LIGO detectors means that environmental noise can potentially contaminate gravitational wave signals. Consequently, environmental monitoring efforts have been undertaken and novel noise mitigation techniques have been developed which have helped keep environmental artifacts from influencing gravitational wave detections for the $90$ gravitational wave events detected from 2015--2020 by the aLIGO detectors. The increasing rate of gravitational wave detections due to detector sensitivity improvements requires sophisticated, reliable and automated ways to monitor and assess the degree of environmental coupling between gravitational wave detectors and their surroundings. We introduce a computational tool, PEMcheck, for quantifying the degree of environmental coupling present in gravitational wave signals using data from the network of environmental monitoring sensors. We study its performance when applied to the $79$ gravitational waves confidently detected in LIGO's third observing run and test its performance in the case of extreme environmental contamination of gravitational wave data. We find that PEMcheck's automated analysis identifies only a small number of gravitational waves that merit further study by environmental noise experts due to possible contamination, a substantial improvement over the manual vetting that occurred for every gravitational wave candidate in previous observing runs. Overall, PEMcheck works as intended. Consequently, PEMcheck will play a critical role in event validation during LIGO's fourth observing run."], "authors": "Adrian Helmling-Cornell"},
{"Title": "Characterization of the M1 and M2 layers in the undisturbed Martian ionosphere at solar minimum with MAVEN ROSE", "abs": ["Is the Martian ionosphere symmetric in local time? Does the ionosphere change between aphelion, when there is no dust in the atmosphere, compared to perihelion, when the temperature rises and there is dust in the air even if no storm is blowing? We utilize data from the MAVEN Radio Occultation Science Experiment (Withers et al., 2020) - with unprecedented coverage in solar zenith angle - to answer these questions and isolate the effects that local time and season induce on the ionosphere at solar minimum. 219 out of the 1228 electron density profiles of the Martian ionosphere collected by MAVEN ROSE between July 2016 and December 2022 show, besides the ever-present dayside M2 layer, a distinct M1 layer right below. This allowed us to study the behavior of the M2 and M1 peak density and altitude as a function of solar zenith angle, and, also, for the first time, local time, and Martian season. We find that the M1 layer at low SZA can occur at altitudes lower than 100 km; that the peak altitudes and densities of both the M2 and M1 layers change more with season than at the dusk ionosphere; and that the M2 peak density decreases at a faster rate than the M1 with SZA. This study provides a baseline to accurately characterize the photoproduced Martian ionosphere at solar minimum."], "authors": "Jennifer Segale"},
{"Title": "What Makes A Discovery", "abs": ["In this contribution to the proceedings of the 182nd Nobel Symposium, I reflect on the concept of \"discovery\" as it is used by physicists and astronomers. In particular, I comment on how the scientific community distinguishes discoveries from propositions that are supported only by lesser forms of evidence, emphasizing the social nature of this process and remarking on the subjective factors that go into making such judgements. I advocate for an approach that is intentionally Bayesian in nature, in which individuals are encouraged to evaluate and publicly state their priors and to update them systematically. I close by applying these practices to the case example of the Galactic Center Gamma-Ray Excess."], "authors": "Dan Hooper"},
{"Title": "The maximum mass of a black hole which can tidally disrupt a star: measuring black hole spins with tidal disruption events", "abs": ["The tidal acceleration experienced by an object at the event horizon of a black hole decreases as one over the square of the black hole's mass. As such there is a maximum mass at which a black hole can tidally disrupt an object outside of its event horizon and potentially produce observable emission. This maximum mass is known as the ``Hills mass'', and in full general relativity is a function of both the black hole's spin $a_\\bullet$ and the inclination angle of the incoming object's orbit with respect to the black hole's spin axis $\\psi$. In this paper we demonstrate that the Hills mass can be represented by a simple analytical function of $a_\\bullet$ and $\\psi$, the first general solution of this problem. This general solution is found by utilising the symmetries of a class of critical Kerr metric orbits known as the innermost bound spherical orbits. Interestingly, at fixed black hole spin the maximum Hills mass can lie at incoming orbital inclinations outside of the black hole's equatorial plane $\\psi \\neq \\pi/2$. When compared to previous results in the literature this effect can lead to an increase in the maximum Hills mass (at fixed spin) by as much as a factor of $\\sqrt{11/5} \\simeq 1.48$ for a maximally rotating black hole. We then demonstrate how Bayesian inference, coupled with an estimate of the mass of a black hole in a tidal disruption event, can be used to place conservative constraints on that black hole's spin. We provide a publicly available code tidalspin which computes these spin distributions."], "authors": "Andrew Mummery"},
{"Title": "Constraining tensor-to-scalar ratio based on VLBI observations: PGWs induced-incoherence approach", "abs": ["The background of primordial gravitational waves (PGWs) predicted by the inflationary scenario induce incoherence of the electromagnetic field propagating over cosmological distances. We propose a new schema to constrain the underlying inflationary parameters, in particular the tensor-to-scalar ratio r, based on angular size-redshift \\theta-z measurement accomplished by very long baseline interferometry (VLBI) surveys. VLBI observations rely on the van-Citter Zernike theorem, which expresses the coherence length in terms of its wavelength and angular size, i.e., d_coh < \\lambda/\\theta. In this study, we show that the interaction of the radio signal (involved in VLBI) with PGWs, along the propagation from a source located at redshift z_* to the Earth, leads to the blurring of the visibility. The blurring effect is evaluated for the highly-squeezed PGW, where it turns out that in order not to ruin the visibility, the projected baseline of the interferometer must be smaller than \\xi_sq(z), which is inversely proportional to the the tensor-to-scalar ratio through \\xi_sq \\propto r^{-1/2}. Hence, VLBI observations based on interference pattern lead to a constraint on r imposed by the fact that \\xi_sq(z) is greater than d_coh of the emitted radiation. In order to evaluate the constraint, we use a sample of compact radio quasars observed in VLBI and located at redshift range 0.46<z<2.73. We obtain a stringent upper-bound on the tensor-to-scalar ratio, r<2.10^{-6}, far beyond present constraints on this parameter. Further issues and caveats that potentially affect the results are reviewed. In particular, the possible effect of quantum-to-classical transition of PGWs is discussed. Ultimately, the background of primordial tensor perturbations may be more constrained with the help of the high-precision VLBI measurement of angular size-redshift of more distant sources."], "authors": "Fateme Shojaei Arani"},
{"Title": "Spherically symmetric anisotropic strange stars", "abs": ["In this work, we made an extensive study about the possible presence of anisotropies in strange stars. To accomplish this task, we use three different configurations for the strange matter: the unpaired matter, a two-flavor super-conducting (2SC) strange matter, and a fully three-flavor super-conducting strange matter (CFL). For each configuration, we calculate the relevant quantities for the strange stars, such as the mass-radius relation, the dimensionless tidal parameter, the moment of inertia, and the surface curvature for different degrees of anisotropies. Whenever possible, we compare our results with constraints found in the literature, especially focusing on the existence of very massive pulsars (PSR J0952-0607), as well as very light compact objects (HESS J1731-347)."], "authors": "Luiz L. Lopes"},
{"Title": "Anatomy of Diluted Dark Matter in the Minimal Left-Right Symmetric Model", "abs": ["Temporary matter domination and late entropy dilution, injected by a \"long-lived\" particle in the early universe, serves as a standard mechanism for yielding the correct dark matter relic density. We recently pointed out the cosmological significance of diluting particle's partial decay into dark matter. When repopulated in such a way, dark matter carries higher momentum than its thermal counterpart, resulting in a suppression of the linear matter power spectrum that is constrained by the large scale structure observations. In this work, we study the impact of such constraints on the minimal left-right symmetric model that accounts for the origin of neutrino mass. We map out a systematic anatomy of possible dilution scenarios with viable parameter spaces, allowed by cosmology and various astrophysical and terrestrial constraints. We show that to accommodate the observed dark matter relic abundance the spontaneous left-right symmetry breaking scale must be above PeV and cosmology will continue to provide the most sensitive probes of it. In case the dilutor is one of the heavier right-handed neutrinos, it can be much lighter and lie near the electroweak scale."], "authors": "Miha Nemevšek"},
{"Title": "XMM-Newton --NuSTAR monitoring campaign of the Seyfert 1 galaxy IC 4329A", "abs": ["We present the results of a joint {\\it XMM-Newton} and {\\it NuSTAR} campaign on the active galactic nucleus (AGN) IC 4329A, consisting of 9 $\\times$ 20 ks {\\it XMM-Newton} observations, and 5 $\\times$ 20 ks {\\it NuSTAR} observations within nine days, performed in August 2021. Within each observation, the AGN is not very variable, with the fractional variability never exceeding 5%. Flux variations are observed between the different observations, on timescales of days, with a 30% ratio between the minimum and the maximum 2-10 keV flux. These variations follow the softer-when-brighter behavior typically observed in AGN. In all observations, a soft excess is clearly present. Consistently with previous observations, the X-ray spectra of the source exhibit a cut-off energy between 140 and 250 keV, constant within the error in the different observations. We detected a narrow iron \\ka line consistent with being constant during the monitoring, and likely originating in a distant neutral medium. We do not find evidence of a broad component of the iron line, suggesting that the inner disk does not produce strong reflection. We find that the reflection component is weak ($R_{\\rm max}=0.009\\pm0.002$). We also found the presence of a warm absorber component together with an ultra-fast outflow. Looking at their energetic, these outflows have enough mechanical power to exercise a significant feedback impact on the AGN surrounding environment."], "authors": "A. Tortosa"},
{"Title": "Quasimonochromatic LISA Sources in the Frequency Domain", "abs": ["Among the binary sources of interest for LISA some are quasimonochromatic, in the sense that the change in the gravitational wave frequency $\\Delta f\\lesssim 1\\;\\mbox{yr}^{-1}$ during the observation time. We study these sources in the frequency domain (FD) by taking into account the Doppler shift induced by LISA's motion and the LISA pattern functions, and we compare our results with previous work in the time domain. We also discuss the transition from the quasimonochromatic case to the stationary phase approximation commonly used in Fisher matrix calculations, which applies when $\\Delta f\\gtrsim 1\\;\\mbox{yr}^{-1}$."], "authors": "Vladimir Strokov"},
{"Title": "Environmental Quenching of Low Surface Brightness Galaxies near Milky Way mass Hosts", "abs": ["Low Surface Brightness Galaxies (LSBGs) are excellent probes of quenching and other environmental processes near massive galaxies. We study an extensive sample of LSBGs near massive hosts in the local universe that are distributed across a diverse range of environments. The LSBGs with surface-brightness $\\mu_{\\rm eff,g}> $24.2 mag arcsec$^{-2}$ are drawn from the Dark Energy Survey Year 3 catalog while the hosts with masses $9.0< log(M_{\\star}/M_{\\odot})< 11.0$ comparable to the Milky Way and the Large Magellanic Cloud are selected from the z0MGS sample. We study the projected radial density profiles of LSBGs as a function of their color and surface brightness around hosts in both the rich Fornax-Eridanus cluster environment and the low-density field. We detect an overdensity with respect to the background density, out to 2.5 times the virial radius for both hosts in the cluster environment and the isolated field galaxies. When the LSBG sample is split by $g-i$ color or surface brightness $\\mu_{\\rm eff,g}$, we find the LSBGs closer to their hosts are significantly redder and brighter, like their high surface-brightness counterparts. The LSBGs form a clear 'red sequence' in both the cluster and isolated environments that is visible beyond the virial radius of the hosts. This suggests a pre-processing of infalling LSBGs and a quenched backsplash population around both host samples. However, the relative prominence of the 'blue cloud' feature implies that pre-processing is ongoing near the isolated hosts compared to the cluster hosts."], "authors": "J. Bhattacharyya"},
{"Title": "LiteBIRD Science Goals and Forecasts. A Case Study of the Origin of Primordial Gravitational Waves using Large-Scale CMB Polarization", "abs": ["We study the possibility of using the $LiteBIRD$ satellite $B$-mode survey to constrain models of inflation producing specific features in CMB angular power spectra. We explore a particular model example, i.e. spectator axion-SU(2) gauge field inflation. This model can source parity-violating gravitational waves from the amplification of gauge field fluctuations driven by a pseudoscalar \"axionlike\" field, rolling for a few e-folds during inflation. The sourced gravitational waves can exceed the vacuum contribution at reionization bump scales by about an order of magnitude and can be comparable to the vacuum contribution at recombination bump scales. We argue that a satellite mission with full sky coverage and access to the reionization bump scales is necessary to understand the origin of the primordial gravitational wave signal and distinguish among two production mechanisms: quantum vacuum fluctuations of spacetime and matter sources during inflation. We present the expected constraints on model parameters from $LiteBIRD$ satellite simulations, which complement and expand previous studies in the literature. We find that $LiteBIRD$ will be able to exclude with high significance standard single-field slow-roll models, such as the Starobinsky model, if the true model is the axion-SU(2) model with a feature at CMB scales. We further investigate the possibility of using the parity-violating signature of the model, such as the $TB$ and $EB$ angular power spectra, to disentangle it from the standard single-field slow-roll scenario. We find that most of the discriminating power of $LiteBIRD$ will reside in $BB$ angular power spectra rather than in $TB$ and $EB$ correlations."], "authors": "P. Campeti"},
{"Title": "Euclid preparation. TBD. Galaxy power spectrum modelling in real space", "abs": ["We investigate the accuracy of the perturbative galaxy bias expansion in view of the forthcoming analysis of the Euclid spectroscopic galaxy samples. We compare the performance of an Eulerian galaxy bias expansion, using state-of-art prescriptions from the effective field theory of large-scale structure (EFTofLSS), against a hybrid approach based on Lagrangian perturbation theory and high-resolution simulations. These models are benchmarked against comoving snapshots of the Flagship I N-body simulation at $z=(0.9,1.2,1.5,1.8)$, which have been populated with H$\\alpha$ galaxies leading to catalogues of millions of objects within a volume of about $58\\,h^{-3}\\,{\\rm Gpc}^3$. Our analysis suggests that both models can be used to provide a robust inference of the parameters $(h, \\omega_{\\rm c})$ in the redshift range under consideration, with comparable constraining power. We additionally determine the range of validity of the EFTofLSS model in terms of scale cuts and model degrees of freedom. From these tests, it emerges that the standard third-order Eulerian bias expansion can accurately describe the full shape of the real-space galaxy power spectrum up to the maximum wavenumber $k_{\\rm max}=0.45\\,h\\,{\\rm Mpc}^{-1}$, even with a measurement precision well below the percent level. In particular, this is true for a configuration with six free nuisance parameters, including local and non-local bias parameters, a matter counterterm, and a correction to the shot-noise contribution. Fixing either tidal bias parameters to physically-motivated relations still leads to unbiased cosmological constraints. We finally repeat our analysis assuming a volume that matches the expected footprint of Euclid, but without considering observational effects, as purity and completeness, showing that we can get consistent cosmological constraints over this range of scales and redshifts."], "authors": "Euclid Collaboration"},
{"Title": "Initial Results From the First Field Expedition of UAPx to Study Unidentified Anomalous Phenomena", "abs": ["In July 2021, faculty from the UAlbany Department of Physics participated in a week-long field expedition with the organization UAPx to collect data on UAPs in Avalon, California, located on Catalina Island, and nearby. This paper reviews both the hardware and software techniques which this collaboration employed, and contains a frank discussion of the successes and failures, with a section about how to apply lessons learned to future expeditions. Both observable-light and infrared cameras were deployed, as well as sensors for other (non-EM) emissions. A pixel-subtraction method was augmented with other similarly simple methods to provide initial identification of objects in the sky and/or the sea crossing the cameras' fields of view. The first results will be presented based upon approximately one hour in total of triggered visible/night-vision-mode video and over 600 hours of untriggered (far) IR video recorded, as well as 55 hours of (background) radiation measurements. Following multiple explanatory resolutions of several ambiguities that were potentially anomalous at first, we focus on the primary remaining ambiguity captured at approximately 4am Pacific Time on Friday, July 16: a dark spot in the visible/near-IR camera possibly coincident with ionizing radiation that has thus far resisted a prosaic explanation. We conclude with quantitative suggestions for serious researchers in this still-nascent field of hard-science-based UAP studies, with an ultimate goal of identifying UAPs without confirmation bias toward either mundane or speculative conclusions."], "authors": "M. Szydagis"},
{"Title": "Stochastic gravitational waves produced by the first-order QCD phase transition", "abs": ["We investigate the stochastic gravitational waves background arising from the first-order QCD chiral phase transition, considering three distinct sources: bubble collisions, sound waves, and fluid turbulence. Within the framework of the Polyakov-Nambu-Jona-Lasinio (PNJL) model, we calculate the parameters governing the intensity of the gravitational wave phase transition and determine their magnitudes along the adiabatic evolutionary path. We introduce the effective bag constant $B_{\\mathrm{eff}}$ related to the dynamical evolution of quarks to evaluate the intensity of the phase transition. By calculating expanded potential at the point of false vacuum, we find that all the bubbles are in the mode of runaway, leading the velocity of the bubble wall to the speed of light. The resulting gravitational wave energy spectrum is estimated, revealing a characteristic amplitude of the generated gravitational waves within the centihertz frequency range. We present the gravitational wave spectrum and compare it with the sensitivity range of detectors, and find that the gravitational wave spectra generated by these sources have the potential to be detected by future detectors such as BBO and $\\mu$ARES."], "authors": "Xu Han"},
{"Title": "GaiaNIR: Note on processing and photometry", "abs": ["Some ideas for onboard processing and photometry with an astrometry satellite are presented, especially designed for GaiaNIR which may be launched about 2045 as a successor of Gaia. - Increased sensitivity, reduced image overlap, and simpler PSF calibration in GaiaNIR will result if the proposed initial processing of data from the detectors is implemented, because the across-scan smearing will become insignificant. - Filter photometry is required for high angular resolution as needed for astrometric and astrophysical reasons. Low-dispersion spectra are questioned because they fail at high star density. This will be a much greater problem with GaiaNIR than it is with Gaia because of the larger number of stars expected. It was the aim to collect in this note all arguments about GaiaNIR photometry which can be stated with words only, in correspondence with readers. The remaining work to be done for the definition of photometric equipment on the satellite requires further quantitative assessments and comparison of various options. Finally, 1) an advantage of filters is that the photometric observations can also be used for astrometry, 2) the XP spectra in Gaia will give very good astrophysical data for about 400 million single stars with G <~ 18.5 mag, but filters would have been better for all fainter and for all multiple stars, and 3) it is presently not clear which advantages for astrophysics low-dispersion spectra in the NIR might have over filters."], "authors": "Erik Høg"},
{"Title": "Dynamics of pairwise motions in the fully non-linear regime in LCDM and Modified Gravity cosmologies", "abs": ["In contrast to our understanding of density field tracers, the modelling of direct statistics pertaining to the cosmic velocity field remains open to significant opportunities for improvement. The lack of accurate modelling for the non-linear domain of pairwise velocities restricts our capacity to fully exploit the information encoded in this observable. We present a robust approach for modelling the mean infall velocities, $v_{12}(r,a)$, with broad applicability spanning sub-megaparsec scales and cosmologies extending beyond the standard LCDM paradigm. Our approach involves solving the full pair-conservation equation using accurate non-linear power spectrum descriptions. To assess the robustness of our model, we extend it to cosmologies beyond the standard LCDM, in particular, the Hu-Sawicki $f(R)$-gravity and Dvali-Gabadadze-Porrati (DGP) modified gravity models. Remarkably, our predictions for pairwise velocities of dark matter particles at kilo-parsec scales exhibit excellent agreement with N-body simulations throughout the entire dynamical range ($0.1 \\lesssim \\xi \\lesssim 1000$, or $r\\geq0.4$Mpc/h). Furthermore, we show that different gravity models leave distinct signatures in the shape and dynamics of the mean pairwise velocities, providing a potent test of cosmological gravity laws."], "authors": "Mariana Jaber"},
{"Title": "RadioGalaxyNET: Dataset and Novel Computer Vision Algorithms for the Detection of Extended Radio Galaxies and Infrared Hosts", "abs": ["Creating radio galaxy catalogues from next-generation deep surveys requires automated identification of associated components of extended sources and their corresponding infrared hosts. In this paper, we introduce RadioGalaxyNET, a multimodal dataset, and a suite of novel computer vision algorithms designed to automate the detection and localization of multi-component extended radio galaxies and their corresponding infrared hosts. The dataset comprises 4,155 instances of galaxies in 2,800 images with both radio and infrared channels. Each instance provides information about the extended radio galaxy class, its corresponding bounding box encompassing all components, the pixel-level segmentation mask, and the keypoint position of its corresponding infrared host galaxy. RadioGalaxyNET is the first dataset to include images from the highly sensitive Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope, corresponding infrared images, and instance-level annotations for galaxy detection. We benchmark several object detection algorithms on the dataset and propose a novel multimodal approach to simultaneously detect radio galaxies and the positions of infrared hosts."], "authors": "Nikhel Gupta"},
{"Title": "A Large Sample of Extremely Metal-poor Galaxies at $z<1$ Identified from the DESI Early Data", "abs": ["Extremely metal-poor galaxies (XMPGs) at relatively low redshift are excellent laboratories for studying galaxy formation and evolution in the early universe. Much effort has been spent on identifying them from large-scale spectroscopic surveys or spectroscopic follow-up observations. Previous work has identified a few hundred XMPGs. In this work, we obtain a large sample of 223 XMPGs at $z<1$ from the early data of the Dark Energy Spectroscopic Instrument (DESI). The oxygen abundance is determined using the direct $T_{\\rm e}$ method based on the detection of the [O III]$\\lambda$4363 line. The sample includes 95 confirmed XMPGs based on the oxygen abundance uncertainty; remaining 128 galaxies are regarded as XMPG candidates. These XMPGs are only 0.01% of the total DESI observed galaxies. Their coordinates and other proprieties are provided in the paper. The most XMPG has an oxygen abundance of $\\sim 1/34 Z_{\\odot}$, stellar mass of about $1.5\\times10^7 M_{\\odot}$ and star formation rate of 0.22 $M_{\\odot}$ yr$^{-1}$. The two most XMPGs present distinct morphologies suggesting different formation mechanisms. The local environmental investigation shows that XMPGs preferentially reside in relatively low-density regions. Many of them fall below the stellar mass-metallicity relations (MZRs) of normal star-forming galaxies. From a comparison of the MZR with theoretical simulations, it appears that XMPGs are good analogs to high-redshift star-forming galaxies. The nature of these XMPG populations will be further investigated in detail with larger and more complete samples from the on-going DESI survey."], "authors": "Hu Zou"},
{"Title": "aeons: approximating the end of nested sampling", "abs": ["This paper presents analytic results on the anatomy of nested sampling, from which a technique is developed to estimate the run-time of the algorithm that works for any nested sampling implementation. We test these methods on both toy models and true cosmological nested sampling runs. The method gives an order-of-magnitude prediction of the end point at all times, forecasting the true endpoint within standard error around the halfway point."], "authors": "Zixiao Hu"},
{"Title": "Orbit decay in encounters between anisotropic spherical galaxies of equal mass", "abs": ["We investigate the effect of radial anisotropy on the rate of orbit decay in parabolic encounters of identical spherical galaxies. Our galaxy models have Hernquist density profiles and Osipkov--Merritt velocity distributions. We find that radially anisotropic models merge in as little as half the time of their isotropic counterparts. Anisotropic models are more susceptible to tidal deformation; this accelerates the transfer of orbital angular momentum to internal degrees of freedom. Even during the initial approach, the anisotropic models become more distorted, and arrive at pericentre already having lost substantial amounts of angular momentum. Our results may have implications for estimates of merger rates and persistence of tidal tails."], "authors": "Lucas Saleh"},
{"Title": "Short Review of the main achievements of the Scalar Field, Fuzzy, Ultralight, Wave, BEC Dark Matter model", "abs": ["The Scalar Field Dark Matter model has been known in various ways throughout its history; Fuzzy, BEC, Wave, Ultralight, Axion-like Dark Matter, etc. All of them consist in proposing that the dark matter of the universe is a spinless field $\\Phi$ that follows the Klein-Gordon (KG) equation of motion $\\Box\\Phi-dV/d\\Phi=0$, for a given scalar field potential $V$. The difference between different models is sometimes the choice of the scalar field potential $V$. In the literature we find that people usually work in the nonrelativistic, weak-field limit of the KG equation where it transforms into the Schrödinger equation and the Einstein equations into the Poisson equation, reducing the KG-Einstein system, to the Schrödinger-Poisson system. In this paper, we review some of the most interesting achievements of this model from the historical point of view and its comparison with observations, showing that this model could be the last answer to the question about the nature of dark matter in the universe."], "authors": "Tonatiuh Matos"},
{"Title": "Spectroastrometry and Imaging Science with Photonic Lanterns on Extremely Large Telescopes", "abs": ["Photonic lanterns (PLs) are tapered waveguides that gradually transition from a multi-mode fiber geometry to a bundle of single-mode fibers. In astronomical applications, PLs can efficiently couple multi-mode telescope light into a multi-mode fiber entrance and convert it into multiple single-mode beams. The output beams are highly stable and suitable for feeding into high-resolution spectrographs or photonic chip beam combiners. For instance, by using relative intensities in the output cores as a function of wavelength, PLs can enable spectroastrometry. In addition, by interfering beams in the output cores with a beam combiner in the backend, PLs can be used for high-throughput interferometric imaging. When used on an Extremely Large Telescope (ELT), with its increased sensitivity and angular resolution, the imaging and spectroastrometric capabilities of PLs will be extended to higher contrast and smaller angular scales. We study the potential spectroastrometry and imaging science cases of PLs on ELTs, including study of exomoons, broad-line regions of quasars, and inner circumstellar disks."], "authors": "Yoo Jung Kim"},
{"Title": "The impact of free-streaming on dwarf galaxy counts in low-density regions", "abs": ["We study the statistics of dwarf galaxy populations as a function of environment in the cold dark matter (CDM) and warm dark matter (WDM) cosmogonies, using hydrodynamical simulations starting from initial conditions with matched phases but differing power spectra, and evolved with the EAGLE galaxy formation model. We measure the abundance of dwarf galaxies within 3~Mpc of DM haloes with a present-day halo mass similar to that of the Milky Way (MW), and find that the radial distribution of galaxies $M_{*}>10^7$\\Msun is nearly identical for WDM and CDM. However, the cumulative mass function becomes shallower for WDM at lower masses, yielding 50~per~cent fewer dwarf galaxies of $M_{*}\\gtrsim10^{5}$~\\Msun than CDM. The suppression of low-mass halo counts in WDM relative to CDM increases significantly from high-density regions to low-density regions for haloes in the region of the half-mode mass, $M_\\rm{hm}$. The luminous fraction in the two models also diverges from the overdense to the underdense regions for $M>2M_\\rm{hm}$, as the increased collapse delay at small densities pushes the collapse to after the reionization threshold. However, the stellar mass--halo mass relation of WDM haloes relative to CDM increases towards lower-density regions. Finally, we conclude that the suppression of galaxies with $M_{*}\\gtrsim10^5$\\Msun between WDM and CDM is independent of density: the suppression of halo counts and the luminous fraction is balanced by an enhancement in stellar mass--halo mass relation."], "authors": "Tamar Meshveliani"},
{"Title": "Atmospheric metallicity and C/O of HD 189733 b from high-resolution spectroscopy", "abs": ["We present high-resolution $K$-band emission spectra of the quintessential hot Jupiter HD 189733 b from the Keck Planet Imager and Characterizer (KPIC). Using a Bayesian retrieval framework, we fit the dayside pressure-temperature profile, orbital kinematics, mass-mixing ratios of H$_2$O, CO, CH$_4$, NH$_3$, HCN, and H$_2$S, and the $\\rm ^{13}CO/^{12}CO$ ratio. We measure mass fractions of $\\rm \\log H_2O = -2.0^{+0.4}_{-0.4}$ and $\\rm \\log CO = -2.2^{+0.5}_{-0.5}$, and place upper limits on the remaining species. Notably, we find $\\rm \\log CH_4 < -4.5$ at 99\\% confidence, despite its anticipated presence at the equilibrium temperature of HD 189733 b assuming local thermal equilibrium. We make a tentative ($\\sim3\\sigma$) detection of $\\rm ^{13}CO$, and the retrieved posteriors suggest a $\\rm ^{12}C/^{13}C$ ratio similar to or substantially less than the local interstellar value. The possible $\\rm ^{13}C$ enrichment would be consistent with accretion of fractionated material in ices or in the protoplanetary disk midplane. The retrieved abundances correspond to a substantially sub-stellar atmospheric $\\rm C/O = 0.3\\pm0.1$, while the carbon and oxygen abundances are stellar to slightly super-stellar, consistent with core-accretion models which predict an inverse correlation between C/O and metallicity. The specific combination of low C/O and high metallicity suggests significant accretion of solid material may have occurred late in the formation process of HD 189733 b."], "authors": "Luke Finnerty"},
{"Title": "$\\texttt{tdescore}$: An Accurate Photometric Classifier for Tidal Disruption Events", "abs": ["Optical surveys have become increasingly adept at identifying candidate Tidal Disruption Events (TDEs) in large numbers, but classifying these generally requires extensive spectroscopic resources. We here present $\\texttt{tdescore}$, a simple photometric classifier that is trained using a systematic census of $\\sim$3000 nuclear transients from the Zwicky Transient Facility (ZTF). The sample is highly imbalanced, with TDEs representing $<$2% of the total. $\\texttt{tdescore}$ is nonetheless able to reject non-TDEs with 99.6% accuracy, yielding a sample of probable TDEs with completeness of 77.0% and a purity of 80.3%. $\\texttt{tdescore}$ is thus substantially better than any available TDE photometric classifier scheme in the literature, and performs comparably well to the single-epoch spectroscopy as a method for classifying ZTF nuclear transients, despite relying solely on ZTF data and multi-wavelength catalogue crossmatching. In a novel extension, we use 'SHapley Additive exPlanations' (SHAP) to provide a human-readable justification for each individual $\\texttt{tdescore}$ classification, enabling users to understand and form opinions about the underlying classifier reasoning. $\\texttt{tdescore}$ serves as a model for photometric identification of TDEs with time-domain surveys, such as the upcoming Rubin observatory."], "authors": "Robert Stein"},
{"Title": "The dense and non-homogeneous circumstellar medium revealed in radio wavelengths around the Type Ib SN 2019oys", "abs": ["We present here broadband radio observations of the CSM interacting SN2019oys. SN2019oys was first detected in the optical and was classified as a Type Ib SN. Then, about $\\sim 100$ days after discovery, it showed an optical rebrightening and a spectral transition to a spectrum dominated by strong narrow emission lines, which suggests strong interaction with a distant, dense, CSM shell. We modeled the broadband, multi-epoch, radio spectra, covering 2.2 to 36 GHz and spanning from 22 to 1425 days after optical discovery, as a synchrotron emitting source. Using this modeling we characterized the shockwave and the mass-loss rate of the progenitor. Our broadband radio observations show strong synchrotron emission. This emission, as observed 201 and 221 days after optical discovery, exhibits signs of free-free absorption from the material in front of the shock traveling in the CSM. In addition, the steep power law of the optically thin regime points towards synchrotron cooling of the radiating electrons. Analyzing these spectra in the context of the SN-CSM interaction model gives a shock velocity of 14,000 $\\rm km \\, s^{-1}$, and an electron number density of $2.6 \\times 10^5 \\, \\rm cm^{-3}$ at a distance of $2.6 \\times 10^{16}$ cm. This translates to a high mass-loss rate from the progenitor massive star of $6.7 \\times 10^{-4} \\, \\rm M_{\\odot} yr^{-1}$ for an assumed wind of 100 $\\rm km s^{-1}$ (assuming constant mass-loss rate in steady winds). The late-time radio spectra, 392 and 557 days after optical discovery, are showing broad spectral peaks. We show that this can be explained by introducing a non-homogeneous CSM structure."], "authors": "Itai Sfaradi"},
{"Title": "Scalable Bayesian uncertainty quantification with data-driven priors for radio interferometric imaging", "abs": ["Next-generation radio interferometers like the Square Kilometer Array have the potential to unlock scientific discoveries thanks to their unprecedented angular resolution and sensitivity. One key to unlocking their potential resides in handling the deluge and complexity of incoming data. This challenge requires building radio interferometric imaging methods that can cope with the massive data sizes and provide high-quality image reconstructions with uncertainty quantification (UQ). This work proposes a method coined QuantifAI to address UQ in radio-interferometric imaging with data-driven (learned) priors for high-dimensional settings. Our model, rooted in the Bayesian framework, uses a physically motivated model for the likelihood. The model exploits a data-driven convex prior, which can encode complex information learned implicitly from simulations and guarantee the log-concavity of the posterior. We leverage probability concentration phenomena of high-dimensional log-concave posteriors that let us obtain information about the posterior, avoiding MCMC sampling techniques. We rely on convex optimisation methods to compute the MAP estimation, which is known to be faster and better scale with dimension than MCMC sampling strategies. Our method allows us to compute local credible intervals, i.e., Bayesian error bars, and perform hypothesis testing of structure on the reconstructed image. In addition, we propose a novel blazing-fast method to compute pixel-wise uncertainties at different scales. We demonstrate our method by reconstructing radio-interferometric images in a simulated setting and carrying out fast and scalable UQ, which we validate with MCMC sampling. Our method shows an improved image quality and more meaningful uncertainties than the benchmark method based on a sparsity-promoting prior. QuantifAI's source code:", "."], "authors": "Tobías I. Liaudat"},
{"Title": "The Ubiquity and Magnitude of Large FeK$α$ Equivalent Widths in AGN Extended Regions", "abs": ["Narrow Fe K$\\alpha$ fluorescent emission lines arising at $\\sim$kpc-scale separations from the nucleus have only been detected in a few AGN. The detections require that the extended line emission be spatially resolved and sufficiently bright. Compared to narrow Fe K$\\alpha$ lines arising closer to the nucleus, they have much lower fluxes but show substantially larger equivalent widths, EW$_{\\rm Fe K\\alpha}$. We show that, in the optically-thin limit, a purely analytical argument naturally predicts large, EW$_{\\rm FeK\\alpha}\\sim$1 keV, values for such lines, regardless of the details of equivalent hydrogen column density, $N_H$, or reprocessor geometry. Monte Carlo simulations corroborate this result and show that the simple analytic EW$_{\\rm FeK\\alpha}$ prescription holds up to higher $N_H$ approaching the Compton-thick regime. We compare to $Chandra$ observations from the literature and discuss that our results are consistent with the large EW$_{\\rm FeK\\alpha}$ values reported for local AGN, for which the line is detected in extended, up to $\\sim$kpc-scale, regions. We argue that large EW$_{\\rm FeK\\alpha}$ from kpc-scale regions in AGN should be ubiquitous, because they do not depend on the absolute luminosity of the central X-ray source, and are measured only against the scattered continuum. We predict values to be of the order of $\\sim$1 keV or larger, even for covering factors $\\ll$1, and for arbitrarily small column densities. We propose that the large-scale molecular material that is now routinely being detected with the Atacama Large Millimeter/Submillimeter Array (ALMA) may act as an extended X-ray scattering reprocessor giving rise to $\\sim$kpc-scale Fe K$\\alpha$ emission."], "authors": "P. Tzanavaris"},
{"Title": "Reconstructing patchy helium reionization using the cosmic microwave background and large-scale structure", "abs": ["The intergalactic helium became fully ionized by the end of cosmic noon ($z\\sim2$). Similarly to the reionization of hydrogen, helium reionization is expected to be patchy, driven by luminous quasars that ionize the intergalactic gas in their surrounding environment. Probing the morphology of ionized electrons during this epoch can provide crucial information about early structure formation, including the clustering and luminosities of quasars, the accretion rates, variability, and lifetimes of active galactic nuclei, as well as the growth and evolution of supermassive black holes. In this study, we present how measurements of the cosmic microwave background (CMB) can be used to reconstruct the optical-depth fluctuations resulting from patchy helium reionization. As helium reionization occurred at lower redshifts, upcoming probes of large-scale structure surveys will present a significant opportunity to enhance the prospects of probing this epoch by their combined analysis with the CMB. Using a joint information-matrix analysis of hydrogen and helium reionization, we show that near-future galaxy and CMB surveys will have enough statistical power to detect optical-depth fluctuations due to doubly-ionized helium, providing a way of measuring the redshift and duration of helium reionization to high significance. We also show that modeling uncertainties in helium reionization can impact the measurement precision of parameters characterizing hydrogen reionization."], "authors": "Mesut Çalışkan"},
{"Title": "Atmospheric Escape From Three Terrestrial Planets in the L 98-59 System", "abs": ["A critically important process affecting the climate evolution and potential habitability of an exoplanet is atmospheric escape, in which high-energy radiation from a star drives the escape of hydrogen atoms and other light elements from a planet's atmosphere. L 98-59 is a benchmark system for studying such atmospheric processes, with three transiting terrestrial-size planets receiving Venus-like instellations (4-25 S$_\\oplus$) from their M3 host star. We use the VPLanet model to simulate the evolution of the L 98-59 system and the atmospheric escape of its inner three small planets, given different assumed initial water quantities. We find that, regardless of their initial water content, all three planets accumulate significant quantities of oxygen due to efficient water photolysis and hydrogen loss. All three planets also receive enough XUV flux to drive rapid water loss, which considerably affects their developing climates and atmospheres. Even in scenarios of low initial water content, our results suggest that the James Webb Space Telescope (JWST) will be sensitive to observations of retained oxygen on the L 98-59 planets in its future scheduled observations, with planets b and c being the most likely targets to possess an extended atmosphere. Our results constrain the atmospheric evolution of these small rocky planets, and they provide context for current and future observations of the L 98-59 system to generalize our understanding of multi-terrestrial planet systems."], "authors": "Emeline F. Fromont"},
{"Title": "Behaviour of n-point scattering amplitudes at high energies", "abs": ["We study the on-shell scattering amplitudes in quantum gravity for high-energy collisions in the eikonal approximation. We first evaluate the $n$-loop 2-particle scattering amplitude in the high energy and low momentum transfer limit. We do so in a symmetrized manner by finding the contributions of each of the particle worldines to the scattering amplitude and gluing them together via the $n$ intermediate particle exchanges. In this limit on applying the eikonal approximation and summing over all $n$-loop Feynman diagrams we obtain a closed form for the 2 particle scattering amplitude. Finally, we extend this approach to obtain a generalized eikonal approximation for $N$-particle scattering at high energies and small momentum transfers. The generalised form of the scattering amplitude can then be used to evaluate the bound states of the system."], "authors": "Shreya Shrivastava"},
{"Title": "Discovery of radio eclipses from 4FGL J1646.5$-$4406: a new candidate redback pulsar binary", "abs": ["Large widefield surveys make possible the serendipitous discovery of rare sub-classes of pulsars. One such class are \"spider\"-type pulsar binaries, comprised of a pulsar in a compact orbit with a low-mass (sub)stellar companion. In a search for circularly-polarized radio sources in ASKAP Pilot Survey observations, we discovered highly variable and circularly polarized emission from a radio source within the error region of the $\\gamma$-ray source {4FGL}~J1646.5$-$4406. The variability is consistent with the eclipse of a compact, steep-spectrum source behind ablated material from a companion in a $\\sim 5.3\\,$h binary orbit. Based on the eclipse properties and spatial coincidence with {4FGL} J1646.5$-$4406, we argue that the source is likely a recycled pulsar in a \"redback\" binary system. Using properties of the eclipses from ASKAP and Murchison Widefield Array observations, we provide broad constraints on the properties of the eclipse medium. We identified a potential optical/infra-red counterpart in archival data consistent with a variable low-mass star. Using the Parkes Radio Telescope \"Murriyang\" and MeerKAT, we searched extensively for radio pulsations but yielded no viable detections of pulsed emission. We suggest that the non-detection of pulses is due to scattering in the intra-binary material, but scattering from the ISM can also plausibly explain the pulse non-detections if the interstellar dispersion measure exceeds $\\sim$600$\\,$pc$\\,$cm$^{-3}$. Orbital constraints derived from optical observations of the counterpart would be highly valuable for future $\\gamma$-ray pulsation searches, which may confirm the source nature as a pulsar."], "authors": "Andrew Zic"},
{"Title": "The Hoyle and associated excited states from the viewpoint of pocket resonances in alpha + 8Be reactions", "abs": ["We examine the production of the Hoyle and associated excited states from the viewpoint of pocket resonances in the reaction of an $\\alpha$-particle on a ground state prolate $^8$Be nucleus within the optical model coupled-channel framework. The predicted reaction cross sections, as a function of the center-of-mass energy $E_{\\rm cm}$, show prominent resonances, including the Hoyle resonance. The positions and widths of these resonances are sensitive to the target deformation ($\\beta_2$ parameter) and the parity of the nuclear surface potential $-$ deeper for the even-parity $L$ partial waves relative to those for the odd-parity $L$ partial waves at the surface region because of the Bose-Einstein exchange of the $\\alpha$-bosons. Decomposing the reaction cross sections to different partial waves, we find that the resonance energies and widths reasonably agree with the available experimental data and previous hyperspherical calculations for the $0_2^+$ (Hoyle state), $0_3^+$, $1_1^-$ and $3_1^-$ states of $^{12}$C, except for the narrow theoretical width of the $2_2^+$ state. Analyzing the wavefunctions and the resonance widths, we identify the narrow and sharp $0_2^+$, $3_1^-$ and $2_2^+$ resonances as pocket resonances -- resonances which occur below the potential barrier, while the broad $0_3^+$ and $1_1^-$ resonances as above-the-barrier resonances. For astrophysical applications, we also evaluate the astrophysical $S(E_{\\rm cm})$-factor for $E_{\\rm cm}$ $<$ 1.0 MeV, for the fusion of $\\alpha$+$^8$Be into the $^{12}$C$(2^+)$ state based on our estimated $s$-wave $\\alpha$+$^8$Be reaction cross section and the associated $\\gamma$- and $\\alpha$-decay widths for the decay of $^{12}$C excited states in the potential pocket."], "authors": "Teck-Ghee Lee"},
{"Title": "Investigations in Calabi-Yau modularity and mirror symmetry", "abs": ["This is the author's PhD thesis. Two main sections address various aspects of mirror symmetry for compact Calabi-Yau threefolds and the roles that classically modular varieties play in string theory compactifications. The main results include a study, and finding an application to the higher genus problem, of infinite Coxeter symmetries in the sets of Gopakumar-Vafa invariants; provision of a new class of solutions to the supersymmetric flux vacuum equations which have elsewhere been conjectured to give weight-two modular manifolds; provision of two new conjectural examples of weight-four modular varieties (rank-two attractors); and discussion of a set of numerical relations between infinite sums of Gromov-Witten invariants and critical L-values."], "authors": "Joseph McGovern"},
{"Title": "SN~2015da: Late-time observations of a persistent superluminous Type~IIn supernova with post-shock dust formation", "abs": ["We present photometry and spectroscopy of the slowly evolving superluminous Type IIn SN2015da. SN2015da is extraordinary for its very high peak luminosity, and also for sustaining a high luminosity for several years. Even at 8\\,yr after explosion, SN2015da remains as luminous as the peak of a normal SNII-P. The total radiated energy integrated over this time period (with no bolometric correction) is at least 1.6 FOE. Including a mild bolometric correction, adding kinetic energy of the expanding cold dense shell of swept-up circumstellar material (CSM), and accounting for asymmetry, the total explosion kinetic energy was likely 5-10 FOE. Powering the light curve with CSM interaction requires an energetic explosion and 20 Msun of H-rich CSM, which in turn implies a massive progenitor system above 30 Msun. Narrow P Cyg features show steady CSM expansion at 90 km/s, requiring a high average mass-loss rate of roughly 0.1 Msun/yr sustained for 2 centuries before explosion (although ramping up toward explosion time). No current theoretical model for single-star pre-SN mass loss can account for this. The slow CSM, combined with broad wings of H$\\alpha$ indicating H-rich material in the unshocked ejecta, disfavor a pulsational pair instability model for the pre-SN mass loss. Instead, violent pre-SN binary interaction is a likely cuprit. Finally, SN2015da exhibits the characteristic asymmetric blueshift in its emission lines from shortly after peak until the present epoch, adding another well-studied superluminous SNeIIn with unambiguous evidence of post-shock dust formation."], "authors": "Nathan Smith"},
{"Title": "Searching for discrete series representations at the late-time boundary of de Sitter", "abs": ["The group $SO(d+1,1)$ makes an appearance both as the conformal group of Euclidean space in $d$ dimensions and as the isometry group of de Sitter spacetime in $d+1$ dimensions. While this common feature can be taken as a hint towards holography on de Sitter space, understanding the representation theory has importance for cosmological applications where de Sitter spacetime is relevant. Among the categories of $SO(d+1,1)$ unitary irreducible representations, discrete series is important in physical applications because they are expected to capture gauge fields. However, they are also the most difficult ones to recognize in field theoretical examples compared to representations from the other categories. Here we point towards some examples where we are able to recognize discrete series representations from fields on de Sitter and highlight some of the properties of these representations."], "authors": "Gizem Şengör"},
{"Title": "The ZTF Source Classification Project: III. A Catalog of Variable Sources", "abs": ["The classification of variable objects provides insight into a wide variety of astrophysics ranging from stellar interiors to galactic nuclei. The Zwicky Transient Facility (ZTF) provides time series observations that record the variability of more than a billion sources. The scale of these data necessitates automated approaches to make a thorough analysis. Building on previous work, this paper reports the results of the ZTF Source Classification Project (SCoPe), which trains neural network and XGBoost machine learning (ML) algorithms to perform dichotomous classification of variable ZTF sources using a manually constructed training set containing 170,632 light curves. We find that several classifiers achieve high precision and recall scores, suggesting the reliability of their predictions for 112,476,749 light curves across 40 ZTF fields. We also identify the most important features for XGB classification and compare the performance of the two ML algorithms, finding a pattern of higher precision among XGB classifiers. The resulting classification catalog is available to the public, and the software developed for SCoPe is open-source and adaptable to future time-domain surveys."], "authors": "Brian F. Healy"},
{"Title": "Liouville theory and the Weil-Petersson geometry of moduli space: bordered, conic, and higher genus surfaces", "abs": ["Two-dimensional conformal field theory is a powerful tool to understand the geometry of surfaces. Here, we study Liouville conformal field theory in the classical (large central charge) limit, where it encodes the geometry of the moduli space of Riemann surfaces. Generalizing previous work, we employ this to study moduli spaces of higher genus surfaces, surfaces with boundaries, and surfaces with cone points. In each case, the knowledge of classical conformal blocks provides an extremely efficient approximation to the Weil-Petersson metric on moduli space. We find detailed agreement with analytic results for volumes and geodesic lengths on moduli space."], "authors": "Kale Colville"},
{"Title": "Beyond Signal and Noise: Unraveling Scale Invariance in Neuroscience and Financial Networks with Topological Data Analysis", "abs": ["This exploratory study delves into persistent homology, an integral component of TDA that initially aimed at differentiating between signal and noise. We explore two methodologies for this differentiation: the conventional cycle length approach and the novel death-birth ratio method proposed by Bobrowski and Skraba. Analyzing comprehensive rs-fMRI data from the Human Connectome Project and daily S\\&P 500 financial networks, our study compares these methods in identifying significant cycles. A pivotal discovery of this paper is a robust relationship between z-score thresholds applied to bar lengths or ratios and, respectively, behavioural traits in brain networks and market volatility in financial networks. In the brain, this is evident in the strong correlation between the number of significant 1-cycles in brain networks, brain volumes, and sex-based differences. In financial markets, a fractal pattern emerges, where market volatility consistently negatively correlates with the number of significant cycles, indicating that more intricate market topologies are associated with increased stability and less susceptibility to rapid shifts. Our findings also imply a fractal nature of 1-cycles at both population levels and across multiple days in the stock market. Notably, the distribution of significant loops, marked by high z-scores, remains consistent across various z-score thresholds, revealing a scale-invariant, fractal structure in both data sets. Given the scale invariance in these fractal structures, the traditional TDA distinction between signal and noise becomes less meaningful. The fractal nature of 1-cycles suggests that all scales of cycle length are relevant, challenging the conventional approach of segregating signal from noise. This realization broadens the scope of TDA, underscoring its potential to reveal intricate, scale-invariant relationships in complex systems."], "authors": "Roel Gisolf"},
{"Title": "The Automatic Identification and Tracking of Coronal Flux Ropes -- Part II: New Mathematical Morphology-based Flux Rope Extraction Method and Deflection Analysis", "abs": ["We present a magnetic flux rope (FR) extraction tool for solar coronal magnetic field modelling data, which builds upon the methodology from Wagner et al. (2023). We apply the scheme to magnetic field simulations of active regions AR12473 and AR11176. We compare the method to its predecessor and study the 3D movement of the newly extracted FRs up to heights of 200 and 300 Mm, respectively. The extraction method is based on the twist parameter and a variety of mathematical morphology algorithms, including the opening transform and the morphological gradient. We highlight the differences between the methods by investigating the circularity of the FRs in the plane we extract from. The simulations for the active regions are carried out with a time-dependent data-driven magnetofrictional model (TMFM; Pomoell et al. (2019)). We investigate the FR trajectories by tracking their apex throughout the full simulation time span. We demonstrate that this upgraded methodology provides the user with more tools and less a-priori assumptions about the FR shape that, in turn, leads to a more accurate set of field lines. The propagation analysis yields that the erupting FR from AR12473 showcases stronger dynamics than the AR11176 FR and a significant deflection during its ascent through the domain. The AR11176 FR appears more stable, though there still is a notable deflection. This confirms that at these low coronal heights, FRs do undergo significant changes in the direction of their propagation even for less dynamic cases. The modelling results are also verified with observations, with AR12473 being indeed dynamic and eruptive, while AR11176 only features an eruption outside of our simulation time window."], "authors": "Andreas Wagner"},
{"Title": "Finding $G_2$ Higgs branch of 4D rank 1 SCFTs", "abs": ["The Schur index of the Higgs branch of four-dimensional $\\mathcal{N}=2$ SCFTs is related to the spectrum of non-unitary two-dimensional CFTs. The rank one case has been shown to lead to the non-unitary CFTs with Deligne-Cvitanovic (DC) exceptional sequence of Lie groups. We show that a subsequence $(A_0, A_{\\frac{1}{2}}, A_1, A_2, D_4)$ within the non-unitary sequence is related to a subsequence in the Mathur-Mukhi-Sen (MMS) sequence of unitary theories. We show that 2D non-unitary $G_2$ theory is related to unitary $E_6$ theory, and using this result along with the Galois conjugation, we propose that the $G_2$ Higgs branch is a sub-branch of the $E_6$ Higgs branch."], "authors": "Md. Abhishek"},
{"Title": "Game-Theoretic Analysis of Adversarial Decision Making in a Complex Sociophysical System", "abs": ["We apply Game Theory to a mathematical representation of two competing teams of agents connected within a complex network, where the ability of each side to manoeuvre their resource and degrade that of the other depends on their ability to internally synchronise decision-making while out-pacing the other. Such a representation of an adversarial socio-physical system has application in a range of business, sporting, and military contexts. Specifically, we unite here two physics-based models, that of Kuramoto to represent decision-making cycles, and an adaptation of a multi-species Lotka-Volterra system for the resource competition. For complex networks we employ variations of the Barabási-Alberts scale-free graph, varying how resources are initially distributed between graph hub and periphery. We adapt as equilibrium solution Nash Dominant Game Pruning as a means of efficiently exploring the dynamical decision tree. Across various scenarios we find Nash solutions where the side initially concentrating resources in the periphery can sustain competition to achieve victory except when asymmetries exist between the two. When structural advantage is limited we find that agility in how the victor stays ahead of decision-state of the other becomes critical."], "authors": "Andrew C. Cullen"},
{"Title": "Exsolution process in white dwarf stars", "abs": ["White dwarf (WD) stars are considered cosmic laboratories to study the physics of dense plasma. Furthermore, the use of WD stars as cosmic clocks to date stellar populations and main sequence companions demands an appropriate understanding of the WD physics in order to provide precise ages for these stars. We aim at studying exsolution in the interior of WD stars, a process in which a crystallized ionic binary mixture separates into two solid solutions with different fractions of the constituents. Depending on the parent solid mixture composition, this process can release or absorb heat, thus leading to a delay or a speed-up of WD cooling. Relying on accurate phase diagrams for exsolution, we have modeled this process in hydrogen-rich WDs with both carbon-oxygen and oxygen-neon core composition, with masses ranging from 0.53 to 1.29Msun and from 1.10 to 1.29Msun, respectively. Exsolution is a slow process that takes place at low luminosities (log(L/Lsun)$\\lesssim$-2.75) and effective temperatures (Teff$\\lesssim$18 000K) in WDs. We find that exsolution begins at brighter luminosities in CO than in ONe WDs of the same mass. Massive WDs undergo exsolution at brighter luminosities than their lower-mass counterparts. The net effect of exsolution on the WD cooling times depends on the stellar mass and the exact chemical profile. For standard core chemical profiles and preferred assumptions regarding miscibility gap microphysics, the cooling delay can be as large as ~0.35 Gyrs at L/Lsun ~ -5. We have neglected a chemical redistribution possibly associated with this process, which could lead to a further cooling delay. Exsolution has a marginal effect on the WD cooling times and, accordingly, we find no WD branches on the Gaia color magnitude diagram associated with it. However, exsolution in massive WDs can alter the faint end of the WD luminosity function, thus impacting WD cosmochronology."], "authors": "Maria Camisassa"},
{"Title": "Trace relations and open string vacua", "abs": ["We study to what extent, and in what form, the notion of gauge-string duality may persist at finite $N$. It is shown, in the half-BPS sector, that the states of D3 giant graviton branes in $\\mathrm{AdS}_5 \\times S^5$ are holographically dual to certain auxiliary ghosts that compensate for finite $N$ trace relations in $U(N)$ $\\mathcal{N}=4$ super Yang-Mills. The complex formed from spaces of states of bulk D3 giants is observed to furnish a BRST-like resolution of the half-BPS Hilbert space of $U(N)$ $\\mathcal{N}=4$ SYM at finite $N$. We argue that the identification between the states of certain bulk D-branes and the auxiliary ghosts in the boundary holds rather generally at vanishing 't Hooft coupling $\\lambda = 0$. We propose that a complex, which furnishes a BRST-like resolution of the finite $N$ Hilbert space of a boundary $U(N)$ gauge theory at $\\lambda = 0$, should be identified as the space of states of the dual string theory in the $\\alpha' \\to \\infty$ limit. The Lefschetz trace formula provides the holographic map in this regime, where bulk observables are computed by taking the alternating sum of the expectation values in an ensemble of states built on each open string vacuum. The giant graviton expansion is recovered and generalized in a limit of the resolution."], "authors": "Ji Hoon Lee"},
{"Title": "The Magnetic Field Calibration of the Full-Disk Magnetograph onboard the Advanced Space based Solar Observatory (ASO-S/FMG)", "abs": ["The Full-disk magnetograph is a main scientific payload onboard the Advanced Space based Solar Observatory (ASO-S/FMG) that through Stokes parameter observation to measures the vector magnetic field. The accuracy of magnetic-field values is an important aspect of checking the quality of the FMG magnetic-field measurement. According to the design of the FMG, the linear calibration method under the weak-field approximation is the preferred scheme for magnetic-field calibration. However, the spacecraft orbital velocity can affect the position of observed spectral lines, then result in a change of the polarization-signal strength. Thus, the magnetic field is modulated by the orbit velocity of the spacecraft. In this article, through cross calibration between FMG and HMI (Helioseismic and Magnetic Imager onboard the Solar Dynamic Observatory), the effects of spacecraft orbital velocity on the coefficient of magnetic-field calibration are investigated. By comparing the magnetic field of FMG and HMI with spacecraft orbital velocity as an auxiliary reference, the revised linear-calibration coefficients that depend on spacecraft orbital velocity are obtained. Magnetic field of FMG corrected by the revised calibration coefficients removing the effect of spacecraft orbital velocity will be more accurate and suitable for scientific research."], "authors": "S. Liu"},
{"Title": "Synchronized oscillatory flows in two parallelly connected Starling resistors", "abs": ["We investigated the synchronization phenomena of the oscillatory flows in two parallelly connected Starling resistors, which are an ideal model system of two coupled collapsible tubes merging into a single tube downstream. The stable synchronization modes depended on the distance between the deformable region and the merging point; only an in-phase mode was stable for the large distance, in-phase and anti-phase modes were bistable for the middle distance, and again only an in-phase mode was stable for the small distance. An anti-phase mode became stable through the subcritical pitchfork bifurcation by decreasing the distance. Further decreasing the distance, the anti-phase mode became unstable through the subcritical Neimark-Sacker bifurcation. We also clarified the distance dependence of the amplitude and frequency for each stable synchronization mode."], "authors": "Yuki Araya"},
{"Title": "Duality between the Maxwell-Chern-Simons and self-dual models in very special relativity", "abs": ["This work aims to investigate the classical-level duality between the $SIM(1)$-Maxwell-Chern-Simons (MCS) model and its self-dual counterpart. Initially, our focus is on free-field cases to establish equivalence through two distinct approaches: comparing the equations of motion and utilizing the master Lagrangian method. In both instances, the classical correspondence between the self-dual field and the MCS dual field undergoes modifications due to very special relativity (VSR). Specifically, duality is established only when the associated VSR-mass parameters are the same. Furthermore, we analyze the duality when the self-dual model is minimally coupled to fermions. As a result, we show that Thirring-like interactions, corrected for non-local VSR contributions, are included in the MCS model. Additionally, we demonstrate the equivalence of the fermion sectors in both models, thereby concluding the proof of classical-level duality."], "authors": "Fernando M. Belchior"},
{"Title": "A Categorical Framework for Quantifying Emergent Effects in Network Topology", "abs": ["Emergent effect is crucial to the understanding of the properties of complex systems that do not appear in their basic units, but there has been a lack of theories to measure and understand its mechanisms. In this paper, we established a framework based on homological algebra that encodes emergence as the mathematical structure of cohomologies and then applied it to network models to develop a computational measure of emergence. This framework ties the emergence of a system to its network topology and local structures, paving the way to predict and understand the cause of emergent effects. We show in our numerical experiment that our measure of emergence correlates with the existing information-theoretic measure of emergence."], "authors": "Johnny Jingze Li"},
{"Title": "VLBI detection of the AE Aqr twin, LAMOST J024048.51+195226.9", "abs": ["LAMOST J024048.51+195226.9 (J0240+1952) was recently identified as the second AE Aquarii (AE Aqr)-type cataclysmic variable, possessing the fastest known rotating white dwarf. We performed a Very Long Baseline Interferometry (VLBI) observation of J0240+1952 utilizing the European VLBI Network at 1.7\\,GHz, to obtain the first view of the radio morphology on mas scale. Our high-resolution VLBI image clearly shows that the radio emission is compact on mas scale ($\\lesssim2$\\,AU), with no evidence for a radio jet or extended emission. The compact radio source has an average flux density of $\\sim0.37$\\,mJy, and its brightness temperature is given at $\\gtrsim2.3\\times10^{7}$\\,K, confirming a non-thermal origin. The emission exhibits irregular variations on a time-scale of tens of minutes, similar to the radio flares seen in AE Aqr. The measured VLBI position of J0240+1952 is consistent with that derived from \\textit{Gaia}. Our results favour the model in which the radio emission is attributed to a superposition of synchrotron radiation from expanding magnetized blobs of this system."], "authors": "Pengfei Jiang"},
{"Title": "Conformal graphs as twisted partition functions", "abs": ["We show that a class of $L$-loop conformal ladder graphs correspond to twisted partition functions of free massive complex scalars in $d=2L+1$ dimensions. The graphs arise as four-point functions in certain two- and four-dimensional conformal fishnet models. The twisted thermal two-point function of the scalars is a generator of such conformal graphs for all loops. We argue that this correspondence is seeded by a system of two decoupled harmonic oscillators twisted by an imaginary chemical potential. We find a number of algebraic and differential relations among the conformal graphs which mirror the underlying free dynamics."], "authors": "Manthos Karydas"},
{"Title": "The IACOB project X. Large-scale quantitative spectroscopic analysis of Galactic blue supergiants", "abs": ["Blue supergiants (BSGs) are key objects for understanding the evolution of massive stars. However, discrepancies between theoretical predictions and empirical observations have opened up important questions yet to be answered. Studying statistically significant and unbiased samples of BSGs can help to improve the situation. We aim to perform a homogeneous and comprehensive quantitative spectroscopic analysis of a large sample of Galactic BSGs from the IACOB spectroscopic database. We derive the projected rotational velocity ($v\\sin i$) and macroturbulent broadening ($v_{\\rm mac}$) using IACOB-BROAD. We used FASTWIND computations to derive effective temperatures ($T_{\\rm eff}$), surface gravities, microturbulences ($\\xi$), Si and He surface abundances, and the wind-strength parameter. We provide estimates of the above-mentioned quantities for the largest sample of Galactic BSGs spectroscopically analyzed to date, comprising 538 O9-B5 type stars. We find a drop in the relative number of BSGs at ~21 kK, coinciding with a scarcity of fast rotating stars below that temperature. We speculate that this feature might be roughly delineating the location of the empirical Terminal-Age-Main-Sequence in the 15-85Msol range. By investigating the main characteristics of the $v\\sin i$ distribution of O stars and BSGs as a function of $T_{\\rm eff}$, we propose that an efficient mechanism transporting angular momentum from the stellar core to the surface might be operating along the main sequence. We find correlations between $\\xi$, $v_{\\rm mac}$ and the spectroscopic luminosity. We also find that no more than 20% of the BSGs have atmospheres enriched in He, and suggest that the origin of this specific sub-sample of BSGs might be in binary evolution. We do not find clear empirical evidence of an increase in the wind-strength over the wind bi-stability region towards lower $T_{\\rm eff}$."], "authors": "Abel de Burgos"},
{"Title": "Bubbles of Nothing: The Tunneling Potential Approach", "abs": ["Bubbles of nothing (BoNs) describe the decay of spacetimes with compact dimensions and are thus of fundamental importance for many higher dimensional theories proposed beyond the Standard Model. BoNs admit a 4-dimensional description in terms of a singular Coleman-de Luccia (CdL) instanton involving the size modulus field, stabilized by some potential $V(\\phi)$. Using the so-called tunneling potential ($V_t$) approach, we study which types of BoNs are possible and for which potentials $V(\\phi)$ can they be present. We identify four different types of BoN, characterized by different asymptotic behaviours at the BoN core and corresponding to different classes of higher dimensional theories, which we also classify. Combining numerous analytical and numerical examples, we study the interplay of BoN decays with other standard decay channels, identify the possible types of quenching of BoN decays and show how BoNs for flux compactifications can also be described in 4 dimensions by a multifield $V_t$. The use of the $V_t$ approach greatly aids our analyses and offers a very simple picture of BoNs which are treated in the same language as any other standard vacuum decays."], "authors": "J.J. Blanco-Pillado"},
{"Title": "The Fibre Resolved opticAl and Near-ultraviolet Czerny-Turner Imaging Spectropolarimeter (FRANCIS)", "abs": ["The solar physics community is entering a golden era that is ripe with next-generation ground- and space-based facilities. With ever-increasing resolving power stemming from the newest observational telescopes, it becomes more challenging to obtain (near-)simultaneous measurements at high spatial, temporal and spectral resolutions, while operating at the diffraction limit of these new facilities. Hence, in recent years there has been increased interest in the capabilities integral field units (IFUs) offer towards obtaining the trifecta of high spatial, temporal and spectral resolutions contemporaneously. To date, IFUs developed for solar physics research have focused on mid-optical and infrared measurements. Here, we present an IFU prototype that has been designed for operation within the near-ultraviolet to mid-optical wavelength range, hence providing additional spectral coverage to the instrument suites developed to date. The IFU was constructed as a low-budget proof-of-concept for the upcoming 2m class Indian National Large Solar Telescope and employs circular cross-section fibres to guide light into a Czerny-Turner configuration spectrograph, with the resulting spectra captured using a high quantum efficiency scientific CMOS camera. Mapping of each input fibre allows for the reconstruction of two-dimensional spectral images, with frame rates exceeding 20 per second possible while operating in a non-polarimetric configuration. The science verification data presented here highlights the suitability of fibre-fed IFUs operating at near-ultraviolet wavelengths for solar physics research. Importantly, the successful demonstration of this type of instrument paves the way for further technological developments to make a future variant suitable for upcoming ground-based and space-borne telescope facilities."], "authors": "D.B. Jess"},
{"Title": "Constraining Glueball Couplings", "abs": ["We set up a numerical S-matrix bootstrap problem to rigorously constrain bound state couplings given by the residues of poles in elastic amplitudes. We extract upper bounds on these couplings that follow purely from unitarity, crossing symmetry, and the Roy equations within their proven domain of validity. First we consider amplitudes with a single spin 0 or spin 2 bound state, both with or without a self-coupling. Subsequently we investigate amplitudes with the spectrum of bound states corresponding to the estimated glueball masses of pure SU(3) Yang-Mills. In the latter case the 'glue-hedron', the space of allowed couplings, provides a first-principles constraint for future lattice estimates."], "authors": "Andrea L. Guerrieri"},
{"Title": "Evolution and final fate of solar metallicity stars in the mass range 7-15 Msun. I. The transition from AGB to SAGB stars, Electron Capture and Core Collapse Supernovae progenitors", "abs": ["According to a standard initial mass function, stars in the range 7-12 Msun constitute ~50% (by number) of the stars more massive than ~7 Msun, but, in spite of this, their evolutionary properties, and in particular their final fate, are still scarcely studied. In this paper we present a detailed study of the evolutionary properties of solar metallicity, non rotating stars in the range 7-15 Msun, from the pre main sequence phase up to the presupernova stage or up to an advanced stage of the thermally pulsing phase, depending on the initial mass. We find that (1) the 7.00 Msun develops a degenerate CO core and evolves as a classical AGB star in the sense that it does not ignite the C burning reactions; (2) stars with the initial mass M >= 9.22 Msun end their life as core collapse supernovae; (3) stars in the range 7.50 <= M/Msun <= 9.20 develop a degenerate ONeMg core and evolve through the thermally pulsing SAGB phase; 4) stars in the mass range 7.50 <= M/Msun <= 8.00 end their life as hybrid CO/ONeMg- or ONeMg- WD; (5) stars with the initial mass in the range 8.50 <= M/Msun <= 9.20 may potentially explode as electron capture supernovae."], "authors": "Marco Limongi"},
{"Title": "Persistence of the Pattern in the Interior of 5d Moduli Spaces", "abs": ["Castellano, Ruiz, and Valenzuela recently observed a remarkable \"pattern\" in infinite-distance limits of moduli spaces in quantum gravity, which relates the field space variation of the mass of the lightest tower of particles to the field space variation of the species scale. In this work, we show how a version of this pattern can be proven to hold for BPS particles and strings throughout the vector multiplet moduli space of a 5d supergravity theory, even in regions where the particle masses and string tensions are substantially modified relative to their asymptotic behavior in the infinite-distance limits. This suggests that a suitably defined version of the pattern may hold not merely in the asymptotic limits of moduli space, but in the interior as well."], "authors": "Tom Rudelius"},
{"Title": "Triangular Automata: The 256 Elementary Cellular Automata of the 2D Plane", "abs": ["Triangular Automata (TA) stands for cellular automata in the triangular grid. This work focuses on the simplest type of TA called Elementary Triangular Automata (ETA). They are argued to be the two-dimensional counterpart of Wolfram's Elementary Cellular Automata. Conceptual and computational tools for their study are presented along with an initial analysis. The paper is accompanied by a website where the results can be explored interactively. The source code is available in the form of a Mathematica package."], "authors": "Paul Cousin"},
{"Title": "Two-particle angular correlations of identified particles in pp collisions at $\\sqrt{s}$ = 13 TeV with ALICE", "abs": ["Two-particle angular correlation is one of the most powerful tools to study the mechanism of particle production in proton--proton (pp) collision systems by relating the difference between the azimuthal angle ($\\Delta\\varphi$) and the rapidity ($\\Delta y$) of the particles from a pair. Hadronization processes are influenced by various physical phenomena, such as resonance decay, Coulomb interactions, laws of conservation of energy and momentum, and others, because of the quark content of the particles involved. Therefore, each correlation function is unique and shows a different dependence on transverse momentum $p_{\\mathrm{T}}$ and/or multiplicity. The angular correlation functions reported by the ALICE Collaboration in pp collisions showed an anticorrelation in short range of ($\\Delta y,\\Delta\\varphi$) for baryon pairs which is not predicted by any theoretical model.\\\\ \\indent In this contribution, this behavior will be investigated by studying identified charged hadrons (i.e., $\\pi^{\\pm}$, $\\rm K^{\\pm}$, and p($\\bar{\\rm p}$)) in the $\\Delta y,\\Delta\\varphi$ space in pp collisions at $\\sqrt{s} = 13$ TeV recorded by ALICE. In addition, to distinguish the various physical contributions, collisions with different multiplicities are analyzed separately and diverse normalization methods are applied."], "authors": "Daniela Ruggiano"},
{"Title": "Identifying the spin trapped character of the $^{32}$Si isomeric state", "abs": ["The properties of a nanosecond isomer in $^{32}$Si, disputed in previous studies, depend on the evolution of proton and neutron shell gaps near the `island of inversion'. We have placed the isomer at 5505.2(2) keV with $J^{\\pi} = 5^-$, decaying primarily via an $E3$ transition to the $2^+_1$ state. The $E3$ strength of 0.0841(10) W.u. is unusually small and suggests that this isomer is dominated by the $(\\nu d_{3/2})^{-1} \\otimes (\\nu f_{7/2})^{1}$ configuration, which is sensitive to the $N=20$ shell gap. A newly observed $4^+_1$ state is placed at 5881.4(13) keV; its energy is enhanced by the $Z=14$ subshell closure. This indicates that the isomer is located in a `yrast trap', a feature rarely seen at low mass numbers."], "authors": "J. Williams"},
{"Title": "Search for the origin of wobbling motion in the $ A \\approx 130 $ region: The case of $^{131}$Xe", "abs": ["In-beam $ \\gamma $-ray spectroscopy of $^{131}$Xe has been carried out to study the structure of the intruder $ \\nu h_{11/2} $ band. Excited states were populated via an $ \\alpha $-induced fusion-evaporation reaction at E$ _{\\alpha} = 38 $ MeV. Inspection of $ \\gamma \\gamma $-coincidence data resulted in the identification of a new rotational sequence. Based on the systematics of excitation energy, assigned spin-parity, decay pattern, and the electromagnetic character of the inter-band $ \\Delta I = 1 $ $ \\gamma $-transitions, this sequence is proposed as the unfavoured signature partner of the $ \\nu h_{11/2} $ band. The structure of this band is further illuminated in the light of the triaxial particle rotor model (TPRM). The possibility of wobbling excitation in $ N = 77 $ Xe-Ba-Ce isotones has been explored in a systematic manner."], "authors": "S. Chakraborty"},
{"Title": "Measurements of strange and multi-strange hadrons elliptic flow in isobar collisions at RHIC by STAR", "abs": ["We present measurements of elliptic flow ($v_{2}$) of $K_{s}^{0}$, $\\Lambda$, $\\bar{\\Lambda}$, $\\phi$, $\\Xi^{-}$, $\\overline{\\Xi}^{+}$, and $\\Omega^{-}$+$\\overline{\\Omega}^{+}$ at mid-rapidity ($|\\eta| <$ 1.0) in isobar collisions ($^{96}_{44}$Ru+$^{96}_{44}$Ru and $^{96}_{40}$Zr+$^{96}_{40}$Zr) at $\\sqrt{s_{\\mathrm{NN}}}$ = 200 GeV. The centrality and transverse momentum ($p_{\\mathrm{T}}$) dependence of elliptic flow is presented. The number of constituent quark (NCQ) scaling of $v_{2}$ in isobar collisions is discussed. $p_{T}$-integrated elliptic flow ($\\left\\langle v_{2}\\right\\rangle$) is observed to increase from central to peripheral collisions. The ratio of $\\left\\langle v_{2}\\right\\rangle$ between the two isobars shows a deviation from unity for strange hadrons ($K_{s}^{0}$, $\\Lambda$ and $\\bar{\\Lambda}$) indicating a difference in nuclear structure and deformation. A system size dependence of strange hadron $v_{2}$ at high $p_{T}$ is observed among Ru+Ru, Zr+Zr, Cu+Cu, Au+Au, and U+U systems. A multi-phase transport (AMPT) model with string melting (SM) describes the experimental data well in the measured $p_{\\mathrm{T}}$ range for isobar collisions at $\\sqrt{s_{\\mathrm{NN}}}$ = 200 GeV."], "authors": "V. Bairathi"},
{"Title": "Measurements of evaporation residue cross-sections and evaporation residue-gated $γ$-ray fold distributions for $^{32}$S+$^{154}$Sm system", "abs": ["Evaporation Residue (ER) cross-sections and ER-gated $\\gamma$-ray fold distributions are measured for the $^{32}$S + $^{154}$Sm nuclear reaction above the Coulomb barrier at six different beam energies from 148 to 191 MeV. $\\gamma$-ray multiplicities and spin distributions are extracted from the ER-gated fold distributions. The ER cross-sections measured in the present work are found to be much higher than what was reported in a previous work using a very different target-projectile ($^{48}$Ti + $^{138}$Ba) combination, leading to the same compound nucleus $^{186}$Pt, with much less mass asymmetry in the entrance channel than the present reaction. This clearly demonstrates the effect of the entrance channel on ER production cross-section. The ER cross-sections measured in the present work are compared with the results of both the statistical model calculations and the dynamical model calculations. Statistical model calculations have been performed to generate a range of parameter space for both the barrier height and Kramers' viscosity parameter over which the ER cross-section data can be reproduced. The calculations performed using the dinuclear system (DNS) model reproduce the data considering both complete and incomplete fusion processes. DNS calculations indicate the need for the inclusion of incomplete fusion channel at higher energies to reproduce the ER cross-sections."], "authors": "R. Sariyal"},
{"Title": "Nuclear level densities and $γ-$ray strength functions of $^{111,112,113}$Sn isotopes studied with the Oslo method", "abs": ["The $^{111,112,113}$Sn isotopes have been studied with ($p,d \\gamma$), ($p,p^{\\prime} \\gamma$), and ($d,p \\gamma$) reactions to extract the nuclear level densities (NLDs) and $\\gamma$-ray strength functions (GSFs) of these nuclei below the neutron separation energy by means of the Oslo method. The experimental NLDs for all three nuclei demonstrate a trend compatible with the constant-temperature model below the neutron separation energy while also being in good agreement with the NLDs of neighboring Sn isotopes, obtained previously with the Oslo-type and neutron evaporation experiments. The extracted microcanonical entropies yield $\\approx 1.5$ $k_B$ entropy of a valence neutron in both $^{111}$Sn and $^{113}$Sn. Moreover, the deduced microcanonical temperatures indeed suggest a clear constant-temperature behavior above $\\approx$ 3 MeV in $^{111,113}$Sn and above $\\approx$ 4.5 MeV in $^{112}$Sn. We observe signatures for the first broken neutron pairs between 2 and 4 MeV in all three nuclei. The GSFs obtained with the Oslo method are found to be in good agreement below the neutron threshold with the strengths of $^{112,114}$Sn extracted in the ($p,p^{\\prime}$) Coulomb excitation experiments."], "authors": "M. Markova"},
{"Title": "Systematic study of the low-lying electric dipole strength in Sn isotopes and its astrophysical implications", "abs": ["The $\\gamma$-ray strength functions (GSF) and nuclear level densities (NLD) below the neutron threshold have been extracted for $^{111-113,116-122,124}$Sn from particle-$\\gamma$ coincidence data with the Oslo method. The evolution of bulk properties of the low-lying electric dipole response has been investigated on the basis of the Oslo GSF data and results of a recent systematic study of electric and magnetic dipole strengths in even-even Sn isotopes with relativistic Coulomb excitation. The obtained GSFs reveal a resonance-like peak on top of the tail of the isovector giant dipole resonance, centered at $\\approx$8 MeV and exhausting $\\approx$2\\% of the classical Thomas-Reiche-Kuhn (TRK) sum. In contrast to predictions of the relativistic quasiparticle random-phase and time-blocking approximation calculations (RQRPA and RQTBA), no monotonous increase in the total low-lying $E1$ strength was observed in the experimental data from $^{111}$Sn to $^{124}$Sn, demonstrating rather similar strength distributions in these nuclei. The Oslo GSFs and NLDs were further used as inputs to constrain the cross sections and Maxwellian-averaged cross sections of $(n,\\gamma)$ reactions in the Sn isotopic chain using TALYS. The obtained results agree well with other available experimental data and the recommended values from the JINA REACLIB, BRUSLIB, and KADoNiS libraries. Despite relatively small exhausted fractions of the TRK sum rule, the low-lying electric dipole strength makes a noticeable impact on the radiative neutron-capture cross sections in stable Sn isotopes. Moreover, the experimental Oslo inputs for the $^{121,123}$Sn$(n,\\gamma)$$^{122,124}$Sn reactions were found to affect the production of Sb in the astrophysical $i$-process, providing new constraints on the uncertainties of the resulting chemical abundances from multi-zone low-metallicity Asymptotic Giant Branch stellar models."], "authors": "M. Markova"},
{"Title": "Fast neutron production at the LNL Tandem from the $^7$Li($^{14}$N,xn)X reaction", "abs": ["Fast neutron beams are of relevance for many scientific and industrial applications. This paper explores fast neutron production using a TANDEM accelerator at the Legnaro National Laboratories, via an energetic ion beam (90 MeV $^{14}N$) onto a lithium target. The high energy models for nuclear collision of FLUKA foresee large neutron yields for reactions of this kind. The experiment aimed at validating the expected neutron yields from FLUKA simulations, using two separate and independent set-ups: one based on the multi-foil activation technique, and the other on the time of flight technique, by using liquid scintillator detectors.", "The results of the experiment show clear agreement of the measured spectra with the FLUKA simulations, both in the shape and the magnitude of the neutron flux at the measured positions. The neutron spectrum is centered around the 8 MeV range with mild tails, and a maximum neutron energy spanning up to 50 MeV.", "These advantageous results provide a starting point in the development of fast neutron beams based on high energy ion beams from medium-sized accelerator facilities."], "authors": "Pablo Torres-Sánchez"},
{"Title": "Revisit to the yield ratio of triton and $^3$He as an indicator of neutron-rich neck emission", "abs": ["The neutron rich neck zone created in heavy ion reaction is experimentally probed by the production of the $A=3$ isobars. The energy spectra and angular distributions of triton and $^3$He are measured with the CSHINE detector in $^{86}$Kr +$^{208}$Pb reactions at 25 MeV/u. While the energy spectrum of $^{3}$He is harder than that of triton, known as \"$^{3}$He-puzzle\", the yield ratio $R({\\rm t/^3He})$ presents a robust rising trend with the polar angle in laboratory. Using the fission fragments to reconstruct the fission plane, the enhancement of out-plane $R({\\rm t/^3He})$ is confirmed in comparison to the in-plane ratios. Transport model simulations reproduce qualitatively the experimental trends, but the quantitative agreement is not achieved. The results demonstrate that a neutron rich neck zone is formed in the reactions. Further studies are called for to understand the clustering and the isospin dynamics related to neck formation."], "authors": "Yijie Wang"},
{"Title": "New Measurement of the Hoyle State Radiative Transition Width", "abs": ["The radiative decay of the Hoyle state is the doorway to the production of heavier elements in stellar environment. Here we report, an exclusive measurement of electric quadruple (E$_2$) transitions of the Hoyle state to the ground state of $^{12}$C through the $^{12}$C(p, p$^\\prime$$\\gamma$$\\gamma$)$^{12}$C reaction. Triple coincidence measurement yields a value of radiative branching ratio $\\Gamma_{rad}$/$\\Gamma$ = 4.01 (30) $\\times$ 10$^{-4}$. The result has been corroborated by an independent experiment based on the complete kinematical measurement $via.$ $^{12}$C(p, p$^\\prime$)$^{12}$C reaction ($\\Gamma_{rad}$/$\\Gamma$ = 4.04 (30) $\\times$ 10$^{-4}$). Using our results together with the currently adopted values of $\\Gamma_{\\pi}$(E$_0$)/$\\Gamma$ and $\\Gamma_{\\pi}$($E_0$), the radiative width of the Hoyle state is found to be 3.75 (40) $\\times$ 10$^{-3}$ eV. We emphasize here that our result is not in agreement with 34 $\\%$ increase in the radiative decay width of the Hoyle state measured recently but consistent with the currently adopted value."], "authors": "T. K. Rana"},
{"Title": "Total cross sections for the reactions $^{10,11,12}$Be+$^{28}$Si and $^{14}$B+$^{28}$Si", "abs": ["In this paper, the results of measurements of the total cross sections for the reactions $^{10,11,12}$Be+$^{28}$Si and $^{14}$B+$^{28}$Si in the beam energy range $13A$--$47A$ MeV are presented. The experimental cross sections were obtained by detection of the gamma quanta and neutrons accompanying the interaction of the isotopes of Be and B with $^{28}$Si. It was found that the cross sections for $^{11,12}$Be are similar, but significantly exceed those for $^{10}$Be. A significant increase in the cross sections for $^{12}$Be with decreasing energy is observed in the entire measured energy range. A theoretical explanation of the obtained experimental data is given based on the microscopic model of deformed nuclei and the numerical solution of the time-dependent Schrödinger equation for the outer weakly bound neutrons of the projectile nuclei. The calculated total reaction cross sections are in good agreement with the experimental data."], "authors": "Yu. G. Sobolev"},
{"Title": "Isoscaling in Dilute Warm Nuclear Systems", "abs": ["Heavy-ion collisions are a good tool to explore hot nuclear matter below saturation density. It has been established that if a nuclear system reaches the thermal and chemical equilibrium, this leads to scaling properties in the isotope production when comparing two systems which differ in proton fraction. This article presents a study of the isoscaling properties of an expanding gas source exploring different thermodynamic states (density, temperature, proton fraction). This experimental work highlights the existence of an isoscaling relationship for hydrogen and 3He, 4He helium isotopes which agrees with the hypothesis of thermal and chemical equilibrium. Moreover, this work reveals the limitations of isoscaling when the two systems differ slightly in total mass and temperature. Also, a discrepancy has been observed for the 6He isotope, which could be explained by finite size effects or by the specific halo nature of this cluster."], "authors": "Alex Rebillard-Soulié"},
{"Title": "Observation of the distribution of nuclear magnetization in a molecule", "abs": ["Rapid progress in the experimental control and interrogation of molecules, combined with developments in precise calculations of their structure, are enabling new opportunities in the investigation of nuclear and particle physics phenomena. Molecules containing heavy, octupole-deformed nuclei such as radium are of particular interest for such studies, offering an enhanced sensitivity to the properties of fundamental particles and interactions. Here, we report precision laser spectroscopy measurements and theoretical calculations of the structure of the radioactive radium monofluoride molecule, $^{225}$Ra$^{19}$F. Our results allow fine details of the short-range electron-nucleus interaction to be revealed, indicating the high sensitivity of this molecule to the distribution of magnetization, currently a poorly constrained nuclear property, within the radium nucleus. These results provide a direct and stringent test of the description of the electronic wavefunction inside the nuclear volume, highlighting the suitability of these molecules to investigate subatomic phenomena."], "authors": "S. G. Wilkins"},
{"Title": "First measurement of the low-energy direct capture in 20Ne(p, γ)21Na and improved energy and strength of the Ecm = 368 keV resonance", "abs": ["The $\\mathrm{^{20}Ne(p, \\gamma)^{21}Na}$ reaction is the slowest in the NeNa cycle and directly affects the abundances of the Ne and Na isotopes in a variety of astrophysical sites. Here we report the measurement of its direct capture contribution, for the first time below $E\\rm_{cm} = 352$~keV, and of the contribution from the $E^{\\rm }_{cm} = 368$~keV resonance, which dominates the reaction rate at $T=0.03-1.00$~GK. The experiment was performed deep underground at the Laboratory for Underground Nuclear Astrophysics, using a high-intensity proton beam and a windowless neon gas target. Prompt $\\gamma$ rays from the reaction were detected with two high-purity germanium detectors. We obtain a resonance strength $\\omega \\gamma~=~(0.112 \\pm 0.002_{\\rm stat}~\\pm~0.005_{\\rm sys})$~meV, with an uncertainty a factor of $3$ smaller than previous values. Our revised reaction rate is 20\\% lower than previously adopted at $T < 0.1$~GK and agrees with previous estimates at temperatures $T \\geq 0.1$~GK.", "Initial astrophysical implications are presented."], "authors": "E. Masha"},
{"Title": "Isomeric pair ${^{95\\rm m,g}\\rm{Nb}}$ in photonuclear reactions on $^{\\rm nat}$Mo at end-point bremsstrahlung energy of 35-95 MeV", "abs": ["The ${^{\\rm nat}\\rm{Mo}}(\\gamma,x\\rm np)^{95\\rm m,g}$Nb photonuclear reaction was studied using the electron beam from the NSC KIPT linear accelerator LUE-40. Experiment was performed using the activation and off-line $\\gamma$-ray spectrometric technique. The experimental isomeric yield ratio $d(E_{\\rm{\\gamma max}}) = Y_{\\rm m}(E_{\\rm{\\gamma max}}) / Y_{\\rm g}(E_{\\rm{\\gamma max}})$ was determined for the reaction products $^{95\\rm m,g}\\rm{Nb}$ at the end-point bremsstrahlung energy $E_{\\rm{\\gamma max}}$ range of 35-95 MeV. The obtained values of $d(E_{\\rm{\\gamma max}})$ are in satisfactory agreement with the results of other authors and extend the range of previously known data. The theoretical values of the yields $Y_{\\rm m,g}(E_{\\rm{\\gamma max}})$ and the isomeric yield ratio $d(E_{\\rm{\\gamma max}})$ for the isomeric pair $^{95\\rm m,g}\\rm{Nb}$ from the ${^{\\rm nat}\\rm{Mo}}(\\gamma,x\\rm np)$ reaction were calculated using the partial cross-sections $\\sigma(E)$ from the TALYS1.95 code for six different level density models $LD$. The comparison showed a noticeable excess (more than 3.85 times) of the experimental isomeric yield ratio over all theoretical estimates. At the investigated range of $E_{\\rm{\\gamma max}}$ the theoretical dependence of $d(E_{\\rm{\\gamma max}})$ on energy was confirmed - the isomeric yield ratio smoothly decreases with increasing energy."], "authors": "I.S. Timchenko"},
{"Title": "Cross-section of the ${^{95\\rm}\\rm{Nb}}$ production on natural molybdenum at the bremsstrahlung end-point energy up to 95 MeV", "abs": ["The photoproduction of $^{95\\rm m}$Nb on ${^{\\rm nat}\\rm{Mo}}$ was studied using the electron beam of the LUE-40 linac RDC \"Accelerator\" NSC KIPT. Measurements were performed using activation and off-line $\\gamma$-ray spectrometric techniques. The experimental flux-averaged cross-section $\\langle{\\sigma(E_{\\rm{\\gamma max}})}\\rangle_{\\rm{m}}$ for the ${^{\\rm nat}\\rm{Mo}}(\\gamma,x\\rm np)^{95\\rm m}$Nb reaction at the bremsstrahlung end-point energy range of 38--93 MeV has been first time obtained. The estimated values $\\langle{\\sigma(E_{\\rm{\\gamma max}})}\\rangle_{\\rm{g}}$ for the formation of $^{95}$Nb in the ground state and total cross-sections $\\langle{\\sigma(E_{\\rm{\\gamma max}})}\\rangle_{\\rm{tot}}$ for the studied reaction were determined. The theoretical values of the yields $Y_{\\rm m,g,tot}(E_{\\rm{\\gamma max}})$ and flux-averaged cross-sections $\\langle{\\sigma(E_{\\rm{\\gamma max}})}\\rangle_{\\rm{m,g,tot}}$ for the ${^{\\rm nat}\\rm{Mo}}(\\gamma,x\\rm np)^{95\\rm m,g,tot}$Nb reactions were calculated using the cross-sections $\\sigma(E)$ from the TALYS1.95 code for six different level density models. The comparison showed a significant excess of the experimental results over the theoretical $\\langle{\\sigma(E_{\\rm{\\gamma max}})}\\rangle_{\\rm{m,g,tot}}$ values."], "authors": "I.S. Timchenko"},
{"Title": "Study the isomeric ratios in photonuclear experiments on the LUE-40 linac RDC \"Accelerator\" NSC KIPT", "abs": ["The results of the photoproduction of isomeric pairs from the ({\\gamma},xn) and ({\\gamma},pxn) reactions on nuclei from Zr up to Ta at the bremsstrahlung end-point energy range 30-100 MeV are systematized. Measurements were performed at the electron beam of the LUE-40 linac RDC \"Accelerator\" NSC KIPT using the activation method and off-line {\\gamma}-ray spectrometric technique. The theoretical isomeric ratios IR for the nuclei-products of studied reactions were calculated using the cross-sections {\\sigma}(E) from the TALYS1.95 code for six different level density models. The data from the international databases were additionally used to compare experimental results and theoretical predictions. The obtained results let us make conclusions about trends of values and energy dependence of IR in studied photonuclear reactions. Further directions of experimental research in the RDC \"Accelerator\" NSC KIPT are discussed."], "authors": "I.S. Timchenko"},
{"Title": "Does the excited state of the $^3$H nucleus exist?", "abs": ["The suggestion is made that the excited state of the $^3 H$ nucleus found out recently in the reaction $H$ ($^6 He$,$\\alpha$) ({\\it Pis'ma JETPh\\/} {\\bf 59} (1994) 301) has spin and parity $1/2^+$ and the same configuration that the ground one of $^6 He$. An amplitude of electromagnetic transition to the triton ground state is strongly suppressed, therefore the excited state cannot be detected in radiative capture of neutrons by deuterons. It is shown that in an elastic nd-scattering a resonance associated with the exited state may be absent due to the destructive interference of potential and resonant scattering phases."], "authors": "A.L.Barabanov"},
{"Title": "Hydrodynamics near the QCD Phase Transition: Looking for the Longest-Lived Fireball", "abs": ["We propose a new strategy for the experimental search of the QCD phase transition in heavy ion collisions: One may tune collision energy around the point where the lifetime of the fireball is expected to be longest. We demonstrate that the hydrodynamic evolution of excited nuclear matter does change dramatically as the initial energy density goes through the \"softest point\" (where the pressure to energy density ratio reaches its minimum). For our choice of equation of state, this corresponds to epsilon_i approx. = 1.5 GeV/fm^3 and collision energy E_lab/A approx. = 30 GeV (for Au+Au). Various observables seem to show distinct changes near the softest point."], "authors": "C.M.Hung"},
{"Title": "Relative spins and excitation energies of superdeformed bands in 190Hg: Further evidence for octupole vibration", "abs": ["An experiment using the Eurogam Phase II gamma-ray spectrometer confirms the existence of an excited superdeformed (SD) band in 190Hg and its very unusual decay into the lowest SD band over 3-4 transitions. The energies and dipole character of the transitions linking the two SD bands have been firmly established. Comparisons with RPA calculations indicate that the excited SD band can be interpreted as an octupole-vibrational structure."], "authors": "B. Crowell"},
{"Title": "Charged Particle Pseudorapidity Distributions in Au+Al, Cu, Au, and U Collisions at 10.8 A$\\cdot$GeV/c", "abs": ["We present the results of an analysis of charged particle pseudorapidity distributions in the central region in collisions of a Au projectile with Al, Cu, Au, and U targets at an incident energy of 10.8~GeV/c per nucleon. The pseudorapidity distributions are presented as a function of transverse energy produced in the target or central pseudorapidity regions. The correlation between charged multiplicity and transverse energy measured in the central region, as well as the target and projectile regions is also presented. We give results for transverse energy per charged particle as a function of pseudorapidity and centrality."], "authors": "E877 Collaboration"},
{"Title": "Measurement of Pion Enhancement at Low Transverse Momentum and of the Delta-Resonance Abundance in Si-Nucleus Collisions at AGS Energy", "abs": ["We present measurements of the pion transverse momentum (p_t) spectra in central Si-nucleus collisions in the rapidity range 2.0<y<5.0 for p_t down to and including p_t=0. The data exhibit an enhanced pion yield at low p_t compared to what is expected for a purely thermal spectral shape. This enhancement is used to determine the Delta-resonance abundance at freeze-out. The results are consistent with a direct measurement of the Delta-resonance yield by reconstruction of proton-pion pairs and imply a temperature of the system at freeze-out close to 140 MeV."], "authors": "J. Barrette"},
{"Title": "Dilepton production from p-p to Ca-Ca at the Bevalac", "abs": ["The DLS collaboration has recently completed a high statistics study of dilepton production at the Bevalac. In particular, we have measured dielectrons (e+e-) from p-p and p-d collisions to understand the basic dilepton production mechanisms in the energy range from 1.05 - 4.9 GeV. These data can be used to determine the basic processes which contribute to nucleon-nucleon dilepton production such as hadronic bremsstrahlung, vector meson processes, and hadronic Dalitz decay. The data show that a simple elastic bremsstrahlung calculation is insufficient to explain the data. Theoretical models are compared with the data. A new high statistics study of Ca-Ca at 1.05 A GeV has been made to study the collectivity of A-A collisions."], "authors": "H.S. Matis"},
{"Title": "An improved limit on the neutrinoless double-electron capture of $^{36}$Ar with GERDA", "abs": ["The GERmanium Detector Array (GERDA) experiment operated enriched high-purity germanium detectors in a liquid argon cryostat, which contains 0.33% of $^{36}$Ar, a candidate isotope for the two-neutrino double-electron capture (2$\\nu$ECEC) and therefore for the neutrinoless double-electron capture (0$\\nu$ECEC). If detected, this process would give evidence of lepton number violation and the Majorana nature of neutrinos. In the radiative 0$\\nu$ECEC of $^{36}$Ar, a monochromatic photon is emitted with an energy of 429.88 keV, which may be detected by the GERDA germanium detectors. We searched for the $^{36}$Ar 0$\\nu$ECEC with GERDA data, with a total live time of 4.34 yr (3.08 yr accumulated during GERDA Phase II and 1.26 yr during GERDA Phase I). No signal was found and a 90% C.L. lower limit on the half-life of this process was established T$_{1/2}$ > 1.5x10$^{22}$ yr"], "authors": "GERDA Collaboration"},
{"Title": "Nuclear density dependence of polarization transfer in quasi-elastic ${\\rm A}(\\vec{e},e' \\vec{p})$ reactions", "abs": ["The ratio of the transverse and longitudinal component of polarization transfer to protons in quasi-elastic $(\\vec{e}, e^{\\prime} \\vec{p}\\,)$ reaction, $P^{\\prime}_x/P^{\\prime}_z$, is sensitive to the proton's electromagnetic form factor ratio, $G_E/G_M$. To explore density-dependent in-medium modifications, a comparison of polarization transfer ratios involving protons from distinct nuclear shells, each with different local nuclear densities, has been proposed. In this study, we present such comparisons between four shells, $1s_{1/2}$, $1p_{3/2}$ in $^{12}\\mathrm{C}$ and $1d_{3/2}$, $2s_{1/2}$ in $^{40}\\mathrm{Ca}$. In an effort to account for other many-body effects that may differ between shells, we use state-of-the-art relativistic distorted-wave impulse-approximation (RDWIA) calculation and present the double ratios, $(P^{\\prime}_x/P^{\\prime}_z)_{\\rm Data}/(P^{\\prime}_x/P^{\\prime}_z)_{\\rm RDWIA}$ as well as the super ratios, $\\left[(P^{\\prime}_x/P^{\\prime}_z)_{\\rm A}/(P^{\\prime}_x/P^{\\prime}_z)_{\\rm B}\\right]_{\\rm Data}/\\left[(P^{\\prime}_x/P^{\\prime}_z)_{\\rm A}/(P^{\\prime}_x/P^{\\prime}_z)_{\\rm B}\\right]_{\\rm RDWIA}$, for chosen shells A and B, as a function of effective local nuclear densities. We find that double ratios for individual shells show a dependence on the probed effective nuclear densities. Studying the ratios, we observed a systematic variation between pairs of higher- and lower-density shells."], "authors": "T. Kolar"},
{"Title": "Direct demonstration of the two-phonon structure of the $J^π = 1_{4742~\\mathrm{keV}}^{-}$ state of $^{88}$Sr", "abs": ["We have studied the decay pattern of the $J^{\\pi} = 1_{4742~\\mathrm{keV}}^{-}$ state of $^{88}$Sr to probe its quadrupole-octupole coupled two-phonon structure. In particular, a unique fingerprint to prove the two-phonon nature is the $E2$ decay strength of the $1_{4742~\\mathrm{keV}}^{-} \\to 3_{1}^{-}$ transition into the one-octupole-phonon state. $\\gamma$-ray spectroscopy was performed after the $\\beta$-decay of $^{88}$Rb to obtain the necessary sensitivity for this weak-intensity decay branch. Sufficient amounts of $^{88}$Rb (T$_{1/2}$ = 17.8 min) were produced by neutron activation of natural Rb in the TR IGA Mark II reactor. The results show that the $B(E2)$ value of the $1_{4742~\\mathrm{keV}}^{-} \\to 3_{1}^{-}$ transition is equal to the $B(E2)$ of the $2_{1}^{+} \\to 0_{1}^{+}$ transition, directly demonstrating the quadrupole-octupole coupled two-phonon nature of the $1^-$ state. A comparison of the results with energy-density functional plus quasiparticle-phonon model calculations shows rema rkable agreement, corroborating this assignment."], "authors": "J. Isaak"},
{"Title": "Electromagnetic moments of the antimony isotopes $^{112-133}$Sb", "abs": ["Nuclear moments of the antimony isotopes $^{113-133}$Sb are measured by collinear laser spectroscopy and used to benchmark phenomenological shell-model and \\textit{ab initio} calculations in the valence-space in-medium similarity renormalization group (VS-IMSRG). The shell-model calculations reproduce the electromagnetic moments over all Sb isotopes when suitable effective $g$-factors and charges are employed. Good agreement is achieved by VS-IMSRG for magnetic moments on the neutron-deficient side for both odd-even and odd-odd Sb isotopes while its results deviate from experiment on the neutron-rich side. When the same effective $g$-factors are used, VS-IMSRG agrees with experiment nearly as well as the shell model. Hence, the wave functions are very similar in both approaches and missing contributions to the M1 operator are identified as the cause of the discrepancy of VS-IMSRG with experiment. Electric quadrupole moments remain more challenging for VS-IMSRG."], "authors": "S. Lechner"},
{"Title": "Measurements of charged-particle multiplicity dependence of higher-order net-proton cumulants in $p$+$p$ collisions at $\\sqrt{s} =$ 200 GeV from STAR at RHIC", "abs": ["We report on the charged-particle multiplicity dependence of net-proton cumulant ratios up to sixth order from $\\sqrt{s}$ = 200 GeV $p$+$p$ collisions at the Relativistic Heavy Ion Collider (RHIC). The measured ratios $C_{4}/C_{2}$, $C_{5}/C_{1}$, and $C_{6}/C_{2}$ decrease with increased charged-particle multiplicity and rapidity acceptance. Neither the Skellam baselines nor PYTHIA8 calculations account for the observed multiplicity dependence. In addition, the ratios $C_{5}/C_{1}$ and $C_{6}/C_{2}$ approach negative values in the highest-multiplicity events. The negative ratios in the most central p+p collisions at 200 GeV, similar to those observed in central Au+Au 200 GeV collisions, imply the formation of thermalized QCD matter."], "authors": "STAR Collaboration"},
{"Title": "Hidden quasi-local charges and Gibbs ensemble in a Lindblad system", "abs": ["We consider spin-1/2 chains with external driving that breaks the continuous symmetries of the Hamiltonian. We introduce a family of models described by the Lindblad equation with local jump operators. The models have hidden strong symmetries in the form of quasi-local charges, leading to multiple non-equilibrium steady states. We compute them exactly in the form of Matrix Product Operators, and argue that they are the analogues of quantum many body scars in the Lindbladian setting. We observe that the dynamics leads to the emergence of a Gibbs ensemble constructed from the hidden charges."], "authors": "Marius de Leeuw"},
{"Title": "A range three elliptic deformation of the Hubbard model", "abs": ["In this paper we present a new integrable deformation of the Hubbard model. Our deformation gives rise to a range 3 interaction term in the Hamiltonian which does not preserve spin or particle number. This is the first non-trivial medium range deformation of the Hubbard model that is integrable. Our model can be mapped to a new integrable nearest-neighbour model via a duality transformation. The resulting nearest-neighbour model also breaks spin conservation. We compute the $R$-matrices for our models, and find that there is a very unusual dependence on the spectral parameters in terms of the elliptic amplitude."], "authors": "Marius de Leeuw"},
{"Title": "The Bethe ansatz for a new integrable open quantum system", "abs": ["In this paper we apply the nested algebraic Bethe ansatz to compute the eigenvalues and the Bethe equations of the transfer matrix of the new integrable Lindbladian found in [1]. We show that it can be written as an integrable spin chain consisting of two interacting XXZ spin chains. We numerically compute the Liouville gap and its dependence on the parameters in the system such as scaling with the system length and interaction strength."], "authors": "Marius de Leeuw"},
{"Title": "Constructing Integrable Lindblad Superoperators", "abs": ["We develop a new method for the construction of one-dimensional integrable Lindblad systems, which describe quantum many body models in contact with a Markovian environment. We find several new models with interesting features, such as annihilation-diffusion processes, a mixture of coherent and classical particle propagation, and a rectified steady state current. We also find new ways to represent known classical integrable stochastic equations by integrable Lindblad operators. Our method can be extended to various other situations and it establishes a structured approach to the study of solvable open quantum systems."], "authors": "Marius de Leeuw"},
{"Title": "Free Fermions, vertex Hamiltonians, and lower-dimensional AdS/CFT", "abs": ["In this paper we first demonstrate explicitly that the new models of integrable nearest-neighbour Hamiltonians recently introduced in PRL 125 (2020) 031604 satisfy the so-called free fermion condition. This both implies that all these models are amenable to reformulations as free fermion theories, and establishes the universality of this condition. We explicitly recast the transfer matrix in free fermion form for arbitrary number of sites in the 6-vertex sector, and on two sites in the 8-vertex sector, using a Bogoliubov transformation. We then put this observation to use in lower-dimensional instances of AdS/CFT integrable R-matrices, specifically pure Ramond-Ramond massless and massive AdS_3, mixed-flux relativistic AdS_3 and massless AdS_2. We also attack the class of models akin to AdS_5 with our free fermion machinery. In all cases we use the free fermion realisation to greatly simplify and reinterpret a wealth of known results, and to provide a very suggestive reformulation of the spectral problem in all these situations."], "authors": "Marius de Leeuw"},
{"Title": "Is the resonant wave interaction approximation consistent with the dynamics of internal wave fields?", "abs": ["Nonlinear interaction and breaking of internal ocean waves are responsible for much of the interior ocean mixing, affecting ocean carbon storage and the global overturning circulation. These interactions are also believed to dictate the observed Garrett-Munk wave energy spectrum, which is still unexplained after 50 years of studies. According to the resonant wave interaction approximation, used to derive the kinetic equation for the energy spectrum, the dominant interactions are between wave triads whose wavevectors satisfy $\\mathbf{k}=\\mathbf{p}+\\mathbf{q}$, and whose frequencies satisfy $\\omega_{\\mathbf{k}}=|\\omega_{\\mathbf{p}}\\pm\\omega_{\\mathbf{q}}|$. In order to test the validity of the resonant wave interaction approximation, we examine several analytical derivations of the theory. The assumptions underlying each derivation are tested using idealized direct 2d numerical simulations, representing near-observed energy levels of the oceanic internal wave field. We show that the assumptions underlying the derivations are not consistent with the simulated dynamics. In addition, most of the triads satisfying the resonant conditions do not contribute significantly to nonlinear wave energy transfer in our simulations, while some interactions that are dominant in nonlinear energy transfers do not satisfy the resonance conditions. We also point to possible self-consistency issues with some derivations found in the literature."], "authors": "Golan Bel"},
{"Title": "Yang-Baxter and the Boost: splitting the difference", "abs": ["In this paper we continue our classification of regular solutions of the Yang-Baxter equation using the method based on the spin chain boost operator developed in \\cite{deLeeuw:2019zsi}. We provide details on how to find all non-difference form solutions and apply our method to spin chains with local Hilbert space of dimensions two, three and four. We classify all $16\\times 16$ solutions which exhibit $\\mathfrak{su}(2)\\oplus \\mathfrak{su}(2)$ symmetry, which include the one-dimensional Hubbard model and the $S$-matrix of the ${\\rm AdS}_5 \\times {\\rm S}^5$ superstring sigma model. In all cases we find interesting novel solutions of the Yang-Baxter equation."], "authors": "Marius de Leeuw"},
{"Title": "Classifying nearest-neighbour interactions and deformations of AdS", "abs": ["We classify all regular solutions of the Yang-Baxter equation of eight-vertex type. Regular solutions correspond to spin chains with nearest-neighbour interactions. We find a total of four independent solutions. Two are related to the usual six- and eight-vertex models that have R-matrices of difference form. We find two completely new solutions of the Yang-Baxter equation, which are manifestly of non-difference form. These new solutions contain the S-matrices of the AdS2 and AdS3 integrable models as a special case. Consequently, we can classify all possible integrable deformations of eight-vertex type of these holographic integrable systems."], "authors": "Marius de Leeuw"},
{"Title": "Yang-Baxter integrable open quantum systems", "abs": ["This work is based on the author's PhD thesis. The main result of the thesis is the use of the boost operator to develop a systematic method to construct new integrable spin chains with nearest-neighbour interaction and characterized by an R-matrix of non-difference form. This method has the advantage of being more feasible than directly solving the Yang-Baxter equation. We applied this approach to various contexts, in particular, in the realm of open quantum systems, we achieved the first classification of integrable Lindbladians. These operators describe the dynamics of physical systems in contact with a Markovian environment. Within this classification, we discovered a novel deformation of the Hubbard model spanning three sites of the spin chain. Additionally, we applied our method to classify models with $\\mathfrak{su}(2)\\oplus \\mathfrak{su}(2)$ symmetry and we recovered the matrix part of the S-matrix of $AdS_5 \\times S^5$ derived by requiring centrally extended $\\mathfrak{su}(2|2)$ symmetry. Furthermore, we focus on spin 1/2 chain on models of 8-Vertex type and we showed that the models of this class satisfy the free fermion condition. This enables us to express the transfer matrix associated to some of the models in a diagonal form, simplifying the computation of the eigenvalues and eigenvectors. The thesis is based on the works:", ",", ",", ",", ",", ",", ",", "."], "authors": "Chiara Paletta"},
{"Title": "Unveilling Chaos in Particle Motion: Analyzing the Impact of Horizon in $f(R)$ Gravity", "abs": ["This article is devoted to investigate the effects of $f(R)$ theory in the dynamics of a massless particle near the horizon of a static spherically symmetric (SSS) black hole. Deriving the equations of motion within $f(R)$ gravitational theories, novel solutions for charged and neutral black holes are obtained, introducing a dimensional parameter $a$ in $f(R)=R-2a\\sqrt{R}$. Departing from General Relativity, these solutions showcase unique properties reliant on the dynamics of Ricci scalar. Analysis shows that chaos manifests within a specific energy range, with $a$ playing a crucial role. The study underscores the general applicability of the spherically symmetric metric, revealing insights into particle dynamics near black hole horizons. Despite an initially integrable nature, the introduction of harmonic perturbation leads to chaos, aligning with the Kolmogorov-Arnold-Moser theory. This research contributes to a nuanced understanding of black hole dynamics, emphasizing the importance of alternative theories of gravity."], "authors": "Surajit Das"},
{"Title": "Caputo Fractional Standard Map: Scaling Invariance Analyses", "abs": ["Some statistical properties was studied for discret maps obtained from kicked differential equations of motion with derivatives of noninteger orders, more specifically, for a generalization of the standard map considering Caputo fractional derivatives. Thus, the Caputo fractional standard map, parameterized by $K$ and $1<\\alpha\\leq2$, is derived from Caputo Generalization nonlinear Volterra integral equations of second kind. The survival probability that a particle moving along phase space has to survive a specific domain has a short plateau follow by a decay exponential and present a interesting property, it is scaling invariant for all control parameters."], "authors": "Daniel Borin"},
{"Title": "Uniformly Strict Equilibrium for Repeated Games with Private Monitoring and Communication", "abs": ["Cooperation through repetition is an important theme in game theory. In this regard, various celebrated ``folk theorems'' have been proposed for repeated games in increasingly more complex environments. There has, however, been insufficient attention paid to the robustness of a large set of equilibria that is needed for such folk theorems. Starting with perfect public equilibrium as our starting point, we study uniformly strict equilibria in repeated games with private monitoring and direct communication (cheap talk). We characterize the limit equilibrium payoff set and identify the conditions for the folk theorem to hold with uniformly strict equilibrium."], "authors": "Richard McLean"},
{"Title": "Successive Incentives", "abs": ["We study the design of optimal incentives in sequential processes. To do so, we consider a basic and fundamental model in which an agent initiates a value-creating sequential process through costly investment with random success. If unsuccessful, the process stops. If successful, a new agent thereafter faces a similar investment decision, and so forth. For any outcome of the process, the total value is distributed among the agents using a reward rule. Reward rules thus induce a game among the agents. By design, the reward rule may lead to an asymmetric game, yet we are able to show equilibrium existence with optimal symmetric equilibria. We characterize optimal reward rules that yield the highest possible welfare created by the process, and the highest possible expected payoff for the initiator of the process. Our findings show that simple reward rules invoking short-run incentives are sufficient to meet long-run objectives."], "authors": "Jens Gudmundsson"},
{"Title": "Underreaction and dynamic inconsistency in communication games under noise", "abs": ["Communication is rarely perfect, but rather prone to error of transmission and reception. Often the origin of these errors cannot be properly quantified and is thus imprecisely known. We analyze the impact of an ambiguous noise which may alter the received message on a communication game of common interest. The noise is ambiguous in the sense that the parameters of the error-generating process and thus the likelihood to receive a message by mistake are Knightianly unknown. Ex-ante and interim responses are characterized under maxmin preferences. While the sender can disregard ambiguity, the receiver reveals a dynamically inconsistent, but astonishing behavior under a quadratic loss. Their interim actions will be closer to the pooling action than their ex-ante ones, as if facing a higher likelihood of an occurring error."], "authors": "Gerrit Bauch"},
{"Title": "A duality and free boundary approach to adverse selection", "abs": ["Adverse selection is a version of the principal-agent problem that includes monopolist nonlinear pricing, where a monopolist with known costs seeks a profit-maximizing price menu facing a population of potential consumers whose preferences are known only in the aggregate. For multidimensional spaces of agents and products, Rochet and Choné (1998) reformulated this problem to a concave maximization over the set of convex functions, by assuming agent preferences combine bilinearity in the product and agent parameters with a quasilinear sensitivity to prices. We characterize solutions to this problem by identifying a dual minimization problem. This duality allows us to reduce the solution of the square example of Rochet-Choné to a novel free boundary problem, giving the first analytical description of an overlooked market segment."], "authors": "Robert J. McCann"},
{"Title": "Comment on \"Ironing, sweeping, and multidimensional screening''", "abs": ["In their study of price discrimination for a monopolist selling heterogeneous products to consumers having private information about their own multidimensional types, Rochet and Choné (1998) discovered a new form of screening in which consumers with intermediate types are bunched together into isochoice groups of various dimensions incentivized to purchase the same product. They analyzed a particular example involving customer types distributed uniformly over the unit square. For this example, we prove that their proposed solution cannot be correct, and explain how it can be corrected."], "authors": "Robert J. McCann"},
{"Title": "Belief identification by proxy", "abs": ["It is well known that individual beliefs cannot be identified using traditional choice data, unless we exogenously assume state-independent utilities. In this paper, I propose a novel methodology that solves this long-standing identification problem in a simple way. This method relies on the extending the state space by introducing a proxy, for which the agent has no stakes conditional on the original state space. The latter allows us to identify the agent's conditional beliefs about the proxy given each state realization, which in turn suffices for indirectly identifying her beliefs about the original state space. This approach is analogous to the one of instrumental variables in econometrics. Similarly to instrumental variables, the appeal of this method comes from the flexibility in selecting a proxy."], "authors": "Elias Tsakas"},
{"Title": "Correlated Equilibria of Classical Strategic Games with Quantum Signals", "abs": ["Correlated equilibria are sometimes more efficient than the Nash equilibria of a game without signals. We investigate whether the availability of quantum signals in the context of a classical strategic game may allow the players to achieve even better efficiency than in any correlated equilibrium with classical signals, and find the answer to be positive."], "authors": "Pierfrancesco La Mura"},
{"Title": "Projective Expected Utility", "abs": ["Motivated by several classic decision-theoretic paradoxes, and by analogies with the paradoxes which in physics motivated the development of quantum mechanics, we introduce a projective generalization of expected utility along the lines of the quantum-mechanical generalization of probability theory. The resulting decision theory accommodates the dominant paradoxes, while retaining significant simplicity and tractability. In particular, every finite game within this larger class of preferences still has an equilibrium."], "authors": "Pierfrancesco La Mura"},
{"Title": "Organizational economic sustainability via process optimization and human capital: a Soft Systems Methodology (SSM) approach", "abs": ["This review paper focuses on enhancing organizational economic sustainability through process optimization and human capital effective management utilizing the soft systems methodology (SSM) approach which offers a holistic approach for understanding complex real-world challenges. By emphasizing systems thinking and engaging diverse stakeholders in problem-solving, SSM provides a comprehensive understanding of the problem's context and potential solutions. The approach guides a systematic process of inquiry that leads to feasible and desirable changes in tackling complex problems effectively. Our paper employs the bibliometric analysis based on the sample of 5171 research articles, proceedings papers, and book chapters indexed in Web of Science (WoS) database. We carry out the network cluster analysis using the text data and the bibliometric data with the help of VOSViewer software. Our results confirm that as the real-world situations are becoming more complex and the new challenges such as the global warming and climate change are threatening many economic and social processes, SSM approach is currently getting back at the forefront of academic research related to such topics as organizational management and sustainable human capital efficiency."], "authors": "Wadim Strielkowski"},
{"Title": "Generative artificial intelligence enhances individual creativity but reduces the collective diversity of novel content", "abs": ["Creativity is core to being human. Generative artificial intelligence (GenAI) holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on GenAI ideas. We study the causal impact of GenAI ideas on the production of an unstructured creative output in an online experimental study where some writers could obtain ideas for a story from a GenAI platform. We find that access to GenAI ideas causes stories to be evaluated as more creative, better written and more enjoyable, especially among less creative writers. However, objective measures of story similarity within each condition reveal that GenAI-enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity, but at the same time there is a risk of losing collective novelty: this dynamic resembles a social dilemma where individual writers are better off using GenAI to improve their own writing, but collectively a narrower scope of novel content may be produced with GenAI. Our results have implications for researchers, policy-makers and practitioners interested in bolstering creativity, but point to potential downstream consequences from over-reliance."], "authors": "Anil R. Doshi"},
{"Title": "Optimal Consumption--Investment Problems under Time-Varying Incomplete Preferences", "abs": ["The main objective of this paper is to develop a martingale-type solution to optimal consumption--investment choice problems ([Merton, 1969] and [Merton, 1971]) under time-varying incomplete preferences driven by externalities such as patience, socialization effects, and market volatility. The market is composed of multiple risky assets and multiple consumption goods, while in addition there are multiple fluctuating preference parameters with inexact values connected to imprecise tastes. Utility maximization is a multi-criteria problem with possibly function-valued criteria. To come up with a complete characterization of the solutions, first we motivate and introduce a set-valued stochastic process for the dynamics of multi-utility indices and formulate the optimization problem in a topological vector space. Then, we modify a classical scalarization method allowing for infiniteness and randomness in dimensions and prove results of equivalence to the original problem. Illustrative examples are given to demonstrate practical interests and method applicability progressively. The link between the original problem and a dual problem is also discussed, relatively briefly. Finally, using Malliavin calculus with stochastic geometry, we find optimal investment policies to be generally set-valued, each of whose selectors admits a four-way decomposition involving an additional indecisiveness risk-hedging portfolio. Our results touch on new directions for optimal consumption--investment choices in the presence of incomparability and time inconsistency, also signaling potentially testable assumptions on the variability of asset prices. Simulation techniques for set-valued processes are studied for how solved optimal policies can be computed in practice."], "authors": "Weixuan Xia"},
{"Title": "Advancing AI Audits for Enhanced AI Governance", "abs": ["As artificial intelligence (AI) is integrated into various services and systems in society, many companies and organizations have proposed AI principles, policies, and made the related commitments. Conversely, some have proposed the need for independent audits, arguing that the voluntary principles adopted by the developers and providers of AI services and systems insufficiently address risk. This policy recommendation summarizes the issues related to the auditing of AI services and systems and presents three recommendations for promoting AI auditing that contribute to sound AI governance. Recommendation1.Development of institutional design for AI audits. Recommendation2.Training human resources for AI audits. Recommendation3. Updating AI audits in accordance with technological progress.", "In this policy recommendation, AI is assumed to be that which recognizes and predicts data with the last chapter outlining how generative AI should be audited."], "authors": "Arisa Ema"},
{"Title": "Identifying patterns and recommendations of and for sustainable open data initiatives: a benchmarking-driven analysis of open government data initiatives among European countries", "abs": ["Open government and open (government) data are seen as tools to create new opportunities, eliminate or at least reduce information inequalities and improve public services. More than a decade of these efforts has provided much experience, practices, and perspectives to learn how to better deal with them. This paper focuses on benchmarking of open data initiatives over the years and attempts to identify patterns observed among European countries that could lead to disparities in the development, growth, and sustainability of open data ecosystems. To do this, we studied benchmarks and indices published over the last years (57 editions of 8 artifacts) and conducted a comparative case study of eight European countries, identifying patterns among them considering different potentially relevant contexts such as e-government, open government data, open data indices and rankings, and others relevant for the country under consideration. Using a Delphi method, we reached a consensus within a panel of experts and validated a final list of 94 patterns, including their frequency of occurrence among studied countries and their effects on the respective countries. Finally, we took a closer look at the developments in identified contexts over the years and defined 21 recommendations for more resilient and sustainable open government data initiatives and ecosystems and future steps in this area."], "authors": "Martin Lnenicka"},
{"Title": "Causal propensity as an antecedent of entrepreneurial intentions in tourism students", "abs": ["The tourism sector is a sector with many opportunities for business development. Entrepreneurship in this sector promotes economic growth and job creation. Knowing how entrepreneurial intention develops facilitates its transformation into entrepreneurial behaviour. Entrepreneurial behaviour can adopt a causal logic, an effectual logic or a combination of both. Considering the causal logic, decision-making is done through prediction. In this way, entrepreneurs try to increase their market share by planning strategies and analysing possible deviations from their plans. Previous literature studies causal entrepreneurial behaviour, as well as variables such as creative innovation, proactive decisions and entrepreneurship training when the entrepreneur has already created his or her firm. However, there is an obvious gap at a stage prior to the start of entrepreneurial activity when the entrepreneurial intention is formed. This paper analyses how creativity, proactivity, entrepreneurship education and the propensity for causal behaviour influence entrepreneurial intentions. To achieve the research objective, we analysed a sample of 464 undergraduate tourism students from two universities in southern Spain. We used SmartPLS 3 software to apply a structural equation methodology to the measurement model composed of nine hypotheses. The results show, among other relationships, that causal propensity, entrepreneurship learning programmes and proactivity are antecedents of entrepreneurial intentions. These findings have implications for theory, as they fill a gap in the field of entrepreneurial intentions. Considering propensity towards causal behaviour before setting up the firm is unprecedented. Furthermore, the results of this study have practical implications for the design of public education policies and the promotion of business creation in the tourism sector."], "authors": "Alicia Martin-Navarro"},
{"Title": "Business process management systems in port processes: a systematic literature review", "abs": ["Business Process Management Systems (BPMS) represent a technology that automates business processes, connecting users to their tasks. There are many business processes within the port activity that can be improved through the use of more efficient technologies and BPMS in particular, which can help to coordinate and automate critical processes such as cargo manifests, customs declaration the management of scales, or dangerous goods, traditionally supported by EDI technologies. These technologies could be integrated with BPMS, modernizing port logistics management. The aim of this work is to demonstrate, through a systematic analysis of the literature, the state of the art in BPMS research in the port industry. For this, a systematic review of the literature of the last ten years was carried out. The works generated by the search were subsequently analysed and filtered. After the investigation, it is discovered that the relationship between BPMS and the port sector is practically non-existent which represents an important gap to be covered and a future line of research."], "authors": "Alicia Martin-Navarro"},
{"Title": "BPMS for management: a systematic literature review", "abs": ["The aim of this paper is to carry out a systematic analysis of the literature to show the state of the art of Business Processes Management Systems (BPMS). BPMS represents a technology that automates business processes connecting users with their tasks. For this, a systematic review of the literature of the last ten years was carried out, using scientific papers indexed in the main databases of the knowledge area. The papers generated by the search were later analysed and filtered. Among the findings of this study, the academic interest and the multidisciplinary nature of the subject, as this type of studies have been identified in different areas of knowledge. Our research is a starting point for future research eager to develop a more robust theory and broaden the interest of the subject due its economic impact on process management."], "authors": "Alicia Martin-Navarro"},
{"Title": "GMM-lev estimation and individual heterogeneity: Monte Carlo evidence and empirical applications", "abs": ["The generalized method of moments (GMM) estimator applied to equations in levels, GMM-lev, has the advantage of being able to estimate the effect of measurable time-invariant covariates using all available information. This is not possible with GMM-dif, applied to equations in each period transformed into first differences, while GMM-sys uses little information, as it adds the equation in levels for only one period. The GMM-lev, by implying a two-component error term containing the individual heterogeneity and the shock, exposes the explanatory variables to possible double endogeneity. For example, the estimation of true persistence could suffer from bias if instruments were correlated with the unit-specific error component. We propose to exploit the \\citet{Mundlak1978}'s approach together with GMM-lev estimation to capture initial conditions and improve inference. Monte Carlo simulations for different panel types and under different double endogeneity assumptions show the advantage of our approach."], "authors": "Maria Elena Bontempi"},
{"Title": "Stochastic volatility models with skewness selection", "abs": ["This paper expands traditional stochastic volatility models by allowing for time-varying skewness without imposing it. While dynamic asymmetry may capture the likely direction of future asset returns, it comes at the risk of leading to overparameterization. Our proposed approach mitigates this concern by leveraging sparsity-inducing priors to automatically selects the skewness parameter as being dynamic, static or zero in a data-driven framework. We consider two empirical applications. First, in a bond yield application, dynamic skewness captures interest rate cycles of monetary easing and tightening being partially explained by central banks' mandates. In an currency modeling framework, our model indicates no skewness in the carry factor after accounting for stochastic volatility which supports the idea of carry crashes being the result of volatility surges instead of dynamic skewness."], "authors": "Igor Ferreira Batista Martins"},
{"Title": "Algorithmic Persuasion Through Simulation: Information Design in the Age of Generative AI", "abs": ["How can an informed sender persuade a receiver, having only limited information about the receiver's beliefs? Motivated by research showing generative AI can simulate economic agents, we initiate the study of information design with an oracle. We assume the sender can learn more about the receiver by querying this oracle, e.g., by simulating the receiver's behavior. Aside from AI motivations such as general-purpose Large Language Models (LLMs) and problem-specific machine learning models, alternate motivations include customer surveys and querying a small pool of live users.", "Specifically, we study Bayesian Persuasion where the sender has a second-order prior over the receiver's beliefs. After a fixed number of queries to an oracle to refine this prior, the sender commits to an information structure. Upon receiving the message, the receiver takes a payoff-relevant action maximizing her expected utility given her posterior beliefs. We design polynomial-time querying algorithms that optimize the sender's expected utility in this Bayesian Persuasion game. As a technical contribution, we show that queries form partitions of the space of receiver beliefs that can be used to quantify the sender's knowledge."], "authors": "Keegan Harris"},
{"Title": "Resource Sharing in Energy Communities: A Cooperative Game Approach", "abs": ["We analyze the overall benefits of an energy community cooperative game under which distributed energy resources (DER) are shared behind a regulated distribution utility meter under a general net energy metering (NEM) tariff. Two community DER scheduling algorithms are examined. The first is a community with centrally controlled DER, whereas the second is decentralized letting its members schedule their own DER locally. For both communities, we prove that the cooperative game's value function is superadditive, hence the grand coalition achieves the highest welfare. We also prove the balancedness of the cooperative game under the two DER scheduling algorithms, which means that there is a welfare re-distribution scheme that de-incentivizes players from leaving the grand coalition to form smaller ones. Lastly, we present five ex-post and an ex-ante welfare re-distribution mechanisms and evaluate them in simulation, in addition to investigating the performance of various community sizes under the two DER scheduling algorithms."], "authors": "Ahmed S. Alahmed"},
{"Title": "Ascending auctions and Walrasian equilibrium", "abs": ["We present a family of submodular valuation classes that generalizes gross substitute. We show that Walrasian equilibrium always exist for one class in this family, and there is a natural ascending auction which finds it. We prove some new structural properties on gross-substitute auctions which, in turn, show that the known ascending auctions for this class (Gul-Stacchetti and Ausbel) are, in fact, identical. We generalize these two auctions, and provide a simple proof that they terminate in a Walrasian equilibrium."], "authors": "Oren Ben-Zwi"},
{"Title": "No Ascending Auction can find Equilibrium for SubModular valuations", "abs": ["We show that no efficient ascending auction can guarantee to find even a minimal envy-free price vector if all valuations are submodular, assuming a basic complexity theory's assumption."], "authors": "Oren Ben-Zwi"},
{"Title": "Baumol's Climate Disease", "abs": ["We investigate optimal carbon abatement in a dynamic general equilibrium climate-economy model with endogenous structural change. By differentiating the production of investment from consumption, we show that social cost of carbon can be conceived as a reduction in physical capital. In addition, we distinguish two final sectors in terms of productivity growth and climate vulnerability. We theoretically show that heterogeneous climate vulnerability results in a climate-induced version of Baumol's cost disease. Further, if climate-vulnerable sectors have high (low) productivity growth, climate impact can either ameliorate (aggravate) the Baumol's cost disease, call for less (more) stringent climate policy. We conclude that carbon abatement should not only factor in unpriced climate capital, but also be tailored to Baumol's cost and climate diseases."], "authors": "Fangzhi Wang"},
{"Title": "Surge of power transmission in flat and nearly flat band lattices", "abs": ["Flat band systems can yield interesting phenomena, such as dispersion suppression of waves with frequency at the band. While linear transport vanishes, the corresponding nonlinear case is still an open question. Here, we study power transmission along nonlinear sawtooth lattices due to waves with the flat band frequency injected at one end. While there is no power transfer for small intensity, there is a threshold amplitude above which a surge of power transmission occurs, i.e., supratransmission, for defocusing nonlinearity. This is due to a nonlinear evanescent wave with the flat band frequency that becomes unstable. We show that dispersion suppression and supratransmission also exist even when the band is nearly flat."], "authors": "H. Susanto"},
{"Title": "$α$-induction for bi-unitary connections", "abs": ["The tensor functor called $\\alpha$-induction arises from a Frobenius algebra object, or a Q-system, in a braided unitary fusion category. In the operator algebraic language, it gives extensions of endomorphism of $N$ to $M$ arising from a subfactor $N\\subset M$ of finite index and finite depth giving a braided fusion category of endomorpshisms of $N$. It is also understood in terms of Ocneanu's graphical calculus. We study this $\\alpha$-induction for bi-unitary connections, which give a characterization of finite-dimensional nondegenerate commuting squares and gives certain 4-tensors appearing in recent studies of 2-dimensional topological order. We show that the resulting $\\alpha$-induced bi-unitary connections are flat if we have a commutative Frobenius algebra, or a local Q-system. Examples related to chiral conformal field theory and the Dynkin diagrams are presented."], "authors": "Yasuyuki Kawahigashi"},
{"Title": "Bilinear maps on C$^*$-algebras that have product property at a compact element", "abs": ["We study bounded bilinear maps on a C$^*$-algebra $A$ having product property at $c\\in A$. This leads us to the question of when a C$^*$-algebra is determined by products at $c.$ In the first part of our paper, we investigate this question for compact C$^*$-algebras, and in the second part, we deal with von Neumann algebras having non-trivial atomic part. Our results are applicable to descriptions of homomorphism-like and derivation-like maps at a fixed point on such algebras."], "authors": "Jorge J. Garcés"},
{"Title": "Exploring the sensing power of mixed vehicle fleets", "abs": ["Vehicle-based mobile sensing (a.k.a. drive-by sensing) has become an important means to survey urban environment at low costs by leveraging the mobility of urban vehicles. Recent studies have focused on characterizing and optimizing the power of drive-by sensing, but restricted to fleets of a single type. In this work, we explore the sensing power and cost effectiveness of fleets comprised of taxis, buses and dedicated vehicles (DVs), each characterized by unique mobility patterns and operational characteristics. This is achieved by solving the drive-by sensing coverage (DSC) problem, which includes (1) a method to quantify the sensing utility of spatial-temporal vehicle coverage, followed by a first-order optimality analysis leading to target sensing distributions; (2) an optimization procedure that simultaneously determines fleet composition, sensor allocation and vehicle routing for a given budget. Such a procedure includes a convex program for the taxi-bus fleet, and a dual-spatial-scale routing problem for the DVs. An air quality sensing case study in Longquanyi District (Chengdu, China) shows that (1) mixed fleets considerably increase the sensing utilities and yields close approximation to the target sensing distribution even with low budgets; (2) mixed fleet can save at least 30% budget while achieving sensing quality no worse than homogenous fleets. These insights are generalized to two additional real-world networks, with a regression analysis that further uncover the key factors underlying the sensing power of mixed fleets. This work offers quantitative and managerial insights into drive-by sensing, which represents a positive externality of urban transport activities."], "authors": "Ke Han"},
{"Title": "Geometry of exactness of moment-SOS relaxations for polynomial optimization", "abs": ["The moment-SOS (sum of squares) hierarchy is a powerful approach for solving globally non-convex polynomial optimization problems (POPs) at the price of solving a family of convex semidefinite optimization problems (called moment-SOS relaxations) of increasing size, controlled by an integer, the relaxation order. We say that a relaxation of a given order is exact if solving the relaxation actually solves the POP globally. In this note, we study the geometry of the exactness cone, defined as the set of polynomial objective functions for which the relaxation is exact. Generalizing previous foundational work on quadratic optimization on real varieties, we prove by elementary arguments that the exactness cones are unions of semidefinite representable cones monotonically embedded for increasing relaxation order."], "authors": "Didier Henrion"},
{"Title": "A New Smoothing Technique for Bang-Bang Optimal Control Problems", "abs": ["Bang-bang control is ubiquitous for Optimal Control Problems (OCPs) where the constrained control variable appears linearly in the dynamics and cost function. Based on the Pontryagin's Minimum Principle, the indirect method is widely used to numerically solve OCPs because it enables to derive the theoretical structure of the optimal control. However, discontinuities in the bang-bang control structure may result in numerical difficulties for gradient-based indirect method. In this case, smoothing or regularization procedures are usually applied to eliminating the discontinuities of bang-bang controls. Traditional smoothing or regularization procedures generally modify the cost function by adding a term depending on a small parameter, or introducing a small error into the state equation. Those procedures may complexify the numerical algorithms or degenerate the convergence performance. To overcome these issues, we propose a bounded smooth function, called normalized L2-norm function, to approximate the sign function in terms of the switching function. The resulting optimal control is smooth and can be readily embedded into the indirect method. Then, the simplicity and improved performance of the proposed method over some existing methods are numerically demonstrated by a minimal-time oscillator problem and a minimal-fuel low-thrust trajectory optimization problem that involves many revolutions."], "authors": "Kun Wang"},
{"Title": "A real moment-HSOS hierarchy for complex polynomial optimization with real coefficients", "abs": ["This paper proposes a real moment-HSOS hierarchy for complex polynomial optimization problems with real coefficients. We show that this hierarchy provides the same sequence of lower bounds as the complex analogue, yet is much cheaper to solve. In addition, we prove that global optimality is achieved when the ranks of the moment matrix and certain submatrix equal two in case that a sphere constraint is present, and as a consequence, the complex polynomial optimization problem has either two real optimal solutions or a pair of conjugate optimal solutions. A simple procedure for extracting a pair of conjugate optimal solutions is given in the latter case. Various numerical examples are presented to demonstrate the efficiency of this new hierarchy, and an application to polyphase code design is also provided."], "authors": "Jie Wang"},
{"Title": "Distributed Optimization under Edge Agreements: A Continuous-Time Algorithm", "abs": ["Generalized from the concept of consensus, this paper considers a group of edge agreements, i.e. constraints defined for neighboring agents, in which each pair of neighboring agents is required to satisfy one edge agreement constraint. Edge agreements are defined locally to allow more flexibility than a global consensus. This work formulates a multi-agent optimization problem under edge agreements and proposes a continuous-time distributed algorithm to solve it. Both analytical proof and numerical examples are provided to validate the effectiveness of the proposed algorithm."], "authors": "Zehui Lu"},
{"Title": "On Some Geometric Behavior of Value Iteration on the Orthant: Switching System Perspective", "abs": ["In this paper, the primary goal is to offer additional insights into the value iteration through the lens of switching system models in the control community. These models establish a connection between value iteration and switching system theory and reveal additional geometric behaviors of value iteration in solving discounted Markov decision problems. Specifically, the main contributions of this paper are twofold: 1) We provide a switching system model of value iteration and, based on it, offer a different proof for the contraction property of the value iteration. 2) Furthermore, from the additional insights, new geometric behaviors of value iteration are proven when the initial iterate lies in a special region. We anticipate that the proposed perspectives might have the potential to be a useful tool, applicable in various settings. Therefore, further development of these methods could be a valuable avenue for future research."], "authors": "Donghwan Lee"},
{"Title": "Linear Boundary Port-Hamiltonian Systems with Implicitly Defined Energy", "abs": ["In this paper we extend the previously introduced class of boundary port-Hamiltonian systems to boundary control systems where the variational derivative of the Hamiltonian functional is replaced by a pair of reciprocal differential operators. In physical systems modelling, these differential operators naturally represent the constitutive relations associated with the implicitly defined energy of the system and obey Maxwell's reciprocity conditions. On top of the boundary variables associated with the Stokes-Dirac structure, this leads to additional boundary port variables and to the new notion of a Stokes-Lagrange subspace. This extended class of boundary port-Hamiltonian systems is illustrated by a number of examples in the modelling of elastic rods with local and non-local elasticity relations. Finally it shown how a Hamiltonian functional on an extended state space can be associated with the Stokes-Lagrange subspace, and how this leads to an energy balance equation involving the boundary variables of the Stokes-Dirac structure as well as of the Stokes-Lagrange subspace."], "authors": "Bernhard Maschke"},
{"Title": "A Bregman-Kaczmarz method for nonlinear systems of equations", "abs": ["We propose a new randomized method for solving systems of nonlinear equations, which can find sparse solutions or solutions under certain simple constraints. The scheme only takes gradients of component functions and uses Bregman projections onto the solution space of a Newton equation. In the special case of euclidean projections, the method is known as nonlinear Kaczmarz method. Furthermore, if the component functions are nonnegative, we are in the setting of optimization under the interpolation assumption and the method reduces to SGD with the recently proposed stochastic Polyak step size. For general Bregman projections, our method is a stochastic mirror descent with a novel adaptive step size. We prove that in the convex setting each iteration of our method results in a smaller Bregman distance to exact solutions as compared to the standard Polyak step. Our generalization to Bregman projections comes with the price that a convex one-dimensional optimization problem needs to be solved in each iteration. This can typically be done with globalized Newton iterations. Convergence is proved in two classical settings of nonlinearity: for convex nonnegative functions and locally for functions which fulfill the tangential cone condition. Finally, we show examples in which the proposed method outperforms similar methods with the same memory requirements."], "authors": "Robert Gower"},
{"Title": "Upper and lower bounds for the Lipschitz constant of random neural networks", "abs": ["Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. In this paper, we study upper and lower bounds for the Lipschitz constant of random ReLU neural networks. Specifically, we assume that the weights and biases follow a generalization of the He initialization, where general symmetric distributions for the biases are permitted. For shallow neural networks, we characterize the Lipschitz constant up to an absolute numerical constant. For deep networks with fixed depth and sufficiently large width, our established bounds differ by a factor that is logarithmic in the width."], "authors": "Paul Geuchen"},
{"Title": "Optimal Stopping via Randomized Neural Networks", "abs": ["This paper presents the benefits of using randomized neural networks instead of standard basis functions or deep neural networks to approximate the solutions of optimal stopping problems. The key idea is to use neural networks, where the parameters of the hidden layers are generated randomly and only the last layer is trained, in order to approximate the continuation value. Our approaches are applicable to high dimensional problems where the existing approaches become increasingly impractical. In addition, since our approaches can be optimized using simple linear regression, they are easy to implement and theoretical guarantees can be provided. We test our approaches for American option pricing on Black--Scholes, Heston and rough Heston models and for optimally stopping a fractional Brownian motion. In all cases, our algorithms outperform the state-of-the-art and other relevant machine learning approaches in terms of computation time while achieving comparable results. Moreover, we show that they can also be used to efficiently compute Greeks of American options."], "authors": "Calypso Herrera"},
{"Title": "Probabilistic shadowing in linear skew products", "abs": ["We investigate the probability of shadowing of a random finite pseudotrajectory by an exact trajectory for linear skew products. We describe general conditions under which a random pseudotrajectory can be shadowed with polynomial (with respect to its length) precision with high probability. Examples satisfying that general condition are continuous linear skew products over Bernoulli shift, doubling map on a circle, and any Anosov linear map on a torus. The main tool used in the proof is Cramer's large deviation theorem."], "authors": "Grigorii Monakov"},
{"Title": "Exceptional times for the instantaneous propagation of superprocess", "abs": ["For a Dawson-Watanabe superprocess $X$ on $\\mathbb{R}^d$, it is shown in Perkins (1990) that if the underlying spatial motion belongs to a certain class of Lévy processes that admit jumps, then with probability one the closed support of $X_t$ is the whole space for almost all $t>0$ before extinction, the so-called ``instantaneous propagation'' property. In this paper for superprocesses on $\\mathbb{R}^1$ whose spatial motion is the symmetric stable process of index $\\alpha \\in (0,2/3)$, we prove that there exist exceptional times at which the support is compact and nonempty. Moreover, we show that the set of exceptional times is dense with full Hausdorff dimension. Besides, we prove that near extinction, the support of the superprocess is concentrated arbitrarily close to the distinction point, thus upgrading the corresponding results in Tribe (1992) from $\\alpha \\in (0,1/2)$ to $\\alpha \\in (0,2/3)$, and we further show that the set of such exceptional times also admits a full Hausdorff dimension."], "authors": "Jieliang Hong"},
{"Title": "Exceptional times for the instantaneous propagation of superprocess", "abs": ["For a Dawson-Watanabe superprocess $X$ on $\\mathbb{R}^d$, it is shown in Perkins (1990) that if the underlying spatial motion belongs to a certain class of Lévy processes that admit jumps, then with probability one the closed support of $X_t$ is the whole space for almost all $t>0$ before extinction, the so-called \"instantaneous propagation\" property. We prove that exceptional times exist at which the support is compact and nonempty. Moreover, the set of exceptional times is dense and its Hausdorff dimension equals $1$."], "authors": "Jieliang Hong"},
{"Title": "Probabilistic Limit Theorems Induced by the Zeros of Polynomials", "abs": ["Sequences of discrete random variables are studied whose probability generating functions are zero-free in a sector of the complex plane around the positive real axis. Sharp bounds on the cumulants of all orders are stated, leading to Berry-Esseen bounds, moderate deviation results, concentration inequalities and mod-Gaussian convergence. In addition, an alternate proof of the cumulant bound with improved constants for a class of polynomials all of whose roots lie on the unit circle is provided. A variety of examples is discussed in detail."], "authors": "Nils Heerten"},
{"Title": "Infinite geodesics, competition interfaces and the second class particle in the scaling limit", "abs": ["We establish fundamental properties of infinite geodesics and competition interfaces in the directed landscape. We construct infinite geodesics in the directed landscape, establish their uniqueness and coalescence, and define Busemann functions. We then define competition interfaces in the directed landscape. We prove the second class particle in tasep converges under KPZ scaling to a competition interface. Under suitable conditions, we show the competition interface has an asymptotic direction, analogous to the speed of a second class particle, and determine its law. Moreover, we prove the competition interface has an absolutely continuous law on compact sets with respect to infinite geodesics."], "authors": "Mustazee Rahman"},
{"Title": "A resolution theorem for extriangulated categories with applications to the index", "abs": ["Quillen's Resolution Theorem in algebraic $K$-theory provides a powerful computational tool for calculating $K$-groups of exact categories. At the level of $K_0$, this result goes back to Grothendieck. In this article, we first establish an extriangulated version of Grothendieck's Resolution Theorem. Second, we use this Extriangulated Resolution Theorem to gain new insight into the index theory of triangulated categories. Indeed, we propose an index with respect to an extension-closed subcategory $\\mathscr{N}$ of a triangulated category $\\mathscr{C}$ and we prove an additivity formula with error term. Our index recovers the index with respect to a contravariantly finite, rigid subcategory $\\mathscr{X}$ defined by Jørgensen and the second author, as well as an isomorphism between $K_0^{\\mathsf{sp}}(\\mathscr{X})$ and the Grothendieck group of a relative extriangulated structure on $\\mathscr{C}$ when $\\mathscr{X}$ is cluster tilting. In addition, we generalize and enhance some results of Fedele. Our perspective allows us to remove certain restrictions and simplify some arguments."], "authors": "Yasuaki Ogawa"},
{"Title": "Characters of the unitriangular group and the Mackey method", "abs": ["Let $U$ be the unitriangular group over a finite field. We consider an interesting class of irreducible complex characters of $U$, so-called characters of depth 2. This is a next natural step after characters of maximal and submaximal dimension, whose description is already known. We explicitly describe the support of a character of depth 2 by a system of defining algebraic equations. After that, we calculate the value of such a character on an element from the support. The main technical tool used in the proofs is the Mackey little group method for semidirect products."], "authors": "Mikhail Ignatev"},
{"Title": "The Wiener index and the Wiener Complexity of the zero-divisor graph of a ring", "abs": ["We calculate the Wiener index of the zero-divisor graph of a finite semisimple ring. We also calculate the Wiener complexity of the zero-divisor graph of a finite simple ring and find an upper bound for the Wiener complexity in the semisimple case."], "authors": "David Dolžan"},
{"Title": "Algebras of one-sided subshifts over arbitrary alphabets", "abs": ["We introduce two algebras associated with a subshift over an arbitrary alphabet. One is unital and the other not necessarily. We focus on the unital case and describe a conjugacy between Ott-Tomforde-Willis subshifts in terms of a homeomorphism between the Stone duals of suitable Boolean algebras, and in terms of a diagonal-preserving isomorphism of the associated unital algebras. For this, we realise the unital algebra associated with a subshift as a groupoid algebra and as a partial skew group ring."], "authors": "Giuliano Boava"},
{"Title": "Isospectral connections, ergodicity of frame flows, and polynomial maps between spheres", "abs": ["We show that on closed negatively curved Riemannian manifolds with simple length spectrum, the spectrum of the Bochner Laplacian determines both the isomorphism class of the vector bundle and the connection up to gauge under a low-rank assumption. We also show that flows of frames on low-rank frame bundles extending the geodesic flow in negative curvature are ergodic whenever the bundle admits no holonomy reduction. This is achieved by exhibiting a link between these problems and the classification of polynomial maps between spheres in real algebraic geometry."], "authors": "Mihajlo Cekić"},
{"Title": "Volkov solutions for relativistic magnetized plasma in strong field quantum electrodynamics regime", "abs": ["This study shows the dynamics of relativistic electrons in terms of Dirac equation solutions when an ultra-intense short laser pulse of intensity $\\ge 10^{23} {", "^{-2}}$ propagates through magnetized dense plasma ($B_0\\approx {1MG})$. The interaction dynamics is analyzed near the strong-field quantum electrodynamics (SF-QED) regime. Our study finds new solutions in plasma media considering the effects of the re-normalized mass of relativistic electrons and the nonzero effective mass of accelerated photons. We have provided a general method for constructing exact solutions of the Dirac relativistic equation that correctly explains the dynamics of electrons in the strongly magnetized plasma medium. The modified solutions of the Dirac equation for one electron are derived and compared to the Volkov solutions. The new solutions are a basis for a feasible explanation of quantum attributes of relativistic electrons in a strong electromagnetic field of very short ultra-intense laser pulses with intensity near Schwinger field intensity. The solutions are called new Volkov solutions in a plasma medium. These solutions can be used to understand better the theory of quantum radiation reaction for the next-generation laser-plasma accelerator. Our results show that the Volkov solutions are not applicable in a magnetized plasma medium"], "authors": "B.S. Sharma"},
{"Title": "Molecular Dynamics Study of Electro-Osmotic Flow in a Nanochannel with Molybdenum Disulfide Walls", "abs": ["The electro-osmotic flow (EOF) in a neutral system consisting of an aqueous NaCl solution confined in a nanochannel with two parallel Molybdenum disulfide ($\\textrm{MoS}_{\\textrm{2}}$) walls and in the presence of an external electric field parallel to the channel walls, is investigated for the first time. The results indicate that the thickness of the Stern layer grows as the negative electric surface charge density on the nanochannel walls increases. The Stern layer becomes thinner as the salt concentration is increased. Moreover, the EOF occurs under the no-slip condition on the walls. In addition, by increasing the surface charge density the average of the flow velocity across the nanochannel initially grows (Debye--H$\\ddot{\\textrm{u}}$ckel regime) and reaches its maximum value. Then, by further increasing the surface charge density the water flow rate decreases (intermediate regime), and gets the zero value and becomes negative (reverse flow regime) at even larger values of the surface charge densities. Comparing the results of the previous work wherein the channels are composed of the black phosphorene walls with those of the present study for a channel composed of $\\textrm{MoS}_{\\textrm{2}}$ surfaces, show that for the latter case the reverse flow occurs at a lower surface charge density and with a greater value of the peak velocity with respect to the change in the surface charge density for the former case."], "authors": "S.M.Kazem Manzoorolajdad"},
{"Title": "Giant microwave-optical Kerr nonlinearity via Rydberg excitons in cuprous oxide", "abs": ["Microwave-optical conversion is key to future networks of quantum devices, such as those based on superconducting technology. Conversion at the single quantum level requires strong nonlinearity, high bandwidth, and compatibility with a millikelvin environment. A large nonlinearity is observed in Rydberg atoms, but combining atomic gases with dilution refrigerators is technically challenging. Here we demonstrate that a strong microwave-optical nonlinearity in a cryogenic, solid-state system by exploiting Rydberg states of excitons in \\cuprite. We measure a microwave-optical cross-Kerr coefficient of $B_0 = 0.022 \\pm 0.008 $ m V$^{-2}$ at 4~K, which is several orders of magnitude larger than other solid-state systems. Our results highlight the potential of Rydberg excitons for nonlinear optics, and form the basis for a microwave-optical frequency converter based on Cu$_2$O."], "authors": "Jon D. Pritchett"},
{"Title": "Area Selective Chemical Vapor Deposition of Gold by Electron Beam Seeding", "abs": ["Chemical vapour deposition (CVD) is an established method for producing high-purity thin films, but it typically necessitates the pre- and post-processing of a mask to produce structures. This paper presents a novel maskless patterning technique that enables area selective CVD of gold. A focused electron beam is used to decompose the metal-organic precursor Au(acac)Me$_2$ locally, thereby creating an autocatalytically active seed layer for subsequent CVD with the same precursor. The procedure can be included in the same CVD cycle without the need for clean room lithographic processing. Moreover, it operates at low temperatures of 80 °C, over 200 K lower than standard CVD temperatures for this precursor, reducing thermal load on the specimen. Given that electron beam seeding operates on any even moderately conductive surface, the process does not constrain device design. This is demonstrated by the example of vertical nanostructures with high aspect ratios of around 40:1 and more. Written using a focused electron beam and the same precursor, these nanopillars exhibit catalytically active nuclei on their surface. Furthermore, they allow for the first time the precise determination of the local temperature increase caused by the writing of nanostructures with an electron beam."], "authors": "Aleksei Tsarapkin"},
{"Title": "Forecasting Trends in Food Security: a Reservoir Computing Approach", "abs": ["Early warning systems are an essential tool for effective humanitarian action. Advance warnings on impending disasters facilitate timely and targeted response which help save lives, livelihoods, and scarce financial resources. In this work we present a new quantitative methodology to forecast levels of food consumption for 60 consecutive days, at the sub-national level, in four countries: Mali, Nigeria, Syria, and Yemen. The methodology is built on publicly available data from the World Food Programme's integrated global hunger monitoring system which collects, processes, and displays daily updates on key food security metrics, conflict, weather events, and other drivers of food insecurity across 90 countries (", "). In this study, we assessed the performance of various models including ARIMA, XGBoost, LSTMs, CNNs, and Reservoir Computing (RC), by comparing their Root Mean Squared Error (RMSE) metrics. This comprehensive analysis spanned classical statistical, machine learning, and deep learning approaches. Our findings highlight Reservoir Computing as a particularly well-suited model in the field of food security given both its notable resistance to over-fitting on limited data samples and its efficient training capabilities. The methodology we introduce establishes the groundwork for a global, data-driven early warning system designed to anticipate and detect food insecurity."], "authors": "Joschka Herteux"},
{"Title": "Restructuring a passive colloidal suspension using a rotationally driven particle", "abs": ["The interactions between passive and active/driven particles have been explored as a means to modify structures in solutions. Often times hydrodynamics plays a significant role in explaining emergent patterns in such mixtures. In this study, we demonstrate that strong advective flows generated by a single driven rotating particle near a surface can induce large-scale structural rearrangements in a passive suspension. The resulting emergent pattern exhibits an accumulation area in front of the driven particle and a wake along its trajectory. Notably, the center of the accumulation is found at a distance from the driven particle. Through experiments and Stokesian dynamics simulations, we show that the driven-passive interaction is solely determined by the heights of both particle types, which determines the shape and the size of the pattern. By modulating the height of the driven particle we can control the extension of the emergent pattern from 3 to 6 times its diameter ($\\sim 12 \\, \\mu \\mathrm{m}$)."], "authors": "Shih-Yuan Chen"},
{"Title": "The role of interface design on prompt-mediated creativity in Generative AI", "abs": ["Generative AI models for the creation of images is becoming a staple in the toolkit of digital artists and visual designers. The interaction with these systems is mediated by prompting, a process in which users write a short text to describe the desired image's content and style. The study of prompts offers an unprecedented opportunity to gain insight into the process of human creativity, yet our understanding of how people use them remains limited. We analyze more than 145,000 prompts from the logs of two Generative AI platforms (Stable Diffusion and Pick-a-Pic) to shed light on how people explore new concepts over time, and how their exploration might be influenced by different design choices in human-computer interfaces to Generative AI. We find that users exhibit a tendency towards exploration of new topics over exploitation of concepts visited previously. However, a comparative analysis of the two platforms, which differ both in scope and functionalities, reveals that the introduction of features diverting user focus from prompting and providing instead shortcuts for generating new image variants with simple clicks is associated with a considerable reduction in both exploration of novel concepts and detail in the submitted prompts. These results carry direct implications for the design of human interfaces to Generative AI and raise new questions regarding how the process of prompting should be aided in ways that best support creativity."], "authors": "Maddalena Torricelli"},
{"Title": "Convolutional Neural Networks for Segmentation of Malignant Pleural Mesothelioma: Analysis of Probability Map Thresholds (CALGB 30901, Alliance)", "abs": ["Malignant pleural mesothelioma (MPM) is the most common form of mesothelioma. To assess response to treatment, tumor measurements are acquired and evaluated based on a patient's longitudinal computed tomography (CT) scans. Tumor volume, however, is the more accurate metric for assessing tumor burden and response. Automated segmentation methods using deep learning can be employed to acquire volume, which otherwise is a tedious task performed manually. The deep learning-based tumor volume and contours can then be compared with a standard reference to assess the robustness of the automated segmentations. The purpose of this study was to evaluate the impact of probability map threshold on MPM tumor delineations generated using a convolutional neural network (CNN). Eighty-eight CT scans from 21 MPM patients were segmented by a VGG16/U-Net CNN. A radiologist modified the contours generated at a 0.5 probability threshold. Percent difference of tumor volume and overlap using the Dice Similarity Coefficient (DSC) were compared between the standard reference provided by the radiologist and CNN outputs for thresholds ranging from 0.001 to 0.9. CNN annotations consistently yielded smaller tumor volumes than radiologist contours. Reducing the probability threshold from 0.5 to 0.1 decreased the absolute percent volume difference, on average, from 43.96% to 24.18%. Median and mean DSC ranged from 0.58 to 0.60, with a peak at a threshold of 0.5; no distinct threshold was found for percent volume difference. No single output threshold in the CNN probability maps was optimal for both tumor volume and DSC. This work underscores the need to assess tumor volume and spatial overlap when evaluating CNN performance. While automated segmentations may yield comparable tumor volumes to that of the reference standard, the spatial region delineated by the CNN at a specific threshold is equally important."], "authors": "Mena Shenouda"},
{"Title": "Integration of Swin UNETR and statistical shape modeling for a semi-automated segmentation of the knee and biomechanical modeling of articular cartilage", "abs": ["Simulation studies like finite element (FE) modeling provide insight into knee joint mechanics without patient experimentation. Generic FE models represent biomechanical behavior of the tissue by overlooking variations in geometry, loading, and material properties of a population. On the other hand, subject-specific models include these specifics, resulting in enhanced predictive precision. However, creating such models is laborious and time-intensive. The present study aimed to enhance subject-specific knee joint FE modeling by incorporating a semi-automated segmentation algorithm. This segmentation was a 3D Swin UNETR for an initial segmentation of the femur and tibia, followed by a statistical shape model (SSM) adjustment to improve surface roughness and continuity. Five hundred and seven magnetic resonance images (MRIs) from the Osteoarthritis Initiative (OAI) database were used to build and validate the segmentation model. A semi-automated FE model was developed using this semi-automated segmentation. On the other hand, a manual FE model was developed through manual segmentation (i.e., the gold standard approach). Both FE models were subjected to gait loading. The predicted mechanical response of manual and semi-automated FE models were compared. In the result, our semi-automated segmentation achieved Dice similarity coefficient (DSC) over 98% for both femur and tibia. The mechanical results (max principal stress, max principal strain, fluid pressure, fibril strain, and contact area) showed no significant differences between the manual and semi-automated FE models, indicating the effectiveness of the proposed semi-automated segmentation in creating accurate knee joint FE models. (", ")."], "authors": "Reza Kakavand"},
{"Title": "Photo-acoustic spectroscopy using a quantum cascade laser (QCL) for analysis of ammonia in water solutions", "abs": ["Ammonia (NH$_3$) toxicity, stemming from nitrification, can adversely affect aquatic life and influence the taste and odor of drinking water. This underscores the necessity for highly responsive and accurate sensors to continuously monitor NH$_3$ levels in water, especially in complex environments where reliable sensors have been lacking until this point. Herein, we detail the development of a sensor comprising a compact and selective analyzer with low gas consumption and a timely response, based on photoacoustic spectroscopy. This, combined with an automated liquid sampling system, enables the precise detection of ammonia traces in water. The sensor system incorporates a state-of-the art quantum cascade laser as the excitation source emitting at 9 \\textmu m in resonance with the absorption line of NH$_3$ located at 1103.46 cm$^{-1}$. Our instrument demonstrated detection sensitivity at low ppm level for total ammonia nitrogen with response times less than 60 seconds. For the sampling system, an ammonia stripping solution was designed resulting in a prompt full measurement cycle (6.35 mins). A further evaluation of the sensor within a pilot study showed good reliability and agreement with the reference method for real water samples, confirming the potential of our NH$_3$ analyzer for water-quality monitoring applications."], "authors": "Apostolos Apostolakis"},
{"Title": "Polymeric Liquids in Nanoporous Photonic Structures: From Precursor Film Spreading to Imbibition Dynamics at the Nanoscale", "abs": ["Polymers are known to wet nanopores with high surface energy through an atomically thin precursor film followed by slower capillary filling. We present here light interference spectroscopy using a nanoporous membrane-based chip that allows us to observe the dynamics of these phenomena in situ with sub-nanometer spatial and milli- to microsecond temporal resolution. The device consists of a mesoporous silicon film (average pore size 6 nm) with an integrated photonic crystal, which permits to simultaneously measure the phase shift of the thin-film interference and the resonance of the photonic crystal upon imbibition. For a styrene dimer, we find a flat fluid front without a precursor film, while the pentamer forms an expanding molecular thin film moving in front of the menisci of the capillary filling. These different behaviors are attributed to a significantly faster pore-surface diffusion compared to the imbibition dynamics for the pentamer and vice versa for the dimer. In addition, both oligomers exhibit anomalously slow imbibition dynamics, which could be explained by apparent viscosities of six and eleven times the bulk value, respectively. However, a more consistent description of the dynamics is achieved by a constriction model that emphasizes the increasing importance of local undulations in the pore radius with the molecular size and includes a sub-nanometer hydrodynamic dead, immobile zone at the pore wall, but otherwise uses bulk fluid parameters. Overall, our study illustrates that interferometric, opto-fluidic experiments with nanoporous media allow for a remarkably detailed exploration of the nano-rheology of polymeric liquids."], "authors": "Guido Dittrich"},
{"Title": "Flow Matching Beyond Kinematics: Generating Jets with Particle-ID and Trajectory Displacement Information", "abs": ["We introduce the first generative model trained on the JetClass dataset. Our model generates jets at the constituent level, and it is a permutation-equivariant continuous normalizing flow (CNF) trained with the flow matching technique. It is conditioned on the jet type, so that a single model can be used to generate the ten different jet types of JetClass. For the first time, we also introduce a generative model that goes beyond the kinematic features of jet constituents. The JetClass dataset includes more features, such as particle-ID and track impact parameter, and we demonstrate that our CNF can accurately model all of these additional features as well. Our generative model for JetClass expands on the versatility of existing jet generation techniques, enhancing their potential utility in high-energy physics research, and offering a more comprehensive understanding of the generated jets."], "authors": "Joschka Birk"},
{"Title": "Anomaly Detection in Collider Physics via Factorized Observables", "abs": ["To maximize the discovery potential of high-energy colliders, experimental searches should be sensitive to unforeseen new physics scenarios. This goal has motivated the use of machine learning for unsupervised anomaly detection. In this paper, we introduce a new anomaly detection strategy called FORCE: factorized observables for regressing conditional expectations. Our approach is based on the inductive bias of factorization, which is the idea that the physics governing different energy scales can be treated as approximately independent. Assuming factorization holds separately for signal and background processes, the appearance of non-trivial correlations between low- and high-energy observables is a robust indicator of new physics. Under the most restrictive form of factorization, a machine-learned model trained to identify such correlations will in fact converge to the optimal new physics classifier. We test FORCE on a benchmark anomaly detection task for the Large Hadron Collider involving collimated sprays of particles called jets. By teasing out correlations between the kinematics and substructure of jets, our method can reliably extract percent-level signal fractions. This strategy for uncovering new physics adds to the growing toolbox of anomaly detection methods for collider physics with a complementary set of assumptions."], "authors": "Eric M. Metodiev"},
{"Title": "Nanocolumnar Material Platforms:Universal structural parameters revealed from optical anisotropy", "abs": ["Nanostructures represent a frontier where meticulous attention to the control and assessment of structural dimensions becomes a linchpin for their seamless integration into diverse technological applications. By using integrative and comprehensive methodical series of studies, we investigate the evolution of the depolarization factors in the anisotropic Bruggeman effective medium approximation, that are extremely sensitive to the changes in critical dimensions of the nanostructure platforms. To this end, we fabricate spatially coherent highly-ordered slanted nanocolumns from zirconia, silicon, titanium, and permalloy on silicon substrates with varying column lengths using glancing angle deposition. In tandem, broad-spectral range Mueller matrix spectroscopic ellipsometry data, spanning from the near-infrared to the vacuum ultraviolet (0.72 eV to 6.5 eV), is analyzed with a best-match model approach based on the anisotropic Bruggeman effective medium theory. We thereby extracted the anisotropic optical properties including complex dielectric function, birefringence, and dichroism. Most notably, our research unveils a universal, material-independent inverse relationship between depolarization factors and column length. We envision that the presented universal relationship will permit accurate prediction of optical properties of nanocolumnar thin films improving their integration and optimization for optoelectronic and photonic device applications."], "authors": "Ufuk Kilic"},
{"Title": "CompuCell3D Model of Cell Migration Reproduces Chemotaxis", "abs": ["Chemotaxis combines three processes: directional sensing, polarity reorientation and migration. Directed migration plays an important role in immune response, metastasis, wound healing and development. To describe chemotaxis, we extend a previously published computational model of a 3D single cell, that presents three compartments (lamellipodium, nucleus and cytoplasm), whose migration on a flat surface quantitatively describes experiments. The simulation is built in the framework of CompuCell3D, an environment based on the Cellular Potts Model. In our extension, we treat chemotaxis as a compound process rather than a response to a potential force. We propose robust protocols to measure cell persistence, drift speed, terminal speed, chemotactic efficiency, taxis time, and we analyse cell migration dynamics in the cell reference frame from position and polarization recordings through time. Our metrics can be applied to experimental results and allow quantitative comparison between simulations and experiments. We found that our simulated cells exhibit a trade-off between polarization stability and chemotactic efficiency. Specifically, we found that cells with lower protrusion forces and smaller lamellipodia exhibit an increased ability to undergo chemotaxis. We also noticed no significant change in cell movement due to external chemical gradient when analysing cell displacement in the cell reference frame. Our results demonstrate the importance of measuring cell polarity throughout the entire cell trajectory, and treating velocity quantities carefully when cell movement is diffusive at short time intervals. The simulation we developed is adequate to the development of new measurement protocols, and it helps paving the way to more complex multicellular simulations to model collective migration and their interaction with external fields, which are under development on this date."], "authors": "Pedro C. Dal-Castel"},
{"Title": "Effects of three-dimensional slit geometry on flashback of premixed hydrogen flames in perforated burners", "abs": ["Given the growing interest in hydrogen as a clean fuel for residential and commercial heating, there is an increasing need for the development of new designs for end-user devices, which must ensure both efficiency and safety. In this study, 3D simulations are used for the first time to investigate how the length of slits impacts the flashback limits for hydrogen-premixed flames in perforated burners, commonly employed in end-user devices such as condensing boilers. Flashback limits are computed for hydrogen flames at three equivalence ratios ($\\phi=0.6$, $0.8$, and $1.0$), investigating a circular hole and slits with increasing lengths up to 8 mm. Both transient and steady-state simulations are conducted to comprehensively capture the flashback dynamics and investigate a broad range of parameter variations. The results are compared with 2D simulations, which are found to underestimate considerably the flashback velocities. For sufficiently long slits, it is observed that the flashback velocity is practically unaffected by the slit length, and an explanation is given based on the observation of the initiation of flashback at the far ends of the slit. A significant focus is posed on preferential diffusion effects, elucidating their role in the importance of slit extremities in flashback dynamics."], "authors": "Filippo Fruzza"},
{"Title": "Resilience in Highways: Proposal of Roadway Redundancy Indicators and Application in Segments of the Brazilian Network", "abs": ["With the growing realization that transport systems must operate satisfactorily not only in typical situations, but also in adverse circumstances, ensuring redundancies in road systems has gained crucial importance. In this context, several methods have been proposed for measuring the vulnerabilities and resilience of transport systems. However, a simple metric to understand and quantify the degree of redundancy of a given road segment is still necessary, mainly to guide the responsible bodies regarding the need for intervention or special care with certain sections of the system. Thus, this paper proposes a redundancy indicator based on network analyses in the vicinity of an element. The proposed indicator was first calculated on nine application examples and then on a substantial sample of the Brazilian road network (~10% of segments). The results demonstrate that the indicator can satisfactorily describe the variety of cases in the Brazilian network, capturing cases where there is significant redundancy in the elements, as in some regions of the Southeast and South; or cases of very low redundancy, such as the sparse grid in the north of the country. It was also verified that the indicator has a particular sensitivity to parameters of the defined function, requiring further research for an acceptable calibration."], "authors": "André Borgato Morelli"},
{"Title": "On the performance of HRPA(D) for NMR spin-spin coupling constants: Smaller molecules, aromatic and fluoroaromatic compounds", "abs": ["In this study, the performance of the doubles-corrected higher random-phase approximation (HRPA(D)) has been investigated in calculations of NMR spin-spin coupling constants (SSCCs) for 58 molecules with the experimental values used as the reference values. HRPA(D) is an approximation to the second-order polarization propagator approximation (SOPPA), and is therefore computationally less expensive than SOPPA. HRPA(D) performs comparable and sometimes even better than SOPPA, and therefore when calculating SSCCs it should be considered as an alternative to SOPPA. Furthermore, it was investigated whether a CCSD(T) or MP2 geometry optimization was optimal for a SOPPA and a HRPA(D) SSCCs calculation for 8 smaller molecules. CCSD(T) is the optimal geometry optimization for the SOPPA calculation, and MP2 was optimal for the HRPA(D) SSCC calculations."], "authors": "Louise Møller Jessen"},
{"Title": "Ensemble variational Monte Carlo for optimization of correlated excited state wave functions", "abs": ["Variational Monte Carlo methods have recently been applied to the calculation of excited states; however, it is still an open question what objective function is most effective. A promising approach is to optimize excited states using a penalty to minimize overlap with lower eigenstates, which has the drawback that states must be computed one at a time. We derive a general framework for constructing objective functions with minima at the the lowest $N$ eigenstates of a many-body Hamiltonian. The objective function uses a weighted average of the energies and an overlap penalty, which must satisfy several conditions. We show this objective function has a minimum at the exact eigenstates for a finite penalty, and provide a few strategies to minimize the objective function. The method is demonstrated using ab initio variational Monte Carlo to calculate the degenerate first excited state of a CO molecule."], "authors": "William A. Wheeler"},
{"Title": "How the zebra got its stripes: Curvature-dependent diffusion orients Turing patterns on 3D surfaces", "abs": ["Many animals have patterned fur, feathers, or scales, such as the stripes of a zebra. Turing models, or reaction-diffusion systems, are a class of mathematical models of interacting species that have been successfully used to generate animal-like patterns for many species. When diffusion of the inhibitor is high enough relative to the activator, a diffusion-driven instability can spontaneously form patterns. However, it is not just the type of pattern but also the orientation that matters, and it remains unclear how this is done in practice. Here, we propose a mechanism by which the curvature of the surface influence the rate of diffusion, and can recapture the correct orientation of stripes on models of a zebra and of a cat in numerical simulations. Previous work has shown how anisotropic diffusion can give stripe forming reaction-diffusion systems a bias in orientation. From the observation that zebra stripes run around the direction of highest curvature, that is around the torso and legs, we apply this result by modifying the diffusion rate in a direction based on the local curvature. These results show how local geometry can influence the reaction dynamics to give robust, global-scale patterns. Overall, this model proposes a coupling between the system geometry and reaction-diffusion dynamics that can give global control over the patterning by using only local curvature information. Such a model can give shape and positioning information in animal development without the need for spatially dependent morphogen gradients."], "authors": "Michael F. Staddon"},
{"Title": "Global Public Goods: The Case for the Global Earth Observation System of Systems", "abs": ["The debate surrounding the provision of welfare by state institutions has been widely discussed in the field of political economics since the 1930s. Related research also focuses on welfare supply at an international system level. This article assesses whether international cooperation in the area of sharing remote sensing data leads to the supply of global public goods, which to date has not yet been discussed in related scholarly literature. The supply of global public goods is assessed within the GEO international regime and leads to the use of the non-rivalrous GEOSS, which can be accessed by every socio-economic group in every UN member country including future generations. However, providing the benefit of GEOSS is not always favourable because of the low number of financially participating consumers."], "authors": "Miloslav Machon"},
{"Title": "The Influence of Epistemic Communities on International Political Negotiations about the Space Debris Problem", "abs": ["Since the 1970's the debate about the rising importance of transnational relations has existed in international relations. Apart from states, related research also focuses on other actors, including epistemic communities. The article uses the concept of epistemic communities and finds whether the activity of epistemic communities determines the process of the international management of outer space in the case of the political negotiations relating to space debris in UNCOPUOS and UNOOSA. The activity of epistemic communities exists in the political negotiations relating to space debris in UNCOPUOS and UNOOSA, but it has not been reflected in the related scholarly literature. Epistemic communities from the non-governmental organizations IAF, COSPAR and IISL contributed to setting the space debris problem on the agenda of UNCOPUOS. Also, under the influence of epistemic communities from the governmental organization IADC, UNCOPUOS adopted guidelines preventing the creation of further amounts of space debris."], "authors": "Miloslav Machon"},
{"Title": "Correlations in a weakly interacting two-dimensional random flow", "abs": ["We analytically examine fluctuations of vorticity excited by an external random force in two-dimensional fluid. We develop the perturbation theory enabling one to calculate nonlinear corrections to correlation functions of the flow fluctuations found in the linear approximation. We calculate the correction to the pair correlation function and the triple correlation function. It enables us to establish the criterion of validity of the perturbation theory for different ratios of viscosity and bottom friction. We find that the corrections to the second moment are anomalously weak in the cases of small bottom friction and of small viscosity and rely the weakness to the energy balance and to the enstrophy balance. We demonstrate that at small bottom friction the triple correlation function is characterized by a universal scaling behavior in some region of lengths. The developed perturbation method was verified and confirmed by direct numerical simulations."], "authors": "I.V. Kolokolov"},
{"Title": "Active Loss Engineering in Vanadium Dioxide Based BIC Metasurfaces", "abs": ["Metasurfaces have unlocked significant advancements across photonics, yet their efficient active control remains challenging. The active materials required often lack continuous tunability, exhibit inadequate refractive index (RI) changes, or suffer from high losses. These aspects pose an inherent limitation for resonance-shifting based switching: when RI changes are small, the resulting shift is also minor. Conversely, high RI changes typically come with high intrinsic losses necessitating broad modes because narrow ones cannot tolerate such losses. Therefore, larger spectral shifts are required to effectively detune the modes. This paper introduces a novel active metasurface approach that converts the constraint of high intrinsic losses into a beneficial feature. This is achieved by controlling the losses in a hybrid vanadium dioxide (VO$_{2}$) - silicon metasurface, supporting symmetry-protected bound states in the continuum (BICs) within the infrared spectrum. By leveraging the temperature-controlled losses in VO$_{2}$ and combining them with the inherent far-field-coupling tunability of BICs, we gain unprecedented precision in independently controlling both the radiative and nonradiative losses of the resonant system. Our dual-control mechanism allows us to optimize our metasurfaces and we experimentally demonstrate quality factors above 200, a maximum reflectance amplitude of 90%, a relative switching contrast of 78%, and continuous tuning from under- to over-coupling within the infrared spectral range. This study provides a foundation for experimentally and technologically simple, fine-tunable, active metasurfaces for applications ranging from molecular sensors to filters and optical modulators."], "authors": "Andreas Aigner"},
{"Title": "MoSi Superconducting Nanowire Single-Photon Detectors on GaAs for On-Chip Integration", "abs": ["We report on MoSi-based superconducting nanowire single-photon detectors on a gallium arsenide substrate. MoSi deposited on a passivated GaAs surface has the same critical temperature as MoSi deposited on silicon. The critical temperature decreases slightly on depositing MoSi directly on the native oxide of GaAs. Hence, MoSi works well as a thin-film superconductor on GaAs. We propose that the amorphous structure of MoSi ensures compatibility with the GaAs matrix. Superconducting nanowire single-photon detectors (SNSPDs) are fabricated with MoSi on GaAs using a meander-wire design. The SNSPD metrics are very similar to those of devices fabricated with the same procedure on a silicon substrate. We observe a plateau in the response-versus-bias curve signalling a saturated internal quantum efficiency. The plateau remains even at an elevated temperature, 2.2 K, at a wavelength of 980 nm. We achieve a timing jitter of 50 ps and a recovery time of 29 ns. These results point to the promise of integrating MoSi SNSPDs with GaAs photonic circuits."], "authors": "M. Erbe"},
{"Title": "An investigation of information flux between turbulent boundary layer and porous medium", "abs": ["The interaction between boundary layer turbulence and a porous layer is the cornerstone to the interface engineering. In this study, the spatial resolved transfer entropy is used to assess the asymmetry of the causal interaction next to a permeable wall. The analysis was based on pore-resolved direct numerical simulation of turbulent channel flow over a cylinder array. The spatial map of transfer entropy reveals the information flux between the porous medium and arbitrary nearby position."], "authors": "Xu Chu"},
{"Title": "Nanowire Array Breath Acetone Sensor for Diabetes Monitoring", "abs": ["Diabetic ketoacidosis (DKA) is a life-threatening acute complication of diabetes in which ketone bodies accumulate in the blood. Breath acetone (a ketone) directly correlates with blood ketones, such that breath acetone monitoring could be used to improve safety in diabetes care. In this work, we report the design and fabrication of a chitosan/Pt/InP nanowire array based chemiresistive acetone sensor. By implementing chitosan as a surface functionalization layer and a Pt Schottky contact for efficient charge transfer processes and photovoltaic effect, self-powered, highly selective acetone sensing has been achieved. This sensor has an ultra-wide detection range from sub-ppb to >100,000 ppm levels at room temperature, incorporating the range from healthy individuals (300-800 ppb) to those at high-risk of DKA (> 75 ppm). The nanowire sensor has been further integrated into a handheld breath testing prototype, the Ketowhistle, which can successfully detect different ranges of acetone concentrations in simulated breath. The Ketowhistle demonstrates immediate potential for non-invasive ketone testing and monitoring for persons living with diabetes, in particular for DKA prevention."], "authors": "Shiyu Wei"},
{"Title": "Pathways to explosive transitions in interacting contagion dynamics", "abs": ["Yet often neglected, dynamical interdependencies between concomitant contagion processes can alter their intrinsic equilibria and bifurcations. A particular case of interest for disease control is the emergence of explosive transitions in epidemic dynamics coming from their interactions with other simultaneous processes. To address this problem, here we propose a framework coupling a standard epidemic dynamics with another contagion process, presenting a tunable parameter shaping the nature of its transitions. Our model retrieves well-known results in the literature, such as the existence of first-order transitions arising from the mutual cooperation of epidemics or the onset of explosive transitions when social contagions unidirectionally drive epidemics. We also reveal that negative feedback loops between simultaneous dynamical processes might suppress explosive phenomena, thus increasing systems robustness against external perturbations. Our results render a general perspective towards finding different pathways to explosive phenomena from the interaction of contagion processes."], "authors": "Santiago Lamata-Otín"},
{"Title": "Nonlinear interaction of two cross-propagating plane waves", "abs": ["An ideal contrast-enhanced ultrasound image should display microbubble-induced nonlinearities while avoiding wave propagation nonlinearities. One of the most successful ultrasound pulse sequences to disentangle these nonlinear effects relies on the transmission of cross-propagating plane waves. However, theory describing the noncollinear nonlinear interaction of two finite plane waves has not been fully developed and a better understanding of these effects would improve contrast-enhanced ultrasound imaging further. Here, local nonlinear interactions at the intersection of two plane-waves are investigated by extending the Westervelt equation with a term including the Lagrangian density. The Iterative Nonlinear Contrast Source (INCS) method is employed to numerically solve this full nonlinear wave equation for two 3D finite cross-propagating pulsed plane waves. In addition, analytical expressions for the cross-propagation of two infinite continuous plane waves are derived. Numerical results obtained with INCS show good agreement with the analytical expressions. Overall, the generated results show that the pressure associated with local nonlinear effects is two orders of magnitude lower than the pressure associated with global nonlinear effects. Local nonlinear effects are therefore expected to be negligible in the context of single-shot ultrasound imaging, but they may influence approaches that subtract pressure fields such as amplitude modulation or pulse inversion."], "authors": "A. Matalliotakis"},
{"Title": "Suppression of the Talbot effect in Fourier transform acousto-optic imaging", "abs": ["We report on the observation and correction of an imaging artifact attributed to the Talbot effect in the context of acousto-optic imaging using structured acoustic waves. When ultrasound waves are emitted with a periodic structure, the Talbot effect produces $\\pi$ -phase shifts of that periodic structure at every half of the Talbot distance in propagation. This unwanted artifact is detrimental to the image reconstruction, which assumes near-field diffraction is negligible. Here, we demonstrate both theoretically and experimentally how imposing an additional phase modulation on the acoustic periodic structure induces a symmetry constraint leading to the annihilation of the Talbot effect. This will significantly improve the acousto-optic image reconstruction quality and allows for an improvement of the reachable spatial resolution of the image."], "authors": "Maïmouna Bocoum"},
{"Title": "Enhancement of CO2 conversion by counterflow gas quenching of the post-discharge region in microwave plasma sustained by gyrotron radiation", "abs": ["A threefold increase in the CO2 conversion and energy efficiency due to the cooling of the post-discharge region by the counter gas flow has been achieved in the plasma of an atmospheric pressure discharge supported by microwave radiation of a gyrotron with a frequency of 24 GHz in a carbon dioxide gas flow. The role of convective heat transfer in the process of gas mixture cooling in the post-discharge region has been experimentally demonstrated. At nitrogen quench gas flow of 4.5 l/min, the CO2 conversion was 23.8 % and energy efficiency was 19.7 %. The possibility of using the flow of cooled gas mixture (CO2,CO,O2) taken from the reactor as quenching gas has been experimentally demonstrated, which made it possible to achieve a CO2 conversion degree of 23.4 % and to eliminate the problem of dilution of reaction products by third-party gases. Based on numerical modeling, it is shown that the increase in the conversion degree upon the destruction of the plasma torch structure is due to the increase in heat exchange with the surrounding atmosphere, and the efficiency of this destruction is determined by the velocity and density of quenching gas."], "authors": "N. V. Chekmarev"},
{"Title": "Mist Generation Behavior in Ultrasonic Atomizer for Aerosol Jet Printing", "abs": ["Continuous ultrasonic atomization in a closed chamber is expected to generate a mist with an equilibrium droplet concentration and size distribution. Such a mist of microdroplets with controllable mist density has been used for Aerosol Jet printing in the fabrication of a variety of additively manufactured microscale devices. Despite many unique capabilities demonstrated with the Aerosol Jet printing technology, its ultrasonic atomization behavior appears to be rather sensitive to the ink properties with gaps in our understanding of the fundamental physics underlying its operation. In this work, we investigate some basic mechanisms in the Aerosol Jet ultrasonic atomizer with a lumped-parameter kinetic coagulation model for highly concentrated mist. To mitigate the difficulty with unavailable knowledge about the complex turbulent flow inside the atomizer chamber, we present results for several orders of magnitude of the turbulent energy dissipation rates in order to examine a range of possibilities. The same approach is taken for analyzing the scavenging effect of the swirling bulk liquid. Our results also demonstrate the theoretical possibility for achieving a mist saturation condition where the mist output from the atomizer can become insensitive to process variables. As observed in experiments, such a saturated mist is highly desirable for Aerosol Jet printing with maximized and well-controlled throughput in additive manufacturing."], "authors": "James Q Feng"},
{"Title": "Transfer learning for predicting source terms of principal component transport in chemically reactive flow", "abs": ["The objective of this study is to evaluate whether the number of requisite training samples can be reduced with the use of various transfer learning models for predicting, for example, the chemical source terms of the data-driven reduced-order model that represents the homogeneous ignition process of a hydrogen/air mixture. Principal component analysis is applied to reduce the dimensionality of the hydrogen/air mixture in composition space. Artificial neural networks (ANNs) are used to tabulate the reaction rates of principal components, and subsequently, a system of ordinary differential equations is solved. As the number of training samples decreases at the target task (i.e.,for T0 > 1000 K and various phi), the reduced-order model fails to predict the ignition evolution of a hydrogen/air mixture. Three transfer learning strategies are then applied to the training of the ANN model with a sparse dataset. The performance of the reduced-order model with a sparse dataset is found to be remarkably enhanced if the training of the ANN model is restricted by a regularization term that controls the degree of knowledge transfer from source to target tasks. To this end, a novel transfer learning method is introduced, parameter control via partial initialization and regularization (PaPIR), whereby the amount of knowledge transferred is systemically adjusted for the initialization and regularization of the ANN model in the target task. It is found that an additional performance gain can be achieved by changing the initialization scheme of the ANN model in the target task when the task similarity between source and target tasks is relatively low."], "authors": "Ki Sung Jung"},
{"Title": "T2 Relaxation during Radiofrequency (RF) pulses", "abs": ["Radiofrequency (RF) pulses are a critical part of every MRI pulse sequence, and must be specifically designed for ultrashort echo time (UTE) and zero echo time (ZTE) acquisitions. When considering the behavior of RF pulses, most often longitudinal T1 or transverse T2 relaxation is assumed to be negligible during the RF pulses themselves. This is usually valid with conventional sequences since most tissue T1s and T2s are much longer than typical RF pulse durations. However, when imaging tissues that have transverse relaxation times that are of the order of, or shorter than, the RF pulse duration, as is often the case with UTE and ZTE MRI, then relaxation during the pulse must be considered. This article covers the theory of T2/T2* relaxation during an RF pulse, and the implications and applications of this for imaging of ultrashort-T2* species."], "authors": "Peder E. Z. Larson"},
{"Title": "Design of auxetic cellular structures for in-plane response through out-of-plane actuation of stimuli-responsive bridge films", "abs": ["In this work, we propose novel designs of cellular structures exhibiting unconventional in-plane actuation responses to external stimuli. We strategically introduce stimuli-responsive bilayer bridge films within conventional honeycombs to achieve the desired actuation. The films are incorporated such that, in response to an external field (thermal, electric, chemical, etc.), the bridge film bends out-of-plane, activating the honeycomb in the plane. The conventional out-of-plane deformation of the bridge film can lead to interesting and unconventional actuation in the plane. An analytical model of this coupled unit cell behaviour is developed using curved beam theory, and the model is validated against finite element simulations. Several applications of such designs are presented. Unit cell architectures exhibiting both positive and negative macroscopic actuation are proposed, and the criterion for achieving such actuation is derived analytically. Furthermore, we demonstrate that by altering the topology, unidirectional and bidirectional negative actuation can be achieved. We also propose designs that result in the negative actuation of the structure with both monotonically increasing and monotonically decreasing stimuli. Finally, by combining two macroscopic structures with positive and negative actuation, we design efficient actuators/sensors that bend in the plane in response to a stimulus."], "authors": "Anirudh Chandramouli"},
{"Title": "Lung Imaging with UTE MRI", "abs": ["Cross-sectional imaging of the lungs, or pulmonary imaging, has proven to be an incredibly valuable tool in a wide range of pulmonary diseases. The vast majority of lung imaging is done with CT, as it is fast enough to freeze respiratory motion and provides high spatial resolution to visualize fine structure of the lungs.", "MRI of the lungs is inherently challenging due to the presence of large local magnetic field gradients, relatively low proton density, and motion. The benefits of performing MRI for lung imaging include no ionizing radiation, opportunities for multiple contrasts, and integration with other MRI also offers the opportunity to obtain multiple tissue contrasts.", "The most common lung MRI techniques are structural T1-weighted scans, but also emerging are functional contrasts such as ventilation and perfusion, as well as other MRI contrast mechanisms including T2-weighting and diffusion-weighting. Finally, lung MRI can be combined with other MRI scanning techniques, including cardiac MRI, abdominal MRI, whole-body MRI, and PET/MRI, for increasing examination efficiency by only requiring a single scan session and providing more comprehensive assessment that includes evaluation of the pulmonary system.", "This article covers pulse sequences, motion management methods, image reconstruction, and contrast mechanisms of UTE MRI (e.g. T1-weighting, ventilation mapping) for imaging of the lung."], "authors": "Peder E. Z. Larson"},
{"Title": "Transition from quasi-unidirectional to unidirectional guided resonances in leaky-mode photonic lattices", "abs": ["Unidirectional light emission from planar photonic structures is highly advantageous for a wide range of optoelectronic applications. Recently, it has been demonstrated that unidirectional guided resonances (UGRs) can be realized by utilizing topological polarization singularities in momentum space. However, the practical application of these topological unidirectional emitters has been limited due to their intricate geometric configurations, requiring special efforts with high-cost fabrication processes. In this study, we show that unidirectional light emission can be achieved in conventional one-dimensional zero-contrast gratings (ZCGs), which can be easily fabricated using current nanofabrication technologies. In ZCGs, the interband coupling between even-like and odd-like waveguide modes leads to the formation of quasi-UGRs, characterized by significantly higher decay rates in either the upward or downward direction compared to the opposite direction. We demonstrate that these quasi-UGRs evolve into genuine UGRs with an gradual increase in grating thickness. Moreover, the emission direction of UGRs can be selectively steered either upward or downward by adjusting the lattice parameters. In addition to quasi-UGRs and UGRs, our study also reveals additional topological phenomena in ZCGs, including exceptional points and quasi-BICs."], "authors": "Sun-Goo Lee"},
{"Title": "Skilful Precipitation Nowcasting Using NowcastNet", "abs": ["Designing early warning system for precipitation requires accurate short-term forecasting system. Climate change has led to an increase in frequency of extreme weather events, and hence such systems can prevent disasters and loss of life. Managing such events remain a challenge for both public and private institutions. Precipitation nowcasting can help relevant institutions to better prepare for such events as they impact agriculture, transport, public health and safety, etc. Physics-based numerical weather prediction (NWP) is unable to perform well for nowcasting because of large computational turn-around time. Deep-learning based models on the other hand are able to give predictions within seconds. We use recently proposed NowcastNet, a physics-conditioned deep generative network, to forecast precipitation for different regions of Europe using satellite images. Both spatial and temporal transfer learning is done by forecasting for the unseen regions and year. Model makes realistic predictions and is able to outperform baseline for such a prediction task."], "authors": "Ajitabh Kumar"},
{"Title": "Precipitation Nowcasting With Spatial And Temporal Transfer Learning Using Swin-UNETR", "abs": ["Climate change has led to an increase in frequency of extreme weather events. Early warning systems can prevent disasters and loss of life. Managing such events remain a challenge for both public and private institutions. Precipitation nowcasting can help relevant institutions to better prepare for such events. Numerical weather prediction (NWP) has traditionally been used to make physics based forecasting, and recently deep learning based approaches have been used to reduce turn-around time for nowcasting. In this work, recently proposed Swin-UNETR (Swin UNEt TRansformer) is used for precipitation nowcasting for ten different regions of Europe. Swin-UNETR utilizes a U-shaped network within which a swin transformer-based encoder extracts multi-scale features from multiple input channels of satellite image, while CNN-based decoder makes the prediction. Trained model is capable of nowcasting not only for the regions for which data is available, but can also be used for new regions for which data is not available."], "authors": "Ajitabh Kumar"},
{"Title": "Exploring the Interplay of Left Coronary Tree Anatomy and Haemodynamics: Implications for Plaque Formation", "abs": ["The link between atherosclerosis and blood flow-induced haemodynamic luminal shear stresses is well established. However, this understanding has not been translated into clinical practice because of the interdependent effects of the complex coronary anatomy and a multitude of potential haemodynamic metrics, which have been challenging to delineate. Thus, this study aims to identify anatomical and haemodynamic differences in coronary trees at different stages of stenoses. A total of 39 left coronary trees were considered, which are publicly available. Each coronary tree was dissected into bifurcations and non-bifurcating segments for comparisons. We calculated a full set of anatomical metrics and performed transient flow simulations to solve the normalised luminal area exposed to Low Time-Average Endothelial Shear Stress (%LowTAESS), High Oscillatory Shear Index (%HighOSI), and High Relative Residence Time (%HighRRT). We statistically investigated the differences between non-stenosed (n=20, Diameter Stenosis DS=0%), moderately (n=12, 0%<DS<70%), and severely (n=7, DS>=70%) stenosed cases, whereby p<0.05* is considered significant. Only the average curvature and %HighOSI differed between the non-stenosed, and moderately or severely stenosed for the coronary trees (p=0.024* and p<0.001*), and non-bifurcating segments (p=0.027* and p<0.001*). %LowTAESS@0.5Pa and %HighRRT@2.5Pa-1 significantly differed between moderately (0%<DS<70%) and severely (DS>=70\\%) stenosed trees (p=0.009* and p=0.012*). Our findings suggest curvature and potentially %HighOSI being critical factors in coronary plaque onset in non-bifurcating segments, whereas %LowTAESS and %HighRRT affect plaque progression after onset."], "authors": "Mingzi Zhang"},
{"Title": "Imaging Resonance Effects in C + H$_2$ Collisions using a Zeeman Decelerator", "abs": ["An intriguing phenomenon in molecular collisions is the occurrence of scattering resonances, which originate from bound and quasi-bound states supported by the interaction potential at low collision energies. The resonance effects in the scattering behaviour are extraordinarily sensitive to the interaction potential, and their observation provides one of the most stringent tests for theoretical models. We present high-resolution measurements of state-resolved angular scattering distributions for inelastic collisions between Zeeman-decelerated C($^3P_1$) atoms and $\\textit{para}$-H$_2$ molecules at collision energies ranging from 77 cm$^{-1}$ down to 0.5 cm$^{-1}$. Rapid variations in the angular distributions were observed that can be attributed to the consecutive reduction of contributing partial waves and effects of scattering resonances. The measurements showed excellent agreement with distributions predicted by $\\textit{ab initio}$ quantum scattering calculations. However, discrepancies were found at specific collision energies, which most likely originate from an incorrectly predicted quasi-bound state. These observations provide exciting prospects for further high-precision and low-energy investigations of scattering processes that involve paramagnetic species."], "authors": "Vikram Plomp"},
{"Title": "Over-the-Air Emulation of Electronically Adjustable Rician MIMO Channels in a Programmable-Metasurface-Stirred Reverberation Chamber", "abs": ["We experimentally investigate the feasibility of evaluating multiple-input multiple-output (MIMO) radio equipment under adjustable Rician fading channel conditions in a programmable-metasurface-stirred (PM-stirred) reverberation chamber (RC). Whereas within the \"smart radio environment\" paradigm PMs offer partial control over the channels to the wireless system, in our use case the PM emulates the uncontrollable fading. We implement a desired Rician K-factor by sweeping a suitably sized subset of all meta-atoms through random configurations. We discover in our setup an upper bound on the accessible K-factors for which the statistics of the channel coefficient distributions closely follow the sought-after Rician distribution. We also discover a lower bound on the accessible K-factors in our setup: there are unstirred paths that never encounter the PM, and paths that encounter the PM are not fully stirred because the average of the meta-atoms' accessible polarizability values is not zero (i.e., the meta-atoms have a non-zero \"structural\" cross-section). We corroborate these findings with experiments in an anechoic chamber, physics-compliant PhysFad simulations with Lorentzian vs \"ideal\" meta-atoms, and theoretical analysis. Our work clarifies the scope of applicability of PM-stirred RCs for MIMO Rician channel emulation, as well as electromagnetic compatibility test."], "authors": "Ismail Ahmed"},
{"Title": "System for Analysis of Wind Collocations (SAWC): A Novel Archive and Collocation Software Application for the Intercomparison of Winds from Multiple Observing Platforms", "abs": ["Accurate atmospheric 3D wind observations are a high priority in the science community. To address this requirement and to support researchers' needs to acquire and analyze wind data from multiple sources, the System for Analysis of Wind Collocations (SAWC) was jointly developed by NOAA/NESDIS/STAR, UMD/ESSIC/CISESS, and UW-Madison/CIMSS. SAWC encompasses a multi-year archive of global 3D winds observed by Aeolus, sondes, aircraft, stratospheric superpressure balloons, and satellite-derived atmospheric motion vectors, archived and uniformly formatted in netCDF for public consumption; identified pairings between select datasets collocated in space and time; and a downloadable software application developed for users to interactively collocate and statistically compare wind observations based on their research needs. The utility of SAWC is demonstrated by conducting a one-year (September 2019-August 2020) evaluation of Aeolus level-2B (L2B) winds (Baseline 11 L2B processor version). Observations from four archived conventional wind datasets are collocated with Aeolus. Recommended quality controls are applied. Wind comparisons are assessed using the SAWC collocation application. Comparison statistics are stratified by season, geographic region, and Aeolus observing mode. The results highlight the value of SAWC's capabilities, from product validation through intercomparison studies to the evaluation of data usage in applications and advances in the global Earth observing architecture"], "authors": "Katherine E. Lukens"},
{"Title": "Characterisation of the laminar pulsatile flow in toroidal pipes", "abs": ["This study analyses the main characteristics of the fully developed laminar pulsatile flow in a toroidal pipe as the governing parameters vary. A novel computational technique is developed to obtain time-periodic solutions of the Navier$\\unicode{x2013}$Stokes equations. They are computed as fixed points of the system in the frequency domain via a Newton$\\unicode{x2013}$Raphson method. Advantages and drawbacks of the adopted methodology with respect to a time-stepping technique are discussed. The unsteady component of the driving pressure gradient is found to change linearly with the pulsation amplitude, with a proportionality coefficient dependent on the pulsation frequency. Although the time-averaged streamwise wall shear stress is very close to the value in the steady case, significant fluctuations are observed within the period. Flow reversal occurs during certain time intervals in the period for high pulsation amplitudes. The analysis of the spatial structure of the unsteady component of the velocity field shows that three different flow regimes can be identified, depending on the pulsation frequency, termed quasi-steady, intermediate and plug-flow regimes."], "authors": "Valerio Lupi"},
{"Title": "Analysis of High-Contrast All-Optical Dual Wavelength Switching in Asymmetric Dual-Core Fibers", "abs": ["We systematically present experimental and theoretical results for the dual-wavelength switching of 1560 nm, 75 fs signal pulses (SPs) driven by 1030 nm, 270 fs control pulses (CPs) in a dual-core fiber (DCF). We demonstrate a switching contrast of 31.9 dB, corresponding to a propagation distance of 14 mm, achieved by launching temporally synchronized SP-CP pairs into the fast core of the DCF with moderate inter-core asymmetry. Our analysis employs a system of three coupled propagation equations to identify the compensation of the asymmetry by nonlinearity as the physical mechanism behind the efficient switching performance."], "authors": "Le Xuan The Tai"},
{"Title": "Low latency optical-based mode tracking with machine learning deployed on FPGAs on a tokamak", "abs": ["Active feedback control in magnetic confinement fusion devices is desirable to mitigate plasma instabilities and enable robust operation. Optical high-speed cameras provide a powerful, non-invasive diagnostic and can be suitable for these applications. In this study, we process fast camera data, at rates exceeding 100kfps, on $\\textit{in situ}$ Field Programmable Gate Array (FPGA) hardware to track magnetohydrodynamic (MHD) mode evolution and generate control signals in real-time. Our system utilizes a convolutional neural network (CNN) model which predicts the $n$=1 MHD mode amplitude and phase using camera images with better accuracy than other tested non-deep-learning-based methods. By implementing this model directly within the standard FPGA readout hardware of the high-speed camera diagnostic, our mode tracking system achieves a total trigger-to-output latency of 17.6$\\mu$s and a throughput of up to 120kfps. This study at the High Beta Tokamak-Extended Pulse (HBT-EP) experiment demonstrates an FPGA-based high-speed camera data acquisition and processing system, enabling application in real-time machine-learning-based tokamak diagnostic and control as well as potential applications in other scientific domains."], "authors": "Yumou Wei"},
{"Title": "Predicting breast cancer with AI for individual risk-adjusted MRI screening and early detection", "abs": ["Women with an increased life-time risk of breast cancer undergo supplemental annual screening MRI. We propose to predict the risk of developing breast cancer within one year based on the current MRI, with the objective of reducing screening burden and facilitating early detection. An AI algorithm was developed on 53,858 breasts from 12,694 patients who underwent screening or diagnostic MRI and accrued over 12 years, with 2,331 confirmed cancers. A first U-Net was trained to segment lesions and identify regions of concern. A second convolutional network was trained to detect malignant cancer using features extracted by the U-Net. This network was then fine-tuned to estimate the risk of developing cancer within a year in cases that radiologists considered normal or likely benign. Risk predictions from this AI were evaluated with a retrospective analysis of 9,183 breasts from a high-risk screening cohort, which were not used for training. Statistical analysis focused on the tradeoff between number of omitted exams versus negative predictive value, and number of potential early detections versus positive predictive value. The AI algorithm identified regions of concern that coincided with future tumors in 52% of screen-detected cancers. Upon directed review, a radiologist found that 71.3% of cancers had a visible correlate on the MRI prior to diagnosis, 65% of these correlates were identified by the AI model. Reevaluating these regions in 10% of all cases with higher AI-predicted risk could have resulted in up to 33% early detections by a radiologist. Additionally, screening burden could have been reduced in 16% of lower-risk cases by recommending a later follow-up without compromising current interval cancer rate. With increasing datasets and improving image quality we expect this new AI-aided, adaptive screening to meaningfully reduce screening burden and improve early detection."], "authors": "Lukas Hirsch"},
{"Title": "The Geopolitics behind the Cryptocurrency Mining in Kazakhstan", "abs": ["On 25 January 2022, following a beginning to the year which had been affected by major political unrest resulting in the deaths of more than 230 people 1 , Kazakhstan was hit by a major power blackout. For around twelve hours, the entire southern regions of the country were left without power, as were Uzbekistan and Kyrgyzstan, two neighboring countries with which the southern country shares the same electricity network. This event is the culmination of several months of over-consumption, power surges and localized outages on the Central Asian networks. In Kazakhstan, electricity consumption rose by 8% in 2021, according to Ministry of Energy 2 , the national electricity operator, compared with the 1-2% annual increase previously recorded. This explosion in consumption is said to have been driven by the widespread development of cryptocurrency mining, a digital activity that can be extremely energy-intensive when operated on a large scale."], "authors": "Hugo Estecahandy"},
{"Title": "DeepTreeGAN: Fast Generation of High Dimensional Point Clouds", "abs": ["In High Energy Physics, detailed and time-consuming simulations are used for particle interactions with detectors. To bypass these simulations with a generative model, the generation of large point clouds in a short time is required, while the complex dependencies between the particles must be correctly modelled. Particle showers are inherently tree-based processes, as each particle is produced by the decay or detector interaction of a particle of the previous generation. In this work, we present a novel Graph Neural Network model (DeepTreeGAN) that is able to generate such point clouds in a tree-based manner. We show that this model can reproduce complex distributions, and we evaluate its performance on the public JetNet dataset."], "authors": "Moritz Alfons Wilhelm Scham"},
{"Title": "DeepTreeGANv2: Iterative Pooling of Point Clouds", "abs": ["In High Energy Physics, detailed and time-consuming simulations are used for particle interactions with detectors. To bypass these simulations with a generative model, the generation of large point clouds in a short time is required, while the complex dependencies between the particles must be correctly modelled. Particle showers are inherently tree-based processes, as each particle is produced by the decay or detector interaction of a particle of the previous generation. In this work, we present a significant extension to DeepTreeGAN, featuring a critic, that is able to aggregate such point clouds iteratively in a tree-based manner. We show that this model can reproduce complex distributions, and we evaluate its performance on the public JetNet 150 dataset."], "authors": "Moritz Alfons Wilhelm Scham"},
{"Title": "A Physics-Constrained NeuralODE Approach for Robust Learning of Stiff Chemical Kinetics", "abs": ["The high computational cost associated with solving for detailed chemistry poses a significant challenge for predictive computational fluid dynamics (CFD) simulations of turbulent reacting flows. These models often require solving a system of coupled stiff ordinary differential equations (ODEs). While deep learning techniques have been experimented with to develop faster surrogate models, they often fail to integrate reliably with CFD solvers. This instability arises because deep learning methods optimize for training error without ensuring compatibility with ODE solvers, leading to accumulation of errors over time. Recently, NeuralODE-based techniques have offered a promising solution by effectively modeling chemical kinetics. In this study, we extend the NeuralODE framework for stiff chemical kinetics by incorporating mass conservation constraints directly into the loss function during training. This ensures that the total mass and the elemental mass are conserved, a critical requirement for reliable downstream integration with CFD solvers. Our results demonstrate that this enhancement not only improves the physical consistency with respect to mass conservation criteria but also ensures better robustness and makes the training process more computationally efficient."], "authors": "Tadbhagya Kumar"},
{"Title": "Photonic Neural Networks and Optics-informed Deep Learning Fundamentals", "abs": ["The recent explosive compute growth, mainly fueled by the boost of AI and DNNs, is currently instigating the demand for a novel computing paradigm that can overcome the insurmountable barriers imposed by conventional electronic computing architectures. PNNs implemented on silicon integration platforms stand out as a promising candidate to endow NN hardware, offering the potential for energy efficient and ultra-fast computations through the utilization of the unique primitives of photonics i.e. energy efficiency, THz bandwidth and low-latency. Thus far, several demonstrations have revealed the huge potential of PNNs in performing both linear and non-linear NN operations at unparalleled speed and energy consumption metrics. Transforming this potential into a tangible reality for DL applications requires, however, a deep understanding of the basic PNN principles, requirements and challenges across all constituent architectural, technological and training aspects. In this tutorial, we, initially, review the principles of DNNs along with their fundamental building blocks, analyzing also the key mathematical operations needed for their computation in a photonic hardware. Then, we investigate, through an intuitive mathematical analysis, the interdependence of bit precision and energy efficiency in analog photonic circuitry, discussing the opportunities and challenges of PNNs. Followingly, a performance overview of PNN architectures, weight technologies and activation functions is presented, summarizing their impact in speed, scalability and power consumption. Finally, we provide an holistic overview of the optics-informed NN training framework that incorporates the physical properties of photonic building blocks into the training process in order to improve the NN classification accuracy and effectively elevate neuromorphic photonic hardware into high-performance DL computational settings."], "authors": "A. Tsakyridis"},
{"Title": "Dowker-type theorems for disk-polygons in normed planes", "abs": ["A classical result of Dowker (Bull. Amer. Math. Soc. 50: 120-122, 1944) states that for any plane convex body $K$ in the Euclidean plane, the areas of the maximum (resp. minimum) area convex $n$-gons inscribed (resp. circumscribed) in $K$ is a concave (resp. convex) sequence. It is known that this theorem remains true if we replace area by perimeter, the Euclidean plane by an arbitrary normed plane, or convex $n$-gons by disk-$n$-gons, obtained as the intersection of $n$ closed Euclidean unit disks. The aim of our paper is to investigate these problems for $C$-$n$-gons, defined as intersections of $n$ translates of the unit disk $C$ of a normed plane. In particular, we show that Dowker's theorem remains true for the areas and the perimeters of circumscribed $C$-$n$-gons, and the perimeters of inscribed $C$-$n$-gons. We also show that in the family of origin-symmetric plane convex bodies, for a typical element $C$ with respect to Hausdorff distance, Dowker's theorem for the areas of inscribed $C$-$n$-gons fails."], "authors": "Bushra Basit"},
{"Title": "Extending and improving conical bicombings", "abs": ["We study metric spaces that admit a conical bicombing and thus obey a weak form of non-positive curvature. Prime examples of such spaces are injective metric spaces. In this article we give a complete characterization of complete metric spaces admitting a conical bicombing by showing that every such space is isometric to a closed $\\sigma$-convex subset of some injective metric space. In addition, we show that every proper metric space that admits a conical bicombing also admits a consistent bicombing that satisfies certain convexity conditions. This can be seen as a strong indication that a question from Descombes and Lang about improving conical bicombings might have a positive answer. As an application, we prove that any group acting geometrically on a proper metric space with a conical bicombing admits a $\\mathcal{Z}$-structure."], "authors": "Giuliano Basso"},
{"Title": "Complex dimensions for IFS with overlaps", "abs": ["The notion of complex dimension of a one-dimensional Cantor set $C=\\bigcap_{n=1}^\\infty C_n$ dates back decades. It is defined as the set of poles of the meromorphic $\\zeta$-function $\\zeta(s)=\\sum_{n=1}^{\\infty}d_j^s$, where $\\Re s>0$, and $d_j$ is the length of the $j$th interval in $C_n$.", "Following the trend, I switch from sets to measures, which will allow me to generalize the construction to iterated function schemes that do not necessarily satisfy the Open Set Condition."], "authors": "Nikita Sidorov"},
{"Title": "Inhomogeneous order 1 iterative functional equations with applications to combinatorics", "abs": ["We show that if a Laurent series $f\\in\\mathbb{C}((t))$ satisfies a particular kind of linear iterative equation, then $f$ is either a rational function or it is differentially transcendental over $\\mathbb{C}(t)$. This condition is more precisely stated as follows: We consider $R,b\\in \\mathbb{C}(t)$ with $R(0)=0$, such that $f(R(t))=f(t)+b(t)$. If either $R'(0)=0$ or $R'(0)$ is a root of unity, then either $f$ is a rational function, or $f$ does not satisfy a polynomial differential equation. More generally a solution of a functional equation of the form $f(R(t))=a(t)f(t)+b(t)$ will be either differentially trascendental or the solution of an inhomogeneous linear differential equation of order $1$ with rational coefficients.", "We illustrate how to apply these results to deduce the differential transcendence of combinatorial generating functions by considering three examples: the ordinary generating function for a family of complete trees; the Green function for excursions on the Sierpinski graph; and a series related to the enumeration of permutations avoiding the consecutive pattern 1423.", "The proof strategy is inspired by the Galois theory of functional equations and relies on the property of the dynamics of $R$."], "authors": "Lucia Di Vizio"},
{"Title": "The conservative matrix field", "abs": ["We present a new structure called the \"conservative matrix field\", initially developed to elucidate and provide insight into the methodologies employed by Apéry's in his proof og the irrationality of the Riemann zeta function at 3. This framework is also applicable to other well known mathematical constants, such as e, {\\pi}, ln(2), and more, and can be used to study their properties. Moreover, the conservative matrix field exhibits inherent connections to various ideas and techniques in number theory, thereby indicating promising avenues for further applications and investigations."], "authors": "Ofir David"},
{"Title": "On Euler polynomial continued fractions", "abs": ["In this paper, we introduce the polynomial continued fraction, a close relative of the well-known simple continued fraction expansions which are widely used in number theory and in general. While they may not possess all the intriguing properties of simple continued fractions, polynomial continued fractions have many interesting patterns which can be exploited. Specifically, we explore the Euler continued fractions within this framework and present an algorithm for their identification"], "authors": "Ofir David"},
{"Title": "The Manin-Peyre conjecture for smooth spherical Fano varieties of semisimple rank one", "abs": ["The Manin-Peyre conjecture is established for a class of smooth spherical Fano varieties of semisimple rank one. This includes all smooth spherical Fano threefolds of type T as well as some higher-dimensional smooth spherical Fano varieties."], "authors": "Valentin Blomer"},
{"Title": "Non-cuspidal Hida theory for Siegel modular forms and trivial zeros of $p$-adic $L$-functions", "abs": ["We study the derivative of the standard $p$-adic $L$-function associated with a $P$-ordinary Siegel modular form (for $P$ a parabolic subgroup of $\\mathrm{GL}(n)$) when it presents a semi-stable trivial zero. This implies part of Greenberg's conjecture on the order and leading coefficient of $p$-adic $L$-functions at such trivial zero. We use the method of Greenberg-Stevens. For the construction of the improved $p$-adic $L$-function we develop Hida theory for non-cuspidal Siegel modular forms."], "authors": "Zheng Liu"},
{"Title": "On the powerful values of polynomials over number fields", "abs": ["Let ${\\mathcal B}=\\{b_i \\}_{i=1}^\\infty$ be a fixed sequence of pairwise distinct elements of a number field $k$. Given the integers $2\\leq s \\leq r$, assuming a quantitative version of Vojta's conjecture on the bounded degree algebraic numbers on a number field $k$, we provide lower and upper bounds for the cardinal number of ${\\mathbf G}_{r,s}^{{\\mathcal B}_M}$ the set of polynomials $f\\in k[x]$ of degree $r\\geq 2$ whose irreducible factors have multiplicity strictly less than $s$ and $f(b_1),\\cdots, f(b_M)$ are nonzero $s$-powerful elements in $k$, where $M=2r^2+6r +1$ if $r=s$, and $2sr^2+ s r+1$ otherwise. Moreover, considering certain conditions on ${\\mathcal B}$, we show the existence of an integer $M_0> M$ such that no polynomial in ${\\mathbf G}_{r,s}^{{\\mathcal B}_M}$ takes $s$-powerful values at all of $b_1, \\cdots, b_n $ for $n\\geq M_0$."], "authors": "Sajad Salami"},
{"Title": "Coarse-Graining Hamiltonian Systems Using WSINDy", "abs": ["The Weak-form Sparse Identification of Nonlinear Dynamics algorithm (WSINDy) has been demonstrated to offer coarse-graining capabilities in the context of interacting particle systems (", "). In this work we extend this capability to the problem of coarse-graining Hamiltonian dynamics which possess approximate symmetries associated with timescale separation. Such approximate symmetries often lead to the existence of a Hamiltonian system of reduced dimension that may be used to efficiently capture the dynamics of the symmetry-invariant dependent variables. Deriving such reduced systems, or approximating them numerically, is an ongoing challenge. We demonstrate that WSINDy can successfully identify this reduced Hamiltonian system in the presence of large intrinsic perturbations while remaining robust to extrinsic noise. This is significant in part due to the nontrivial means by which such systems are derived analytically. WSINDy also naturally preserves the Hamiltonian structure by restricting to a trial basis of Hamiltonian vector fields. The methodology is computational efficient, often requiring only a single trajectory to learn the global reduced Hamiltonian, and avoiding forward solves in the learning process. Using nearly-periodic Hamiltonian systems as a prototypical class of systems with approximate symmetries, we show that WSINDy robustly identifies the correct leading-order system, with dimension reduced by at least two, upon observation of the relevant degrees of freedom. We also provide a contribution to averaging theory by proving that first-order averaging at the level of vector fields preserves Hamiltonian structure in nearly-periodic Hamiltonian systems. We provide physically relevant examples, namely coupled oscillator dynamics, the Hénon-Heiles system for stellar motion within a galaxy, and the dynamics of charged particles."], "authors": "Daniel A. Messenger"},
{"Title": "ChebNet: Efficient and Stable Constructions of Deep Neural Networks with Rectified Power Units via Chebyshev Approximations", "abs": ["In a previous study [B. Li, S. Tang and H. Yu, Commun. Comput. Phy. 27(2):379-411, 2020], it is shown that deep neural networks built with rectified power units (RePU) as activation functions can give better approximation for sufficient smooth functions than those built with rectified linear units, by converting polynomial approximations using power series into deep neural networks with optimal complexity and no approximation error. However, in practice, power series approximations are not easy to obtain due to the associated stability issue. In this paper, we propose a new and more stable way to construct RePU deep neural networks based on Chebyshev polynomial approximations. By using a hierarchical structure of Chebyshev polynomial approximation in frequency domain, we obtain efficient and stable deep neural network construction, which we call ChebNet. The approximation of smooth functions by ChebNets is no worse than the approximation by deep RePU nets using power series. On the same time, ChebNets are much more stable. Numerical results show that the constructed ChebNets can be further fine-tuned to obtain much better results than those obtained by tuning deep RePU nets constructed by power series approach. As spectral accuracy is hard to obtain by direct training of deep neural networks, ChebNets provide a practical way to obtain spectral accuracy, it is expected to be useful in real applications that require efficient approximations of smooth functions."], "authors": "Shanshan Tang"},
{"Title": "An entropy stable discontinuous Galerkin method for the spherical thermal shallow water equations", "abs": ["We develop a novel discontinuous Galerkin method for solving the rotating thermal shallow water equations (TRSW) on a curvilinear mesh. Our method is provably entropy stable, conserves mass, buoyancy and vorticity, while also semi-discretely conserving energy. This is achieved by using novel numerical fluxes and splitting the pressure and convection operators. We implement our method on a cubed sphere mesh and numerically verify our theoretical results. Our experiments demonstrate the robustness of the method for a regime of well developed turbulence, where it can be run stably without any dissipation. The entropy stable fluxes are sufficient to control the grid scale noise generated by geostrophic turbulence, eliminating the need for artificial stabilization."], "authors": "Kieran Ricardo"},
{"Title": "A fully coupled regularized mortar-type finite element approach for embedding one-dimensional fibers into three-dimensional fluid flow", "abs": ["The present article proposes a partitioned Dirichlet-Neumann algorithm, that allows to address unique challenges arising from a novel mixed-dimensional coupling of very slender fibers embedded in fluid flow using a regularized mortar-type finite element discretization. The fibers are modeled via one-dimensional (1D) partial differential equations based on geometrically exact nonlinear beam theory, while the flow is described by the three-dimensional (3D) incompressible Navier-Stokes equations. The arising truly mixed-dimensional 1D-3D coupling scheme constitutes a novel approximate model and numerical strategy, that naturally necessitates specifically tailored solution schemes to ensure an accurate and efficient computational treatment. In particular, we present a strongly coupled partitioned solution algorithm based on a Quasi-Newton method for applications involving fibers with high slenderness ratios that usually present a challenge with regard to the well-known added mass effect. The influence of all employed algorithmic and numerical parameters, namely the applied acceleration technique, the employed constraint regularization parameter as well as shape functions, on efficiency and results of the solution procedure is studied through appropriate examples. Finally, the convergence of the two-way coupled mixed-dimensional problem solution under uniform mesh refinement is demonstrated, a comparison to a 3D reference solution is performed, and the method's capabilities in capturing flow phenomena at large geometric scale separation is illustrated by the example of a submersed vegetation canopy."], "authors": "Nora Hagmeyer"},
{"Title": "Semi-randomized block Kaczmarz methods with simple random sampling for large-scale linear systems", "abs": ["Randomized block Kaczmraz method plays an important role in solving large-scale linear system. One of the key points of this type of methods is how to effectively select working rows. However, in most of the state-of-the-art randomized block Kaczmarz-type methods, one has to scan all the rows of the coefficient matrix in advance for computing probabilities or paving, or to compute the residual vector of the linear system in each iteration to determine the working rows. Thus, we have to access all the rows of the data matrix in these methods, which are unfavorable for big-data problems. Moreover, to the best of our knowledge, how to efficiently choose working rows in randomized block Kaczmarz-type methods for multiple linear systems is still an open problem. In order to deal with these problems, we propose semi-randomized block Kaczmarz methods with simple random sampling for linear systems with single and multiple right-hand sides, respectively. In these methods, there is no need to scan or pave all the rows of the coefficient matrix, nor to compute probabilities and the residual vector of the linear system in each step. Specifically, one can update all the solutions of a large-scale linear system with multiple right-hand sides simultaneously. The convergence of the proposed methods is considered. Numerical experiments on both real-world and synthetic data sets show that the proposed methods are superior to many state-of-the-art randomized Kaczmarz-type methods for large-scale linear systems."], "authors": "Gang Wu"},
{"Title": "Generalized Convolution Quadrature for non smooth sectorial problems", "abs": ["We consider the application of the generalized Convolution Quadrature (gCQ) to approximate the solution of an important class of sectorial problems. The gCQ is a generalization of Lubich's Convolution Quadrature (CQ) that allows for variable steps. The available stability and convergence theory for the gCQ requires non realistic regularity assumptions on the data, which do not hold in many applications of interest, such as the approximation of subdiffusion equations. It is well known that for non smooth enough data the original CQ, with uniform steps, presents an order reduction close to the singularity. We generalize the analysis of the gCQ to data satisfying realistic regularity assumptions and provide sufficient conditions for stability and convergence on arbitrary sequences of time points. We consider the particular case of graded meshes and show how to choose them optimally, according to the behaviour of the data. An important advantage of the gCQ method is that it allows for a fast and memory reduced implementation. We describe how the fast and oblivious gCQ can be implemented and illustrate our theoretical results with several numerical experiments."], "authors": "Jing Guo"},
{"Title": "Saddle point preconditioners for weak-constraint 4D-Var", "abs": ["Data assimilation algorithms combine information from observations and prior model information to obtain the most likely state of a dynamical system. The linearised weak-constraint four-dimensional variational assimilation problem can be reformulated as a saddle point problem, which admits more scope for preconditioners than the primal form. In this paper we design new terms which can be used within existing preconditioners, such as block diagonal and constraint-type preconditioners. Our novel preconditioning approaches: (i) incorporate model information, and (ii) are designed to target correlated observation error covariance matrices. To our knowledge (i) has not previously been considered for data assimilation problems. We develop new theory demonstrating the effectiveness of the new preconditioners within Krylov subspace methods. Linear and non-linear numerical experiments reveal that our new approach leads to faster convergence than existing state-of-the-art preconditioners for a broader range of problems than indicated by the theory alone. We present a range of numerical experiments performed in serial."], "authors": "Jemima M. Tabeart"},
{"Title": "Characterizing the ambiguity in topological entanglement entropy", "abs": ["Topological entanglement entropy (TEE), the sub-leading term in the entanglement entropy of topological order, is the direct evidence of the long-range entanglement. While effective in characterizing topological orders on closed manifolds, TEE is model-dependent when entanglement cuts intersect with physical gapped boundaries. In this paper, we study the origin of this model-dependence by introducing a model-independent picture of partitioning the topological orders with gapped boundaries. In our picture, the entanglement boundaries (EBs), i.e. the virtual boundaries of each subsystem induced by the entanglement cuts, are assumed to be gapped boundaries with boundary defects. At this model-independent stage, there are two choices one has to make manually in defining the bi-partition: the boundary condition on the EBs, and the coherence between certain boundary states. We show that TEE appears because of a constraint on the defect configurations on the EBs, which is choice-dependent in the cases where the EBs touch gapped boundaries. This choice-dependence is known as the ambiguity in entanglement entropy. Different models intrinsically employ different choices, rendering TEE model-dependent. For Z2 toric code, the ambiguity can be fully characterized by two parameters that respectively quantifies the EB condition and the coherence. In particular, calculations compatible with the folding trick naturally choose EB conditions that respect electric-magnetic duality and set specific parameter values."], "authors": "Yingcheng Li"},
{"Title": "Self-duality under gauging a non-invertible symmetry", "abs": ["We discuss two-dimensional conformal field theories (CFTs) which are invariant under gauging a non-invertible global symmetry. At every point on the orbifold branch of $c=1$ CFTs, it is known that the theory is self-dual under gauging a $\\mathbb{Z}_2\\times \\mathbb{Z}_2$ symmetry, and has $\\mathsf{Rep}(H_8)$ and $\\mathsf{Rep}(D_8)$ fusion category symmetries as a result. We find that gauging the entire $\\mathsf{Rep}(H_8)$ fusion category symmetry maps the orbifold theory at radius $R$ to that at radius $2/R$. At $R=\\sqrt{2}$, which corresponds to two decoupled Ising CFTs (Ising$^2$ in short), the theory is self-dual under gauging the $\\mathsf{Rep}(H_8)$ symmetry. This implies the existence of a topological defect line in the Ising$^2$ CFT obtained from half-space gauging of the $\\mathsf{Rep}(H_8)$ symmetry, which commutes with the $c=1$ Virasoro algebra but does not preserve the fully extended chiral algebra. We bootstrap its action on the $c=1$ Virasoro primary operators, and find that there are no relevant or marginal operators preserving it. Mathematically, the new topological line combines with the $\\mathsf{Rep}(H_8)$ symmetry to form a bigger fusion category which is a $\\mathbb{Z}_2$-extension of $\\mathsf{Rep}(H_8)$. We solve the pentagon equations including the additional topological line and find 8 solutions, where two of them are realized in the Ising$^2$ CFT. Finally, we show that the torus partition functions of the Monster$^2$ CFT and Ising$\\times$Monster CFT are also invariant under gauging the $\\mathsf{Rep}(H_8)$ symmetry."], "authors": "Yichul Choi"},
{"Title": "Ponderomotive forces in magnetized non-thermal space plasmas due to cyclotron waves", "abs": ["The ponderomotive force is involved in a variety of space plasmas phenomena which are characterized by the family of Kappa distributions. Therefore, evaluating these nonthermal effects in the ponderomotive force is required. The Washimi and Karpman ponderomotive interaction due to cyclotron waves is evaluated for different space conditions considering low-temperature magnetized plasmas described by an isotropic Kappa distribution and with a wave propagation parallel to the background magnetic field. We performed a brief analysis of the influence of the Kappa distribution in the dispersion relation for a low-temperature plasma expansion at the lowest order in which the thermal effects are appreciated without considering the damping characteristics of the wave. The different factors of the ponderomotive force are obtained and analyzed separately as a function of the wavenumber, the spectral index $\\kappa$, and the plasma beta. We have found a relevant influence of the non-thermal effects in all the factors of the ponderomotive force for magnetized plasmas. The effect of the kappa distribution has been evaluated for a wide variety of space environments as the solar wind and the different regions of our magnetosphere where it has been found that these results can be relevant for the solar wind, the magnetosheath, the plasmasheet, and the polar cusps. We have also analyzed the role of the non-thermal effect in the induced Washimi and Karpman ponderomotive magnetization in the context of spatial plasmas and the total power radiated associated with it. We find that even for nearly cold magnetized plasmas and waves far from the resonances the effect of the kappa parameter in the ponderomotive force cannot be neglected. This suggests a significant role of the Kappa distribution in ponderomotive phenomena of space physics."], "authors": "Joaquín Espinoza-Troni"},
{"Title": "Regainingly approximable numbers and sets", "abs": ["We call an $\\alpha \\in \\mathbb{R}$ regainingly approximable if there exists a computable nondecreasing sequence $(a_n)_n$ of rational numbers converging to $\\alpha$ with $\\alpha - a_n < 2^{-n}$ for infinitely many $n \\in \\mathbb{N}$. We also call a set $A\\subseteq\\mathbb{N}$ regainingly approximable if it is c.e. and the strongly left-computable number $2^{-A}$ is regainingly approximable. We show that the set of regainingly approximable sets is neither closed under union nor intersection and that every c.e. Turing degree contains such a set. Furthermore, the regainingly approximable numbers lie properly between the computable and the left-computable numbers and are not closed under addition. While regainingly approximable numbers are easily seen to be i.o. $K$-trivial, we construct such an $\\alpha$ such that ${K(\\alpha \\restriction n)>n}$ for infinitely many $n$. Similarly, there exist regainingly approximable sets whose initial segment complexity infinitely often reaches the maximum possible for c.e. sets. Finally, there is a uniform algorithm splitting regular real numbers into two regainingly approximable numbers that are still regular."], "authors": "Peter Hertling"},
{"Title": "A note on the Hamiltonian structure of transgression forms", "abs": ["By incorporating two gauge connections, transgression forms provide a generalization of Chern-Simons actions that are genuinely gauge-invariant on bounded manifolds. In this work, we show that, when defined on a manifold with a boundary, the Hamiltonian formulation of a transgression field theory can be consistently carried out without the need to implement regularizing boundary terms at the level of first-class constraints. By considering boundary variations of the relevant functionals in the Poisson brackets, the surface integral in the very definition of a transgression action can be translated into boundary contributions in the generators of gauge transformations and diffeomorphisms. This prescription systematically leads to the corresponding surface charges of the theory, reducing to the general expression for conserved charges in (higher-dimensional) Chern-Simons theories when one of the gauge connections in the transgression form is set to zero."], "authors": "Pablo Pais"},
{"Title": "Local well-posedness and singularity formation in non-Newtonian compressible fluids", "abs": ["We investigate the initial value problem of a very general class of $3+1$ non-Newtonian compressible fluids in which the viscous stress tensor with shear and bulk viscosity relaxes to its Navier-Stokes values. These fluids correspond to the non-relativistic limit of well-known Israel-Stewart-like theories used in the relativistic fluid dynamic simulations of high-energy nuclear and astrophysical systems. After establishing the local well-posedness of the Cauchy problem, we show for the first time in the literature that there exists a large class of initial data for which the corresponding evolution breaks down in finite time due to the formation of singularities. This implies that a large class of non-Newtonian fluids do not have finite solutions defined at all times."], "authors": "Ariel Lerman"},
{"Title": "Lie-Poisson gauge theories and $κ$-Minkowski electrodynamics", "abs": ["We consider gauge theories on Poisson manifolds emerging as semiclassical approximations of noncommutative spacetime with Lie algebra type noncommutativity. We prove an important identity, which allows to obtain simple and manifestly gauge-covariant expressions for the Euler-Lagrange equations of motion, the Bianchi and the Noether identities. We discuss the non-Lagrangian equations of motion, and apply our findings to the $\\kappa$-Minkowski case. We construct a family of exact solutions of the deformed Maxwell equations in the vacuum. In the classical limit, these solutions recover plane waves with left-handed and right-handed circular polarization, being classical counterparts of photons. The deformed dispersion relation appears to be nontrivial."], "authors": "V. G. Kupriyanov"},
{"Title": "Goldstone modes and the golden spiral in the ferromagnetic spin-1 biquadratic model", "abs": ["Ferromagnetic ground states have often been overlooked in comparison to seemingly more interesting antiferromagnetic ground states. However, both the physical and mathematical structure of ferromagnetic ground states are particularly rich. We show that the highly degenerate and highly entangled ground states of the ferromagnetic spin-1 biquadratic model are scale invariant, originating from spontaneous symmetry breaking from ${\\rm SU}(3)$ to ${\\rm U}(1)\\times {\\rm U}(1)$ with two type-B Goldstone modes. The ground state degeneracies are characterized as the Fibonacci-Lucas sequences -- an ancient mathematical gem, under open and periodic boundary conditions, with the residual entropy being non-zero. This implies that the ground state degeneracies for this model are asymptotically the golden spiral. In addition, sequences of degenerate ground states generated from highest and generalized highest weight states are constructed to establish that the entanglement entropy scales logarithmically with the block size in the thermodynamic limit, with the prefactor being half the number of type-B Goldstone modes. The latter in turn is identified to be the fractal dimension."], "authors": "Huan-Qiang Zhou"},
{"Title": "Free Fermionic Schur Functions", "abs": ["We introduce a new family of Schur functions $s_{\\lambda/\\mu;a,b}(x/y)$ that depend on two sets of variables and two sequences of parameters. These free fermionic Schur functions have a hidden symmetry between the two sets of parameters that allows us to generalize and unify factorial, supersymmetric, and dual Schur functions from literature.", "We then prove that these functions satisfy the supersymmetric Cauchy identity $$", "\\sum_{\\lambda}s_{\\lambda;a,b}(x/y)\\widehat{s}_{\\lambda;a,b}(z/w) = \\prod_{i,j}\\frac{1+y_iz_j}{1-x_iz_j}\\frac{1+x_iw_j}{1-y_iw_j}, $$ where $\\widehat{s}_{\\lambda;a,b}(z/w) = s_{\\lambda';b',a'}(w/z)$ are the dual functions.", "Our approach is based on the integrable six vertex model with free fermionic Boltzmann weights. We show that these weights satisfy the \\textit{refined Yang-Baxter equation}, which allows us to prove well-known properties of Schur functions: supersymmetry, combinatorial descriptions, the Jacobi-Trudi identity, the Nägelsbach-Kostka formula, the Giambelli formula, the Ribbon formula, the Weyl determinant formula, the Berele-Regev factorization, dual Cauchy identity, the flagged determinant formula, and many others. We emphasize that many of these results are novel even in special cases."], "authors": "Slava Naprienko"},
{"Title": "On a novel gradient flow structure for the aggregation equation", "abs": ["The aggregation equation arises naturally in kinetic theory in the study of granular media, and its interpretation as a 2-Wasserstein gradient flow for the nonlocal interaction energy is well-known. Starting from the spatially homogeneous inelastic Boltzmann equation, a formal Taylor expansion reveals a link between this equation and the aggregation equation with an appropriately chosen interaction potential. Inspired by this formal link and the fact that the associated aggregation equation also dissipates the kinetic energy, we present a novel way of interpreting the aggregation equation as a gradient flow, in the sense of curves of maximal slope, of the kinetic energy, rather than the usual interaction energy, with respect to an appropriately constructed transportation metric on the space of probability measures."], "authors": "A. Esposito"},
{"Title": "Dissipative dynamics for infinite lattice systems", "abs": ["We study dissipative dynamics constructed by means of non-commutative Dirichlet forms for various lattice systems with multiparticle interactions associated to CCR algebras. We give a number of explicit examples of such models. Using an idea of quasi-invariance of a state, we show how one can construct unitary representations of various groups. Moreover in models with locally conserved quantities associated to an infinite lattice we show that there is no spectral gap and the corresponding dissipative dynamics decay to equilibrium polynomially in time."], "authors": "Shreya Mehta"},
{"Title": "Classification of the anyon sectors of Kitaev's quantum double model", "abs": ["We give a complete classification of the anyon sectors of Kitaev's quantum double model on the infinite triangular lattice and for finite gauge group $G$, including the non-abelian case. As conjectured, the anyon sectors of the model correspond precisely to the irreducible representations of the quantum double algebra of $G$. Our proof consists of two main parts. In the first part, we construct for each irreducible representation of the quantum double algebra a pure state and show that the GNS representations of these pure states are pairwise disjoint anyon sectors. In the second part we show that any anyon sector is unitarily equivalent to one of the anyon sectors constructed in the first part. Purity of the states constructed in the first part is shown by characterising these states as the unique states that satisfy appropriate local constraints. These constraints are of two types, namely flux constraints and gauge constraints. The flux constraints single out certain string-net states, while the gauge constraints fix the way in which these string-nets condense. At the core of the proof is the fact that certain groups of local gauge transformations act freely and transitively on collections of local string-nets. The proof that the GNS representations of these states are anyon sectors relies on showing that they are unitarily equivalent to amplimorphism representations which are much easier to compare to the ground state representation. For the second part, we show that any anyon sector contains a pure state that satisfies all but a finite number of the constraints characterising the pure states of the first part. Using known techniques we can then construct a pure state in the anyon sector that satisfies all but one of these constraints. Finally, we show that any such state must be a vector state in one of the anyon sectors constructed in the first part."], "authors": "Alex Bols"},
{"Title": "The Dunkl-Fokker-Planck Equation in $1+1$ Dimensions", "abs": ["By replacing the spatial derivative with the Dunkl derivative, we generalize the Fokker-Planck equation in (1+1) dimensions. We obtain the Dunkl-Fokker-Planck eigenvalues equation and solve it for the harmonic oscillator plus a centrifugal-type potential. Furthermore, when the drift function is odd, we reduce our results to those of the recently developed Wigner-Dunkl supersymmetry."], "authors": "R. D. Mota"},
{"Title": "Even-odd alternative dispersions and beyond. Part II. Noninertial and inertial particles, and, astrophysical chirality analogy", "abs": ["Particle transports in carriers with even-odd alternating dispersions (introduced in Part I) are investigated. For the third-order dispersion as in Korteweg-de-Vries (KdV), such alternating dispersion has the effects of not only regularizing the velocity from forming shock singularity (thus the attenuation of particle clustering strength) but also symmetrizing the oscillations (thus the corresponding skewness of the particle densities), among others, as demonstrated numerically. The analogy of such dispersion effects and consequences (on particle transports in particular) with those of helicity in Burgers turbulence, addressed in the context of astrophysics and cosmology, is made for illumination and promoting models. Both dispersion and helicity regularize the respective systems, and both are shown to be transferred by the drag to the flows of the respective inertial particles carried by the latter and to similarly affect the particle clustering. A reward from studying particle transports is the understanding of the (asymptotic) $k^0$-scaling (equipartition among the wavenumbers, $k$s), before large-$k$ exponential decay, of the power spectrum of KdV solitons [resulting in the more general statement (valid beyond the KdV soliton and Burgers shock) that \"a (one-dimensional) soliton is the derivative of a classical shock, just like the Dirac delta is the derivative of a step function\"], motivated by the explanation of the the same scaling law of the particle densities as the apparent approximation of the Dirac deltas; while, the \"shocliton\" from the even-odd alternating dispersion in aKdV appears to be, indeed, $shock \\oplus soliton$, accordingly the decomposition of the averaged odd-mode spectrum, from sinusoidal initial field, into a $k^{-2}$ part for the shock and a $k^0$-scaling part for the solitonic pulses, only the latter being contained in the averaged even-mode spectrum."], "authors": "Jian-Zhou Zhu"},
{"Title": "Even-odd alternative dispersions and beyond. Part I. Similar oscillations on both sides of the shock and miscellaneous numerical indications", "abs": ["Mathematically, the variational principle and Hamiltonian formulation of some models, such as the Korteweg-de Vries (KdV) equation, are preserved, \\textit{mutatis mutandis}, if each mode of freedom is assigned a different dispersion coefficient; and, physically, dispersive oscillations appear on both sides of some ion-acoustic and quantum shocks, not generated by the dynamics of the models such as the KdV(-Burgers) equation. We thus consider assigning different types of dispersions for different dynamical modes, particularly with the alternation of the signs for alternative Fourier components. The KdV equation with periodic boundary condition and longest-wave sinusoidal initial field, as used by N. Zabusky and M. D. Kruskal, is chosen for our case study with such alternating-dispersion of the Fourier modes of (normalized) even and odd wavenumbers. Numerical results verify the capability of our new model to produce two-sided (around the shock) oscillations, as appear on both sides of some ion-acoustic and quantum shocks, and also indicate even more, including singular zero-dispersion limit or non-convergence to the classical shock (described by the entropy solution), non-thermalization (of the Galerkin-truncated models) and applicability to other models (showcased by the modified KdV equation with cubic nonlinearity). A unification of various dispersive models, keeping the essential mathematical elegance (such as the variational principle and Hamiltonian formulation) of each, for phenomena with complicated dispersion relation is thus suggested with a further explicit example of two even-order dispersions (from the Hilbert transforms) extending the Benjamin-Ono model."], "authors": "Jian-Zhou Zhu"},
{"Title": "Inertial evolution of non-linear viscoelastic solids in the face of (self-)collision", "abs": ["We study the time evolution of non-linear viscoelastic solids in the presence of inertia and (self-)contact. For this problem we prove the existence of weak solutions for arbitrary times and initial data, thereby solving an open problem in the field. Our construction directly includes the physically correct, measure-valued contact forces and thus obeys conservation of momentum and an energy balance. In particular, we prove an independently useful compactness result for contact forces."], "authors": "Antonín Češík"},
{"Title": "Functional Continuous Uncertainty Principle", "abs": ["Let $(\\Omega, \\mu)$, $(\\Delta, \\nu)$ be measure spaces. Let $(\\{f_\\alpha\\}_{\\alpha\\in \\Omega}, \\{\\tau_\\alpha\\}_{\\alpha\\in \\Omega})$ and $(\\{g_\\beta\\}_{\\beta\\in \\Delta}, \\{\\omega_\\beta\\}_{\\beta\\in \\Delta})$ be continuous p-Schauder frames for a Banach space $\\mathcal{X}$. Then for every $x \\in \\mathcal{X}\\setminus\\{0\\}$, we show that \\begin{align} (1) \\quad \\quad \\quad \\quad \\mu(\\operatorname{supp}(\\theta_f x))^\\frac{1}{p} \\nu(\\operatorname{supp}(\\theta_g x))^\\frac{1}{q} \\geq \\frac{1}{\\displaystyle\\sup_{\\alpha \\in \\Omega, \\beta \\in \\Delta}|f_\\alpha(\\omega_\\beta)|}, \\quad \\nu(\\operatorname{supp}(\\theta_g x))^\\frac{1}{p} \\mu(\\operatorname{supp}(\\theta_f x))^\\frac{1}{q}\\geq \\frac{1}{\\displaystyle\\sup_{\\alpha \\in \\Omega , \\beta \\in \\Delta}|g_\\beta(\\tau_\\alpha)|}. \\end{align} where \\begin{align*} &\\theta_f: \\mathcal{X} \\ni x \\mapsto \\theta_fx \\in \\mathcal{L}^p(\\Omega, \\mu); \\quad \\theta_fx: \\Omega \\ni \\alpha \\mapsto (\\theta_fx) (\\alpha):= f_\\alpha (x) \\in \\mathbb{K}, &\\theta_g: \\mathcal{X} \\ni x \\mapsto \\theta_gx \\in \\mathcal{L}^p(\\Delta, \\nu); \\quad \\theta_gx: \\Delta \\ni \\beta \\mapsto (\\theta_gx) (\\beta):= g_\\beta (x) \\in \\mathbb{K} \\end{align*} and $q$ is the conjugate index of $p$. We call Inequality (1) as \\textbf{Functional Continuous Uncertainty Principle}. It improves the Functional Donoho-Stark-Elad-Bruckstein-Ricaud-Torrésani Uncertainty Principle obtained by K. Mahesh Krishna in [", "[math.FA], 5 April 2023]. It also answers a question asked by Prof. Philip B. Stark to the author. Based on Donoho-Elad Sparsity Theorem, we formulate Measure Minimization Conjecture."], "authors": "K. Mahesh Krishna"},
{"Title": "Learning with Errors over Group Rings Constructed by Semi-direct Product", "abs": ["The Learning with Errors (LWE) problem has been widely utilized as a foundation for numerous cryptographic tools over the years. In this study, we focus on an algebraic variant of the LWE problem called Group ring LWE (GR-LWE). We select group rings (or their direct summands) that underlie specific families of finite groups constructed by taking the semi-direct product of two cyclic groups. Unlike the Ring-LWE problem described in \\cite{lyubashevsky2010ideal}, the multiplication operation in the group rings considered here is non-commutative. As an extension of Ring-LWE, it maintains computational hardness and can be potentially applied in many cryptographic scenarios. In this paper, we present two polynomial-time quantum reductions. Firstly, we provide a quantum reduction from the worst-case shortest independent vectors problem (SIVP) in ideal lattices with polynomial approximate factor to the search version of GR-LWE. This reduction requires that the underlying group ring possesses certain mild properties; Secondly, we present another quantum reduction for two types of group rings, where the worst-case SIVP problem is directly reduced to the (average-case) decision GR-LWE problem. The pseudorandomness of GR-LWE samples guaranteed by this reduction can be consequently leveraged to construct semantically secure public-key cryptosystems."], "authors": "Jiaqi Liu"},
{"Title": "DeepJSCC-l++: Robust and Bandwidth-Adaptive Wireless Image Transmission", "abs": ["This paper presents a novel vision transformer (ViT) based deep joint source channel coding (DeepJSCC) scheme, dubbed DeepJSCC-l++, which can be adaptive to multiple target bandwidth ratios as well as different channel signal-to-noise ratios (SNRs) using a single model. To achieve this, we train the proposed DeepJSCC-l++ model with different bandwidth ratios and SNRs, which are fed to the model as side information. The reconstruction losses corresponding to different bandwidth ratios are calculated, and a new training methodology is proposed, which dynamically assigns different weights to the losses of different bandwidth ratios according to their individual reconstruction qualities. Shifted window (Swin) transformer, is adopted as the backbone for our DeepJSCC-l++ model. Through extensive simulations it is shown that the proposed DeepJSCC-l++ and successive refinement models can adapt to different bandwidth ratios and channel SNRs with marginal performance loss compared to the separately trained models. We also observe the proposed schemes can outperform the digital baseline, which concatenates the BPG compression with capacity-achieving channel code."], "authors": "Chenghong Bian"},
{"Title": "Artificial Intelligence in Sustainable Vertical Farming", "abs": ["As global challenges of population growth, climate change, and resource scarcity intensify, the agricultural landscape is at a critical juncture. Sustainable vertical farming emerges as a transformative solution to address these challenges by maximizing crop yields in controlled environments. This paradigm shift necessitates the integration of cutting-edge technologies, with Artificial Intelligence (AI) at the forefront. The paper provides a comprehensive exploration of the role of AI in sustainable vertical farming, investigating its potential, challenges, and opportunities. The review synthesizes the current state of AI applications, encompassing machine learning, computer vision, the Internet of Things (IoT), and robotics, in optimizing resource usage, automating tasks, and enhancing decision-making. It identifies gaps in research, emphasizing the need for optimized AI models, interdisciplinary collaboration, and the development of explainable AI in agriculture. The implications extend beyond efficiency gains, considering economic viability, reduced environmental impact, and increased food security. The paper concludes by offering insights for stakeholders and suggesting avenues for future research, aiming to guide the integration of AI technologies in sustainable vertical farming for a resilient and sustainable future in agriculture."], "authors": "Hribhu Chowdhury"},
{"Title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based Alignment Framework", "abs": ["Modern Large language models (LLMs) can still generate responses that may not be aligned with human expectations or values. While many weight-based alignment methods have been proposed, many of them still leave models vulnerable to attacks when used on their own. To help mitigate this issue, we introduce Bergeron, a framework designed to improve the robustness of LLMs against adversarial attacks. Bergeron employs a two-tiered architecture. Here, a secondary LLM serves as a simulated conscience that safeguards a primary LLM. We do this by monitoring for and correcting potentially harmful text within both the prompt inputs and the generated outputs of the primary LLM. Empirical evaluation shows that Bergeron can improve the alignment and robustness of several popular LLMs without costly fine-tuning. It aids both open-source and black-box LLMs by complementing and reinforcing their existing alignment training."], "authors": "Matthew Pisano"},
{"Title": "Stealthy and Persistent Unalignment on Large Language Models via Backdoor Injections", "abs": ["Recent developments in Large Language Models (LLMs) have manifested significant advancements. To facilitate safeguards against malicious exploitation, a body of research has concentrated on aligning LLMs with human preferences and inhibiting their generation of inappropriate content. Unfortunately, such alignments are often vulnerable: fine-tuning with a minimal amount of harmful data can easily unalign the target LLM. While being effective, such fine-tuning-based unalignment approaches also have their own limitations: (1) non-stealthiness, after fine-tuning, safety audits or red-teaming can easily expose the potential weaknesses of the unaligned models, thereby precluding their release/use. (2) non-persistence, the unaligned LLMs can be easily repaired through re-alignment, i.e., fine-tuning again with aligned data points. In this work, we show that it is possible to conduct stealthy and persistent unalignment on large language models via backdoor injections. We also provide a novel understanding on the relationship between the backdoor persistence and the activation pattern and further provide guidelines for potential trigger design. Through extensive experiments, we demonstrate that our proposed stealthy and persistent unalignment can successfully pass the safety evaluation while maintaining strong persistence against re-alignment defense."], "authors": "Yuanpu Cao"},
{"Title": "Scalable Meta-Learning with Gaussian Processes", "abs": ["Meta-learning is a powerful approach that exploits historical data to quickly solve new tasks from the same distribution. In the low-data regime, methods based on the closed-form posterior of Gaussian processes (GP) together with Bayesian optimization have achieved high performance. However, these methods are either computationally expensive or introduce assumptions that hinder a principled propagation of uncertainty between task models. This may disrupt the balance between exploration and exploitation during optimization. In this paper, we develop ScaML-GP, a modular GP model for meta-learning that is scalable in the number of tasks. Our core contribution is a carefully designed multi-task kernel that enables hierarchical training and task scalability. Conditioning ScaML-GP on the meta-data exposes its modular nature yielding a test-task prior that combines the posteriors of meta-task GPs. In synthetic and real-world meta-learning experiments, we demonstrate that ScaML-GP can learn efficiently both with few and many meta-tasks."], "authors": "Petru Tighineanu"},
{"Title": "Infrared Image Super-Resolution via GAN", "abs": ["The ability of generative models to accurately fit data distributions has resulted in their widespread adoption and success in fields such as computer vision and natural language processing. In this chapter, we provide a brief overview of the application of generative models in the domain of infrared (IR) image super-resolution, including a discussion of the various challenges and adversarial training methods employed. We propose potential areas for further investigation and advancement in the application of generative models for IR image super-resolution."], "authors": "Yongsong Huang"},
{"Title": "Unsupervised Adaptive Implicit Neural Representation Learning for Scan-Specific MRI Reconstruction", "abs": ["In recent studies on MRI reconstruction, advances have shown significant promise for further accelerating the MRI acquisition. Most state-of-the-art methods require a large amount of fully-sampled data to optimise reconstruction models, which is impractical and expensive under certain clinical settings. On the other hand, for unsupervised scan-specific reconstruction methods, overfitting is likely to happen due to insufficient supervision, while restrictions on acceleration rates and under-sampling patterns further limit their applicability. To this end, we propose an unsupervised, adaptive coarse-to-fine framework that enhances reconstruction quality without being constrained by the sparsity levels or patterns in under-sampling. The framework employs an implicit neural representation for scan-specific MRI reconstruction, learning a mapping from multi-dimensional coordinates to their corresponding signal intensities. Moreover, we integrate a novel learning strategy that progressively refines the use of acquired k-space signals for self-supervision. This approach effectively adjusts the proportion of supervising signals from unevenly distributed information across different frequency bands, thus mitigating the issue of overfitting while improving the overall reconstruction. Comprehensive evaluation on a public dataset, including both 2D and 3D data, has shown that our method outperforms current state-of-the-art scan-specific MRI reconstruction techniques, for up to 8-fold under-sampling."], "authors": "Junwei Yang"},
{"Title": "Dual-Domain Multi-Contrast MRI Reconstruction with Synthesis-based Fusion Network", "abs": ["Purpose: To develop an efficient dual-domain reconstruction framework for multi-contrast MRI, with the focus on minimising cross-contrast misalignment in both the image and the frequency domains to enhance optimisation. Theory and Methods: Our proposed framework, based on deep learning, facilitates the optimisation for under-sampled target contrast using fully-sampled reference contrast that is quicker to acquire. The method consists of three key steps: 1) Learning to synthesise data resembling the target contrast from the reference contrast; 2) Registering the multi-contrast data to reduce inter-scan motion; and 3) Utilising the registered data for reconstructing the target contrast. These steps involve learning in both domains with regularisation applied to ensure their consistency. We also compare the reconstruction performance with existing deep learning-based methods using a dataset of brain MRI scans. Results: Extensive experiments demonstrate the superiority of our proposed framework, for up to an 8-fold acceleration rate, compared to state-of-the-art algorithms. Comprehensive analysis and ablation studies further present the effectiveness of the proposed components. Conclusion:Our dual-domain framework offers a promising approach to multi-contrast MRI reconstruction. It can also be integrated with existing methods to further enhance the reconstruction."], "authors": "Junwei Yang"},
{"Title": "A Recent Survey of Vision Transformers for Medical Image Segmentation", "abs": ["Medical image segmentation plays a crucial role in various healthcare applications, enabling accurate diagnosis, treatment planning, and disease monitoring. In recent years, Vision Transformers (ViTs) have emerged as a promising technique for addressing the challenges in medical image segmentation. In medical images, structures are usually highly interconnected and globally distributed. ViTs utilize their multi-scale attention mechanism to model the long-range relationships in the images. However, they do lack image-related inductive bias and translational invariance, potentially impacting their performance. Recently, researchers have come up with various ViT-based approaches that incorporate CNNs in their architectures, known as Hybrid Vision Transformers (HVTs) to capture local correlation in addition to the global information in the images. This survey paper provides a detailed review of the recent advancements in ViTs and HVTs for medical image segmentation. Along with the categorization of ViT and HVT-based medical image segmentation approaches we also present a detailed overview of their real-time applications in several medical image modalities. This survey may serve as a valuable resource for researchers, healthcare practitioners, and students in understanding the state-of-the-art approaches for ViT-based medical image segmentation."], "authors": "Asifullah Khan"},
{"Title": "Weighted Riesz Particles", "abs": ["Markov chain Monte Carlo (MCMC) methods are simulated by local exploration of complex statistical distributions, and while bypassing the cumbersome requirement of a specific analytical expression for the target, this stochastic exploration of an uncertain parameter space comes at the expense of a large number of samples, and this computational complexity increases with parameter dimensionality. Although at the exploration level, some methods are proposed to accelerate the convergence of the algorithm, such as tempering, Hamiltonian Monte Carlo, Rao-redwellization, and scalable methods for better performance, it cannot avoid the stochastic nature of this exploration. We consider the target distribution as a mapping where the infinite-dimensional Eulerian space of the parameters consists of a number of deterministic submanifolds and propose a generalized energy metric, termed weighted Riesz energy, where a number of points is generated through pairwise interactions, to discretize rectifiable submanifolds. We study the properties of the point, called Riesz particle, and embed it into sequential MCMC, and we find that there will be higher acceptance rates with fewer evaluations, we validate it through experimental comparative analysis from a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility model with real-world data."], "authors": "Xiongming Dai"},
{"Title": "RIS-Based On-the-Air Semantic Communications -- a Diffractional Deep Neural Network Approach", "abs": ["Semantic communication has gained significant attention recently due to its advantages in achieving higher transmission efficiency by focusing on semantic information instead of bit-level information. However, current AI-based semantic communication methods require digital hardware for implementation. With the rapid advancement on reconfigurable intelligence surfaces (RISs), a new approach called on-the-air diffractional deep neural networks (D$^2$NN) can be utilized to enable semantic communications on the wave domain. This paper proposes a new paradigm of RIS-based on-the-air semantic communications, where the computational process occurs inherently as wireless signals pass through RISs. We present the system model and discuss the data and control flows of this scheme, followed by a performance analysis using image transmission as an example. In comparison to traditional hardware-based approaches, RIS-based semantic communications offer appealing features, such as light-speed computation, low computational power requirements, and the ability to handle multiple tasks simultaneously."], "authors": "Shuyi Chen"},
{"Title": "Adaptive Parameter-Free Robust Learning using Latent Bernoulli Variables", "abs": ["We present an efficient parameter-free approach for statistical learning from corrupted training sets. We identify corrupted and non-corrupted samples using latent Bernoulli variables, and therefore formulate the robust learning problem as maximization of the likelihood where latent variables are marginalized out. The resulting optimization problem is solved via variational inference using an efficient Expectation-Maximization based method. The proposed approach improves over the state-of-the-art by automatically inferring the corruption level and identifying outliers, while adding minimal computational overhead. We demonstrate our robust learning method on a wide variety of machine learning tasks including online learning and deep learning where it exhibits ability to adapt to different levels of noise and attain high prediction accuracy."], "authors": "Aleksandr Karakulev"},
{"Title": "Chebyshev Particles", "abs": ["Markov chain Monte Carlo (MCMC) provides a feasible method for inferring Hidden Markov models, however, it is often computationally prohibitive, especially constrained by the curse of dimensionality, as the Monte Carlo sampler traverses randomly taking small steps within uncertain regions in the parameter space. We are the first to consider the posterior distribution of the objective as a mapping of samples in an infinite-dimensional Euclidean space where deterministic submanifolds are embedded and propose a new criterion by maximizing the weighted Riesz polarization quantity, to discretize rectifiable submanifolds via pairwise interaction. We study the characteristics of Chebyshev particles and embed them into sequential MCMC, a novel sampler with a high acceptance ratio that proposes only a few evaluations. We have achieved high performance from the experiments for parameter inference in a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility model with real-world data."], "authors": "Xiongming Dai"},
{"Title": "Algorithm-based diagnostic application for diabetic retinopathy detection", "abs": ["Diabetic retinopathy (DR) is a growing health problem worldwide and is a leading cause of visual impairment and blindness, especially among working people aged 20-65. Its incidence is increasing along with the number of diabetes cases, and it is more common in developed countries than in developing countries. Recent research in the field of diabetic retinopathy diagnosis is using advanced technologies, such as analysis of images obtained by ophthalmoscopy. Automatic methods for analyzing eye images based on neural networks, deep learning and image analysis algorithms can improve the efficiency of diagnosis. This paper describes an automatic DR diagnosis method that includes processing and analysis of ophthalmoscopic images of the eye. It uses morphological algorithms to identify the optic disc and lesions characteristic of DR, such as microaneurysms, hemorrhages and exudates. Automated DR diagnosis has the potential to improve the efficiency of early detection of this disease and contribute to reducing the number of cases of diabetes-related visual impairment. The final step was to create an application with a graphical user interface that allowed retinal images taken at cooperating ophthalmology offices to be uploaded to the server. These images were then analyzed using a developed algorithm to make a diagnosis."], "authors": "Agnieszka Cisek"},
{"Title": "Bayesian causal discovery from unknown general interventions", "abs": ["We consider the problem of learning causal Directed Acyclic Graphs (DAGs) using combinations of observational and interventional experimental data. Current methods tailored to this setting assume that interventions either destroy parent-child relations of the intervened (target) nodes or only alter such relations without modifying the parent sets, even when the intervention targets are unknown. We relax this assumption by proposing a Bayesian method for causal discovery from general interventions, which allow for modifications of the parent sets of the unknown targets. Even in this framework, DAGs and general interventions may be identifiable only up to some equivalence classes. We provide graphical characterizations of such interventional Markov equivalence and devise compatible priors for Bayesian inference that guarantee score equivalence of indistinguishable structures. We then develop a Markov Chain Monte Carlo (MCMC) scheme to approximate the posterior distribution over DAGs, intervention targets and induced parent sets. Finally, we evaluate the proposed methodology on both simulated and real protein expression data."], "authors": "Alessandro Mascaro"},
{"Title": "Auto-encoding GPS data to reveal individual and collective behaviour", "abs": ["We propose an innovative and generic methodology to analyse individual and collective behaviour through individual trajectory data. The work is motivated by the analysis of GPS trajectories of fishing vessels collected from regulatory tracking data in the context of marine biodiversity conservation and ecosystem-based fisheries management. We build a low-dimensional latent representation of trajectories using convolutional neural networks as non-linear mapping. This is done by training a conditional variational auto-encoder taking into account covariates. The posterior distributions of the latent representations can be linked to the characteristics of the actual trajectories. The latent distributions of the trajectories are compared with the Bhattacharyya coefficient, which is well-suited for comparing distributions. Using this coefficient, we analyse the variation of the individual behaviour of each vessel during time. For collective behaviour analysis, we build proximity graphs and use an extension of the stochastic block model for multiple networks. This model results in a clustering of the individuals based on their set of trajectories. The application to French fishing vessels enables us to obtain groups of vessels whose individual and collective behaviours exhibit spatio-temporal patterns over the period 2014-2018."], "authors": "Saint-Clair Chabert-Liddell"},
{"Title": "Partition-based K-space Synthesis for Multi-contrast Parallel Imaging", "abs": ["Multi-contrast magnetic resonance imaging is a significant and essential medical imaging technique.However, multi-contrast imaging has longer acquisition time and is easy to cause motion artifacts. In particular, the acquisition time for a T2-weighted image is prolonged due to its longer repetition time (TR). On the contrary, T1-weighted image has a shorter TR. Therefore,utilizing complementary information across T1 and T2-weighted image is a way to decrease the overall imaging time. Previous T1-assisted T2 reconstruction methods have mostly focused on image domain using whole-based image fusion approaches. The image domain reconstruction method has the defects of high computational complexity and limited flexibility. To address this issue, we propose a novel multi-contrast imaging method called partition-based k-space synthesis (PKS) which can achieve super reconstruction quality of T2-weighted image by feature fusion. Concretely, we first decompose fully-sampled T1 k-space data and under-sampled T2 k-space data into two sub-data, separately. Then two new objects are constructed by combining the two sub-T1/T2 data. After that, the two new objects as the whole data to realize the reconstruction of T2-weighted image. Finally, the objective T2 is synthesized by extracting the sub-T2 data of each part. Experimental results showed that our combined technique can achieve comparable or better results than using traditional k-space parallel imaging(SAKE) that processes each contrast independently."], "authors": "Yuxia Huang"},
{"Title": "QIENet: Quantitative irradiance estimation network using recurrent neural network based on satellite remote sensing data", "abs": ["Global horizontal irradiance (GHI) plays a vital role in estimating solar energy resources, which are used to generate sustainable green energy. In order to estimate GHI with high spatial resolution, a quantitative irradiance estimation network, named QIENet, is proposed. Specifically, the temporal and spatial characteristics of remote sensing data of the satellite Himawari-8 are extracted and fused by recurrent neural network (RNN) and convolution operation, respectively. Not only remote sensing data, but also GHI-related time information (hour, day, and month) and geographical information (altitude, longitude, and latitude), are used as the inputs of QIENet. The satellite spectral channels B07 and B11 - B15 and time are recommended as model inputs for QIENet according to the spatial distributions of annual solar energy. Meanwhile, QIENet is able to capture the impact of various clouds on hourly GHI estimates. More importantly, QIENet does not overestimate ground observations and can also reduce RMSE by 27.51%/18.00%, increase R2 by 20.17%/9.42%, and increase r by 8.69%/3.54% compared with ERA5/NSRDB. Furthermore, QIENet is capable of providing a high-fidelity hourly GHI database with spatial resolution 0.02° * 0.02°(approximately 2km * 2km) for many applied energy fields."], "authors": "Longfeng Nie"},
{"Title": "From Mutual Information to Expected Dynamics: New Generalization Bounds for Heavy-Tailed SGD", "abs": ["Understanding the generalization abilities of modern machine learning algorithms has been a major research topic over the past decades. In recent years, the learning dynamics of Stochastic Gradient Descent (SGD) have been related to heavy-tailed dynamics. This has been successfully applied to generalization theory by exploiting the fractal properties of those dynamics. However, the derived bounds depend on mutual information (decoupling) terms that are beyond the reach of computability. In this work, we prove generalization bounds over the trajectory of a class of heavy-tailed dynamics, without those mutual information terms. Instead, we introduce a geometric decoupling term by comparing the learning dynamics (depending on the empirical risk) with an expected one (depending on the population risk). We further upper-bound this geometric term, by using techniques from the heavy-tailed and the fractal literature, making it fully computable. Moreover, as an attempt to tighten the bounds, we propose a PAC-Bayesian setting based on perturbed dynamics, in which the same geometric term plays a crucial role and can still be bounded using the techniques described above."], "authors": "Benjamin Dupuis"},
{"Title": "Local monotone operator learning using non-monotone operators: MnM-MOL", "abs": ["The recovery of magnetic resonance (MR) images from undersampled measurements is a key problem that has seen extensive research in recent years. Unrolled approaches, which rely on end-to-end training of convolutional neural network (CNN) blocks within iterative reconstruction algorithms, offer state-of-the-art performance. These algorithms require a large amount of memory during training, making them difficult to employ in high-dimensional applications. Deep equilibrium (DEQ) models and the recent monotone operator learning (MOL) approach were introduced to eliminate the need for unrolling, thus reducing the memory demand during training. Both approaches require a Lipschitz constraint on the network to ensure that the forward and backpropagation iterations converge. Unfortunately, the constraint often results in reduced performance compared to unrolled methods. The main focus of this work is to relax the constraint on the CNN block in two different ways. Inspired by convex-non-convex regularization strategies, we now impose the monotone constraint on the sum of the gradient of the data term and the CNN block, rather than constrain the CNN itself to be a monotone operator. This approach enables the CNN to learn possibly non-monotone score functions, which can translate to improved performance. In addition, we only restrict the operator to be monotone in a local neighborhood around the image manifold. Our theoretical results show that the proposed algorithm is guaranteed to converge to the fixed point and that the solution is robust to input perturbations, provided that it is initialized close to the true solution. Our empirical results show that the relaxed constraints translate to improved performance and that the approach enjoys robustness to input perturbations similar to MOL."], "authors": "Maneesh John"},
{"Title": "A Generalizable Deep Learning System for Cardiac MRI", "abs": ["Cardiac MRI allows for a comprehensive assessment of myocardial structure, function, and tissue characteristics. Here we describe a foundational vision system for cardiac MRI, capable of representing the breadth of human cardiovascular disease and health. Our deep learning model is trained via self-supervised contrastive learning, by which visual concepts in cine-sequence cardiac MRI scans are learned from the raw text of the accompanying radiology reports. We train and evaluate our model on data from four large academic clinical institutions in the United States. We additionally showcase the performance of our models on the UK BioBank, and two additional publicly available external datasets. We explore emergent zero-shot capabilities of our system, and demonstrate remarkable performance across a range of tasks; including the problem of left ventricular ejection fraction regression, and the diagnosis of 35 different conditions such as cardiac amyloidosis and hypertrophic cardiomyopathy. We show that our deep learning system is capable of not only understanding the staggering complexity of human cardiovascular disease, but can be directed towards clinical problems of interest yielding impressive, clinical grade diagnostic accuracy with a fraction of the training data typically required for such tasks."], "authors": "Rohan Shad"},
{"Title": "Enhancing Ligand Pose Sampling for Molecular Docking", "abs": ["Deep learning promises to dramatically improve scoring functions for molecular docking, leading to substantial advances in binding pose prediction and virtual screening. To train scoring functions-and to perform molecular docking-one must generate a set of candidate ligand binding poses. Unfortunately, the sampling protocols currently used to generate candidate poses frequently fail to produce any poses close to the correct, experimentally determined pose, unless information about the correct pose is provided. This limits the accuracy of learned scoring functions and molecular docking. Here, we describe two improved protocols for pose sampling: GLOW (auGmented sampLing with sOftened vdW potential) and a novel technique named IVES (IteratiVe Ensemble Sampling). Our benchmarking results demonstrate the effectiveness of our methods in improving the likelihood of sampling accurate poses, especially for binding pockets whose shape changes substantially when different ligands bind. This improvement is observed across both experimentally determined and AlphaFold-generated protein structures. Additionally, we present datasets of candidate ligand poses generated using our methods for each of around 5,000 protein-ligand cross-docking pairs, for training and testing scoring functions. To benefit the research community, we provide these cross-docking datasets and an open-source Python implementation of GLOW and IVES at", "."], "authors": "Patricia Suriana"},
{"Title": "Planning Reliability Assurance Tests for Autonomous Vehicles", "abs": ["Artificial intelligence (AI) technology has become increasingly prevalent and transforms our everyday life. One important application of AI technology is the development of autonomous vehicles (AV). However, the reliability of an AV needs to be carefully demonstrated via an assurance test so that the product can be used with confidence in the field. To plan for an assurance test, one needs to determine how many AVs need to be tested for how many miles and the standard for passing the test. Existing research has made great efforts in developing reliability demonstration tests in the other fields of applications for product development and assessment. However, statistical methods have not been utilized in AV test planning. This paper aims to fill in this gap by developing statistical methods for planning AV reliability assurance tests based on recurrent events data. We explore the relationship between multiple criteria of interest in the context of planning AV reliability assurance tests. Specifically, we develop two test planning strategies based on homogeneous and non-homogeneous Poisson processes while balancing multiple objectives with the Pareto front approach. We also offer recommendations for practical use. The disengagement events data from the California Department of Motor Vehicles AV testing program is used to illustrate the proposed assurance test planning methods."], "authors": "Simin Zheng"},
{"Title": "Compression of end-to-end non-autoregressive image-to-speech system for low-resourced devices", "abs": ["People with visual impairments have difficulty accessing touchscreen-enabled personal computing devices like mobile phones and laptops. The image-to-speech (ITS) systems can assist them in mitigating this problem, but their huge model size makes it extremely hard to be deployed on low-resourced embedded devices. In this paper, we aim to overcome this challenge by developing an efficient endto-end neural architecture for generating audio from tiny segments of display content on low-resource devices. We introduced a vision transformers-based image encoder and utilized knowledge distillation to compress the model from 6.1 million to 2.46 million parameters. Human and automatic evaluation results show that our approach leads to a very minimal drop in performance and can speed up the inference time by 22%."], "authors": "Gokul Srinivasagan"},
{"Title": "Dense Optical Tracking: Connecting the Dots", "abs": ["Recent approaches to point tracking are able to recover the trajectory of any scene point through a large portion of a video despite the presence of occlusions. They are, however, too slow in practice to track every point observed in a single frame in a reasonable amount of time. This paper introduces DOT, a novel, simple and efficient method for solving this problem. It first extracts a small set of tracks from key regions at motion boundaries using an off-the-shelf point tracking algorithm. Given source and target frames, DOT then computes rough initial estimates of a dense flow field and visibility mask through nearest-neighbor interpolation, before refining them using a learnable optical flow estimator that explicitly handles occlusions and can be trained on synthetic data with ground-truth correspondences. We show that DOT is significantly more accurate than current optical flow techniques, outperforms sophisticated \"universal\" trackers like OmniMotion, and is on par with, or better than, the best point tracking algorithms like CoTracker while being at least two orders of magnitude faster. Quantitative and qualitative experiments with synthetic and real videos validate the promise of the proposed approach. Code, data, and videos showcasing the capabilities of our approach are available in the project webpage:", "."], "authors": "Guillaume Le Moing"},
{"Title": "PDB-Struct: A Comprehensive Benchmark for Structure-based Protein Design", "abs": ["Structure-based protein design has attracted increasing interest, with numerous methods being introduced in recent years. However, a universally accepted method for evaluation has not been established, since the wet-lab validation can be overly time-consuming for the development of new algorithms, and the $\\textit{in silico}$ validation with recovery and perplexity metrics is efficient but may not precisely reflect true foldability. To address this gap, we introduce two novel metrics: refoldability-based metric, which leverages high-accuracy protein structure prediction models as a proxy for wet lab experiments, and stability-based metric, which assesses whether models can assign high likelihoods to experimentally stable proteins. We curate datasets from high-quality CATH protein data, high-throughput $\\textit{de novo}$ designed proteins, and mega-scale experimental mutagenesis experiments, and in doing so, present the $\\textbf{PDB-Struct}$ benchmark that evaluates both recent and previously uncompared protein design methods. Experimental results indicate that ByProt, ProteinMPNN, and ESM-IF perform exceptionally well on our benchmark, while ESM-Design and AF-Design fall short on the refoldability metric. We also show that while some methods exhibit high sequence recovery, they do not perform as well on our new benchmark. Our proposed benchmark paves the way for a fair and comprehensive evaluation of protein design methods in the future. Code is available at", "."], "authors": "Chuanrui Wang"},
{"Title": "A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging", "abs": ["Functional Magnetic Resonance Imaging (fMRI) data is a kind of widely used four-dimensional biomedical data, demanding effective compression but presenting unique challenges for compression due to its intricate temporal dynamics, low signal-to-noise ratio, and complicated underlying redundancies. This paper reports a novel compression paradigm specifically tailored for fMRI data based on Implicit Neural Representation (INR). The proposed approach focuses on removing the various redundancies among the time series, including (i) conducting spatial correlation modeling for intra-region dynamics, (ii) decomposing reusable neuronal activation patterns, and using proper initialization together with nonlinear fusion to describe the inter-region similarity. The above scheme properly incorporates the unique features of fMRI data, and experimental results on publicly available datasets demonstrate the effectiveness of the proposed method, surpassing state-of-the-art algorithms in both conventional image quality evaluation metrics and fMRI downstream tasks. This work in this paper paves the way for sharing massive fMRI data at low bandwidth and high fidelity."], "authors": "Ruoran Li"},
{"Title": "Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning?", "abs": ["Inverse Reinforcement Learning (IRL) -- the problem of learning reward functions from demonstrations of an \\emph{expert policy} -- plays a critical role in developing intelligent systems, such as those that understand and imitate human behavior. While widely used in applications, theoretical understandings of IRL admit unique challenges and remain less developed compared with standard RL theory. For example, it remains open how to do IRL efficiently in standard \\emph{offline} settings with pre-collected data, where states are obtained from a \\emph{behavior policy} (which could be the expert policy itself), and actions are sampled from the expert policy.", "This paper provides the first line of results for efficient IRL in vanilla offline and online settings using polynomial samples and runtime. We first design a new IRL algorithm for the offline setting, Reward Learning with Pessimism (RLP), and show that it achieves polynomial sample complexity in terms of the size of the MDP, a concentrability coefficient between the behavior policy and the expert policy, and the desired accuracy. Building on RLP, we further design an algorithm Reward Learning with Exploration (RLE), which operates in a natural online setting where the learner can both actively explore the environment and query the expert policy, and obtain a stronger notion of IRL guarantee from polynomial samples. We establish sample complexity lower bounds for both settings showing that RLP and RLE are nearly optimal. Finally, as an application, we show that the learned reward functions can \\emph{transfer} to another target MDP with suitable guarantees when the target MDP satisfies certain similarity assumptions with the original (source) MDP."], "authors": "Lei Zhao"},
{"Title": "Sequential Modeling Enables Scalable Learning for Large Vision Models", "abs": ["We introduce a novel sequential modeling approach which enables learning a Large Vision Model (LVM) without making use of any linguistic data. To do this, we define a common format, \"visual sentences\", in which we can represent raw images and videos as well as annotated data sources such as semantic segmentations and depth reconstructions without needing any meta-knowledge beyond the pixels. Once this wide variety of visual data (comprising 420 billion tokens) is represented as sequences, the model can be trained to minimize a cross-entropy loss for next token prediction. By training across various scales of model architecture and data diversity, we provide empirical evidence that our models scale effectively. Many different vision tasks can be solved by designing suitable visual prompts at test time."], "authors": "Yutong Bai"},
{"Title": "Making Large Multimodal Models Understand Arbitrary Visual Prompts", "abs": ["While existing large vision-language multimodal models focus on whole image understanding, there is a prominent gap in achieving region-specific comprehension. Current approaches that use textual coordinates or spatial encodings often fail to provide a user-friendly interface for visual prompting. To address this challenge, we introduce a novel multimodal model capable of decoding arbitrary visual prompts. This allows users to intuitively mark images and interact with the model using natural cues like a \"red bounding box\" or \"pointed arrow\". Our simple design directly overlays visual markers onto the RGB image, eliminating the need for complex region encodings, yet achieves state-of-the-art performance on region-understanding tasks like Visual7W, PointQA, and Visual Commonsense Reasoning benchmark. Furthermore, we present ViP-Bench, a comprehensive benchmark to assess the capability of models in understanding visual prompts across multiple dimensions, enabling future research in this domain. Code, data, and model are publicly available."], "authors": "Mu Cai"},
{"Title": "MorpheuS: Neural Dynamic 360° Surface Reconstruction from Monocular RGB-D Video", "abs": ["Neural rendering has demonstrated remarkable success in dynamic scene reconstruction. Thanks to the expressiveness of neural representations, prior works can accurately capture the motion and achieve high-fidelity reconstruction of the target object. Despite this, real-world video scenarios often feature large unobserved regions where neural representations struggle to achieve realistic completion. To tackle this challenge, we introduce MorpheuS, a framework for dynamic 360° surface reconstruction from a casually captured RGB-D video. Our approach models the target scene as a canonical field that encodes its geometry and appearance, in conjunction with a deformation field that warps points from the current frame to the canonical space. We leverage a view-dependent diffusion prior and distill knowledge from it to achieve realistic completion of unobserved regions. Experimental results on various real-world and synthetic datasets show that our method can achieve high-fidelity 360° surface reconstruction of a deformable object from a monocular RGB-D video."], "authors": "Hengyi Wang"},
{"Title": "Modeling False Data Injection Attacks on Integrated Electricity-Gas Systems", "abs": ["This work studies the modeling of false data injection attacks (FDIAs) on IEGSs. First, we introduce a static state estimation model and bad data detection method for IEGSs. Then, we develop FDIAs on IEGSs with complete network topology and parameter information. Next, we develop FDIAs on IEGSs when intruders have only local network topology and parameter information of an IEGS. Lastly, we explore FDIAs on IEGSs when intruders have only local network topology information of an IEGS."], "authors": "Rong-Peng Liu"},
{"Title": "VideoBooth: Diffusion-based Video Generation with Image Prompts", "abs": ["Text-driven video generation witnesses rapid progress. However, merely using text prompts is not enough to depict the desired subject appearance that accurately aligns with users' intents, especially for customized content creation. In this paper, we study the task of video generation with image prompts, which provide more accurate and direct content control beyond the text prompts. Specifically, we propose a feed-forward framework VideoBooth, with two dedicated designs: 1) We propose to embed image prompts in a coarse-to-fine manner. Coarse visual embeddings from image encoder provide high-level encodings of image prompts, while fine visual embeddings from the proposed attention injection module provide multi-scale and detailed encoding of image prompts. These two complementary embeddings can faithfully capture the desired appearance. 2) In the attention injection module at fine level, multi-scale image prompts are fed into different cross-frame attention layers as additional keys and values. This extra spatial information refines the details in the first frame and then it is propagated to the remaining frames, which maintains temporal consistency. Extensive experiments demonstrate that VideoBooth achieves state-of-the-art performance in generating customized high-quality videos with subjects specified in image prompts. Notably, VideoBooth is a generalizable framework where a single model works for a wide range of image prompts with feed-forward pass."], "authors": "Yuming Jiang"},
{"Title": "Context Retrieval via Normalized Contextual Latent Interaction for Conversational Agent", "abs": ["Conversational agents leveraging AI, particularly deep learning, are emerging in both academic research and real-world applications. However, these applications still face challenges, including disrespecting knowledge and facts, not personalizing to user preferences, and enormous demand for computational resources during training and inference. Recent research efforts have been focused on addressing these challenges from various aspects, including supplementing various types of auxiliary information to the conversational agents. However, existing methods are still not able to effectively and efficiently exploit relevant information from these auxiliary supplements to further unleash the power of the conversational agents and the language models they use. In this paper, we present a novel method, PK-NCLI, that is able to accurately and efficiently identify relevant auxiliary information to improve the quality of conversational responses by learning the relevance among persona, chat history, and knowledge background through low-level normalized contextual latent interaction. Our experimental results indicate that PK-NCLI outperforms the state-of-the-art method, PK-FoCus, by 47.80%/30.61%/24.14% in terms of perplexity, knowledge grounding, and training efficiency, respectively, and maintained the same level of persona grounding performance. We also provide a detailed analysis of how different factors, including language model choices and trade-offs on training weights, would affect the performance of PK-NCLI."], "authors": "Junfeng Liu"},
{"Title": "Towards Generalizable Zero-Shot Manipulation via Translating Human Interaction Plans", "abs": ["We pursue the goal of developing robots that can interact zero-shot with generic unseen objects via a diverse repertoire of manipulation skills and show how passive human videos can serve as a rich source of data for learning such generalist robots. Unlike typical robot learning approaches which directly learn how a robot should act from interaction data, we adopt a factorized approach that can leverage large-scale human videos to learn how a human would accomplish a desired task (a human plan), followed by translating this plan to the robots embodiment. Specifically, we learn a human plan predictor that, given a current image of a scene and a goal image, predicts the future hand and object configurations. We combine this with a translation module that learns a plan-conditioned robot manipulation policy, and allows following humans plans for generic manipulation tasks in a zero-shot manner with no deployment-time training. Importantly, while the plan predictor can leverage large-scale human videos for learning, the translation module only requires a small amount of in-domain data, and can generalize to tasks not seen during training. We show that our learned system can perform over 16 manipulation skills that generalize to 40 objects, encompassing 100 real-world tasks for table-top manipulation and diverse in-the-wild manipulation."], "authors": "Homanga Bharadhwaj"},
{"Title": "Automated Material Properties Extraction For Enhanced Beauty Product Discovery and Makeup Virtual Try-on", "abs": ["The multitude of makeup products available can make it challenging to find the ideal match for desired attributes. An intelligent approach for product discovery is required to enhance the makeup shopping experience to make it more convenient and satisfying. However, enabling accurate and efficient product discovery requires extracting detailed attributes like color and finish type. Our work introduces an automated pipeline that utilizes multiple customized machine learning models to extract essential material attributes from makeup product images. Our pipeline is versatile and capable of handling various makeup products. To showcase the efficacy of our pipeline, we conduct extensive experiments on eyeshadow products (both single and multi-shade ones), a challenging makeup product known for its diverse range of shapes, colors, and finish types. Furthermore, we demonstrate the applicability of our approach by successfully extending it to other makeup categories like lipstick and foundation, showcasing its adaptability and effectiveness across different beauty products. Additionally, we conduct ablation experiments to demonstrate the superiority of our machine learning pipeline over human labeling methods in terms of reliability. Our proposed method showcases its effectiveness in cross-category product discovery, specifically in recommending makeup products that perfectly match a specified outfit. Lastly, we also demonstrate the application of these material attributes in enabling virtual-try-on experiences which makes makeup shopping experience significantly more engaging."], "authors": "Fatemeh Taheri Dezaki"},
{"Title": "Explaining Knock-on Effects of Bias Mitigation", "abs": ["In machine learning systems, bias mitigation approaches aim to make outcomes fairer across privileged and unprivileged groups. Bias mitigation methods work in different ways and have known \"waterfall\" effects, e.g., mitigating bias at one place may manifest bias elsewhere. In this paper, we aim to characterise impacted cohorts when mitigation interventions are applied. To do so, we treat intervention effects as a classification task and learn an explainable meta-classifier to identify cohorts that have altered outcomes. We examine a range of bias mitigation strategies that work at various stages of the model life cycle. We empirically demonstrate that our meta-classifier is able to uncover impacted cohorts. Further, we show that all tested mitigation strategies negatively impact a non-trivial fraction of cases, i.e., people who receive unfavourable outcomes solely on account of mitigation efforts. This is despite improvement in fairness metrics. We use these results as a basis to argue for more careful audits of static mitigation interventions that go beyond aggregate metrics."], "authors": "Svetoslav Nizhnichenkov"},
{"Title": "Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses", "abs": ["Large language model (LLM) powered chatbots are primarily text-based today, and impose a large interactional cognitive load, especially for exploratory or sensemaking tasks such as planning a trip or learning about a new city. Because the interaction is textual, users have little scaffolding in the way of structure, informational \"scent\", or ability to specify high-level preferences or goals. We introduce ExploreLLM that allows users to structure thoughts, help explore different options, navigate through the choices and recommendations, and to more easily steer models to generate more personalized responses. We conduct a user study and show that users find it helpful to use ExploreLLM for exploratory or planning tasks, because it provides a useful schema-like structure to the task, and guides users in planning. The study also suggests that users can more easily personalize responses with high-level preferences with ExploreLLM. Together, ExploreLLM points to a future where users interact with LLMs beyond the form of chatbots, and instead designed to support complex user tasks with a tighter integration between natural language and graphical user interfaces."], "authors": "Xiao Ma"},
{"Title": "Deep Unlearning: Fast and Efficient Training-free Approach to Controlled Forgetting", "abs": ["Machine unlearning has emerged as a prominent and challenging area of interest, driven in large part by the rising regulatory demands for industries to delete user data upon request and the heightened awareness of privacy. Existing approaches either retrain models from scratch or use several finetuning steps for every deletion request, often constrained by computational resource limitations and restricted access to the original training data. In this work, we introduce a novel class unlearning algorithm designed to strategically eliminate an entire class or a group of classes from the learned model. To that end, our algorithm first estimates the Retain Space and the Forget Space, representing the feature or activation spaces for samples from classes to be retained and unlearned, respectively. To obtain these spaces, we propose a novel singular value decomposition-based technique that requires layer wise collection of network activations from a few forward passes through the network. We then compute the shared information between these spaces and remove it from the forget space to isolate class-discriminatory feature space for unlearning. Finally, we project the model weights in the orthogonal direction of the class-discriminatory space to obtain the unlearned model. We demonstrate our algorithm's efficacy on ImageNet using a Vision Transformer with only $\\sim$1.5% drop in retain accuracy compared to the original model while maintaining under 1% accuracy on the unlearned class samples. Further, our algorithm consistently performs well when subject to Membership Inference Attacks showing 7.8% improvement on average across a variety of image classification datasets and network architectures, as compared to other baselines while being $\\sim$6x more computationally efficient."], "authors": "Sangamesh Kodge"},
{"Title": "${L}^{\\infty}$-norm computation for linear time-invariant systems depending on parameter", "abs": ["This paper focuses on representing the $L^{\\infty}$-norm of finite-dimensional linear time-invariant systems with parameter-dependent coefficients. Previous studies tackled the problem in a non-parametric scenario by simplifying it to finding the maximum $y$-projection of real solutions $(x, y)$ of a system of the form $\\Sigma=\\{P=0, \\, \\partial P/\\partial x=0\\}$, where $P \\in \\Z[x, y]$. To solve this problem, standard computer algebra methods were employed and analyzed \\cite{bouzidi2021computation}.", "In this paper, we extend our approach to address the parametric case. We aim to represent the \"maximal\" $y$-projection of real solutions of $\\Sigma$ as a function of the given parameters. %a set of parameters $\\alpha$. To accomplish this, we utilize cylindrical algebraic decomposition. This method allows us to determine the desired value as a function of the parameters within specific regions of parameter space."], "authors": "Alban Quadrat"},
{"Title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", "abs": ["Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation."], "authors": "Albert Gu"},
{"Title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals", "abs": ["Transformers have achieved remarkable success in a wide range of natural language processing and computer vision applications. However, the representation capacity of a deep transformer model is degraded due to the over-smoothing issue in which the token representations become identical when the model's depth grows. In this work, we show that self-attention layers in transformers minimize a functional which promotes smoothness, thereby causing token uniformity. We then propose a novel regularizer that penalizes the norm of the difference between the smooth output tokens from self-attention and the input tokens to preserve the fidelity of the tokens. Minimizing the resulting regularized energy functional, we derive the Neural Transformer with a Regularized Nonlocal Functional (NeuTRENO), a novel class of transformer models that can mitigate the over-smoothing issue. We empirically demonstrate the advantages of NeuTRENO over the baseline transformers and state-of-the-art methods in reducing the over-smoothing of token representations on various practical tasks, including object classification, image segmentation, and language modeling."], "authors": "Tam Nguyen"},
{"Title": "Reduction from sparse LPN to LPN, Dual Attack 3.0", "abs": ["The security of code-based cryptography relies primarily on the hardness of decoding generic linear codes. Until very recently, all the best algorithms for solving the decoding problem were information set decoders (ISD). However, recently a new algorithm called RLPN-decoding which relies on a completely different approach was introduced and it has been shown that RLPN outperforms significantly ISD decoders for a rather large range of rates. This RLPN decoder relies on two ingredients, first reducing decoding to some underlying LPN problem, and then computing efficiently many parity-checks of small weight when restricted to some positions. We revisit RLPN-decoding by noticing that, in this algorithm, decoding is in fact reduced to a sparse-LPN problem, namely with a secret whose Hamming weight is small. Our new approach consists this time in making an additional reduction from sparse-LPN to plain-LPN with a coding approach inspired by coded-BKW. It outperforms significantly the ISD's and RLPN for code rates smaller than 0.42. This algorithm can be viewed as the code-based cryptography cousin of recent dual attacks in lattice-based cryptography. We depart completely from the traditional analysis of this kind of algorithm which uses a certain number of independence assumptions that have been strongly questioned recently in the latter domain. We give instead a formula for the LPNs noise relying on duality which allows to analyze the behavior of the algorithm by relying only on the analysis of a certain weight distribution. By using only a minimal assumption whose validity has been verified experimentally we are able to justify the correctness of our algorithm. This key tool, namely the duality formula, can be readily adapted to the lattice setting and is shown to give a simple explanation for some phenomena observed on dual attacks in lattices in [DP23]."], "authors": "Kévin Carrier"},
{"Title": "Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games", "abs": ["In this study, we explore the application of Large Language Models (LLMs) in \"Jubensha\" (Chinese murder mystery role-playing games), a novel area in AI-driven gaming. We introduce the first Chinese dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in the game, enhancing the dynamics of Jubensha gameplay. To evaluate these AI agents, we developed specialized methods targeting their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in critical aspects like information gathering, murderer detection, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a fresh perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents to researchers in the field."], "authors": "Dekun Wu"},
{"Title": "Crystal: Enhancing Blockchain Mining Transparency with Quorum Certificate", "abs": ["Researchers have discovered a series of theoretical attacks against Bitcoin's Nakamoto consensus; the most damaging ones are selfish mining, double-spending, and consistency delay attacks. These attacks have one common cause: block withholding. This paper proposes Crystal, which leverages quorum certificates to resist block withholding misbehavior. Crystal continuously elects committees from miners and requires each block to have a quorum certificate, i.e., a set of signatures issued by members of its committee. Consequently, an attacker has to publish its blocks to obtain quorum certificates, rendering block withholding impossible. To build Crystal, we design a novel two-round committee election in a Sybil-resistant, unpredictable and non-interactive way, and a reward mechanism to incentivize miners to follow the protocol. Our analysis and evaluations show that Crystal can significantly mitigate selfish mining and double-spending attacks. For example, in Bitcoin, an attacker with 30% of the total computation power will succeed in double-spending attacks with a probability of 15.6% to break the 6-confirmation rule; however, in Crystal, the success probability for the same attacker falls to 0.62%. We provide formal end-to-end safety proofs for Crystal, ensuring no unknown attacks will be introduced. To the best of our knowledge, Crystal is the first protocol that prevents selfish mining and double-spending attacks while providing safety proof."], "authors": "Jianyu Niu"},
{"Title": "Adversarial Score Distillation: When score distillation meets GAN", "abs": ["Existing score distillation methods are sensitive to classifier-free guidance (CFG) scale: manifested as over-smoothness or instability at small CFG scales, while over-saturation at large ones. To explain and analyze these issues, we revisit the derivation of Score Distillation Sampling (SDS) and decipher existing score distillation with the Wasserstein Generative Adversarial Network (WGAN) paradigm. With the WGAN paradigm, we find that existing score distillation either employs a fixed sub-optimal discriminator or conducts incomplete discriminator optimization, resulting in the scale-sensitive issue. We propose the Adversarial Score Distillation (ASD), which maintains an optimizable discriminator and updates it using the complete optimization objective. Experiments show that the proposed ASD performs favorably in 2D distillation and text-to-3D tasks against existing methods. Furthermore, to explore the generalization ability of our WGAN paradigm, we extend ASD to the image editing task, which achieves competitive results. The project page and code are at", "."], "authors": "Min Wei"},
{"Title": "SeaLLMs -- Large Language Models for Southeast Asia", "abs": ["Despite the remarkable achievements of large language models (LLMs) in various tasks, there remains a linguistic bias that favors high-resource languages, such as English, often at the expense of low-resource and regional languages. To address this imbalance, we introduce SeaLLMs, an innovative series of language models that specifically focuses on Southeast Asian (SEA) languages. SeaLLMs are built upon the Llama-2 model and further advanced through continued pre-training with an extended vocabulary, specialized instruction and alignment tuning to better capture the intricacies of regional languages. This allows them to respect and reflect local cultural norms, customs, stylistic preferences, and legal considerations. Our comprehensive evaluation demonstrates that SeaLLM-13b models exhibit superior performance across a wide spectrum of linguistic tasks and assistant-style instruction-following capabilities relative to comparable open-source models. Moreover, they outperform ChatGPT-3.5 in non-Latin languages, such as Thai, Khmer, Lao, and Burmese, by large margins while remaining lightweight and cost-effective to operate."], "authors": "Xuan-Phi Nguyen"},
{"Title": "Gaussian Grouping: Segment and Edit Anything in 3D Scenes", "abs": ["The recent Gaussian Splatting achieves high-quality and real-time novel-view synthesis of the 3D scenes. However, it is solely concentrated on the appearance and geometry modeling, while lacking in fine-grained object-level scene understanding. To address this issue, we propose Gaussian Grouping, which extends Gaussian Splatting to jointly reconstruct and segment anything in open-world 3D scenes. We augment each Gaussian with a compact Identity Encoding, allowing the Gaussians to be grouped according to their object instance or stuff membership in the 3D scene. Instead of resorting to expensive 3D labels, we supervise the Identity Encodings during the differentiable rendering by leveraging the 2D mask predictions by SAM, along with introduced 3D spatial consistency regularization. Comparing to the implicit NeRF representation, we show that the discrete and grouped 3D Gaussians can reconstruct, segment and edit anything in 3D with high visual quality, fine granularity and efficiency. Based on Gaussian Grouping, we further propose a local Gaussian Editing scheme, which shows efficacy in versatile scene editing applications, including 3D object removal, inpainting, colorization and scene recomposition. Our code and models will be at", "."], "authors": "Mingqiao Ye"},
{"Title": "Safe Reinforcement Learning in Tensor Reproducing Kernel Hilbert Space", "abs": ["This paper delves into the problem of safe reinforcement learning (RL) in a partially observable environment with the aim of achieving safe-reachability objectives. In traditional partially observable Markov decision processes (POMDP), ensuring safety typically involves estimating the belief in latent states. However, accurately estimating an optimal Bayesian filter in POMDP to infer latent states from observations in a continuous state space poses a significant challenge, largely due to the intractable likelihood. To tackle this issue, we propose a stochastic model-based approach that guarantees RL safety almost surely in the face of unknown system dynamics and partial observation environments. We leveraged the Predictive State Representation (PSR) and Reproducing Kernel Hilbert Space (RKHS) to represent future multi-step observations analytically, and the results in this context are provable. Furthermore, we derived essential operators from the kernel Bayes' rule, enabling the recursive estimation of future observations using various operators. Under the assumption of \\textit{undercompleness}, a polynomial sample complexity is established for the RL algorithm for the infinite size of observation and action spaces, ensuring an $\\epsilon-$suboptimal safe policy guarantee."], "authors": "Xiaoyuan Cheng"},
{"Title": "Efficiently Processing Large Relational Joins on GPUs", "abs": ["With the growing interest in Machine Learning (ML), Graphic Processing Units (GPUs) have become key elements of any computing infrastructure. Their widespread deployment in data centers and the cloud raises the question of how to use them beyond ML use cases, with growing interest in employing them in a database context. In this paper, we explore and analyze the implementation of relational joins on GPUs from an end-to-end perspective, meaning that we take result materialization into account. We conduct a comprehensive performance study of state-of-the-art GPU-based join algorithms over diverse synthetic workloads and TPC-H/TPC-DS benchmarks. Without being restricted to the conventional setting where each input relation has only one key and one non-key with all attributes being 4-bytes long, we investigate the effect of various factors (e.g., input sizes, number of non-key columns, skewness, data types, match ratios, and number of joins) on the end-to-end throughput. Furthermore, we propose a technique called \"Gather-from-Transformed-Relations\" (GFTR) to reduce the long-ignored yet high materialization cost in GPU-based joins. The experimental evaluation shows significant performance improvements from GFTR, with throughput gains of up to 2.3 times over previous work. The insights gained from the performance study not only advance the understanding of GPU-based joins but also introduce a structured approach to selecting the most efficient GPU join algorithm based on the input relation characteristics."], "authors": "Bowen Wu"},
{"Title": "Removing Biases from Molecular Representations via Information Maximization", "abs": ["High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweighs samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes. The code is available at", "."], "authors": "Chenyu Wang"},
{"Title": "Zipr: A High-Impact, Robust, Open-source, Multi-platform, Static Binary Rewriter", "abs": ["Zipr is a tool for static binary rewriting, first published in 2016. Zipr was engineered to support arbitrary program modification with an emphasis on low overhead, robustness, and flexibility to perform security enhancements and instrumentation. Originally targeted to Linux x86-32 binaries, Zipr now supports 32- and 64-bit binaries for X86, ARM, and MIPS architectures, as well as preliminary support for Windows programs.", "These features have helped Zipr make a dramatic impact on research. It was first used in the DARPA Cyber Grand Challenge to take second place overall, with the best security score of any participant, Zipr has now been used in a variety of research areas by both the original authors as well as third parties. Zipr has also led to publications in artificial diversity, program instrumentation, program repair, fuzzing, autonomous vehicle security, research computing security, as well as directly contributing to two student dissertations. The open-source repository has accepted accepted patches from several external authors, demonstrating the impact of Zipr beyond the original authors."], "authors": "Jason D. Hiser"},
{"Title": "SpaCE: The Spatial Confounding Environment", "abs": ["Spatial confounding poses a significant challenge in scientific studies involving spatial data, where unobserved spatial variables can influence both treatment and outcome, possibly leading to spurious associations. To address this problem, we introduce SpaCE: The Spatial Confounding Environment, the first toolkit to provide realistic benchmark datasets and tools for systematically evaluating causal inference methods designed to alleviate spatial confounding. Each dataset includes training data, true counterfactuals, a spatial graph with coordinates, and smoothness and confounding scores characterizing the effect of a missing spatial confounder. It also includes realistic semi-synthetic outcomes and counterfactuals, generated using state-of-the-art machine learning ensembles, following best practices for causal inference benchmarks. The datasets cover real treatment and covariates from diverse domains, including climate, health and social sciences. SpaCE facilitates an automated end-to-end pipeline, simplifying data loading, experimental setup, and evaluating machine learning and causal inference models. The SpaCE project provides several dozens of datasets of diverse sizes and spatial complexity. It is publicly available as a Python package, encouraging community feedback and contributions."], "authors": "Mauricio Tec"},
{"Title": "PointBeV: A Sparse Approach to BeV Predictions", "abs": ["Bird's-eye View (BeV) representations have emerged as the de-facto shared space in driving applications, offering a unified space for sensor data fusion and supporting various downstream tasks. However, conventional models use grids with fixed resolution and range and face computational inefficiencies due to the uniform allocation of resources across all cells. To address this, we propose PointBeV, a novel sparse BeV segmentation model operating on sparse BeV cells instead of dense grids. This approach offers precise control over memory usage, enabling the use of long temporal contexts and accommodating memory-constrained platforms. PointBeV employs an efficient two-pass strategy for training, enabling focused computation on regions of interest. At inference time, it can be used with various memory/performance trade-offs and flexibly adjusts to new specific use cases. PointBeV achieves state-of-the-art results on the nuScenes dataset for vehicle, pedestrian, and lane segmentation, showcasing superior performance in static and temporal settings despite being trained solely with sparse signals. We will release our code along with two new efficient modules used in the architecture: Sparse Feature Pulling, designed for the effective extraction of features from images to BeV, and Submanifold Attention, which enables efficient temporal modeling. Our code is available at", "."], "authors": "Loick Chambon"},
{"Title": "Rethinking Detection Based Table Structure Recognition for Visually Rich Documents", "abs": ["Table Structure Recognition (TSR) aims at transforming unstructured table images into structured formats, such as HTML sequences. One type of popular solution is using detection models to detect components of a table, such as columns and rows, then applying a rule-based post-processing method to convert detection results into HTML sequences. However, existing detection-based studies often have the following limitations. First, these studies usually pay more attention to improving the detection performance, which does not necessarily lead to better performance regarding cell-level metrics, such as TEDS. Second, some solutions over-simplify the problem and can miss some critical information. Lastly, even though some studies defined the problem to detect more components to provide as much information as other types of solutions, these studies ignore the fact this problem definition is a multi-label detection because row, projected row header and column header can share identical bounding boxes. Besides, there is often a performance gap between two-stage and transformer-based detection models regarding the structure-only TEDS, even though they have similar performance regarding the COCO metrics. Therefore, we revisit the limitations of existing detection-based solutions, compare two-stage and transformer-based detection models, and identify the key design aspects for the success of a two-stage detection model for the TSR task, including the multi-class problem definition, the aspect ratio for anchor box generation, and the feature generation of the backbone network. We applied simple methods to improve these aspects of the Cascade R-CNN model, achieved state-of-the-art performance, and improved the baseline Cascade R-CNN model by 19.32%, 11.56% and 14.77% regarding the structure-only TEDS on SciTSR, FinTabNet, and PubTables1M datasets."], "authors": "Bin Xiao"},
{"Title": "A Holistic Approach for Trustworthy Distributed Systems with WebAssembly and TEEs", "abs": ["Publish/subscribe systems play a key role in enabling communication between numerous devices in distributed and large-scale architectures. While widely adopted, securing such systems often trades portability for additional integrity and attestation guarantees. Trusted Execution Environments (TEEs) offer a potential solution with enclaves to enhance security and trust. However, application development for TEEs is complex, and many existing solutions are tied to specific TEE architectures, limiting adaptability. Current communication protocols also inadequately manage attestation proofs or expose essential attestation information. This paper introduces a novel approach using WebAssembly to address these issues, a key enabling technology nowadays capturing academia and industry attention. We present the design of a portable and fully attested publish/subscribe middleware system as a holistic approach for trustworthy and distributed communication between various systems. Based on this proposal, we have implemented and evaluated in-depth a fully-fledged publish/subscribe broker running within Intel SGX, compiled in WebAssembly, and built on top of industry-battled frameworks and standards, i.e., MQTT and TLS protocols. Our extended TLS protocol preserves the privacy of attestation information, among other benefits. Our experimental results showcase most overheads, revealing a 1.55x decrease in message throughput when using a trusted broker. We open-source the contributions of this work to the research community to facilitate experimental reproducibility."], "authors": "Jämes Ménétrey"},
{"Title": "GIFT: Generative Interpretable Fine-Tuning Transformers", "abs": ["We present GIFT (Generative Interpretable Fine-tuning Transformers) for fine-tuning pretrained (often large) Transformer models at downstream tasks in a parameter-efficient way with built-in interpretability. Our GIFT is a deep parameter-residual learning method, which addresses two problems in fine-tuning a pretrained Transformer model: Where to apply the parameter-efficient fine-tuning (PEFT) to be extremely lightweight yet sufficiently expressive, and How to learn the PEFT to better exploit the knowledge of the pretrained model in a direct way? For the former, we select the final projection (linear) layer in the multi-head self-attention of a Transformer model, and verify its effectiveness. For the latter, in contrast to the prior art that directly introduce new model parameters (often in low-rank approximation form) to be learned in fine-tuning with downstream data, we propose a method for learning to generate the fine-tuning parameters. Our GIFT is a hyper-Transformer which take as input the pretrained parameters of the projection layer to generate its fine-tuning parameters using a proposed Parameter-to-Cluster Attention (PaCa). The PaCa results in a simple clustering-based forward explainer that plays the role of semantic segmentation in testing. In experiments, our proposed GIFT is tested on the VTAB benchmark and the fine-grained visual classification (FGVC) benchmark. It obtains significantly better performance than the prior art. Our code is available at"], "authors": "Chinmay Savadikar"},
{"Title": "VisionaryVR: An Optical Simulation Tool for Evaluating and Optimizing Vision Correction Solutions in Virtual Reality", "abs": ["Developing and evaluating vision science methods require robust and efficient tools for assessing their performance in various real-world scenarios. This study presents a novel virtual reality (VR) simulation tool that simulates real-world optical methods while giving high experimental control to the experiment. The tool incorporates an experiment controller, to smoothly and easily handle multiple conditions, a generic eye-tracking controller, that works with most common VR eye-trackers, a configurable defocus simulator, and a generic VR questionnaire loader to assess participants' behavior in virtual reality. This VR-based simulation tool bridges the gap between theoretical and applied research on new optical methods, corrections, and therapies. It enables vision scientists to increase their research tools with a robust, realistic, and fast research environment."], "authors": "Benedikt W. Hosp"},
{"Title": "Object Detector Differences when using Synthetic and Real Training Data", "abs": ["To train well-performing generalizing neural networks, sufficiently large and diverse datasets are needed. Collecting data while adhering to privacy legislation becomes increasingly difficult and annotating these large datasets is both a resource-heavy and time-consuming task. An approach to overcome these difficulties is to use synthetic data since it is inherently scalable and can be automatically annotated. However, how training on synthetic data affects the layers of a neural network is still unclear. In this paper, we train the YOLOv3 object detector on real and synthetic images from city environments. We perform a similarity analysis using Centered Kernel Alignment (CKA) to explore the effects of training on synthetic data on a layer-wise basis. The analysis captures the architecture of the detector while showing both different and similar patterns between different models. With this similarity analysis we want to give insights on how training synthetic data affects each layer and to give a better understanding of the inner workings of complex neural networks. The results show that the largest similarity between a detector trained on real data and a detector trained on synthetic data was in the early layers, and the largest difference was in the head part. The results also show that no major difference in performance or similarity could be seen between frozen and unfrozen backbone."], "authors": "Martin Georg Ljungqvist"},
{"Title": "Open-vocabulary object 6D pose estimation", "abs": ["We introduce the new setting of open-vocabulary object 6D pose estimation, in which a textual prompt is used to specify the object of interest. In contrast to existing approaches, in our setting (i) the object of interest is specified solely through the textual prompt, (ii) no object model (e.g. CAD or video sequence) is required at inference, (iii) the object is imaged from two different viewpoints of two different scenes, and (iv) the object was not observed during the training phase. To operate in this setting, we introduce a novel approach that leverages a Vision-Language Model to segment the object of interest from two distinct scenes and to estimate its relative 6D pose. The key of our approach is a carefully devised strategy to fuse object-level information provided by the prompt with local image features, resulting in a feature space that can generalize to novel concepts. We validate our approach on a new benchmark based on two popular datasets, REAL275 and Toyota-Light, which collectively encompass 39 object instances appearing in four thousand image pairs. The results demonstrate that our approach outperforms both a well-established hand-crafted method and a recent deep learning-based baseline in estimating the relative 6D pose of objects in different scenes. Project website:", "."], "authors": "Jaime Corsetti"},
{"Title": "Towards Transparency in Coreference Resolution: A Quantum-Inspired Approach", "abs": ["Guided by grammatical structure, words compose to form sentences, and guided by discourse structure, sentences compose to form dialogues and documents. The compositional aspect of sentence and discourse units is often overlooked by machine learning algorithms. A recent initiative called Quantum Natural Language Processing (QNLP) learns word meanings as points in a Hilbert space and acts on them via a translation of grammatical structure into Parametrised Quantum Circuits (PQCs). Previous work extended the QNLP translation to discourse structure using points in a closure of Hilbert spaces. In this paper, we evaluate this translation on a Winograd-style pronoun resolution task. We train a Variational Quantum Classifier (VQC) for binary classification and implement an end-to-end pronoun resolution system. The simulations executed on IBMQ software converged with an F1 score of 87.20%. The model outperformed two out of three classical coreference resolution systems and neared state-of-the-art SpanBERT. A mixed quantum-classical model yet improved these results with an F1 score increase of around 6%."], "authors": "Hadi Wazni"},
{"Title": "Classification of cyber attacks on IoT and ubiquitous computing devices", "abs": ["As the Internet of Things (IoT) has become truly ubiquitous, so has the surrounding threat landscape. However, while the security of classical computing systems has significantly matured in the last decades, IoT cybersecurity is still typically low or fully neglected. This paper provides a classification of IoT malware. Major targets and used exploits for attacks are identified and referred to the specific malware. The lack of standard definitions of IoT devices and, therefore, security goals has been identified during this research as a profound barrier in advancing IoT cybersecurity. Furthermore, standardized reporting of IoT malware by trustworthy sources is required in the field. The majority of current IoT attacks continue to be of comparably low effort and level of sophistication and could be mitigated by existing technical measures."], "authors": "Monika Freunek"},
{"Title": "How to Tune Autofocals: A Comparative Study of Advanced Tuning Methods", "abs": ["This study comprehensively evaluates tuning methods for autofocal glasses using virtual reality (VR), addressing the challenge of presbyopia. With aging, presbyopia diminishes the eye's ability to focus on nearby objects, impacting the quality of life for billions. Autofocals, employing focus-tunable lenses, dynamically adjust optical power for each fixation, promising a more natural visual experience than traditional bifocal or multifocal lenses. Our research contrasts the most common tuning methods - manual, gaze-based, and vergence - within a VR setup to mimic real-world scenarios. Utilizing the XTAL VR headset equipped with eye-tracking, the study replicated autofocal scenarios, measuring performance and usability through psychophysical tasks and NASA TLX surveys. Results show varying strengths and weaknesses across methods, with gaze control excelling in precision but not necessarily comfort and manual control providing stability and predictability. The findings guide the selection of tuning methods based on task requirements and user preferences, highlighting a balance between precision and ease of use."], "authors": "Benedikt W. Hosp"},
{"Title": "Contextualized word senses: from attention to compositionality", "abs": ["The neural architectures of language models are becoming increasingly complex, especially that of Transformers, based on the attention mechanism. Although their application to numerous natural language processing tasks has proven to be very fruitful, they continue to be models with little or no interpretability and explainability. One of the tasks for which they are best suited is the encoding of the contextual sense of words using contextualized embeddings. In this paper we propose a transparent, interpretable, and linguistically motivated strategy for encoding the contextual sense of words by modeling semantic compositionality. Particular attention is given to dependency relations and semantic notions such as selection preferences and paradigmatic classes. A partial implementation of the proposed model is carried out and compared with Transformer-based architectures for a given semantic task, namely the similarity calculation of word senses in context. The results obtained show that it is possible to be competitive with linguistically motivated models instead of using the black boxes underlying complex neural architectures."], "authors": "Pablo Gamallo"},
{"Title": "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey", "abs": ["The rapid growth of Large Language Models (LLMs) has been a driving force in transforming various domains, reshaping the artificial general intelligence landscape. However, the increasing computational and memory demands of these models present substantial challenges, hindering both academic research and practical applications. To address these issues, a wide array of methods, including both algorithmic and hardware solutions, have been developed to enhance the efficiency of LLMs. This survey delivers a comprehensive review of algorithmic advancements aimed at improving LLM efficiency. Unlike other surveys that typically focus on specific areas such as training or model compression, this paper examines the multi-faceted dimensions of efficiency essential for the end-to-end algorithmic development of LLMs. Specifically, it covers various topics related to efficiency, including scaling laws, data utilization, architectural innovations, training and tuning strategies, and inference techniques. This paper aims to serve as a valuable resource for researchers and practitioners, laying the groundwork for future innovations in this critical research area. Our repository of relevant references is maintained at url{", "}."], "authors": "Tianyu Ding"},
{"Title": "CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous Cell Populations", "abs": ["In recent years, several unsupervised cell segmentation methods have been presented, trying to omit the requirement of laborious pixel-level annotations for the training of a cell segmentation model. Most if not all of these methods handle the instance segmentation task by focusing on the detection of different cell instances ignoring their type. While such models prove adequate for certain tasks, like cell counting, other applications require the identification of each cell's type. In this paper, we present CellMixer, an innovative annotation-free approach for the semantic segmentation of heterogeneous cell populations. Our augmentation-based method enables the training of a segmentation model from image-level labels of homogeneous cell populations. Our results show that CellMixer can achieve competitive segmentation performance across multiple cell types and imaging modalities, demonstrating the method's scalability and potential for broader applications in medical imaging, cellular biology, and diagnostics."], "authors": "Mehdi Naouar"},
{"Title": "LightCLIP: Learning Multi-Level Interaction for Lightweight Vision-Language Models", "abs": ["Vision-language pre-training like CLIP has shown promising performance on various downstream tasks such as zero-shot image classification and image-text retrieval. Most of the existing CLIP-alike works usually adopt relatively large image encoders like ResNet50 and ViT, while the lightweight counterparts are rarely discussed. In this paper, we propose a multi-level interaction paradigm for training lightweight CLIP models. Firstly, to mitigate the problem that some image-text pairs are not strictly one-to-one correspondence, we improve the conventional global instance-level alignment objective by softening the label of negative samples progressively. Secondly, a relaxed bipartite matching based token-level alignment objective is introduced for finer-grained alignment between image patches and textual words. Moreover, based on the observation that the accuracy of CLIP model does not increase correspondingly as the parameters of text encoder increase, an extra objective of masked language modeling (MLM) is leveraged for maximizing the potential of the shortened text encoder. In practice, an auxiliary fusion module injecting unmasked image embedding into masked text embedding at different network stages is proposed for enhancing the MLM. Extensive experiments show that without introducing additional computational cost during inference, the proposed method achieves a higher performance on multiple downstream tasks."], "authors": "Ying Nie"},
{"Title": "Model bias identification for Bayesian calibration of stochastic digital twins of bridges", "abs": ["Simulation-based digital twins must provide accurate, robust and reliable digital representations of their physical counterparts. Quantifying the uncertainty in their predictions plays, therefore, a key role in making better-informed decisions that impact the actual system. The update of the simulation model based on data must be then carefully implemented. When applied to complex standing structures such as bridges, discrepancies between the computational model and the real system appear as model bias, which hinders the trustworthiness of the digital twin and increases its uncertainty. Classical Bayesian updating approaches aiming to infer the model parameters often fail at compensating for such model bias, leading to overconfident and unreliable predictions. In this paper, two alternative model bias identification approaches are evaluated in the context of their applicability to digital twins of bridges. A modularized version of Kennedy and O'Hagan's approach and another one based on Orthogonal Gaussian Processes are compared with the classical Bayesian inference framework in a set of representative benchmarks. Additionally, two novel extensions are proposed for such models: the inclusion of noise-aware kernels and the introduction of additional variables not present in the computational model through the bias term. The integration of such approaches in the digital twin corrects the predictions, quantifies their uncertainty, estimates noise from unknown physical sources of error and provides further insight into the system by including additional pre-existing information without modifying the computational model."], "authors": "Daniel Andrés Arcones"},
{"Title": "Generalized Label-Efficient 3D Scene Parsing via Hierarchical Feature Aligned Pre-Training and Region-Aware Fine-tuning", "abs": ["Deep neural network models have achieved remarkable progress in 3D scene understanding while trained in the closed-set setting and with full labels. However, the major bottleneck for current 3D recognition approaches is that they do not have the capacity to recognize any unseen novel classes beyond the training categories in diverse kinds of real-world applications. In the meantime, current state-of-the-art 3D scene understanding approaches primarily require high-quality labels to train neural networks, which merely perform well in a fully supervised manner. This work presents a generalized and simple framework for dealing with 3D scene understanding when the labeled scenes are quite limited. To extract knowledge for novel categories from the pre-trained vision-language models, we propose a hierarchical feature-aligned pre-training and knowledge distillation strategy to extract and distill meaningful information from large-scale vision-language models, which helps benefit the open-vocabulary scene understanding tasks. To leverage the boundary information, we propose a novel energy-based loss with boundary awareness benefiting from the region-level boundary predictions. To encourage latent instance discrimination and to guarantee efficiency, we propose the unsupervised region-level semantic contrastive learning scheme for point clouds, using confident predictions of the neural network to discriminate the intermediate feature embeddings at multiple stages. Extensive experiments with both indoor and outdoor scenes demonstrated the effectiveness of our approach in both data-efficient learning and open-world few-shot learning. All codes, models, and data are made publicly available at:", "."], "authors": "Kangcheng Liu"},
{"Title": "Nonparametric Variational Regularisation of Pretrained Transformers", "abs": ["The current paradigm of large-scale pre-training and fine-tuning Transformer large language models has lead to significant improvements across the board in natural language processing. However, such large models are susceptible to overfitting to their training data, and as a result the models perform poorly when the domain changes. Also, due to the model's scale, the cost of fine-tuning the model to the new domain is large. Nonparametric Variational Information Bottleneck (NVIB) has been proposed as a regulariser for training cross-attention in Transformers, potentially addressing the overfitting problem. We extend the NVIB framework to replace all types of attention functions in Transformers, and show that existing pretrained Transformers can be reinterpreted as Nonparametric Variational (NV) models using a proposed identity initialisation. We then show that changing the initialisation introduces a novel, information-theoretic post-training regularisation in the attention mechanism, which improves out-of-domain generalisation without any training. This success supports the hypothesis that pretrained Transformers are implicitly NV Bayesian models."], "authors": "Fabio Fehr"},
{"Title": "Resource-constrained knowledge diffusion processes inspired by human peer learning", "abs": ["We consider a setting where a population of artificial learners is given, and the objective is to optimize aggregate measures of performance, under constraints on training resources. The problem is motivated by the study of peer learning in human educational systems. In this context, we study natural knowledge diffusion processes in networks of interacting artificial learners. By `natural', we mean processes that reflect human peer learning where the students' internal state and learning process is mostly opaque, and the main degree of freedom lies in the formation of peer learning groups by a coordinator who can potentially evaluate the learners before assigning them to peer groups. Among else, we empirically show that such processes indeed make effective use of the training resources, and enable the design of modular neural models that have the capacity to generalize without being prone to overfitting noisy labels."], "authors": "Ehsan Beikihassan"},
{"Title": "Simple Transferability Estimation for Regression Tasks", "abs": ["We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 12% to 36% better results on average while being at least 27% faster than previous state-of-the-art methods."], "authors": "Cuong N. Nguyen"},
{"Title": "A Data-Driven Safety Preserving Control Architecture for Constrained Cyber-Physical Systems", "abs": ["In this paper, we propose a data-driven networked control architecture for unknown and constrained cyber-physical systems capable of detecting networked false-data-injection attacks and ensuring plant's safety. In particular, on the controller's side, we design a novel robust anomaly detector that can discover the presence of network attacks using a data-driven outer approximation of the expected robust one-step reachable set. On the other hand, on the plant's side, we design a data-driven safety verification module, which resorts to worst-case arguments to determine if the received control input is safe for the plant's evolution. Whenever necessary, the same module is in charge of replacing the networked controller with a local data-driven set-theoretic model predictive controller, whose objective is to keep the plant's trajectory in a pre-established safe configuration until an attack-free condition is recovered. Numerical simulations involving a two-tank water system illustrate the features and capabilities of the proposed control architecture."], "authors": "Mehran Attar"},
{"Title": "Machine Learning for Health symposium 2023 -- Findings track", "abs": ["A collection of the accepted Findings papers that were presented at the 3rd Machine Learning for Health symposium (ML4H 2023), which was held on December 10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality submissions on relevant problems in a variety of health-related disciplines including healthcare, biomedicine, and public health. Two submission tracks were offered: the archival Proceedings track, and the non-archival Findings track. Proceedings were targeted at mature work with strong technical sophistication and a high impact to health. The Findings track looked for new ideas that could spark insightful discussion, serve as valuable resources for the community, or could enable new collaborations. Submissions to the Proceedings track, if not accepted, were automatically considered for the Findings track. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process."], "authors": "Stefan Hegselmann"},
{"Title": "TrackDiffusion: Multi-object Tracking Data Generation via Diffusion Models", "abs": ["Diffusion models have gained prominence in generating data for perception tasks such as image classification and object detection. However, the potential in generating high-quality tracking sequences, a crucial aspect in the field of video perception, has not been fully investigated. To address this gap, we propose TrackDiffusion, a novel architecture designed to generate continuous video sequences from the tracklets. TrackDiffusion represents a significant departure from the traditional layout-to-image (L2I) generation and copy-paste synthesis focusing on static image elements like bounding boxes by empowering image diffusion models to encompass dynamic and continuous tracking trajectories, thereby capturing complex motion nuances and ensuring instance consistency among video frames. For the first time, we demonstrate that the generated video sequences can be utilized for training multi-object tracking (MOT) systems, leading to significant improvement in tracker performance. Experimental results show that our model significantly enhances instance consistency in generated video sequences, leading to improved perceptual metrics. Our approach achieves an improvement of 8.7 in TrackAP and 11.8 in TrackAP$_{50}$ on the YTVIS dataset, underscoring its potential to redefine the standards of video data generation for MOT tasks and beyond."], "authors": "Pengxiang Li"},
{"Title": "SPOT: Self-Training with Patch-Order Permutation for Object-Centric Learning with Autoregressive Transformers", "abs": ["Unsupervised object-centric learning aims to decompose scenes into interpretable object entities, termed slots. Slot-based auto-encoders stand out as a prominent method for this task. Within them, crucial aspects include guiding the encoder to generate object-specific slots and ensuring the decoder utilizes them during reconstruction. This work introduces two novel techniques, (i) an attention-based self-training approach, which distills superior slot-based attention masks from the decoder to the encoder, enhancing object segmentation, and (ii) an innovative patch-order permutation strategy for autoregressive transformers that strengthens the role of slot vectors in reconstruction. The effectiveness of these strategies is showcased experimentally. The combined approach significantly surpasses prior slot-based autoencoder methods in unsupervised object segmentation, especially with complex real-world images. We provide the implementation code at", "."], "authors": "Ioannis Kakogeorgiou"},
{"Title": "MaxMem: Colocation and Performance for Big Data Applications on Tiered Main Memory Servers", "abs": ["We present MaxMem, a tiered main memory management system that aims to maximize Big Data application colocation and performance. MaxMem uses an application-agnostic and lightweight memory occupancy control mechanism based on fast memory miss ratios to provide application QoS under increasing colocation. By relying on memory access sampling and binning to quickly identify per-process memory heat gradients, MaxMem maximizes performance for many applications sharing tiered main memory simultaneously. MaxMem is designed as a user-space memory manager to be easily modifiable and extensible, without complex kernel code development. On a system with tiered main memory consisting of DRAM and Intel Optane persistent memory modules, our evaluation confirms that MaxMem provides 11% and 38% better throughput and up to 80% and an order of magnitude lower 99th percentile latency than HeMem and Linux AutoNUMA, respectively, with a Big Data key-value store in dynamic colocation scenarios."], "authors": "Amanda Raybuck"},
{"Title": "Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation", "abs": ["There is a growing need to gain insight into language model capabilities that relate to sensitive topics, such as bioterrorism or cyberwarfare. However, traditional open source benchmarks are not fit for the task, due to the associated practice of publishing the correct answers in human-readable form. At the same time, enforcing mandatory closed-quarters evaluations might stifle development and erode trust. In this context, we propose hashmarking, a protocol for evaluating language models in the open without having to disclose the correct answers. In its simplest form, a hashmark is a benchmark whose reference solutions have been cryptographically hashed prior to publication. Following an overview of the proposed evaluation protocol, we go on to assess its resilience against traditional attack vectors (e.g. rainbow table attacks), as well as against failure modes unique to increasingly capable generative models."], "authors": "Paul Bricman"},
{"Title": "EvE: Exploiting Generative Priors for Radiance Field Enrichment", "abs": ["Modeling large-scale scenes from unconstrained image collections in-the-wild has proven to be a major challenge in computer vision. Existing methods tackling in-the-wild neural rendering operate in a closed-world setting, where knowledge is limited to a scene's captured images within a training set. We propose EvE, which is, to the best of our knowledge, the first method leveraging generative priors to improve in-the-wild scene modeling. We employ pre-trained generative networks to enrich K-Planes representations with extrinsic knowledge. To this end, we define an alternating training procedure to conduct optimization guidance of K-Planes trained on the training set. We carry out extensive experiments and verify the merit of our method on synthetic data as well as real tourism photo collections. EvE enhances rendered scenes with richer details and outperforms the state of the art on the task of novel view synthesis in-the-wild. Our project page can be found at", "."], "authors": "Karim Kassab"},
{"Title": "What if an SQL Statement Returned a Database?", "abs": ["Every SQL statement is limited to return a single, possibly denormalized, table. This design decision has far reaching consequences. (1.) for databases users in terms of slow query performance, long query result transfer times, usability-issues of SQL in web applications and object-relational mappers. In addition, (2.) for database architects it has consequences when designing query optimizers leading to logical (algebraic) join enumeration effort, memory consumption for intermediate result materialization, and physical operator selection effort. So basically, the entire query optimization stack is shaped by that design decision. In this paper, we argue that the single-table limitation should be dropped. We extend the SELECT-clause of SQL by a keyword 'RESULTDB' to support returning a result database. Our approach has clear semantics, i.e. our extended SQL returns subsets of all tables with only those tuples that would be part of the traditional (single-table) query result set, however without performing any denormalization through joins. Our SQL-extension is downward compatible. Moreover, we discuss the surprisingly long list of benefits of our approach. First, for database users: far simpler and more readable application code, better query performance, smaller query results, better query result transfer times. Second, for database architects, we present how to leverage existing closed source systems as well as change open source database systems to support our feature. We propose a couple of algorithms to integrate our feature into both closed-source as well as open source database systems. We present an initial experimental study with promising results."], "authors": "Joris Nix"},
{"Title": "Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach", "abs": ["3D object detection in Bird's-Eye-View (BEV) space has recently emerged as a prevalent approach in the field of autonomous driving. Despite the demonstrated improvements in accuracy and velocity estimation compared to perspective view methods, the deployment of BEV-based techniques in real-world autonomous vehicles remains challenging. This is primarily due to their reliance on vision-transformer (ViT) based architectures, which introduce quadratic complexity with respect to the input resolution. To address this issue, we propose an efficient BEV-based 3D detection framework called BEVENet, which leverages a convolutional-only architectural design to circumvent the limitations of ViT models while maintaining the effectiveness of BEV-based methods. Our experiments show that BEVENet is 3$\\times$ faster than contemporary state-of-the-art (SOTA) approaches on the NuScenes challenge, achieving a mean average precision (mAP) of 0.456 and a nuScenes detection score (NDS) of 0.555 on the NuScenes validation dataset, with an inference speed of 47.6 frames per second. To the best of our knowledge, this study stands as the first to achieve such significant efficiency improvements for BEV-based methods, highlighting their enhanced feasibility for real-world autonomous driving applications."], "authors": "Yuxin Li"},
{"Title": "The Ecosystem of Trust (EoT): Enabling effective deployment of autonomous systems through collaborative and trusted ecosystems", "abs": ["Ecosystems are ubiquitous but trust within them is not guaranteed. Trust is paramount because stakeholders within an ecosystem must collaborate to achieve their objectives. With the twin transitions, digital transformation to go in parallel with green transition, accelerating the deployment of autonomous systems, trust has become even more critical to ensure that the deployed technology creates value. To address this need, we propose an ecosystem of trust approach to support deployment of technology by enabling trust among and between stakeholders, technologies and infrastructures, institutions and governance, and the artificial and natural environments in an ecosystem. The approach can help the stakeholders in the ecosystem to create, deliver, and receive value by addressing their concerns and aligning their objectives. We present an autonomous, zero emission ferry as a real world use case to demonstrate the approach from a stakeholder perspective. We argue that assurance, defined as grounds for justified confidence originated from evidence and knowledge, is a prerequisite to enable the approach. Assurance provides evidence and knowledge that are collected, analysed, and communicated in a systematic, targeted, and meaningful way. Assurance can enable the approach to help successfully deploy technology by ensuring that risk is managed, trust is shared, and value is created."], "authors": "Jon Arne Glomsrud"},
{"Title": "Rethinking the Domain Gap in Near-infrared Face Recognition", "abs": ["Heterogeneous face recognition (HFR) involves the intricate task of matching face images across the visual domains of visible (VIS) and near-infrared (NIR). While much of the existing literature on HFR identifies the domain gap as a primary challenge and directs efforts towards bridging it at either the input or feature level, our work deviates from this trend. We observe that large neural networks, unlike their smaller counterparts, when pre-trained on large scale homogeneous VIS data, demonstrate exceptional zero-shot performance in HFR, suggesting that the domain gap might be less pronounced than previously believed. By approaching the HFR problem as one of low-data fine-tuning, we introduce a straightforward framework: comprehensive pre-training, succeeded by a regularized fine-tuning strategy, that matches or surpasses the current state-of-the-art on four publicly available benchmarks. Corresponding codes can be found at", "."], "authors": "Michail Tarasiou"},
{"Title": "Investigating a domain adaptation approach for integrating different measurement instruments in a longitudinal clinical registry", "abs": ["In a longitudinal clinical registry, different measurement instruments might have been used for assessing individuals at different time points. To combine them, we investigate deep learning techniques for obtaining a joint latent representation, to which the items of different measurement instruments are mapped. This corresponds to domain adaptation, an established concept in computer science for image data. Using the proposed approach as an example, we evaluate the potential of domain adaptation in a longitudinal cohort setting with a rather small number of time points, motivated by an application with different motor function measurement instruments in a registry of spinal muscular atrophy (SMA) patients. There, we model trajectories in the latent representation by ordinary differential equations (ODEs), where person-specific ODE parameters are inferred from baseline characteristics. The goodness of fit and complexity of the ODE solutions then allows to judge the measurement instrument mappings. We subsequently explore how alignment can be improved by incorporating corresponding penalty terms into model fitting. To systematically investigate the effect of differences between measurement instruments, we consider several scenarios based on modified SMA data, including scenarios where a mapping should be feasible in principle and scenarios where no perfect mapping is available. While misalignment increases in more complex scenarios, some structure is still recovered, even if the availability of measurement instruments depends on patient state. A reasonable mapping is feasible also in the more complex real SMA dataset. These results indicate that domain adaptation might be more generally useful in statistical modeling for longitudinal registry data."], "authors": "Maren Hackenberg"},
{"Title": "Experiment on Gender and Racial/Ethnic Bias Against Video Game Streamers: Comparing Perceived Gameplay Skill and Viewer Engagement", "abs": ["Research suggests there is a perception that females and underrepresented racial/ethnic minorities have worse gameplay skills and produce less engaging video game streaming content. This bias might impact streamers' audience size, viewers' financial patronage of a streamer, streamers' sponsorship offers, etc. However, few studies on this topic use experimental methods. To fill this gap, we conducted a between-subjects survey experiment to examine if viewers are biased against video game streamers based on the streamer's gender or race/ethnicity. 200 survey participants rated the gameplay skill and viewer engagement of an identical gameplay recording. The only change between experimental conditions was the streamer's name who purportedly created the recording. The Dunnett's test found no statistically significant differences in viewer engagement ratings when comparing White male streamers to either White female (p = 0.37), Latino male (p = 0.66), or Asian male (p = 0.09) streamers. Similarly, there were no statistically significant differences in gameplay skill ratings when comparing White male streamers to either White female (p = 0.10), Latino male (p = 1.00), or Asian male (p = 0.59) streamers. Potential contributors to statistically non-significant results and counter-intuitive results (i.e., White females received non-significantly higher ratings than White males) are discussed."], "authors": "David V. Nguyen"},
{"Title": "Online Graph Coloring with Predictions", "abs": ["We introduce learning augmented algorithms to the online graph coloring problem. Although the simple greedy algorithm FirstFit is known to perform poorly in the worst case, we are able to establish a relationship between the structure of any input graph $G$ that is revealed online and the number of colors that FirstFit uses for $G$. Based on this relationship, we propose an online coloring algorithm FirstFitPredictions that extends FirstFit while making use of machine learned predictions. We show that FirstFitPredictions is both \\emph{consistent} and \\emph{smooth}. Moreover, we develop a novel framework for combining online algorithms at runtime specifically for the online graph coloring problem. Finally, we show how this framework can be used to robustify by combining it with any classical online coloring algorithm (that disregards the predictions)."], "authors": "Antonios Antoniadis"},
{"Title": "Improving Plasticity in Online Continual Learning via Collaborative Learning", "abs": ["Online Continual Learning (CL) solves the problem of learning the ever-emerging new classification tasks from a continuous data stream. Unlike its offline counterpart, in online CL, the training data can only be seen once. Most existing online CL research regards catastrophic forgetting (i.e., model stability) as almost the only challenge. In this paper, we argue that the model's capability to acquire new knowledge (i.e., model plasticity) is another challenge in online CL. While replay-based strategies have been shown to be effective in alleviating catastrophic forgetting, there is a notable gap in research attention toward improving model plasticity. To this end, we propose Collaborative Continual Learning (CCL), a collaborative learning based strategy to improve the model's capability in acquiring new concepts. Additionally, we introduce Distillation Chain (DC), a novel collaborative learning scheme to boost the training of the models. We adapted CCL-DC to existing representative online CL works. Extensive experiments demonstrate that even if the learners are well-trained with state-of-the-art online CL methods, our strategy can still improve model plasticity dramatically, and thereby improve the overall performance by a large margin."], "authors": "Maorong Wang"},
{"Title": "Learning from One Continuous Video Stream", "abs": ["We introduce a framework for online learning from a single continuous video stream -- the way people and animals learn, without mini-batches, data augmentation or shuffling. This poses great challenges given the high correlation between consecutive video frames and there is very little prior work on it. Our framework allows us to do a first deep dive into the topic and includes a collection of streams and tasks composed from two existing video datasets, plus methodology for performance evaluation that considers both adaptation and generalization. We employ pixel-to-pixel modelling as a practical and flexible way to switch between pre-training and single-stream evaluation as well as between arbitrary tasks, without ever requiring changes to models and always using the same pixel loss. Equipped with this framework we obtained large single-stream learning gains from pre-training with a novel family of future prediction tasks, found that momentum hurts, and that the pace of weight updates matters. The combination of these insights leads to matching the performance of IID learning with batch size 1, when using the same architecture and without costly replay buffers."], "authors": "João Carreira"},
{"Title": "UAVs and Birds: Enhancing Short-Range Navigation through Budgerigar Flight Studies", "abs": ["This study delves into the flight behaviors of Budgerigars (Melopsittacus undulatus) to gain insights into their flight trajectories and movements. Using 3D reconstruction from stereo video camera recordings, we closely examine the velocity and acceleration patterns during three flight motion takeoff, flying and landing. The findings not only contribute to our understanding of bird behaviors but also hold significant implications for the advancement of algorithms in Unmanned Aerial Vehicles (UAVs). The research aims to bridge the gap between biological principles observed in birds and the application of these insights in developing more efficient and autonomous UAVs. In the context of the increasing use of drones, this study focuses on the biologically inspired principles drawn from bird behaviors, particularly during takeoff, flying and landing flight, to enhance UAV capabilities. The dataset created for this research sheds light on Budgerigars' takeoff, flying, and landing techniques, emphasizing their ability to control speed across different situations and surfaces. The study underscores the potential of incorporating these principles into UAV algorithms, addressing challenges related to short-range navigation, takeoff, flying, and landing."], "authors": "Md. Mahmudur Rahman"},
{"Title": "Event Recognition in Laparoscopic Gynecology Videos with Hybrid Transformers", "abs": ["Analyzing laparoscopic surgery videos presents a complex and multifaceted challenge, with applications including surgical training, intra-operative surgical complication prediction, and post-operative surgical assessment. Identifying crucial events within these videos is a significant prerequisite in a majority of these applications. In this paper, we introduce a comprehensive dataset tailored for relevant event recognition in laparoscopic gynecology videos. Our dataset includes annotations for critical events associated with major intra-operative challenges and post-operative complications. To validate the precision of our annotations, we assess event recognition performance using several CNN-RNN architectures. Furthermore, we introduce and evaluate a hybrid transformer architecture coupled with a customized training-inference framework to recognize four specific events in laparoscopic surgery videos. Leveraging the Transformer networks, our proposed architecture harnesses inter-frame dependencies to counteract the adverse effects of relevant content occlusion, motion blur, and surgical scene variation, thus significantly enhancing event recognition accuracy. Moreover, we present a frame sampling strategy designed to manage variations in surgical scenes and the surgeons' skill level, resulting in event recognition with high temporal resolution. We empirically demonstrate the superiority of our proposed methodology in event recognition compared to conventional CNN-RNN architectures through a series of extensive experiments."], "authors": "Sahar Nasirihaghighi"},
{"Title": "BCN: Batch Channel Normalization for Image Classification", "abs": ["Normalization techniques have been widely used in the field of deep learning due to their capability of enabling higher learning rates and are less careful in initialization. However, the effectiveness of popular normalization technologies is typically limited to specific areas. Unlike the standard Batch Normalization (BN) and Layer Normalization (LN), where BN computes the mean and variance along the (N,H,W) dimensions and LN computes the mean and variance along the (C,H,W) dimensions (N, C, H and W are the batch, channel, spatial height and width dimension, respectively), this paper presents a novel normalization technique called Batch Channel Normalization (BCN). To exploit both the channel and batch dependence and adaptively and combine the advantages of BN and LN based on specific datasets or tasks, BCN separately normalizes inputs along the (N, H, W) and (C, H, W) axes, then combines the normalized outputs based on adaptive parameters. As a basic block, BCN can be easily integrated into existing models for various applications in the field of computer vision. Empirical results show that the proposed technique can be seamlessly applied to various versions of CNN or Vision Transformer architecture. The code is publicly available at"], "authors": "Afifa Khaled"},
{"Title": "Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)", "abs": ["Reinforcement learning (RL) for robot control typically requires a detailed representation of the environment state, including information about task-relevant objects not directly measurable. Keypoint detectors, such as spatial autoencoders (SAEs), are a common approach to extracting a low-dimensional representation from high-dimensional image data. SAEs aim at spatial features such as object positions, which are often useful representations in robotic RL. However, whether an SAE is actually able to track objects in the scene and thus yields a spatial state representation well suited for RL tasks has rarely been examined due to a lack of established metrics. In this paper, we propose to assess the performance of an SAE instance by measuring how well keypoints track ground truth objects in images. We present a computationally lightweight metric and use it to evaluate common baseline SAE architectures on image data from a simulated robot task. We find that common SAEs differ substantially in their spatial extraction capability. Furthermore, we validate that SAEs that perform well in our metric achieve superior performance when used in downstream RL. Thus, our metric is an effective and lightweight indicator of RL performance before executing expensive RL training. Building on these insights, we identify three key modifications of SAE architectures to improve tracking performance. We make our code available at anonymous.4open.science/r/sae-rl."], "authors": "Emma Cramer"},
{"Title": "Less is More: Learning Reference Knowledge Using No-Reference Image Quality Assessment", "abs": ["Image Quality Assessment (IQA) with reference images have achieved great success by imitating the human vision system, in which the image quality is effectively assessed by comparing the query image with its pristine reference image. However, for the images in the wild, it is quite difficult to access accurate reference images. We argue that it is possible to learn reference knowledge under the No-Reference Image Quality Assessment (NR-IQA) setting, which is effective and efficient empirically. Concretely, by innovatively introducing a novel feature distillation method in IQA, we propose a new framework to learn comparative knowledge from non-aligned reference images. And then, to achieve fast convergence and avoid overfitting, we further propose an inductive bias regularization. Such a framework not only solves the congenital defects of NR-IQA but also improves the feature extraction framework, enabling it to express more abundant quality information. Surprisingly, our method utilizes less input while obtaining a more significant improvement compared to the teacher models. Extensive experiments on eight standard NR-IQA datasets demonstrate the superior performance to the state-of-the-art NR-IQA methods, i.e., achieving the PLCC values of 0.917 (vs. 0.884 in LIVEC) and 0.686 (vs. 0.661 in LIVEFB)."], "authors": "Xudong Li"},
{"Title": "Merlin:Empowering Multimodal LLMs with Foresight Minds", "abs": ["Humans possess the remarkable ability to foresee the future to a certain extent based on present observations, a skill we term as foresight minds. However, this capability remains largely under explored within existing Multimodal Large Language Models (MLLMs), hindering their capacity to learn the fundamental principles of how things operate and the intentions behind the observed subjects. To address this issue, we introduce the integration of future modeling into the existing learning frameworks of MLLMs. By utilizing the subject trajectory, a highly structured representation of a consecutive frame sequence, as a learning objective, we aim to bridge the gap between the past and the future. We propose two innovative methods to empower MLLMs with foresight minds, Foresight Pre-Training (FPT) and Foresight Instruction-Tuning (FIT), which are inspired by the modern learning paradigm of LLMs. Specifically, FPT jointly training various tasks centered on trajectories, enabling MLLMs to learn how to attend and predict entire trajectories from a given initial observation. Then, FIT requires MLLMs to first predict trajectories of related objects and then reason about potential future events based on them. Aided by FPT and FIT, we build a novel and unified MLLM named Merlin that supports multi-images input and analysis about potential actions of multiple objects for the future reasoning. Experimental results show Merlin powerful foresight minds with impressive performance on both future reasoning and visual comprehension tasks."], "authors": "En Yu"},
{"Title": "LucidDreaming: Controllable Object-Centric 3D Generation", "abs": ["With the recent development of generative models, Text-to-3D generations have also seen significant growth. Nonetheless, achieving precise control over 3D generation continues to be an arduous task, as using text to control often leads to missing objects and imprecise locations. Contemporary strategies for enhancing controllability in 3D generation often entail the introduction of additional parameters, such as customized diffusion models. This often induces hardness in adapting to different diffusion models or creating distinct objects.", "In this paper, we present LucidDreaming as an effective pipeline capable of fine-grained control over 3D generation. It requires only minimal input of 3D bounding boxes, which can be deduced from a simple text prompt using a Large Language Model. Specifically, we propose clipped ray sampling to separately render and optimize objects with user specifications. We also introduce object-centric density blob bias, fostering the separation of generated objects. With individual rendering and optimizing of objects, our method excels not only in controlled content generation from scratch but also within the pre-trained NeRF scenes. In such scenarios, existing generative approaches often disrupt the integrity of the original scene, and current editing methods struggle to synthesize new content in empty spaces. We show that our method exhibits remarkable adaptability across a spectrum of mainstream Score Distillation Sampling-based 3D generation frameworks, and achieves superior alignment of 3D content when compared to baseline approaches. We also provide a dataset of prompts with 3D bounding boxes, benchmarking 3D spatial controllability."], "authors": "Zhaoning Wang"},
{"Title": "Explainable Fraud Detection with Deep Symbolic Classification", "abs": ["There is a growing demand for explainable, transparent, and data-driven models within the domain of fraud detection. Decisions made by fraud detection models need to be explainable in the event of a customer dispute. Additionally, the decision-making process in the model must be transparent to win the trust of regulators and business stakeholders. At the same time, fraud detection solutions can benefit from data due to the noisy, dynamic nature of fraud and the availability of large historical data sets. Finally, fraud detection is notorious for its class imbalance: there are typically several orders of magnitude more legitimate transactions than fraudulent ones. In this paper, we present Deep Symbolic Classification (DSC), an extension of the Deep Symbolic Regression framework to classification problems. DSC casts classification as a search problem in the space of all analytic functions composed of a vocabulary of variables, constants, and operations and optimizes for an arbitrary evaluation metric directly. The search is guided by a deep neural network trained with reinforcement learning. Because the functions are mathematical expressions that are in closed-form and concise, the model is inherently explainable both at the level of a single classification decision and the model's decision process. Furthermore, the class imbalance problem is successfully addressed by optimizing for metrics that are robust to class imbalance such as the F1 score. This eliminates the need for oversampling and undersampling techniques that plague traditional approaches. Finally, the model allows to explicitly balance between the prediction accuracy and the explainability. An evaluation on the PaySim data set demonstrates competitive predictive performance with state-of-the-art models, while surpassing them in terms of explainability. This establishes DSC as a promising model for fraud detection systems."], "authors": "Samantha Visbeek"},
{"Title": "Efficient and Secure Energy Trading with Electric Vehicles and Distributed Ledger Technology", "abs": ["Efficient energy management of Distributed Renewable Energy Resources (DRER) enables a more sustainable and efficient energy ecosystem. Therefore, we propose a holistic Energy Management System (EMS), utilising the computational and energy storage capabilities of nearby Electric Vehicles (EVs), providing a low-latency and efficient management platform for DRER. Through leveraging the inherent, immutable features of Distributed Ledger Technology (DLT) and smart contracts, we create a secure management environment, facilitating interactions between multiple EVs and energy resources. Using a privacy-preserving load forecasting method powered by Vehicular Fog Computing (VFC), we integrate the computational resources of the EVs. Using DLT and our forecasting framework, we accommodate efficient management algorithms in a secure and low-latency manner enabling greater utilisation of the energy storage resources. Finally, we assess our proposed EMS in terms of monetary and energy utility metrics, establishing the increased benefits of multiple interacting EVs and load forecasting. Through the proposed system, we have established the potential of our framework to create a more sustainable and efficient energy ecosystem whilst providing measurable benefits to participating agents."], "authors": "Conor Mullaney"},
{"Title": "The Ethics of Automating Legal Actors", "abs": ["The introduction of large public legal datasets has brought about a renaissance in legal NLP. Many of these datasets are comprised of legal judgements - the product of judges deciding cases. This fact, together with the way machine learning works, means that several legal NLP models are models of judges. While some have argued for the automation of judges, in this position piece, we argue that automating the role of the judge raises difficult ethical challenges, in particular for common law legal systems. Our argument follows from the social role of the judge in actively shaping the law, rather than merely applying it. Since current NLP models come nowhere close to having the facilities necessary for this task, they should not be used to automate judges. Furthermore, even in the case the models could achieve human-level capabilities, there would still be remaining ethical concerns inherent in the automation of the legal process."], "authors": "Josef Valvoda"},
{"Title": "MD-Splatting: Learning Metric Deformation from 4D Gaussians in Highly Deformable Scenes", "abs": ["Accurate 3D tracking in highly deformable scenes with occlusions and shadows can facilitate new applications in robotics, augmented reality, and generative AI. However, tracking under these conditions is extremely challenging due to the ambiguity that arises with large deformations, shadows, and occlusions. We introduce MD-Splatting, an approach for simultaneous 3D tracking and novel view synthesis, using video captures of a dynamic scene from various camera poses. MD-Splatting builds on recent advances in Gaussian splatting, a method that learns the properties of a large number of Gaussians for state-of-the-art and fast novel view synthesis. MD-Splatting learns a deformation function to project a set of Gaussians with non-metric, thus canonical, properties into metric space. The deformation function uses a neural-voxel encoding and a multilayer perceptron (MLP) to infer Gaussian position, rotation, and a shadow scalar. We enforce physics-inspired regularization terms based on local rigidity, conservation of momentum, and isometry, which leads to trajectories with smaller trajectory errors. MD-Splatting achieves high-quality 3D tracking on highly deformable scenes with shadows and occlusions. Compared to state-of-the-art, we improve 3D tracking by an average of 23.9 %, while simultaneously achieving high-quality novel view synthesis. With sufficient texture such as in scene 6, MD-Splatting achieves a median tracking error of 3.39 mm on a cloth of 1 x 1 meters in size. Project website:", "."], "authors": "Bardienus P. Duisterhof"},
{"Title": "Design Patterns for Machine Learning Based Systems with Human-in-the-Loop", "abs": ["The development and deployment of systems using supervised machine learning (ML) remain challenging: mainly due to the limited reliability of prediction models and the lack of knowledge on how to effectively integrate human intelligence into automated decision-making. Humans involvement in the ML process is a promising and powerful paradigm to overcome the limitations of pure automated predictions and improve the applicability of ML in practice. We compile a catalog of design patterns to guide developers select and implement suitable human-in-the-loop (HiL) solutions. Our catalog takes into consideration key requirements as the cost of human involvement and model retraining. It includes four training patterns, four deployment patterns, and two orthogonal cooperation patterns."], "authors": "Jakob Smedegaard Andersen"},
{"Title": "Pathway to a fully data-driven geotechnics: lessons from materials informatics", "abs": ["This paper elucidates the challenges and opportunities inherent in integrating data-driven methodologies into geotechnics, drawing inspiration from the success of materials informatics. Highlighting the intricacies of soil complexity, heterogeneity, and the lack of comprehensive data, the discussion underscores the pressing need for community-driven database initiatives and open science movements. By leveraging the transformative power of deep learning, particularly in feature extraction from high-dimensional data and the potential of transfer learning, we envision a paradigm shift towards a more collaborative and innovative geotechnics field. The paper concludes with a forward-looking stance, emphasizing the revolutionary potential brought about by advanced computational tools like large language models in reshaping geotechnics informatics."], "authors": "Stephen Wu"},
{"Title": "Using Honeybuckets to Characterize Cloud Storage Scanning in the Wild", "abs": ["In this work, we analyze to what extent actors target poorly-secured cloud storage buckets for attack. We deployed hundreds of AWS S3 honeybuckets with different names and content to lure and measure different scanning strategies. Actors exhibited clear preferences for scanning buckets that appeared to belong to organizations, especially commercial entities in the technology sector with a vulnerability disclosure program. Actors continuously engaged with the content of buckets by downloading, uploading, and deleting files. Most alarmingly, we recorded multiple instances in which malicious actors downloaded, read, and understood a document from our honeybucket, leading them to attempt to gain unauthorized server access."], "authors": "Katherine Izhikevich"},
{"Title": "Instruction-tuning Aligns LLMs to the Human Brain", "abs": ["Instruction-tuning is a widely adopted method of finetuning that enables large language models (LLMs) to generate output that more closely resembles human responses to natural language queries, in many cases leading to human-level performance on diverse testbeds. However, it remains unclear whether instruction-tuning truly makes LLMs more similar to how humans process language. We investigate the effect of instruction-tuning on LLM-human similarity in two ways: (1) brain alignment, the similarity of LLM internal representations to neural activity in the human language system, and (2) behavioral alignment, the similarity of LLM and human behavior on a reading task. We assess 25 vanilla and instruction-tuned LLMs across three datasets involving humans reading naturalistic stories and sentences. We discover that instruction-tuning generally enhances brain alignment by an average of 6%, but does not have a similar effect on behavioral alignment. To identify the factors underlying LLM-brain alignment, we compute correlations between the brain alignment of LLMs and various model properties, such as model size, various problem-solving abilities, and performance on tasks requiring world knowledge spanning various domains. Notably, we find a strong positive correlation between brain alignment and model size (r = 0.95), as well as performance on tasks requiring world knowledge (r = 0.81). Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain."], "authors": "Khai Loong Aw"},
{"Title": "Generative models for visualising abstract social processes: Guiding streetview image synthesis of StyleGAN2 with indices of deprivation", "abs": ["This paper presents a novel application of Generative Adverserial Networks (GANs) to study visual aspects of social processes. I train a a StyleGAN2-model on a custom dataset of 14,564 images of London, sourced from Google Streetview taken in London. After training, I invert the images in the training set, finding points in the model's latent space that correspond to them, and compare results from three inversion techniques. I connect each data point with metadata from the Indices of Multiple Deprivation, describing income, health and environmental quality in the area where the photographs were taken. It is then possible to map which parts of the model's latent space encode visual features that are distinctive for health, income and environmental quality, and condition the synthesis of new images based on these factors. The synthetic images created reflect visual features of social processes that were previously unknown and difficult to study, describing recurring visual differences between deprived and privileged areas in London. GANs are known for their capability to produce a continuous range of images that exhibit visual differences. The paper tests how to exploit this ability through visual comparisons in still images as well as through an interactive website where users can guide image synthesis with sliders. Though conditioned synthesis has its limitations and the results are difficult to validate, the paper points to the potential for generative models to be repurposed to be parts of social scientific methods."], "authors": "Aleksi Knuutila"},
{"Title": "Explanatory Argument Extraction of Correct Answers in Resident Medical Exams", "abs": ["Developing the required technology to assist medical experts in their everyday activities is currently a hot topic in the Artificial Intelligence research field. Thus, a number of large language models (LLMs) and automated benchmarks have recently been proposed with the aim of facilitating information extraction in Evidence-Based Medicine (EBM) using natural language as a tool for mediating in human-AI interaction. The most representative benchmarks are limited to either multiple-choice or long-form answers and are available only in English. In order to address these shortcomings, in this paper we present a new dataset which, unlike previous work: (i) includes not only explanatory arguments for the correct answer, but also arguments to reason why the incorrect answers are not correct; (ii) the explanations are written originally by medical doctors to answer questions from the Spanish Residency Medical Exams. Furthermore, this new benchmark allows us to setup a novel extractive task which consists of identifying the explanation of the correct answer written by medical doctors. An additional benefit of our setting is that we can leverage the extractive QA paradigm to automatically evaluate performance of LLMs without resorting to costly manual evaluation by medical experts. Comprehensive experimentation with language models for Spanish shows that sometimes multilingual models fare better than monolingual ones, even outperforming models which have been adapted to the medical domain. Furthermore, results across the monolingual models are mixed, with supposedly smaller and inferior models performing competitively. In any case, the obtained results show that our novel dataset and approach can be an effective technique to help medical practitioners in identifying relevant evidence-based explanations for medical questions."], "authors": "Iakes Goenaga"},
{"Title": "Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?", "abs": ["The evolution of legal datasets and the advent of large language models (LLMs) have significantly transformed the legal field, particularly in the generation of case judgment summaries. However, a critical concern arises regarding the potential biases embedded within these summaries. This study scrutinizes the biases present in case judgment summaries produced by legal datasets and large language models. The research aims to analyze the impact of biases on legal decision making. By interrogating the accuracy, fairness, and implications of biases in these summaries, this study contributes to a better understanding of the role of technology in legal contexts and the implications for justice systems worldwide. In this study, we investigate biases wrt Gender-related keywords, Race-related keywords, Keywords related to crime against women, Country names and religious keywords. The study shows interesting evidences of biases in the outputs generated by the large language models and pre-trained abstractive summarization models. The reasoning behind these biases needs further studies."], "authors": "Aniket Deroy"},
{"Title": "The Discontinuous Strain Method: accurately representing fatigue and failure", "abs": ["Fatigue simulation requires accurate modeling of unloading and reloading. However, classical ductile damage models treat deformations after complete failure as irrecoverable -- which leads to unphysical behavior during unloading. This unphysical behavior stems from the continued accumulation of plastic strains after failure, resulting in an incorrect stress state at crack closure. As a remedy, we introduce a \\textit{discontinuity strain} in the additive elasto-plastic strain decomposition, which absorbs the excess strain after failure. This allows representing pre- and post-cracking regimes in a fully continuous setting, wherein the transition from the elasto-plastic response to cracking can be triggered at any arbitrary stage in a completely smooth manner. Moreover, the presented methodology does not exhibit the spurious energy release observed in hybrid approaches. In addition, our approach guarantees mesh-independent results by relying on a characteristic length scale -- based on the discretization's resolution. We name this new methodology the \\textit{discontinuous strain method}. The proposed approach requires only minor modifications of conventional plastic-damage routines. To convey the method in a didactic manner, the algorithmic modifications are first discussed for one- and subsequently for two-/three-dimensional implementations. Using a simple ductile constitutive model, the discontinuous strain method is validated against established two-dimensional benchmarks. The method is, however, independent of the employed constitutive model. Elastic, plastic, and damage models may thus be chosen arbitrarily. Furthermore, computational efforts associated with the method are minimal, rendering it advantageous for accurately representing low-cycle fatigue but potentially also for other scenarios requiring a discontinuity representation within a plastic-damage framework."], "authors": "Leon Herrmann"},
{"Title": "A Spatio-Temporal Graph Convolutional Network for Gesture Recognition from High-Density Electromyography", "abs": ["Accurate hand gesture prediction is crucial for effective upper-limb prosthetic limbs control. As the high flexibility and multiple degrees of freedom exhibited by human hands, there has been a growing interest in integrating deep networks with high-density surface electromyography (HD-sEMG) grids to enhance gesture recognition capabilities. However, many existing methods fall short in fully exploit the specific spatial topology and temporal dependencies present in HD-sEMG data. Additionally, these studies are often limited number of gestures and lack generality. Hence, this study introduces a novel gesture recognition method, named STGCN-GR, which leverages spatio-temporal graph convolution networks for HD-sEMG-based human-machine interfaces. Firstly, we construct muscle networks based on functional connectivity between channels, creating a graph representation of HD-sEMG recordings. Subsequently, a temporal convolution module is applied to capture the temporal dependences in the HD-sEMG series and a spatial graph convolution module is employed to effectively learn the intrinsic spatial topology information among distinct HD-sEMG channels. We evaluate our proposed model on a public HD-sEMG dataset comprising a substantial number of gestures (i.e., 65). Our results demonstrate the remarkable capability of the STGCN-GR method, achieving an impressive accuracy of 91.07% in predicting gestures, which surpasses state-of-the-art deep learning methods applied to the same dataset."], "authors": "Wenjuan Zhong"},
{"Title": "Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs", "abs": ["Unsupervised relation extraction (URE) aims to extract relations between named entities from raw text without requiring manual annotations or pre-existing knowledge bases. In recent studies of URE, researchers put a notable emphasis on contrastive learning strategies for acquiring relation representations. However, these studies often overlook two important aspects: the inclusion of diverse positive pairs for contrastive learning and the exploration of appropriate loss functions. In this paper, we propose AugURE with both within-sentence pairs augmentation and augmentation through cross-sentence pairs extraction to increase the diversity of positive pairs and strengthen the discriminative power of contrastive learning. We also identify the limitation of noise-contrastive estimation (NCE) loss for relation representation learning and propose to apply margin loss for sentence pairs. Experiments on NYT-FB and TACRED datasets demonstrate that the proposed relation representation learning and a simple K-Means clustering achieves state-of-the-art performance."], "authors": "Qing Wang"},
{"Title": "Domain Adaptive Imitation Learning with Visual Observation", "abs": ["In this paper, we consider domain-adaptive imitation learning with visual observation, where an agent in a target domain learns to perform a task by observing expert demonstrations in a source domain. Domain adaptive imitation learning arises in practical scenarios where a robot, receiving visual sensory data, needs to mimic movements by visually observing other robots from different angles or observing robots of different shapes. To overcome the domain shift in cross-domain imitation learning with visual observation, we propose a novel framework for extracting domain-independent behavioral features from input observations that can be used to train the learner, based on dual feature extraction and image reconstruction. Empirical results demonstrate that our approach outperforms previous algorithms for imitation learning from visual observation with domain shift."], "authors": "Sungho Choi"},
{"Title": "Trained MT Metrics Learn to Cope with Machine-translated References", "abs": ["Neural metrics trained on human evaluations of MT tend to correlate well with human judgments, but their behavior is not fully understood. In this paper, we perform a controlled experiment and compare a baseline metric that has not been trained on human evaluations (Prism) to a trained version of the same metric (Prism+FT). Surprisingly, we find that Prism+FT becomes more robust to machine-translated references, which are a notorious problem in MT evaluation. This suggests that the effects of metric training go beyond the intended effect of improving overall correlation with human judgments."], "authors": "Jannis Vamvas"},
{"Title": "Hiding in text/plain sight: Security defences of Tor Onion Services", "abs": ["Tor Onion Services are a way to host websites and other internet services anonymously. Onion Services are often used to bypass internet censorship and provide information services to users in oppressive regimes. This paper presents an analysis of the security defences deployed on these Onion Services. Onion Services tend to have better security policy than sites on the clear web. However they lag behind in the deployment of HTTPS, a key defence to ensuring the security of users of such services."], "authors": "Q Misell"},
{"Title": "Target-agnostic Source-free Domain Adaptation for Regression Tasks", "abs": ["Unsupervised domain adaptation (UDA) seeks to bridge the domain gap between the target and source using unlabeled target data. Source-free UDA removes the requirement for labeled source data at the target to preserve data privacy and storage. However, work on source-free UDA assumes knowledge of domain gap distribution, and hence is limited to either target-aware or classification task. To overcome it, we propose TASFAR, a novel target-agnostic source-free domain adaptation approach for regression tasks. Using prediction confidence, TASFAR estimates a label density map as the target label distribution, which is then used to calibrate the source model on the target domain. We have conducted extensive experiments on four regression tasks with various domain gaps, namely, pedestrian dead reckoning for different users, image-based people counting in different scenes, housing-price prediction at different districts, and taxi-trip duration prediction from different departure points. TASFAR is shown to substantially outperform the state-of-the-art source-free UDA approaches by averagely reducing 22% errors for the four tasks and achieve notably comparable accuracy as source-based UDA without using source data."], "authors": "Tianlang He"},
{"Title": "LiDAR-based curb detection for ground truth annotation in automated driving validation", "abs": ["Curb detection is essential for environmental awareness in Automated Driving (AD), as it typically limits drivable and non-drivable areas. Annotated data are necessary for developing and validating an AD function. However, the number of public datasets with annotated point cloud curbs is scarce. This paper presents a method for detecting 3D curbs in a sequence of point clouds captured from a LiDAR sensor, which consists of two main steps. First, our approach detects the curbs at each scan using a segmentation deep neural network. Then, a sequence-level processing step estimates the 3D curbs in the reconstructed point cloud using the odometry of the vehicle. From these 3D points of the curb, we obtain polylines structured following ASAM OpenLABEL standard. These detections can be used as pre-annotations in labelling pipelines to efficiently generate curb-related ground truth data. We validate our approach through an experiment in which different human annotators were required to annotate curbs in a group of LiDAR-based sequences with and without our automatically generated pre-annotations. The results show that the manual annotation time is reduced by 50.99% thanks to our detections, keeping the data quality level."], "authors": "Jose Luis Apellániz"},
{"Title": "DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality", "abs": ["Diminished reality (DR) refers to the removal of real objects from the environment by virtually replacing them with their background. Modern DR frameworks use inpainting to hallucinate unobserved regions. While recent deep learning-based inpainting is promising, the DR use case is complicated by the need to generate coherent structure and 3D geometry (i.e., depth), in particular for advanced applications, such as 3D scene editing. In this paper, we propose DeepDR, a first RGB-D inpainting framework fulfilling all requirements of DR: Plausible image and geometry inpainting with coherent structure, running at real-time frame rates, with minimal temporal artifacts. Our structure-aware generative network allows us to explicitly condition color and depth outputs on the scene semantics, overcoming the difficulty of reconstructing sharp and consistent boundaries in regions with complex backgrounds. Experimental results show that the proposed framework can outperform related work qualitatively and quantitatively."], "authors": "Christina Gsaxner"},
{"Title": "Automated design space exploration for poultry processing systems using discrete-event simulation", "abs": ["The poultry processing industry struggles to keep up with new developments in meat consumption and livestock breeding. Designing poultry processing systems is becoming increasingly more complex, and an increasing number of iterations of (re)design are required to optimize the product flow in these systems. To address this issue, this study presents a discrete-event simulation-based method for design space exploration of production systems. This method is mostly automated, greatly reducing the time and effort required in the design process. The steps that are automated are iterating on the design, model construction, performing simulation experiments, and interpreting the simulation results. An industrial case study in which a poultry processing system is redesigned is used to validate the effectiveness of the proposed method. A detailed description of this case study is given to showcase the different ways in which this design space exploration method can be used."], "authors": "Nick Paape"},
{"Title": "SurreyAI 2023 Submission for the Quality Estimation Shared Task", "abs": ["Quality Estimation (QE) systems are important in situations where it is necessary to assess the quality of translations, but there is no reference available. This paper describes the approach adopted by the SurreyAI team for addressing the Sentence-Level Direct Assessment shared task in WMT23. The proposed approach builds upon the TransQuest framework, exploring various autoencoder pre-trained language models within the MonoTransQuest architecture using single and ensemble settings. The autoencoder pre-trained language models employed in the proposed systems are XLMV, InfoXLM-large, and XLMR-large. The evaluation utilizes Spearman and Pearson correlation coefficients, assessing the relationship between machine-predicted quality scores and human judgments for 5 language pairs (English-Gujarati, English-Hindi, English-Marathi, English-Tamil and English-Telugu). The MonoTQ-InfoXLM-large approach emerges as a robust strategy, surpassing all other individual models proposed in this study by significantly improving over the baseline for the majority of the language pairs."], "authors": "Archchana Sindhujan"},
{"Title": "The Impact of Privacy and Security Attitudes and Concerns of Travellers on Their Willingness to Use Mobility-as-a-Service Systems", "abs": ["This paper reports results from an online survey on the impact of travellers' privacy and security attitudes and concerns on their willingness to use mobility-as-a-service (MaaS) systems. This study is part of a larger project that aims at investigating barriers to potential MaaS uptake. The online survey was designed to cover data privacy and security attitudes and concerns as well as a variety of socio-psychological and socio-demographic variables associated with travellers' intentions to use MaaS systems. The study involved $n=320$ UK participants recruited via the Prolific survey platform. Overall, correlation analysis and a multiple regression model indicated that, neither attitudes nor concerns of participants over the privacy and security of personal data would significantly impact their decisions to use MaaS systems, which was an unexpected result, however, their trust in (commercial and governmental) websites would. Another surprising result is that, having been a victim of improper invasion of privacy did not appear to affect individuals' intentions to use MaaS systems, whereas frequency with which one heard about misuse of personal data did. Implications of the results and future directions are also discussed, e.g., MaaS providers are encouraged to work on improving the trustworthiness of their corporate image."], "authors": "Maria Sophia Heering"},
{"Title": "Spatio-Temporal-Decoupled Masked Pre-training for Traffic Forecasting", "abs": ["Accurate forecasting of multivariate traffic flow time series remains challenging due to substantial spatio-temporal heterogeneity and complex long-range correlative patterns. To address this, we propose Spatio-Temporal-Decoupled Masked Pre-training (STD-MAE), a novel framework that employs masked autoencoders to learn and encode complex spatio-temporal dependencies via pre-training. Specifically, we use two decoupled masked autoencoders to reconstruct the traffic data along spatial and temporal axes using a self-supervised pre-training approach. These mask reconstruction mechanisms capture the long-range correlations in space and time separately. The learned hidden representations are then used to augment the downstream spatio-temporal traffic predictor. A series of quantitative and qualitative evaluations on four widely-used traffic benchmarks (PEMS03, PEMS04, PEMS07, and PEMS08) are conducted to verify the state-of-the-art performance, with STD-MAE explicitly enhancing the downstream spatio-temporal models' ability to capture long-range intricate spatial and temporal patterns. Codes are available at", "."], "authors": "Haotian Gao"},
{"Title": "Preprocess your Paths -- Speeding up Linear Programming-based Optimization for Segment Routing Traffic Engineering", "abs": ["Many state-of-the-art Segment Routing (SR) Traffic Engineering (TE) algorithms rely on Linear Program (LP)-based optimization. However, the poor scalability of the latter and the resulting high computation times impose severe restrictions on the practical usability of such approaches for many use cases. To tackle this problem, a variety of preprocessing approaches have been proposed that aim to reduce computational complexity by preemtively limiting the number of SR paths to consider during optimization. In this paper, we provide the first extensive literature review of existing preprocessing approaches for SR. Based on this, we conduct a large scale comparative study using various real-world topologies, including recent data from a Tier-1 Internet Service Provider (ISP) backbone. Based on the insights obtained from this evaluation, we finally propose a combination of multiple preprocessing approaches and show that this can reliably reduce computation times by around a factor of 10 or more, without resulting in relevant deterioration of the solution quality. This is a major improvement over the current state-of-the-art and facilitates the reliable usability of LP-based optimization for large segment-routed networks."], "authors": "Alexander Brundiers"},
{"Title": "Summarization-based Data Augmentation for Document Classification", "abs": ["Despite the prevalence of pretrained language models in natural language understanding tasks, understanding lengthy text such as document is still challenging due to the data sparseness problem. Inspired by that humans develop their ability of understanding lengthy text from reading shorter text, we propose a simple yet effective summarization-based data augmentation, SUMMaug, for document classification. We first obtain easy-to-learn examples for the target document classification task by summarizing the input of the original training examples, while optionally merging the original labels to conform to the summarized input. We then use the generated pseudo examples to perform curriculum learning. Experimental results on two datasets confirmed the advantage of our method compared to existing baseline methods in terms of robustness and accuracy. We release our code and data at", "."], "authors": "Yueguan Wang"},
{"Title": "Attack Detection Using Item Vector Shift in Matrix Factorisation Recommenders", "abs": ["This paper proposes a novel method for detecting shilling attacks in Matrix Factorization (MF)-based Recommender Systems (RS), in which attackers use false user-item feedback to promote a specific item. Unlike existing methods that use either use supervised learning to distinguish between attack and genuine profiles or analyse target item rating distributions to detect false ratings, our method uses an unsupervised technique to detect false ratings by examining shifts in item preference vectors that exploit rating deviations and user characteristics, making it a promising new direction. The experimental results demonstrate the effectiveness of our approach in various attack scenarios, including those involving obfuscation techniques."], "authors": "Sulthana Shams"},
{"Title": "PyraTrans: Learning Attention-Enriched Multi-Scale Pyramid Network from Pre-Trained Transformers for Effective Malicious URL Detection", "abs": ["Detecting malicious URLs is a crucial aspect of web search and mining, significantly impacting internet security. Though advancements in machine learning have improved the effectiveness of detection methods, these methods still face significant challenges in their capacity to generalize and their resilience against evolving threats. In this paper, we propose PyraTrans, an approach that combines the strengths of pretrained Transformers and pyramid feature learning for improving malicious URL detection. We implement PyraTrans by leveraging a pretrained CharBERT as the base and augmenting it with 3 connected feature modules: 1) The Encoder Feature Extraction module, which extracts representations from each encoder layer of CharBERT to obtain multi-order features; 2) The Multi-Scale Feature Learning Module, which captures multi-scale local contextual insights and aggregate information across different layer-levels; and 3) The Pyramid Spatial Attention Module, which learns hierarchical and spatial feature attentions, highlighting critical classification signals while reducing noise. The proposed approach addresses the limitations of the Transformer in local feature learning and spatial awareness, and enabling us to extract multi-order, multi-scale URL feature representations with enhanced attentional focus. PyraTrans is evaluated using 4 benchmark datasets, where it demonstrated significant advancements over prior baseline methods. Particularly, on the imbalanced dataset, our method, with just 10% of the data for training, the TPR is 3.3-6.5 times and the F1-score is 2.9-4.5 times that of the baseline. Our approach also demonstrates robustness against adversarial attacks. Codes and data are available at", "."], "authors": "Ruitong Liu"},
{"Title": "VEXIR2Vec: An Architecture-Neutral Embedding Framework for Binary Similarity", "abs": ["We propose VEXIR2Vec, a code embedding framework for finding similar functions in binaries. Our representations rely on VEX IR, the intermediate representation used by binary analysis tools like Valgrind and angr. Our proposed embeddings encode both syntactic and semantic information to represent a function, and is both application and architecture independent. We also propose POV, a custom Peephole Optimization engine that normalizes the VEX IR for effective similarity analysis. We design several optimizations like copy/constant propagation, constant folding, common subexpression elimination and load-store elimination in POV.", "We evaluate our framework on two experiments -- diffing and searching -- involving binaries targeting different architectures, compiled using different compilers and versions, optimization sequences, and obfuscations. We show results on several standard projects and on real-world vulnerabilities. Our results show that VEXIR2Vec achieves superior precision and recall values compared to the state-of-the-art works. Our framework is highly scalable and is built as a multi-threaded, parallel library by only using open-source tools. VEXIR2Vec achieves about $3.2 \\times$ speedup on the closest competitor, and orders-of-magnitude speedup on other tools."], "authors": "S. VenkataKeerthy"},
{"Title": "On the Out-Of-Distribution Robustness of Self-Supervised Representation Learning for Phonocardiogram Signals", "abs": ["Objective: Despite the recent increase in research activity, deep-learning models have not yet been widely accepted in medicine. The shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with newly-collected, out-of-distribution (OOD) datasets. Methods: Contrastive Self-Supervised Learning (SSL) offers a potential solution to the scarcity of labeled data as it takes advantage of unlabeled data to increase model effectiveness and robustness. In this research, we propose applying contrastive SSL for detecting abnormalities in phonocardiogram (PCG) samples by learning a generalized representation of the signal. Specifically, we perform an extensive comparative evaluation of a wide range of audio-based augmentations and evaluate trained classifiers on multiple datasets across different downstream tasks. Results: We experimentally demonstrate that, depending on its training distribution, the effectiveness of a fully-supervised model can degrade up to 32% when evaluated on unseen data, while SSL models only lose up to 10% or even improve in some cases. Conclusions: Contrastive SSL pretraining can assist in providing robust classifiers which can generalize to unseen, OOD data, without relying on time- and labor-intensive annotation processes by medical experts. Furthermore, the proposed extensive evaluation protocol sheds light on the most promising and appropriate augmentations for robust PCG signal processing. Significance: We provide researchers and practitioners with a roadmap towards producing robust models for PCG classification, in addition to an open-source codebase for developing novel approaches."], "authors": "Aristotelis Ballas"},
{"Title": "Global Localization: Utilizing Relative Spatio-Temporal Geometric Constraints from Adjacent and Distant Cameras", "abs": ["Re-localizing a camera from a single image in a previously mapped area is vital for many computer vision applications in robotics and augmented/virtual reality. In this work, we address the problem of estimating the 6 DoF camera pose relative to a global frame from a single image. We propose to leverage a novel network of relative spatial and temporal geometric constraints to guide the training of a Deep Network for localization. We employ simultaneously spatial and temporal relative pose constraints that are obtained not only from adjacent camera frames but also from camera frames that are distant in the spatio-temporal space of the scene. We show that our method, through these constraints, is capable of learning to localize when little or very sparse ground-truth 3D coordinates are available. In our experiments, this is less than 1% of available ground-truth data. We evaluate our method on 3 common visual localization datasets and show that it outperforms other direct pose estimation methods."], "authors": "Mohammad Altillawi"},
{"Title": "REDUCR: Robust Data Downsampling Using Class Priority Reweighting", "abs": ["Modern machine learning models are becoming increasingly expensive to train for real-world image and text classification tasks, where massive web-scale data is collected in a streaming fashion. To reduce the training cost, online batch selection techniques have been developed to choose the most informative datapoints. However, these techniques can suffer from poor worst-class generalization performance due to class imbalance and distributional shifts. This work introduces REDUCR, a robust and efficient data downsampling method that uses class priority reweighting. REDUCR reduces the training data while preserving worst-class generalization performance. REDUCR assigns priority weights to datapoints in a class-aware manner using an online learning algorithm. We demonstrate the data efficiency and robust performance of REDUCR on vision and text classification tasks. On web-scraped datasets with imbalanced class distributions, REDUCR significantly improves worst-class test accuracy (and average accuracy), surpassing state-of-the-art methods by around 15%."], "authors": "William Bankes"},
{"Title": "Unveiling the Landscape of Smart Contract Vulnerabilities: A Detailed Examination and Codification of Vulnerabilities in Prominent Blockchains", "abs": ["With the rise in using immature smart contract programming languages to build a decentralized application, more vulnerabilities have been introduced to the Blockchain and were the main reasons behind critical financial losses. Moreover, the immutability of Blockchain technology makes deployed smart contracts unfixable for the whole life of the Blockchain itself. The lack of complete and up-to-date resources that explain those vulnerabilities in detail has also contributed to increasing the number of vulnerabilities in Blockchain. In addition, the lack of a standardized nomination of the existing vulnerabilities has made redundant research and made developers more confused. Therefore, in this paper, we propose the most complete list of smart contract vulnerabilities that exist in the most popular Blockchains with a detailed explanation of each one of them. In addition, we propose a new codification system that facilitates the communication of those vulnerabilities between developers and researchers. This codification, help identify the most uncovered vulnerabilities to focus on in future research. Moreover, the discussed list of vulnerabilities covers multiple Blockchain and could be used for even future built Blockchains."], "authors": "Oualid Zaazaa"},
{"Title": "Explainable AI in Diagnosing and Anticipating Leukemia Using Transfer Learning Method", "abs": ["This research paper focuses on Acute Lymphoblastic Leukemia (ALL), a form of blood cancer prevalent in children and teenagers, characterized by the rapid proliferation of immature white blood cells (WBCs). These atypical cells can overwhelm healthy cells, leading to severe health consequences. Early and accurate detection of ALL is vital for effective treatment and improving survival rates. Traditional diagnostic methods are time-consuming, costly, and prone to errors. The paper proposes an automated detection approach using computer-aided diagnostic (CAD) models, leveraging deep learning techniques to enhance the accuracy and efficiency of leukemia diagnosis. The study utilizes various transfer learning models like ResNet101V2, VGG19, InceptionV3, and InceptionResNetV2 for classifying ALL. The methodology includes using the Local Interpretable Model-Agnostic Explanations (LIME) for ensuring the validity and reliability of the AI system's predictions. This approach is critical for overcoming the \"black box\" nature of AI, where decisions made by models are often opaque and unaccountable. The paper highlights that the proposed method using the InceptionV3 model achieved an impressive 98.38% accuracy, outperforming other tested models. The results, verified by the LIME algorithm, showcase the potential of this method in accurately identifying ALL, providing a valuable tool for medical practitioners. The research underscores the impact of explainable artificial intelligence (XAI) in medical diagnostics, paving the way for more transparent and trustworthy AI applications in healthcare."], "authors": "Wahidul Hasan Abir"},
{"Title": "Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic Forecasting", "abs": ["Accurate epidemic forecasting is a critical task in controlling disease transmission. Many deep learning-based models focus only on static or dynamic graphs when constructing spatial information, ignoring their relationship. Additionally, these models often rely on recurrent structures, which can lead to error accumulation and computational time consumption. To address the aforementioned problems, we propose a novel model called Backbone-based Dynamic Graph Spatio-Temporal Network (BDGSTN). Intuitively, the continuous and smooth changes in graph structure, make adjacent graph structures share a basic pattern. To capture this property, we use adaptive methods to generate static backbone graphs containing the primary information and temporal models to generate dynamic temporal graphs of epidemic data, fusing them to generate a backbone-based dynamic graph. To overcome potential limitations associated with recurrent structures, we introduce a linear model DLinear to handle temporal dependencies and combine it with dynamic graph convolution for epidemic forecasting. Extensive experiments on two datasets demonstrate that BDGSTN outperforms baseline models and ablation comparison further verifies the effectiveness of model components. Furthermore, we analyze and measure the significance of backbone and temporal graphs by using information metrics from different aspects. Finally, we compare model parameter volume and training time to confirm the superior complexity and efficiency of BDGSTN."], "authors": "Junkai Mao"},
{"Title": "MultiView Independent Component Analysis with Delays", "abs": ["Linear Independent Component Analysis (ICA) is a blind source separation technique that has been used in various domains to identify independent latent sources from observed signals. In order to obtain a higher signal-to-noise ratio, the presence of multiple views of the same sources can be used. In this work, we present MultiView Independent Component Analysis with Delays (MVICAD). This algorithm builds on the MultiView ICA model by allowing sources to be delayed versions of some shared sources: sources are shared across views up to some unknown latencies that are view- and source-specific. Using simulations, we demonstrate that MVICAD leads to better unmixing of the sources. Moreover, as ICA is often used in neuroscience, we show that latencies are age-related when applied to Cam-CAN, a large-scale magnetoencephalography (MEG) dataset. These results demonstrate that the MVICAD model can reveal rich effects on neural signals without human supervision."], "authors": "Ambroise Heurtebise"},
{"Title": "MalDicom: A Memory Forensic Framework for Detecting Malicious Payload in DICOM Files", "abs": ["Digital Imaging and Communication System (DICOM) is widely used throughout the public health sector for portability in medical imaging. However, these DICOM files have vulnerabilities present in the preamble section. Successful exploitation of these vulnerabilities can allow attackers to embed executable codes in the 128-Byte preamble of DICOM files. Embedding the malicious executable will not interfere with the readability or functionality of DICOM imagery. However, it will affect the underline system silently upon viewing these files. This paper shows the infiltration of Windows malware executables into DICOM files. On viewing the files, the malicious DICOM will get executed and eventually infect the entire hospital network through the radiologist's workstation. The code injection process of executing malware in DICOM files affects the hospital networks and workstations' memory. Memory forensics for the infected radiologist's workstation is crucial as it can detect which malware disrupts the hospital environment, and future detection methods can be deployed. In this paper, we consider the machine learning (ML) algorithms to conduct memory forensics on three memory dump categories: Trojan, Spyware, and Ransomware, taken from the CIC-MalMem-2022 dataset. We obtain the highest accuracy of 75\\% with the Random Forest model. For estimating the feature importance for ML model prediction, we leveraged the concept of Shapley values."], "authors": "Ayushi Mishra"},
{"Title": "Japanese Tort-case Dataset for Rationale-supported Legal Judgment Prediction", "abs": ["This paper presents the first dataset for Japanese Legal Judgment Prediction (LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort prediction and its rationale extraction. The rationale extraction task identifies the court's accepting arguments from alleged arguments by plaintiffs and defendants, which is a novel task in the field. JTD is constructed based on annotated 3,477 Japanese Civil Code judgments by 41 legal experts, resulting in 7,978 instances with 59,697 of their alleged arguments from the involved parties. Our baseline experiments show the feasibility of the proposed two tasks, and our error analysis by legal experts identifies sources of errors and suggests future directions of the LJP research."], "authors": "Hiroaki Yamada"},
{"Title": "Interpretable Meta-Learning of Physical Systems", "abs": ["Machine learning methods can be a valuable aid in the scientific process, but they need to face challenging settings where data come from inhomogeneous experimental conditions. Recent meta-learning methods have made significant progress in multi-task learning, but they rely on black-box neural networks, resulting in high computational costs and limited interpretability. Leveraging the structure of the learning problem, we argue that multi-environment generalization can be achieved using a simpler learning model, with an affine structure with respect to the learning task. Crucially, we prove that this architecture can identify the physical parameters of the system, enabling interpreable learning. We demonstrate the competitive generalization performance and the low computational cost of our method by comparing it to state-of-the-art algorithms on physical systems, ranging from toy models to complex, non-analytical systems. The interpretability of our method is illustrated with original applications to physical-parameter-induced adaptation and to adaptive control."], "authors": "Matthieu Blanke"},
{"Title": "Self-Supervised Learning of Spatial Acoustic Representation with Cross-Channel Signal Reconstruction and Multi-Channel Conformer", "abs": ["Supervised learning methods have shown effectiveness in estimating spatial acoustic parameters such as time difference of arrival, direct-to-reverberant ratio and reverberation time. However, they still suffer from the simulation-to-reality generalization problem due to the mismatch between simulated and real-world acoustic characteristics and the deficiency of annotated real-world data. To this end, this work proposes a self-supervised method that takes full advantage of unlabeled data for spatial acoustic parameter estimation. First, a new pretext task, i.e. cross-channel signal reconstruction (CCSR), is designed to learn a universal spatial acoustic representation from unlabeled multi-channel microphone signals. We mask partial signals of one channel and ask the model to reconstruct them, which makes it possible to learn spatial acoustic information from unmasked signals and extract source information from the other microphone channel. An encoder-decoder structure is used to disentangle the two kinds of information. By fine-tuning the pre-trained spatial encoder with a small annotated dataset, this encoder can be used to estimate spatial acoustic parameters. Second, a novel multi-channel audio Conformer (MC-Conformer) is adopted as the encoder model architecture, which is suitable for both the pretext and downstream tasks. It is carefully designed to be able to capture the local and global characteristics of spatial acoustics exhibited in the time-frequency domain. Experimental results of five acoustic parameter estimation tasks on both simulated and real-world data show the effectiveness of the proposed method. To the best of our knowledge, this is the first self-supervised learning method in the field of spatial acoustic representation learning and multi-channel audio signal processing."], "authors": "Bing Yang"},
{"Title": "Pathologists light level preferences using the microscope -- a study to guide digital pathology display use", "abs": ["There is a paucity of guidelines relating to displays in digital pathology making procurement decisions, and display configuration challenging. Experience suggests pathologists have personal preferences for brightness when using a microscope which we hypothesised could be used as a predictor for display setup. We conducted an online survey across 6 NHS hospitals to capture brightness adjustment habits on both microscopes and screens. A subsample of respondents took part in a practical task to determine microscope brightness and display luminance preferences.", "The survey indicates 81% of respondents adjust the brightness on their microscope, compared with 11% adjusting their digital display. Display adjustments are more likely for visual comfort and ambient light compensation rather than for tissue factors, common for microscope adjustments. Twenty consultants took part in the practical brightness assessment. Light preferences on the microscope showed no correlation with screen preferences, except where a pathologist has a markedly brighter microscope preference. All of the preferences in this cohort were for a display luminance of less than 500cd/m$^2$, with 90% preferring 350cd/m$^2$ or less. There was no correlation between these preferences and the ambient lighting in the room.", "We conclude that microscope preferences can only be used to predict screen luminance requirements where the microscope is being used at very high brightness levels. A display capable of a brightness of 500cd/m$^2$ should be suitable for almost all pathologists with 300cd/m$^2$ suitable for the majority. The ability to adjust display luminance was felt to be important by the majority of respondents. Further work needs to be undertaken to establish the relationship between diagnostic performance, preferences and ambient lighting levels."], "authors": "Charlotte Jennings"},
{"Title": "A Bayesian approach for prompt optimization in pre-trained language models", "abs": ["A prompt is a sequence of symbol or tokens, selected from a vocabulary according to some rule, which is prepended/concatenated to a textual query. A key problem is how to select the sequence of tokens: in this paper we formulate it as a combinatorial optimization problem. The high dimensionality of the token space com-pounded by the length of the prompt sequence requires a very efficient solution. In this paper we propose a Bayesian optimization method, executed in a continuous em-bedding of the combinatorial space. In this paper we focus on hard prompt tuning (HPT) which directly searches for discrete tokens to be added to the text input with-out requiring access to the large language model (LLM) and can be used also when LLM is available only as a black-box. This is critically important if LLMs are made available in the Model as a Service (MaaS) manner as in GPT-4. The current manu-script is focused on the optimization of discrete prompts for classification tasks. The discrete prompts give rise to difficult combinatorial optimization problem which easily become intractable given the dimension of the token space in realistic applications. The optimization method considered in this paper is Bayesian optimization (BO) which has become the dominant approach in black-box optimization for its sample efficiency along with its modular structure and versatility. In this paper we use BoTorch, a library for Bayesian optimization research built on top of pyTorch. Albeit preliminary and obtained using a 'vanilla' version of BO, the experiments on RoB-ERTa on six benchmarks, show a good performance across a variety of tasks and enable an analysis of the tradeoff between size of the search space, accuracy and wall clock time."], "authors": "Antonio Sabbatella"},
{"Title": "Unfolder: Fast localization and image rectification of a document with a crease from folding in half", "abs": ["Presentation of folded documents is not an uncommon case in modern society. Digitizing such documents by capturing them with a smartphone camera can be tricky since a crease can divide the document contents into separate planes. To unfold the document, one could hold the edges potentially obscuring it in a captured image. While there are many geometrical rectification methods, they were usually developed for arbitrary bends and folds. We consider such algorithms and propose a novel approach Unfolder developed specifically for images of documents with a crease from folding in half. Unfolder is robust to projective distortions of the document image and does not fragment the image in the vicinity of a crease after rectification. A new Folded Document Images dataset was created to investigate the rectification accuracy of folded (2, 3, 4, and 8 folds) documents. The dataset includes 1600 images captured when document placed on a table and when held in hand. The Unfolder algorithm allowed for a recognition error rate of 0.33, which is better than the advanced neural network methods DocTr (0.44) and DewarpNet (0.57). The average runtime for Unfolder was only 0.25 s/image on an iPhone XR."], "authors": "A.M. Ershov"},
{"Title": "Learning Unorthogonalized Matrices for Rotation Estimation", "abs": ["Estimating 3D rotations is a common procedure for 3D computer vision. The accuracy depends heavily on the rotation representation. One form of representation -- rotation matrices -- is popular due to its continuity, especially for pose estimation tasks. The learning process usually incorporates orthogonalization to ensure orthonormal matrices. Our work reveals, through gradient analysis, that common orthogonalization procedures based on the Gram-Schmidt process and singular value decomposition will slow down training efficiency. To this end, we advocate removing orthogonalization from the learning process and learning unorthogonalized `Pseudo' Rotation Matrices (PRoM). An optimization analysis shows that PRoM converges faster and to a better solution. By replacing the orthogonalization incorporated representation with our proposed PRoM in various rotation-related tasks, we achieve state-of-the-art results on large-scale benchmarks for human pose estimation."], "authors": "Kerui Gu"},
{"Title": "Semantics of Attack-Defense Trees for Dynamic Countermeasures and a New Hierarchy of Star-free Languages", "abs": ["We present a mathematical setting for attack-defense trees, a classic graphical model to specify attacks and countermeasures. We equip attack-defense trees with (trace) language semantics allowing to have an original dynamic interpretation of countermeasures. Interestingly, the expressiveness of attack-defense trees coincides with star-free languages, and the nested countermeasures impact the expressiveness of attack-defense trees. With an adequate notion of countermeasure-depth, we exhibit a strict hierarchy of the star-free languages that does not coincides with the classic one. Additionally, driven by the use of attack-defense trees in practice, we address the decision problems of trace membership and of non-emptiness, and study their computational complexities parameterized by the countermeasure-depth."], "authors": "Thomas Brihaye"},
{"Title": "An Encoding Framework for Binarized Images using HyperDimensional Computing", "abs": ["Hyperdimensional Computing (HDC) is a brain-inspired and light-weight machine learning method. It has received significant attention in the literature as a candidate to be applied in the wearable internet of things, near-sensor artificial intelligence applications and on-device processing. HDC is computationally less complex than traditional deep learning algorithms and typically achieves moderate to good classification performance. A key aspect that determines the performance of HDC is the encoding of the input data to the hyperdimensional (HD) space. This article proposes a novel light-weight approach relying only on native HD arithmetic vector operations to encode binarized images that preserves similarity of patterns at nearby locations by using point of interest selection and local linear mapping. The method reaches an accuracy of 97.35% on the test set for the MNIST data set and 84.12% for the Fashion-MNIST data set. These results outperform other studies using baseline HDC with different encoding approaches and are on par with more complex hybrid HDC models. The proposed encoding approach also demonstrates a higher robustness to noise and blur compared to the baseline encoding."], "authors": "Laura Smets"},
{"Title": "Towards Generalizable Referring Image Segmentation via Target Prompt and Visual Coherence", "abs": ["Referring image segmentation (RIS) aims to segment objects in an image conditioning on free-from text descriptions. Despite the overwhelming progress, it still remains challenging for current approaches to perform well on cases with various text expressions or with unseen visual entities, limiting its further application. In this paper, we present a novel RIS approach, which substantially improves the generalization ability by addressing the two dilemmas mentioned above. Specially, to deal with unconstrained texts, we propose to boost a given expression with an explicit and crucial prompt, which complements the expression in a unified context, facilitating target capturing in the presence of linguistic style changes. Furthermore, we introduce a multi-modal fusion aggregation module with visual guidance from a powerful pretrained model to leverage spatial relations and pixel coherences to handle the incomplete target masks and false positive irregular clumps which often appear on unseen visual entities. Extensive experiments are conducted in the zero-shot cross-dataset settings and the proposed approach achieves consistent gains compared to the state-of-the-art, e.g., 4.15\\%, 5.45\\%, and 4.64\\% mIoU increase on RefCOCO, RefCOCO+ and ReferIt respectively, demonstrating its effectiveness. Additionally, the results on GraspNet-RIS show that our approach also generalizes well to new scenarios with large domain shifts."], "authors": "Yajie Liu"},
{"Title": "FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting", "abs": ["Novel view synthesis from limited observations remains an important and persistent task. However, high efficiency in existing NeRF-based few-shot view synthesis is often compromised to obtain an accurate 3D representation. To address this challenge, we propose a few-shot view synthesis framework based on 3D Gaussian Splatting that enables real-time and photo-realistic view synthesis with as few as three training views. The proposed method, dubbed FSGS, handles the extremely sparse initialized SfM points with a thoughtfully designed Gaussian Unpooling process. Our method iteratively distributes new Gaussians around the most representative locations, subsequently infilling local details in vacant areas. We also integrate a large-scale pre-trained monocular depth estimator within the Gaussians optimization process, leveraging online augmented views to guide the geometric optimization towards an optimal solution. Starting from sparse points observed from limited input viewpoints, our FSGS can accurately grow into unseen regions, comprehensively covering the scene and boosting the rendering quality of novel views. Overall, FSGS achieves state-of-the-art performance in both accuracy and rendering efficiency across diverse datasets, including LLFF, Mip-NeRF360, and Blender. Project website:", "."], "authors": "Zehao Zhu"},
{"Title": "Dolphins: Multimodal Language Model for Driving", "abs": ["The quest for fully autonomous vehicles (AVs) capable of navigating complex real-world scenarios with human-like understanding and responsiveness. In this paper, we introduce Dolphins, a novel vision-language model architected to imbibe human-like abilities as a conversational driving assistant. Dolphins is adept at processing multimodal inputs comprising video (or image) data, text instructions, and historical control signals to generate informed outputs corresponding to the provided instructions. Building upon the open-sourced pretrained Vision-Language Model, OpenFlamingo, we first enhance Dolphins's reasoning capabilities through an innovative Grounded Chain of Thought (GCoT) process. Then we tailored Dolphins to the driving domain by constructing driving-specific instruction data and conducting instruction tuning. Through the utilization of the BDD-X dataset, we designed and consolidated four distinct AV tasks into Dolphins to foster a holistic understanding of intricate driving scenarios. As a result, the distinctive features of Dolphins are characterized into two dimensions: (1) the ability to provide a comprehensive understanding of complex and long-tailed open-world driving scenarios and solve a spectrum of AV tasks, and (2) the emergence of human-like capabilities including gradient-free instant adaptation via in-context learning and error recovery via reflection."], "authors": "Yingzi Ma"},
{"Title": "Enhancing Image Captioning with Neural Models", "abs": ["This research explores the realm of neural image captioning using deep learning models. The study investigates the performance of different neural architecture configurations, focusing on the inject architecture, and proposes a novel quality metric for evaluating caption generation. Through extensive experimentation and analysis, this work sheds light on the challenges and opportunities in image captioning, providing insights into model behavior and overfitting. The results reveal that while the merge models exhibit a larger vocabulary and higher ROUGE scores, the inject architecture generates relevant and concise image captions. The study also highlights the importance of refining training data and optimizing hyperparameters for improved model performance. This research contributes to the growing body of knowledge in neural image captioning and encourages further exploration in the field, emphasizing the democratization of artificial intelligence."], "authors": "Pooja Bhatnagar"},
{"Title": "PEFTDebias : Capturing debiasing information using PEFTs", "abs": ["The increasing use of foundation models highlights the urgent need to address and eliminate implicit biases present in them that arise during pretraining. In this paper, we introduce PEFTDebias, a novel approach that employs parameter-efficient fine-tuning (PEFT) to mitigate the biases within foundation models. PEFTDebias consists of two main phases: an upstream phase for acquiring debiasing parameters along a specific bias axis, and a downstream phase where these parameters are incorporated into the model and frozen during the fine-tuning process. By evaluating on four datasets across two bias axes namely gender and race, we find that downstream biases can be effectively reduced with PEFTs. In addition, we show that these parameters possess axis-specific debiasing characteristics, enabling their effective transferability in mitigating biases in various downstream tasks. To ensure reproducibility, we release the code to do our experiments."], "authors": "Sumit Agarwal"},
{"Title": "A Low-Power Neuromorphic Approach for Efficient Eye-Tracking", "abs": ["This paper introduces a neuromorphic methodology for eye tracking, harnessing pure event data captured by a Dynamic Vision Sensor (DVS) camera. The framework integrates a directly trained Spiking Neuron Network (SNN) regression model and leverages a state-of-the-art low power edge neuromorphic processor - Speck, collectively aiming to advance the precision and efficiency of eye-tracking systems. First, we introduce a representative event-based eye-tracking dataset, \"Ini-30\", which was collected with two glass-mounted DVS cameras from thirty volunteers. Then,a SNN model, based on Integrate And Fire (IAF) neurons, named \"Retina\", is described , featuring only 64k parameters (6.63x fewer than the latest) and achieving pupil tracking error of only 3.24 pixels in a 64x64 DVS input. The continous regression output is obtained by means of convolution using a non-spiking temporal 1D filter slided across the output spiking layer. Finally, we evaluate Retina on the neuromorphic processor, showing an end-to-end power between 2.89-4.8 mW and a latency of 5.57-8.01 mS dependent on the time window. We also benchmark our model against the latest event-based eye-tracking method, \"3ET\", which was built upon event frames. Results show that Retina achieves superior precision with 1.24px less pupil centroid error and reduced computational complexity with 35 times fewer MAC operations. We hope this work will open avenues for further investigation of close-loop neuromorphic solutions and true event-based training pursuing edge performance."], "authors": "Pietro Bonazzi"},
{"Title": "A Semi-Tensor Product based Circuit Simulation for SAT-sweeping", "abs": ["In recent years, circuit simulators and Boolean satisfiability (SAT) solvers have been tightly integrated to provide efficient logic synthesis and verification. Circuit simulation can generate highly expressive simulation patterns that can either enumerate or filter out most candidates for synthesis. Subsequently, SAT solvers are employed to check those that remain, thereby making the logic synthesis process more efficient. This paper introduces a novel circuit simulator of k-input lookup table (k-LUT) networks, based on semi-tensor product (STP). STP-based simulators use computation of logic matrices, the primitives of logic networks, as opposed to relying on bitwise logic operations for simulation of k-LUT networks. Experimental results show that our STP-based simulator reduces the runtime by an average of 7.2x. Furthermore, we integrate this proposed simulator into a SAT-sweeping engine known as SAT sweeper. Through a combination of structural hashing, simulation, and SAT queries, SAT sweeper simplifies logic networks by systematically merging graph vertices from input to output. To enhance the efficiency, we used STP-based exhaustive simulation, which significantly reduces the number of false equivalence class candidates, thereby improving the computational efficiency by reducing the number of SAT calls required. When compared to the SOTA SAT sweeper, our method demonstrates an average 35% runtime reduction."], "authors": "Hongyang Pan"},
{"Title": "Towards Explaining Satellite Based Poverty Predictions with Convolutional Neural Networks", "abs": ["Deep convolutional neural networks (CNNs) have been shown to predict poverty and development indicators from satellite images with surprising accuracy. This paper presents a first attempt at analyzing the CNNs responses in detail and explaining the basis for the predictions. The CNN model, while trained on relatively low resolution day- and night-time satellite images, is able to outperform human subjects who look at high-resolution images in ranking the Wealth Index categories. Multiple explainability experiments performed on the model indicate the importance of the sizes of the objects, pixel colors in the image, and provide a visualization of the importance of different structures in input images. A visualization is also provided of type images that maximize the network prediction of Wealth Index, which provides clues on what the CNN prediction is based on."], "authors": "Hamid Sarmadi"},
{"Title": "Large-scale Vision-Language Models Learn Super Images for Efficient and High-Performance Partially Relevant Video Retrieval", "abs": ["In this paper, we propose an efficient and high-performance method for partially relevant video retrieval (PRVR), which aims to retrieve untrimmed long videos that contain at least one relevant moment to the input text query. In terms of both efficiency and performance, the overlooked bottleneck of previous studies is the visual encoding of dense frames. This guides researchers to choose lightweight visual backbones, yielding sub-optimal retrieval performance due to their limited capabilities of learned visual representations. However, it is undesirable to simply replace them with high-performance large-scale vision-and-language models (VLMs) due to their low efficiency. To address these issues, instead of dense frames, we focus on super images, which are created by rearranging the video frames in a $N \\times N$ grid layout. This reduces the number of visual encodings to $\\frac{1}{N^2}$ and compensates for the low efficiency of large-scale VLMs, allowing us to adopt them as powerful encoders. Surprisingly, we discover that with a simple query-image attention trick, VLMs generalize well to super images effectively and demonstrate promising zero-shot performance against SOTA methods efficiently. In addition, we propose a fine-tuning approach by incorporating a few trainable modules into the VLM backbones. The experimental results demonstrate that our approaches efficiently achieve the best performance on ActivityNet Captions and TVR."], "authors": "Taichi Nishimura"},
{"Title": "Abstract Syntax Tree for Programming Language Understanding and Representation: How Far Are We?", "abs": ["Programming language understanding and representation (a.k.a code representation learning) has always been a hot and challenging task in software engineering. It aims to apply deep learning techniques to produce numerical representations of the source code features while preserving its semantics. These representations can be used for facilitating subsequent code-related tasks. The abstract syntax tree (AST), a fundamental code feature, illustrates the syntactic information of the source code and has been widely used in code representation learning. However, there is still a lack of systematic and quantitative evaluation of how well AST-based code representation facilitates subsequent code-related tasks. In this paper, we first conduct a comprehensive empirical study to explore the effectiveness of the AST-based code representation in facilitating follow-up code-related tasks. To do so, we compare the performance of models trained with code token sequence (Token for short) based code representation and AST-based code representation on three popular types of code-related tasks. Surprisingly, the overall quantitative statistical results demonstrate that models trained with AST-based code representation consistently perform worse across all three tasks compared to models trained with Token-based code representation. Our further quantitative analysis reveals that models trained with AST-based code representation outperform models trained with Token-based code representation in certain subsets of samples across all three tasks. We also conduct comprehensive experiments to evaluate and reveal the impact of the choice of AST parsing/preprocessing/encoding methods on AST-based code representation and subsequent code-related tasks. Our study provides future researchers with detailed guidance on how to select solutions at each stage to fully exploit AST."], "authors": "Weisong Sun"},
{"Title": "API2Com: On the Improvement of Automatically Generated Code Comments Using API Documentations", "abs": ["Code comments can help in program comprehension and are considered as important artifacts to help developers in software maintenance. However, the comments are mostly missing or are outdated, specially in complex software projects. As a result, several automatic comment generation models are developed as a solution. The recent models explore the integration of external knowledge resources such as Unified Modeling Language class diagrams to improve the generated comments. In this paper, we propose API2Com, a model that leverages the Application Programming Interface Documentations (API Docs) as a knowledge resource for comment generation. The API Docs include the description of the methods in more details and therefore, can provide better context in the generated comments. The API Docs are used along with the code snippets and Abstract Syntax Trees in our model. We apply the model on a large Java dataset of over 130,000 methods and evaluate it using both Transformer and RNN-base architectures. Interestingly, when API Docs are used, the performance increase is negligible. We therefore run different experiments to reason about the results. For methods that only contain one API, adding API Docs improves the results by 4% BLEU score on average (BLEU score is an automatic evaluation metric used in machine translation). However, as the number of APIs that are used in a method increases, the performance of the model in generating comments decreases due to long documentations used in the input. Our results confirm that the API Docs can be useful in generating better comments, but, new techniques are required to identify the most informative ones in a method rather than using all documentations simultaneously."], "authors": "Ramin Shahbazi"},
{"Title": "SCHEME: Scalable Channer Mixer for Vision Transformers", "abs": ["Vision Transformers have received significant attention due to their impressive performance in many vision tasks. While the token mixer or attention block has been studied in great detail, the channel mixer or feature mixing block (FFN or MLP) has not been explored in depth albeit it accounts for a bulk of the parameters and computation in a model. In this work, we study whether sparse feature mixing can replace the dense connections and confirm this with a block diagonal MLP structure that improves the accuracy by supporting larger expansion ratios. To improve the feature clusters formed by this structure and thereby further improve the accuracy, a lightweight, parameter-free, channel covariance attention (CCA) mechanism is introduced as a parallel branch during training. This design of CCA enables gradual feature mixing across channel groups during training whose contribution decays to zero as the training progresses to convergence. This allows the CCA block to be discarded during inference, thus enabling enhanced performance with no additional computational cost. The resulting $\\textit{Scalable CHannEl MixEr}$ (SCHEME) can be plugged into any ViT architecture to obtain a gamut of models with different trade-offs between complexity and performance by controlling the block diagonal structure size in the MLP. This is shown by the introduction of a new family of SCHEMEformer models. Experiments on image classification, object detection, and semantic segmentation, with different ViT backbones, consistently demonstrate substantial accuracy gains over existing designs, especially under lower FLOPs regimes. For example, the SCHEMEformer establishes a new SOTA of 79.7% accuracy for ViTs using pure attention mixers on ImageNet-1K at 1.77G FLOPs."], "authors": "Deepak Sridhar"},
{"Title": "A framework for mining lifestyle profiles through multi-dimensional and high-order mobility feature clustering", "abs": ["Human mobility demonstrates a high degree of regularity, which facilitates the discovery of lifestyle profiles. Existing research has yet to fully utilize the regularities embedded in high-order features extracted from human mobility records in such profiling. This study proposes a progressive feature extraction strategy that mines high-order mobility features from users' moving trajectory records from the spatial, temporal, and semantic dimensions. Specific features are extracted such as travel motifs, rhythms decomposed by discrete Fourier transform (DFT) of mobility time series, and vectorized place semantics by word2vec, respectively to the three dimensions, and they are further clustered to reveal the users' lifestyle characteristics. An experiment using a trajectory dataset of over 500k users in Shenzhen, China yields seven user clusters with different lifestyle profiles that can be well interpreted by common sense. The results suggest the possibility of fine-grained user profiling through cross-order trajectory feature engineering and clustering."], "authors": "Yeshuo Shu"},
{"Title": "Beyond the Screen: Reshaping the Workplace with Virtual and Augmented Reality", "abs": ["Although extended reality technologies have enjoyed an explosion in popularity in recent years, few applications are effectively used outside the entertainment or academic contexts. This work consists of a literature review regarding the effective integration of such technologies in the workplace. It aims to provide an updated view of how they are being used in that context. First, we examine existing research concerning virtual, augmented, and mixed-reality applications. We also analyze which have made their way to the workflows of companies and institutions. Furthermore, we circumscribe the aspects of extended reality technologies that determined this applicability."], "authors": "Nuno Verdelho Trindade"},
{"Title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way", "abs": ["Large language models (LLMs) are increasingly pivotal in a wide range of natural language processing tasks. Access to pre-trained models, courtesy of the open-source community, has made it possible to adapt these models to specific applications for enhanced performance. However, the substantial resources required for training these models necessitate efficient solutions. This paper introduces CoLLiE, an efficient library that facilitates collaborative training of large language models using 3D parallelism, parameter-efficient fine-tuning (PEFT) methods, and optimizers such as Lion, Adan, Sophia, LOMO and AdaLomo. With its modular design and comprehensive functionality, CoLLiE offers a balanced blend of efficiency, ease of use, and customization. CoLLiE has proven superior training efficiency in comparison with prevalent solutions in pre-training and fine-tuning scenarios. Furthermore, we provide an empirical evaluation of the correlation between model size and GPU memory consumption under different optimization methods, as well as an analysis of the throughput. Lastly, we carry out a comprehensive comparison of various optimizers and PEFT methods within the instruction-tuning context. CoLLiE is available at", "."], "authors": "Kai Lv"},
{"Title": "A Causality-Aware Pattern Mining Scheme for Group Activity Recognition in a Pervasive Sensor Space", "abs": ["Human activity recognition (HAR) is a key challenge in pervasive computing and its solutions have been presented based on various disciplines. Specifically, for HAR in a smart space without privacy and accessibility issues, data streams generated by deployed pervasive sensors are leveraged. In this paper, we focus on a group activity by which a group of users perform a collaborative task without user identification and propose an efficient group activity recognition scheme which extracts causality patterns from pervasive sensor event sequences generated by a group of users to support as good recognition accuracy as the state-of-the-art graphical model. To filter out irrelevant noise events from a given data stream, a set of rules is leveraged to highlight causally related events. Then, a pattern-tree algorithm extracts frequent causal patterns by means of a growing tree structure. Based on the extracted patterns, a weighted sum-based pattern matching algorithm computes the likelihoods of stored group activities to the given test event sequence by means of matched event pattern counts for group activity recognition. We evaluate the proposed scheme using the data collected from our testbed and CASAS datasets where users perform their tasks on a daily basis and validate its effectiveness in a real environment. Experiment results show that the proposed scheme performs higher recognition accuracy and with a small amount of runtime overhead than the existing schemes."], "authors": "Hyunju Kim"},
{"Title": "VIoTGPT: Learning to Schedule Vision Tools towards Intelligent Video Internet of Things", "abs": ["Video Internet of Things (VIoT) has shown full potential in collecting an unprecedented volume of video data. Learning to schedule perceiving models and analyzing the collected videos intelligently will be potential sparks for VIoT. In this paper, to address the challenges posed by the fine-grained and interrelated vision tool usage of VIoT, we build VIoTGPT, the framework based on LLMs to correctly interact with humans, query knowledge videos, and invoke vision models to accomplish complicated tasks. To support VIoTGPT and related future works, we meticulously crafted the training dataset and established benchmarks involving 11 representative vision models across three categories based on semi-automatic annotations. To guide LLM to act as the intelligent agent towards intelligent VIoT, we resort to ReAct instruction tuning based on the collected VIoT dataset to learn the tool capability. Quantitative and qualitative experimental results and analyses demonstrate the effectiveness of VIoTGPT."], "authors": "Yaoyao Zhong"},
{"Title": "Learning to Estimate Critical Gait Parameters from Single-View RGB Videos with Transformer-Based Attention Network", "abs": ["Musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. Clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. This paper introduces a novel spatio-temporal Transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and show significant improvements in predicting general gait parameters (including Walking Speed, Gait Deviation Index - GDI, and Knee Flexion Angle at Maximum Extension), while utilizing fewer parameters and alleviating the need for manual feature extraction."], "authors": "Quoc Hung T. Le"},
{"Title": "GFN-SR: Symbolic Regression with Generative Flow Networks", "abs": ["Symbolic regression (SR) is an area of interpretable machine learning that aims to identify mathematical expressions, often composed of simple functions, that best fit in a given set of covariates $X$ and response $y$. In recent years, deep symbolic regression (DSR) has emerged as a popular method in the field by leveraging deep reinforcement learning to solve the complicated combinatorial search problem. In this work, we propose an alternative framework (GFN-SR) to approach SR with deep learning. We model the construction of an expression tree as traversing through a directed acyclic graph (DAG) so that GFlowNet can learn a stochastic policy to generate such trees sequentially. Enhanced with an adaptive reward baseline, our method is capable of generating a diverse set of best-fitting expressions. Notably, we observe that GFN-SR outperforms other SR algorithms in noisy data regimes, owing to its ability to learn a distribution of rewards over a space of candidate solutions."], "authors": "Sida Li"},
{"Title": "Study and Survey on Gesture Recognition Systems", "abs": ["In recent years, there has been a considerable amount of research in the Gesture Recognition domain, mainly owing to the technological advancements in Computer Vision. Various new applications have been conceptualised and developed in this field. This paper discusses the implementation of gesture recognition systems in multiple sectors such as gaming, healthcare, home appliances, industrial robots, and virtual reality. Different methodologies for capturing gestures are compared and contrasted throughout this survey. Various data sources and data acquisition techniques have been discussed. The role of gestures in sign language has been studied and existing approaches have been reviewed. Common challenges faced while building gesture recognition systems have also been explored."], "authors": "Kshitij Deshpande"},
{"Title": "Enhancing Explainability in Mobility Data Science through a combination of methods", "abs": ["In the domain of Mobility Data Science, the intricate task of interpreting models trained on trajectory data, and elucidating the spatio-temporal movement of entities, has persistently posed significant challenges. Conventional XAI techniques, although brimming with potential, frequently overlook the distinct structure and nuances inherent within trajectory data. Observing this deficiency, we introduced a comprehensive framework that harmonizes pivotal XAI techniques: LIME (Local Interpretable Model-agnostic Explanations), SHAP (SHapley Additive exPlanations), Saliency maps, attention mechanisms, direct trajectory visualization, and Permutation Feature Importance (PFI). Unlike conventional strategies that deploy these methods singularly, our unified approach capitalizes on the collective efficacy of these techniques, yielding deeper and more granular insights for models reliant on trajectory data. In crafting this synthesis, we effectively address the multifaceted essence of trajectories, achieving not only amplified interpretability but also a nuanced, contextually rich comprehension of model decisions. To validate and enhance our framework, we undertook a survey to gauge preferences and reception among various user demographics. Our findings underscored a dichotomy: professionals with academic orientations, particularly those in roles like Data Scientist, IT Expert, and ML Engineer, showcased a profound, technical understanding and often exhibited a predilection for amalgamated methods for interpretability. Conversely, end-users or individuals less acquainted with AI and Data Science showcased simpler inclinations, such as bar plots indicating timestep significance or visual depictions pinpointing pivotal segments of a vessel's trajectory."], "authors": "Georgios Makridis"},
{"Title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices", "abs": ["Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of $1.11\\times$ to $1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of $1.29\\times$ to $1.32\\times$."], "authors": "Junchen Zhao"},
{"Title": "Optimal Sample Complexity of Contrastive Learning", "abs": ["Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions, both general $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$ we show that $\\tilde \\Theta(\\min(nd,n^2))$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning."], "authors": "Noga Alon"},
{"Title": "SynFundus: Generating a synthetic fundus images dataset with millions of samples and multi-disease annotations", "abs": ["In the field of medical imaging, the scarcity of large-scale datasets due to privacy restrictions stands as a significant barrier to develop large models for medical. To address this issue, we introduce SynFundus-1M, a high-quality synthetic dataset with over 1 million retinal fundus images and extensive disease and pathologies annotations, which is generated by a Denoising Diffusion Probabilistic Model. The SynFundus-Generator and SynFundus-1M achieve superior Frechet Inception Distance (FID) scores compared to existing methods on main-stream public real datasets. Furthermore, the ophthalmologists evaluation validate the difficulty in discerning these synthetic images from real ones, confirming the SynFundus-1M's authenticity. Through extensive experiments, we demonstrate that both CNN and ViT can benifit from SynFundus-1M by pretraining or training directly. Compared to datasets like ImageNet or EyePACS, models train on SynFundus-1M not only achieve better performance but also faster convergence on various downstream tasks."], "authors": "Fangxin Shang"},
{"Title": "Text-Guided 3D Face Synthesis -- From Generation to Editing", "abs": ["Text-guided 3D face synthesis has achieved remarkable results by leveraging text-to-image (T2I) diffusion models. However, most existing works focus solely on the direct generation, ignoring the editing, restricting them from synthesizing customized 3D faces through iterative adjustments. In this paper, we propose a unified text-guided framework from face generation to editing. In the generation stage, we propose a geometry-texture decoupled generation to mitigate the loss of geometric details caused by coupling. Besides, decoupling enables us to utilize the generated geometry as a condition for texture generation, yielding highly geometry-texture aligned results. We further employ a fine-tuned texture diffusion model to enhance texture quality in both RGB and YUV space. In the editing stage, we first employ a pre-trained diffusion model to update facial geometry or texture based on the texts. To enable sequential editing, we introduce a UV domain consistency preservation regularization, preventing unintentional changes to irrelevant facial attributes. Besides, we propose a self-guided consistency weight strategy to improve editing efficacy while preserving consistency. Through comprehensive experiments, we showcase our method's superiority in face synthesis. Project page:", "."], "authors": "Yunjie Wu"},
{"Title": "Unleashing Cheapfakes through Trojan Plugins of Large Language Models", "abs": ["Open-source Large Language Models (LLMs) have recently gained popularity because of their comparable performance to proprietary LLMs. To efficiently fulfill domain-specialized tasks, open-source LLMs can be refined, without expensive accelerators, using low-rank adapters. However, it is still unknown whether low-rank adapters can be exploited to control LLMs. To address this gap, we demonstrate that an infected adapter can induce, on specific triggers, an LLM to output content defined by an adversary and to even maliciously use tools. To train a Trojan adapter, we propose two novel attacks, POLISHED and FUSION, that improve over prior approaches. POLISHED uses LLM-enhanced paraphrasing to polish benchmark poisoned datasets. In contrast, in the absence of a dataset, FUSION leverages an over-poisoning procedure to transform a benign adaptor. Our experiments validate that our attacks provide higher attack effectiveness than the baseline and, for the purpose of attracting downloads, preserves or improves the adapter's utility. Finally, we provide two case studies to demonstrate that the Trojan adapter can lead a LLM-powered autonomous agent to execute unintended scripts or send phishing emails. Our novel attacks represent the first study of supply chain threats for LLMs through the lens of Trojan plugins."], "authors": "Tian Dong"},
{"Title": "Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime Value", "abs": ["We develop an online learning MCMC approach applicable for hierarchical bayesian models and GLMS. We also develop a fat-tailed LTV model that generalizes over several kinds of fat and thin tails. We demonstrate both developments on commercial LTV data from a large mobile app."], "authors": "Alexey V. Calabourdin"},
{"Title": "Event-driven Real-time Retrieval in Web Search", "abs": ["Information retrieval in real-time search presents unique challenges distinct from those encountered in classical web search. These challenges are particularly pronounced due to the rapid change of user search intent, which is influenced by the occurrence and evolution of breaking news events, such as earthquakes, elections, and wars. Previous dense retrieval methods, which primarily focused on static semantic representation, lack the capacity to capture immediate search intent, leading to inferior performance in retrieving the most recent event-related documents in time-sensitive scenarios. To address this issue, this paper expands the query with event information that represents real-time search intent. The Event information is then integrated with the query through a cross-attention mechanism, resulting in a time-context query representation. We further enhance the model's capacity for event representation through multi-task training. Since publicly available datasets such as MS-MARCO do not contain any event information on the query side and have few time-sensitive queries, we design an automatic data collection and annotation pipeline to address this issue, which includes ModelZoo-based Coarse Annotation and LLM-driven Fine Annotation processes. In addition, we share the training tricks such as two-stage training and hard negative sampling. Finally, we conduct a set of offline experiments on a million-scale production dataset to evaluate our approach and deploy an A/B testing in a real online system to verify the performance. Extensive experimental results demonstrate that our proposed approach significantly outperforms existing state-of-the-art baseline methods."], "authors": "Nan Yang"},
{"Title": "Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning", "abs": ["Multimodal (e.g., RGB-Depth/RGB-Thermal) fusion has shown great potential for improving semantic segmentation in complex scenes (e.g., indoor/low-light conditions). Existing approaches often fully fine-tune a dual-branch encoder-decoder framework with a complicated feature fusion strategy for achieving multimodal semantic segmentation, which is training-costly due to the massive parameter updates in feature extraction and fusion. To address this issue, we propose a surprisingly simple yet effective dual-prompt learning network (dubbed DPLNet) for training-efficient multimodal (e.g., RGB-D/T) semantic segmentation. The core of DPLNet is to directly adapt a frozen pre-trained RGB model to multimodal semantic segmentation, reducing parameter updates. For this purpose, we present two prompt learning modules, comprising multimodal prompt generator (MPG) and multimodal feature adapter (MFA). MPG works to fuse the features from different modalities in a compact manner and is inserted from shadow to deep stages to generate the multi-level multimodal prompts that are injected into the frozen backbone, while MPG adapts prompted multimodal features in the frozen backbone for better multimodal semantic segmentation. Since both the MPG and MFA are lightweight, only a few trainable parameters (3.88M, 4.4% of the pre-trained backbone parameters) are introduced for multimodal feature fusion and learning. Using a simple decoder (3.27M parameters), DPLNet achieves new state-of-the-art performance or is on a par with other complex approaches on four RGB-D/T semantic segmentation datasets while satisfying parameter efficiency. Moreover, we show that DPLNet is general and applicable to other multimodal tasks such as salient object detection and video semantic segmentation. Without special design, DPLNet outperforms many complicated models. Our code will be available at", "."], "authors": "Shaohua Dong"},
{"Title": "Dancing with Images: Video Distillation via Static-Dynamic Disentanglement", "abs": ["Recently, dataset distillation has paved the way towards efficient machine learning, especially for image datasets. However, the distillation for videos, characterized by an exclusive temporal dimension, remains an underexplored domain. In this work, we provide the first systematic study of video distillation and introduce a taxonomy to categorize temporal compression. Our investigation reveals that the temporal information is usually not well learned during distillation , and the temporal dimension of synthetic data contributes little. The observations motivate our unified framework of disentangling the dynamic and static information in the videos. It first distills the videos into still images as static memory and then compensates the dynamic and motion information with a learnable dynamic memory block. Our method achieves state-of-the-art on video datasets at different scales, with notably smaller storage expenditure. Our code will be publicly available."], "authors": "Ziyu Wang"},
{"Title": "Benchmarking Multi-Domain Active Learning on Image Classification", "abs": ["Active learning aims to enhance model performance by strategically labeling informative data points. While extensively studied, its effectiveness on large-scale, real-world datasets remains underexplored. Existing research primarily focuses on single-source data, ignoring the multi-domain nature of real-world data. We introduce a multi-domain active learning benchmark to bridge this gap. Our benchmark demonstrates that traditional single-domain active learning strategies are often less effective than random selection in multi-domain scenarios. We also introduce CLIP-GeoYFCC, a novel large-scale image dataset built around geographical domains, in contrast to existing genre-based domain datasets. Analysis on our benchmark shows that all multi-domain strategies exhibit significant tradeoffs, with no strategy outperforming across all datasets or all metrics, emphasizing the need for future research."], "authors": "Jiayi Li"},
{"Title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training", "abs": ["Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs, and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers."], "authors": "Yefan Zhou"},
{"Title": "On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs", "abs": ["This paper examines the capacity of LLMs to reason with knowledge graphs using their internal knowledge graph, i.e., the knowledge graph they learned during pre-training. Two research questions are formulated to investigate the accuracy of LLMs in recalling information from pre-training knowledge graphs and their ability to infer knowledge graph relations from context. To address these questions, we employ LLMs to perform four distinct knowledge graph reasoning tasks. Furthermore, we identify two types of hallucinations that may occur during knowledge reasoning with LLMs: content and ontology hallucination. Our experimental results demonstrate that LLMs can successfully tackle both simple and complex knowledge graph reasoning tasks from their own memory, as well as infer from input context."], "authors": "Pei-Chi Lo"},
{"Title": "Manipulating the Label Space for In-Context Classification", "abs": ["After pre-training by generating the next word conditional on previous words, the Language Model (LM) acquires the ability of In-Context Learning (ICL) that can learn a new task conditional on the context of the given in-context examples (ICEs). Similarly, visually-conditioned Language Modelling is also used to train Vision-Language Models (VLMs) with ICL ability. However, such VLMs typically exhibit weaker classification abilities compared to contrastive learning-based models like CLIP, since the Language Modelling objective does not directly contrast whether an object is paired with a text. To improve the ICL of classification, using more ICEs to provide more knowledge is a straightforward way. However, this may largely increase the selection time, and more importantly, the inclusion of additional in-context images tends to extend the length of the in-context sequence beyond the processing capacity of a VLM. To alleviate these limitations, we propose to manipulate the label space of each ICE to increase its knowledge density, allowing for fewer ICEs to convey as much information as a larger set would. Specifically, we propose two strategies which are Label Distribution Enhancement and Visual Descriptions Enhancement to improve In-context classification performance on diverse datasets, including the classic ImageNet and more fine-grained datasets like CUB-200. Specifically, using our approach on ImageNet, we increase accuracy from 74.70\\% in a 4-shot setting to 76.21\\% with just 2 shots. surpassing CLIP by 0.67\\%. On CUB-200, our method raises 1-shot accuracy from 48.86\\% to 69.05\\%, 12.15\\% higher than CLIP. The code is given in https://anonymous.4open.science/r/MLS_ICC."], "authors": "Haokun Chen"},
{"Title": "The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific Progress in NLP", "abs": ["I propose a paradigm for scientific progress in NLP centered around developing scalable, data-driven theories of linguistic structure. The idea is to collect data in tightly scoped, carefully defined ways which allow for exhaustive annotation of behavioral phenomena of interest, and then use machine learning to construct explanatory theories of these phenomena which can form building blocks for intelligible AI systems. After laying some conceptual groundwork, I describe several investigations into data-driven theories of shallow semantic structure using Question-Answer driven Semantic Role Labeling (QA-SRL), a schema for annotating verbal predicate-argument relations using highly constrained question-answer pairs. While this only scratches the surface of the complex language behaviors of interest in AI, I outline principles for data collection and theoretical modeling which can inform future scientific progress. This note summarizes and draws heavily on my PhD thesis."], "authors": "Julian Michael"},
{"Title": "Student Activity Recognition in Classroom Environments using Transfer Learning", "abs": ["The recent advances in artificial intelligence and deep learning facilitate automation in various applications including home automation, smart surveillance systems, and healthcare among others. Human Activity Recognition is one of its emerging applications, which can be implemented in a classroom environment to enhance safety, efficiency, and overall educational quality. This paper proposes a system for detecting and recognizing the activities of students in a classroom environment. The dataset has been structured and recorded by the authors since a standard dataset for this task was not available at the time of this study. Transfer learning, a widely adopted method within the field of deep learning, has proven to be helpful in complex tasks like image and video processing. Pretrained models including VGG-16, ResNet-50, InceptionV3, and Xception are used for feature extraction and classification tasks. Xception achieved an accuracy of 93%, on the novel classroom dataset, outperforming the other three models in consideration. The system proposed in this study aims to introduce a safer and more productive learning environment for students and educators."], "authors": "Anagha Deshpande"},
{"Title": "RTQ: Rethinking Video-language Understanding Based on Image-text Model", "abs": ["Recent advancements in video-language understanding have been established on the foundation of image-text models, resulting in promising outcomes due to the shared knowledge between images and videos. However, video-language understanding presents unique challenges due to the inclusion of highly complex semantic details, which result in information redundancy, temporal dependency, and scene complexity. Current techniques have only partially tackled these issues, and our quantitative analysis indicates that some of these methods are complementary. In light of this, we propose a novel framework called RTQ (Refine, Temporal model, and Query), which addresses these challenges simultaneously. The approach involves refining redundant information within frames, modeling temporal relations among frames, and querying task-specific information from the videos. Remarkably, our model demonstrates outstanding performance even in the absence of video-language pre-training, and the results are comparable with or superior to those achieved by state-of-the-art pre-training methods."], "authors": "Xiao Wang"},
{"Title": "TRC: Trust Region Conditional Value at Risk for Safe Reinforcement Learning", "abs": ["As safety is of paramount importance in robotics, reinforcement learning that reflects safety, called safe RL, has been studied extensively. In safe RL, we aim to find a policy which maximizes the desired return while satisfying the defined safety constraints. There are various types of constraints, among which constraints on conditional value at risk (CVaR) effectively lower the probability of failures caused by high costs since CVaR is a conditional expectation obtained above a certain percentile. In this paper, we propose a trust region-based safe RL method with CVaR constraints, called TRC. We first derive the upper bound on CVaR and then approximate the upper bound in a differentiable form in a trust region. Using this approximation, a subproblem to get policy gradients is formulated, and policies are trained by iteratively solving the subproblem. TRC is evaluated through safe navigation tasks in simulations with various robots and a sim-to-real environment with a Jackal robot from Clearpath. Compared to other safe RL methods, the performance is improved by 1.93 times while the constraints are satisfied in all experiments."], "authors": "Dohyeong Kim"},
{"Title": "OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong Baseline", "abs": ["Stereo matching, a pivotal technique in computer vision, plays a crucial role in robotics, autonomous navigation, and augmented reality. Despite the development of numerous impressive methods in recent years, replicating their results and determining the most suitable architecture for practical application remains challenging. Addressing this gap, our paper introduces a comprehensive benchmark focusing on practical applicability rather than solely on performance enhancement. Specifically, we develop a flexible and efficient stereo matching codebase, called OpenStereo. OpenStereo includes training and inference codes of more than 12 network models, making it, to our knowledge, the most complete stereo matching toolbox available. Based on OpenStereo, we conducted experiments on the SceneFlow dataset and have achieved or surpassed the performance metrics reported in the original paper. Additionally, we conduct an in-depth revisitation of recent developments in stereo matching through ablative experiments. These investigations inspired the creation of StereoBase, a simple yet strong baseline model. Our extensive comparative analyses of StereoBase against numerous contemporary stereo matching methods on the SceneFlow dataset demonstrate its remarkably strong performance. The source code is available at", "."], "authors": "Xianda Guo"},
{"Title": "Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value at Risk", "abs": ["This paper aims to solve a safe reinforcement learning (RL) problem with risk measure-based constraints. As risk measures, such as conditional value at risk (CVaR), focus on the tail distribution of cost signals, constraining risk measures can effectively prevent a failure in the worst case. An on-policy safe RL method, called TRC, deals with a CVaR-constrained RL problem using a trust region method and can generate policies with almost zero constraint violations with high returns. However, to achieve outstanding performance in complex environments and satisfy safety constraints quickly, RL methods are required to be sample efficient. To this end, we propose an off-policy safe RL method with CVaR constraints, called off-policy TRC. If off-policy data from replay buffers is directly used to train TRC, the estimation error caused by the distributional shift results in performance degradation. To resolve this issue, we propose novel surrogate functions, in which the effect of the distributional shift can be reduced, and introduce an adaptive trust-region constraint to ensure a policy not to deviate far from replay buffers. The proposed method has been evaluated in simulation and real-world environments and satisfied safety constraints within a few steps while achieving high returns even in complex robotic tasks."], "authors": "Dohyeong Kim"},
{"Title": "Dynamic Matrix of Extremisms and Terrorism (DMET): A Continuum Approach Towards Identifying Different Degrees of Extremisms", "abs": ["We propose to extend the current binary understanding of terrorism (versus non-terrorism) with a Dynamic Matrix of Extremisms and Terrorism (DMET). DMET considers the whole ecosystem of content and actors that can contribute to a continuum of extremism (e.g., right-wing, left-wing, religious, separatist, single-issue). It organizes levels of extremisms by varying degrees of ideological engagement and the presence of violence identified (e.g., partisan, fringe, violent extremism, terrorism) based on cognitive and behavioral cues and group dynamics. DMET is globally applicable due to its comprehensive conceptualization of the levels of extremisms. It is also dynamic, enabling iterative mapping with the region- and time-specific classifications of extremist actors. Once global actors recognize DMET types and their distinct characteristics, they can comprehensively analyze the profiles of extremist actors (e.g., individuals, groups, movements), track these respective actors and their activities (e.g., social media content) over time, and launch targeted counter activities (e.g. de-platforming, content moderation, or redirects to targeted CVE narratives)."], "authors": "Marten Risius"},
{"Title": "Hypergraph Node Representation Learning with One-Stage Message Passing", "abs": ["Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node -> hyperedge -> node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node -> node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52% and 6.70%. Our code and datasets are available."], "authors": "Shilin Qu"},
{"Title": "Learning Anatomically Consistent Embedding for Chest Radiography", "abs": ["Self-supervised learning (SSL) approaches have recently shown substantial success in learning visual representations from unannotated images. Compared with photographic images, medical images acquired with the same imaging protocol exhibit high consistency in anatomy. To exploit this anatomical consistency, this paper introduces a novel SSL approach, called PEAC (patch embedding of anatomical consistency), for medical image analysis. Specifically, in this paper, we propose to learn global and local consistencies via stable grid-based matching, transfer pre-trained PEAC models to diverse downstream tasks, and extensively demonstrate that (1) PEAC achieves significantly better performance than the existing state-of-the-art fully/self-supervised methods, and (2) PEAC captures the anatomical structure consistency across views of the same patient and across patients of different genders, weights, and healthy statuses, which enhances the interpretability of our method for medical image analysis."], "authors": "Ziyu Zhou"},
{"Title": "UAV-Aided Lifelong Learning for AoI and Energy Optimization in Non-Stationary IoT Networks", "abs": ["In this paper, a novel joint energy and age of information (AoI) optimization framework for IoT devices in a non-stationary environment is presented. In particular, IoT devices that are distributed in the real-world are required to efficiently utilize their computing resources so as to balance the freshness of their data and their energy consumption. To optimize the performance of IoT devices in such a dynamic setting, a novel lifelong reinforcement learning (RL) solution that enables IoT devices to continuously adapt their policies to each newly encountered environment is proposed. Given that IoT devices have limited energy and computing resources, an unmanned aerial vehicle (UAV) is leveraged to visit the IoT devices and update the policy of each device sequentially. As such, the UAV is exploited as a mobile learning agent that can learn a shared knowledge base with a feature base in its training phase, and feature sets of a zero-shot learning method in its testing phase, to generalize between the environments. To optimize the trajectory and flying velocity of the UAV, an actor-critic network is leveraged so as to minimize the UAV energy consumption. Simulation results show that the proposed lifelong RL solution can outperform the state-of-art benchmarks by enhancing the balanced cost of IoT devices by $8.3\\%$ when incorporating warm-start policies for unseen environments. In addition, our solution achieves up to $49.38\\%$ reduction in terms of energy consumption by the UAV in comparison to the random flying strategy."], "authors": "Zhenzhen Gong"},
{"Title": "Matching Weak Informative Ontologies", "abs": ["Most existing ontology matching methods utilize the literal information to discover alignments. However, some literal information in ontologies may be opaque and some ontologies may not have sufficient literal information. In this paper, these ontologies are named as weak informative ontologies (WIOs) and it is challenging for existing methods to matching WIOs. On one hand, string-based and linguistic-based matching methods cannot work well for WIOs. On the other hand, some matching methods use external resources to improve their performance, but collecting and processing external resources is still time-consuming. To address this issue, this paper proposes a practical method for matching WIOs by employing the ontology structure information to discover alignments. First, the semantic subgraphs are extracted from the ontology graph to capture the precise meanings of ontology elements. Then, a new similarity propagation model is designed for matching WIOs. Meanwhile, in order to avoid meaningless propagation, the similarity propagation is constrained by semantic subgraphs and other conditions. Consequently, the similarity propagation model ensures a balance between efficiency and quality during matching. Finally, the similarity propagation model uses a few credible alignments as seeds to find more alignments, and some useful strategies are adopted to improve the performance. This matching method for WIOs has been implemented in the ontology matching system Lily. Experimental results on public OAEI benchmark datasets demonstrate that Lily significantly outperforms most of the state-of-the-art works in both WIO matching tasks and general ontology matching tasks. In particular, Lily increases the recall by a large margin, while it still obtains high precision of matching results."], "authors": "Peng Wang"},
{"Title": "StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style Adapter", "abs": ["Text-to-video (T2V) models have shown remarkable capabilities in generating diverse videos. However, they struggle to produce user-desired stylized videos due to (i) text's inherent clumsiness in expressing specific styles and (ii) the generally degraded style fidelity. To address these challenges, we introduce StyleCrafter, a generic method that enhances pre-trained T2V models with a style control adapter, enabling video generation in any style by providing a reference image. Considering the scarcity of stylized video datasets, we propose to first train a style control adapter using style-rich image datasets, then transfer the learned stylization ability to video generation through a tailor-made finetuning paradigm. To promote content-style disentanglement, we remove style descriptions from the text prompt and extract style information solely from the reference image using a decoupling learning strategy. Additionally, we design a scale-adaptive fusion module to balance the influences of text-based content features and image-based style features, which helps generalization across various text and style combinations. StyleCrafter efficiently generates high-quality stylized videos that align with the content of the texts and resemble the style of the reference images. Experiments demonstrate that our approach is more flexible and efficient than existing competitors."], "authors": "Gongye Liu"},
{"Title": "Agent-OM: Leveraging Large Language Models for Ontology Matching", "abs": ["Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM-based agents have become revolutionary in data engineering and have been applied creatively in various domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With thoughtful consideration of several specific challenges to leverage LLMs for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve very close results to the best long-standing performance on simple OM tasks and significantly improve the performance on complex and few-shot OM tasks."], "authors": "Zhangcheng Qiang"},
{"Title": "Machine Learning for Actionable Warning Identification: A Comprehensive Survey", "abs": ["Actionable Warning Identification (AWI) plays a crucial role in improving the usability of static code analyzers. With recent advances in Machine Learning (ML), various approaches have been proposed to incorporate ML techniques into AWI. These ML-based AWI approaches, benefiting from ML's strong ability to learn subtle and previously unseen patterns from historical data, have demonstrated superior performance. However, a comprehensive overview of these approaches is missing, which could hinder researchers/practitioners from understanding the current process and discovering potential for future improvement in the ML-based AWI community. In this paper, we systematically review the state-of-the-art ML-based AWI approaches. First, we employ a meticulous survey methodology and gather 50 primary studies from 2000/01/01 to 2023/09/01. Then, we outline the typical ML-based AWI workflow, including warning dataset preparation, preprocessing, AWI model construction, and evaluation stages. In such a workflow, we categorize ML-based AWI approaches based on the warning output format. Besides, we analyze the techniques used in each stage, along with their strengths, weaknesses, and distribution. Finally, we provide practical research directions for future ML-based AWI approaches, focusing on aspects like data improvement (e.g., enhancing the warning labeling strategy) and model exploration (e.g., exploring large language models for AWI)."], "authors": "Xiuting Ge"},
{"Title": "A DPLL Procedure with Dichotomous Branching for Propositional Product Logic", "abs": ["The propositional product logic is one of the basic fuzzy logics with continuous t-norms, exploiting the multiplication t-norm on the unit interval [0,1]. Our aim is to combine well-established automated deduction (theorem proving) with fuzzy inference. As a first step, we devise a modification of the procedure of Davis, Putnam, Logemann, and Loveland (DPLL) with dichotomous branching inferring in the product logic. We prove that the procedure is refutation sound and finitely complete. As a consequence, solutions to the deduction, satisfiability, and validity problems will be proposed for the finite case. The presented results are applicable to a design of intelligent systems, exploiting some kind of multi-step fuzzy inference."], "authors": "Dusan Guller"},
{"Title": "On Multi-step Fuzzy Inference in Goedel Logic", "abs": ["This paper addresses the logical and computational foundations of multi-step fuzzy inference using the Mamdani-Assilian type of fuzzy rules by implementing such inference in Goedel logic with truth constants. We apply the results achieved in the development of a hyperresolution calculus for this logic. We pose three fundamental problems: reachability, stability, the existence of a k-cycle in multi-step fuzzy inference and reduce them to certain deduction and unsatisfiability problems. The corresponding unsatisfiability problems may be solved using hyperresolution."], "authors": "Dusan Guller"},
{"Title": "Improving Efficiency of DNN-based Relocalization Module for Autonomous Driving with Server-side Computing", "abs": ["In this work, we present a novel framework for camera relocation in autonomous vehicles, leveraging deep neural networks (DNN). While existing literature offers various DNN-based camera relocation methods, their deployment is hindered by their high computational demands during inference. In contrast, our approach addresses this challenge through edge cloud collaboration. Specifically, we strategically offload certain modules of the neural network to the server and evaluate the inference time of data frames under different network segmentation schemes to guide our offloading decisions. Our findings highlight the vital role of server-side offloading in DNN-based camera relocation for autonomous vehicles, and we also discuss the results of data fusion. Finally, we validate the effectiveness of our proposed framework through experimental evaluation."], "authors": "Dengbo Li"},
{"Title": "A bilevel optimal motion planning (BOMP) model with application to autonomous parking", "abs": ["In this paper, we present a bilevel optimal motion planning (BOMP) model for autonomous parking. The BOMP model treats motion planning as an optimal control problem, in which the upper level is designed for vehicle nonlinear dynamics, and the lower level is for geometry collision-free constraints. The significant feature of the BOMP model is that the lower level is a linear programming problem that serves as a constraint for the upper-level problem. That is, an optimal control problem contains an embedded optimization problem as constraints. Traditional optimal control methods cannot solve the BOMP problem directly. Therefore, the modified approximate Karush-Kuhn-Tucker theory is applied to generate a general nonlinear optimal control problem. Then the pseudospectral optimal control method solves the converted problem. Particularly, the lower level is the $J_2$-function that acts as a distance function between convex polyhedron objects. Polyhedrons can approximate vehicles in higher precision than spheres or ellipsoids. Besides, the modified $J_2$-function (MJ) and the active-points based modified $J_2$-function (APMJ) are proposed to reduce the variables number and time complexity. As a result, an iteirative two-stage BOMP algorithm for autonomous parking concerning dynamical feasibility and collision-free property is proposed. The MJ function is used in the initial stage to find an initial collision-free approximate optimal trajectory and the active points, then the APMJ function in the final stage finds out the optimal trajectory. Simulation results and experiment on Turtlebot3 validate the BOMP model, and demonstrate that the computation speed increases almost two orders of magnitude compared with the area criterion based collision avoidance method."], "authors": "Shenglei Shi"},
{"Title": "Improving Normalization with the James-Stein Estimator", "abs": ["Stein's paradox holds considerable sway in high-dimensional statistics, highlighting that the sample mean, traditionally considered the de facto estimator, might not be the most efficacious in higher dimensions. To address this, the James-Stein estimator proposes an enhancement by steering the sample means toward a more centralized mean vector. In this paper, first, we establish that normalization layers in deep learning use inadmissible estimators for mean and variance. Next, we introduce a novel method to employ the James-Stein estimator to improve the estimation of mean and variance within normalization layers. We evaluate our method on different computer vision tasks: image classification, semantic segmentation, and 3D object classification. Through these evaluations, it is evident that our improved normalization layers consistently yield superior accuracy across all tasks without extra computational burden. Moreover, recognizing that a plethora of shrinkage estimators surpass the traditional estimator in performance, we study two other prominent shrinkage estimators: Ridge and LASSO. Additionally, we provide visual representations to intuitively demonstrate the impact of shrinkage on the estimated layer statistics. Finally, we study the effect of regularization and batch size on our modified batch normalization. The studies show that our method is less sensitive to batch size and regularization, improving accuracy under various setups."], "authors": "Seyedalireza Khoshsirat"},
{"Title": "Segment Anything Model-guided Collaborative Learning Network for Scribble-supervised Polyp Segmentation", "abs": ["Polyp segmentation plays a vital role in accurately locating polyps at an early stage, which holds significant clinical importance for the prevention of colorectal cancer. Various polyp segmentation methods have been developed using fully-supervised deep learning techniques. However, pixel-wise annotation for polyp images by physicians during the diagnosis is both time-consuming and expensive. Moreover, visual foundation models such as the Segment Anything Model (SAM) have shown remarkable performance. Nevertheless, directly applying SAM to medical segmentation may not produce satisfactory results due to the inherent absence of medical knowledge. In this paper, we propose a novel SAM-guided Collaborative Learning Network (SAM-CLNet) for scribble-supervised polyp segmentation, enabling a collaborative learning process between our segmentation network and SAM to boost the model performance. Specifically, we first propose a Cross-level Enhancement and Aggregation Network (CEA-Net) for weakly-supervised polyp segmentation. Within CEA-Net, we propose a Cross-level Enhancement Module (CEM) that integrates the adjacent features to enhance the representation capabilities of different resolution features. Additionally, a Feature Aggregation Module (FAM) is employed to capture richer features across multiple levels. Moreover, we present a box-augmentation strategy that combines the segmentation maps generated by CEA-Net with scribble annotations to create more precise prompts. These prompts are then fed into SAM, generating segmentation SAM-guided masks, which can provide additional supervision to train CEA-Net effectively. Furthermore, we present an Image-level Filtering Mechanism to filter out unreliable SAM-guided masks. Extensive experimental results show that our SAM-CLNet outperforms state-of-the-art weakly-supervised segmentation methods."], "authors": "Yiming Zhao"},
{"Title": "3D Face Reconstruction with the Geometric Guidance of Facial Part Segmentation", "abs": ["3D Morphable Models (3DMMs) provide promising 3D face reconstructions in various applications. However, existing methods struggle to reconstruct faces with extreme expressions due to deficiencies in supervisory signals, such as sparse or inaccurate landmarks. Segmentation information contains effective geometric contexts for face reconstruction. Certain attempts intuitively depend on differentiable renderers to compare the rendered silhouettes of reconstruction with segmentation, which is prone to issues like local optima and gradient instability. In this paper, we fully utilize the facial part segmentation geometry by introducing Part Re-projection Distance Loss (PRDL). Specifically, PRDL transforms facial part segmentation into 2D points and re-projects the reconstruction onto the image plane. Subsequently, by introducing grid anchors and computing different statistical distances from these anchors to the point sets, PRDL establishes geometry descriptors to optimize the distribution of the point sets for face reconstruction. PRDL exhibits a clear gradient compared to the renderer-based methods and presents state-of-the-art reconstruction performance in extensive quantitative and qualitative experiments. The project will be publicly available."], "authors": "Zidu Wang"},
{"Title": "A knowledge-based data-driven (KBDD) framework for all-day identification of cloud types using satellite remote sensing", "abs": ["Cloud types, as a type of meteorological data, are of particular significance for evaluating changes in rainfall, heatwaves, water resources, floods and droughts, food security and vegetation cover, as well as land use. In order to effectively utilize high-resolution geostationary observations, a knowledge-based data-driven (KBDD) framework for all-day identification of cloud types based on spectral information from Himawari-8/9 satellite sensors is designed. And a novel, simple and efficient network, named CldNet, is proposed. Compared with widely used semantic segmentation networks, including SegNet, PSPNet, DeepLabV3+, UNet, and ResUnet, our proposed model CldNet with an accuracy of 80.89+-2.18% is state-of-the-art in identifying cloud types and has increased by 32%, 46%, 22%, 2%, and 39%, respectively. With the assistance of auxiliary information (e.g., satellite zenith/azimuth angle, solar zenith/azimuth angle), the accuracy of CldNet-W using visible and near-infrared bands and CldNet-O not using visible and near-infrared bands on the test dataset is 82.23+-2.14% and 73.21+-2.02%, respectively. Meanwhile, the total parameters of CldNet are only 0.46M, making it easy for edge deployment. More importantly, the trained CldNet without any fine-tuning can predict cloud types with higher spatial resolution using satellite spectral data with spatial resolution 0.02°*0.02°, which indicates that CldNet possesses a strong generalization ability. In aggregate, the KBDD framework using CldNet is a highly effective cloud-type identification system capable of providing a high-fidelity, all-day, spatiotemporal cloud-type database for many climate assessment fields."], "authors": "Longfeng Nie"},
{"Title": "Developmental Pretraining (DPT) for Image Classification Networks", "abs": ["In the backdrop of increasing data requirements of Deep Neural Networks for object recognition that is growing more untenable by the day, we present Developmental PreTraining (DPT) as a possible solution. DPT is designed as a curriculum-based pre-training approach designed to rival traditional pre-training techniques that are data-hungry. These training approaches also introduce unnecessary features that could be misleading when the network is employed in a downstream classification task where the data is sufficiently different from the pre-training data and is scarce. We design the curriculum for DPT by drawing inspiration from human infant visual development. DPT employs a phased approach where carefully-selected primitive and universal features like edges and shapes are taught to the network participating in our pre-training regime. A model that underwent the DPT regime is tested against models with randomised weights to evaluate the viability of DPT."], "authors": "Niranjan Rajesh"},
{"Title": "A Review of the In-Network Computing and Its Role in the Edge-Cloud Continuum", "abs": ["Future networks are anticipated to enable exciting applications and industrial services ranging from Multisensory Extended Reality to Holographic and Haptic communication. These services are accompanied by high bandwidth requirements and/or require low latency and low reliability, which leads to the need for scarce and expensive resources. Cloud and edge computing offer different functionalities to these applications that require communication, computing, and caching (3C) resources working collectively. Hence, a paradigm shift is necessary to enable the joint management of the 3Cs in the edge-cloud continuum. We argue that In-Network Computing (INC) is the missing element that completes the edge-cloud continuum. This paper provides a detailed analysis of the driving use-cases, explores the synergy between INC and 3C, and emphasizes the crucial role of INC. A discussion on the opportunities and challenges posed by INC is held from various perspectives, including hardware implementation, architectural design, and regulatory and commercial aspects."], "authors": "Manel Gherari"},
{"Title": "PsyAttention: Psychological Attention Model for Personality Detection", "abs": ["Work on personality detection has tended to incorporate psychological features from different personality models, such as BigFive and MBTI. There are more than 900 psychological features, each of which is helpful for personality detection. However, when used in combination, the application of different calculation standards among these features may result in interference between features calculated using distinct systems, thereby introducing noise and reducing performance. This paper adapts different psychological models in the proposed PsyAttention for personality detection, which can effectively encode psychological features, reducing their number by 85%. In experiments on the BigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and 86.30%, respectively, outperforming state-of-the-art methods, indicating that it is effective at encoding psychological features."], "authors": "Baohua Zhang"},
{"Title": "Towards Aligned Canonical Correlation Analysis: Preliminary Formulation and Proof-of-Concept Results", "abs": ["Canonical Correlation Analysis (CCA) has been widely applied to jointly embed multiple views of data in a maximally correlated latent space. However, the alignment between various data perspectives, which is required by traditional approaches, is unclear in many practical cases. In this work we propose a new framework Aligned Canonical Correlation Analysis (ACCA), to address this challenge by iteratively solving the alignment and multi-view embedding."], "authors": "Biqian Cheng"},
{"Title": "SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection", "abs": ["Deception is the intentional practice of twisting information. It is a nuanced societal practice deeply intertwined with human societal evolution, characterized by a multitude of facets. This research explores the problem of deception through the lens of psychology, employing a framework that categorizes deception into three forms: lies of omission, lies of commission, and lies of influence. The primary focus of this study is specifically on investigating only lies of omission. We propose a novel framework for deception detection leveraging NLP techniques. We curated an annotated dataset of 876,784 samples by amalgamating a popular large-scale fake news dataset and scraped news headlines from the Twitter handle of Times of India, a well-known Indian news media house. Each sample has been labeled with four layers, namely: (i) the type of omission (speculation, bias, distortion, sounds factual, and opinion), (ii) colors of lies(black, white, etc), and (iii) the intention of such lies (to influence, etc) (iv) topic of lies (political, educational, religious, etc). We present a novel multi-task learning pipeline that leverages the dataless merging of fine-tuned language models to address the deception detection task mentioned earlier. Our proposed model achieved an F1 score of 0.87, demonstrating strong performance across all layers including the type, color, intent, and topic aspects of deceptive content. Finally, our research explores the relationship between lies of omission and propaganda techniques. To accomplish this, we conducted an in-depth analysis, uncovering compelling findings. For instance, our analysis revealed a significant correlation between loaded language and opinion, shedding light on their interconnectedness. To encourage further research in this field, we will be making the models and dataset available with the MIT License, making it favorable for open-source research."], "authors": "Anku Rani"},
{"Title": "Learning to forecast diagnostic parameters using pre-trained weather embedding", "abs": ["Data-driven weather prediction (DDWP) models are increasingly becoming popular for weather forecasting. However, while operational weather forecasts predict a wide variety of weather variables, DDWPs currently forecast a specific set of key prognostic variables. Non-prognostic (\"diagnostic\") variables are sometimes modeled separately as dependent variables of the prognostic variables (c.f. FourCastNet), or by including the diagnostic variable as a target in the DDWP. However, the cost of training and deploying bespoke models for each diagnostic variable can increase dramatically with more diagnostic variables, and limit the operational use of such models. Likewise, retraining an entire DDWP each time a new diagnostic variable is added is also cost-prohibitive. We present an two-stage approach that allows new diagnostic variables to be added to an end-to-end DDWP model without the expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen and \"downstream\" models are trained to predict diagnostic variables using only the latent representations of prognostic variables as input. Our experiments indicate that models trained using the two-stage approach offer accuracy comparable to training bespoke models, while leading to significant reduction in resource utilization during training and inference. This approach allows for new \"downstream\" models to be developed as needed, without affecting existing models and thus reducing the friction in operationalizing new models."], "authors": "Peetak P. Mitra"},
{"Title": "Robust Generalized Proportional Integral Control for Trajectory Tracking of Soft Actuators in a Pediatric Wearable Assistive Device", "abs": ["Soft robotics hold promise in the development of safe yet powered assistive wearable devices for infants. Key to this is the development of closed-loop controllers that can help regulate pneumatic pressure in the device's actuators in an effort to induce controlled motion at the user's limbs and be able to track different types of trajectories. This work develops a controller for soft pneumatic actuators aimed to power a pediatric soft wearable robotic device prototype for upper extremity motion assistance. The controller tracks desired trajectories for a system of soft pneumatic actuators supporting two-degree-of-freedom shoulder joint motion on an infant-sized engineered mannequin. The degrees of freedom assisted by the actuators are equivalent to shoulder motion (abduction/adduction and flexion/extension). Embedded inertial measurement unit sensors provide real-time joint feedback. Experimental data from performing reaching tasks using the engineered mannequin are obtained and compared against ground truth to evaluate the performance of the developed controller. Results reveal the proposed controller leads to accurate trajectory tracking performance across a variety of shoulder joint motions."], "authors": "Caio Mucchiani"},
{"Title": "A Scale-out Decentralized Blockchain Ledger System for Web3.0", "abs": ["The development of underlying technologies in blockchain mostly revolves around a difficult problem: how to enhance the performance of the system and reduce various costs of nodes (such as communication, storage and verification) without compromising the system's security and decentralization. Various layer-1 and layer-2 protocols have provided excellent solutions for this challenge. However, they cannot yet be considered as a ``silver bullet\". This paper proposes EZchain -- a novel decentralized ``scale-out\" ledger system designed for web3.0, aiming to enable blockchain technology to truly support ledger applications in large-scale fully decentralized networks. Without compromising security and decentralization, EZchain successfully accomplishes the following milestones: 1) Scalability: The theoretical throughput of EZchain can be infinitely expanded, nearly unaffected by bandwidth and other resource constraints. 2) Consumer-Grade Hardware Compatibility: EZchain is designed to be compatible with consumer-grade hardware, supporting storage, computation, and verification requirements. 3) Efficient Transaction Confirmation: EZchain strives to maintain transaction confirmation delays within one minute. Our prototype experiment demonstrates that under typical daily bandwidth network conditions, EZchain's performance in all aspects approaches that of the accounts in centralized payment systems. This provides a solid infrastructure for realizing mobile payments in web3.0."], "authors": "Lide Xue"},
{"Title": "Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach", "abs": ["With the rapid development of Mobile Edge Computing (MEC), various real-time applications have been deployed to benefit people's daily lives. The performance of these applications relies heavily on the freshness of collected environmental information, which can be quantified by its Age of Information (AoI). In the traditional definition of AoI, it is assumed that the status information can be actively sampled and directly used. However, for many MEC-enabled applications, the desired status information is updated in an event-driven manner and necessitates data processing. To better serve these applications, we propose a new definition of AoI and, based on the redefined AoI, we formulate an online AoI minimization problem for MEC systems. Notably, the problem can be interpreted as a Markov Decision Process (MDP), thus enabling its solution through Reinforcement Learning (RL) algorithms. Nevertheless, the traditional RL algorithms are designed for MDPs with completely unknown system dynamics and hence usually suffer long convergence times. To accelerate the learning process, we introduce Post-Decision States (PDSs) to exploit the partial knowledge of the system's dynamics. We also combine PDSs with deep RL to further improve the algorithm's applicability, scalability, and robustness. Numerical results demonstrate that our algorithm outperforms the benchmarks under various scenarios."], "authors": "Xingqiu He"},
{"Title": "Text Attribute Control via Closed-Loop Disentanglement", "abs": ["Changing an attribute of a text without changing the content usually requires to first disentangle the text into irrelevant attributes and content representations. After that, in the inference phase, the representation of one attribute is tuned to a different value, expecting that the corresponding attribute of the text can also be changed accordingly. The usual way of disentanglement is to add some constraints on the latent space of an encoder-decoder architecture, including adversarial-based constraints and mutual-information-based constraints. However, the previous semi-supervised processes of attribute change are usually not enough to guarantee the success of attribute change and content preservation. In this paper, we propose a novel approach to achieve a robust control of attributes while enhancing content preservation. In this approach, we use a semi-supervised contrastive learning method to encourage the disentanglement of attributes in latent spaces. Differently from previous works, we re-disentangle the reconstructed sentence and compare the re-disentangled latent space with the original latent space, which makes a closed-loop disentanglement process. This also helps content preservation. In addition, the contrastive learning method is also able to replace the role of minimizing mutual information and adversarial training in the disentanglement process, which alleviates the computation cost. We conducted experiments on three text datasets, including the Yelp Service review dataset, the Amazon Product review dataset, and the GoEmotions dataset. The experimental results show the effectiveness of our model."], "authors": "Lei Sha"},
{"Title": "Automating Continual Learning", "abs": ["General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF) -- previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to meta-learn their own in-context continual (meta-)learning algorithms. ACL encodes all desiderata -- good performance on both old and new tasks -- into its meta-learning objectives. Our experiments demonstrate that ACL effectively solves \"in-context catastrophic forgetting\"; our ACL-learned algorithms outperform hand-crafted ones, e.g., on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple few-shot and standard image classification datasets."], "authors": "Kazuki Irie"},
{"Title": "Mark My Words: Analyzing and Evaluating Language Model Watermarks", "abs": ["The capabilities of large language models have grown significantly in recent years and so too have concerns about their misuse. In this context, the ability to distinguish machine-generated text from human-authored content becomes important. Prior works have proposed numerous schemes to watermark text, which would benefit from a systematic evaluation framework. This work focuses on text watermarking techniques - as opposed to image watermarks - and proposes a comprehensive benchmark for them under different tasks as well as practical attacks. We focus on three main metrics: quality, size (e.g. the number of tokens needed to detect a watermark), and tamper-resistance. Current watermarking techniques are good enough to be deployed: Kirchenbauer et al. can watermark Llama2-7B-chat with no perceivable loss in quality in under 100 tokens, and with good tamper-resistance to simple attacks, regardless of temperature. We argue that watermark indistinguishability is too strong a requirement: schemes that slightly modify logit distributions outperform their indistinguishable counterparts with no noticeable loss in generation quality. We publicly release our benchmark."], "authors": "Julien Piet"},
{"Title": "Towards Clinical Prediction with Transparency: An Explainable AI Approach to Survival Modelling in Residential Aged Care", "abs": ["Background: Accurate survival time estimates aid end-of-life medical decision-making. Objectives: Develop an interpretable survival model for elderly residential aged care residents using advanced machine learning. Setting: A major Australasian residential aged care provider. Participants: Residents aged 65+ admitted for long-term care from July 2017 to August 2023. Sample size: 11,944 residents across 40 facilities. Predictors: Factors include age, gender, health status, co-morbidities, cognitive function, mood, nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome: Probability of survival post-admission, specifically calibrated for 6-month survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB, and RF models in 20 experiments with a 90/10 train/test split. Evaluated accuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month predictions using Platt scaling. Employed SHAP values to analyze predictor impacts. Results: GB, XGB, and RF models showed the highest C-Index values (0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors include age, male gender, mobility, health status, pressure ulcer risk, and appetite. Conclusions: The study successfully applies machine learning to create a survival model for aged care, aligning with clinical insights on mortality risk factors and enhancing model interpretability and clinical utility through explainable AI."], "authors": "Teo Susnjak"},
{"Title": "Adaptability of Computer Vision at the Tactical Edge: Addressing Environmental Uncertainty", "abs": ["Computer Vision (CV) systems are increasingly being adopted into Command and Control (C2) systems to improve intelligence analysis on the battlefield, the tactical edge. CV systems leverage Artificial Intelligence (AI) algorithms to help visualize and interpret the environment, enhancing situational awareness. However, the adaptability of CV systems at the tactical edge remains challenging due to rapidly changing environments and objects which can confuse the deployed models. A CV model leveraged in this environment can become uncertain in its predictions, as the environment and the objects existing in the environment begin to change. Additionally, mission objectives can rapidly change leading to adjustments in technology, camera angles, and image resolutions. All of which can negatively affect the performance of and potentially introduce uncertainty into the system. When the training environment and/or technology differs from the deployment environment, CV models can perform unexpectedly. Unfortunately, most scenarios at the tactical edge do not incorporate Uncertainty Quantification (UQ) into their deployed C2 and CV systems. This concept paper explores the idea of synchronizing robust data operations and model fine-tuning driven by UQ all at the tactical edge. Specifically, curating datasets and training child models based on the residuals of predictions, using these child models to calculate prediction intervals (PI), and then using these PI to calibrate the deployed models. By incorporating UQ into the core operations surrounding C2 and CV systems at the tactical edge, we can help drive purposeful adaptability on the battlefield."], "authors": "Hayden Moore"},
{"Title": "Academic competitions", "abs": ["Academic challenges comprise effective means for (i) advancing the state of the art, (ii) putting in the spotlight of a scientific community specific topics and problems, as well as (iii) closing the gap for under represented communities in terms of accessing and participating in the shaping of research fields. Competitions can be traced back for centuries and their achievements have had great influence in our modern world. Recently, they (re)gained popularity, with the overwhelming amounts of data that is being generated in different domains, as well as the need of pushing the barriers of existing methods, and available tools to handle such data. This chapter provides a survey of academic challenges in the context of machine learning and related fields. We review the most influential competitions in the last few years and analyze challenges per area of knowledge. The aims of scientific challenges, their goals, major achievements and expectations for the next few years are reviewed."], "authors": "Hugo Jair Escalante"},
{"Title": "Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration", "abs": ["Preference-based feedback is important for many applications in reinforcement learning where direct evaluation of a reward function is not feasible. A notable recent example arises in reinforcement learning from human feedback (RLHF) on large language models. For many applications of RLHF, the cost of acquiring the human feedback can be substantial. In this work, we take advantage of the fact that one can often choose contexts at which to obtain human feedback in order to most efficiently identify a good policy, and formalize this as an offline contextual dueling bandit problem. We give an upper-confidence-bound style algorithm for this problem and prove a polynomial worst-case regret bound. We then provide empirical confirmation in a synthetic setting that our approach outperforms existing methods. After, we extend the setting and methodology for practical use in RLHF training of large language models. Here, our method is able to reach better performance with fewer samples of human preferences than multiple baselines on three real-world datasets."], "authors": "Viraj Mehta"},
{"Title": "RoboSync: OS for Social Robots with Customizable Behaviour", "abs": ["Traditional robotic systems require complex implementations that are not always accessible or easy to use for Human-Robot Interaction (HRI) application developers. With the aim of simplifying the implementation of HRI applications, this paper introduces a novel real-time operating system (RTOS) designed for customizable HRI - RoboSync. By creating multi-level abstraction layers, the system enables users to define complex emotional and behavioral models without needing deep technical expertise. The system's modular architecture comprises a behavior modeling layer, a machine learning plugin configuration layer, a sensor checks customization layer, a scheduler that fits the need of HRI, and a communication and synchronization layer. This approach not only promotes ease of use without highly specialized skills but also ensures real-time responsiveness and adaptability. The primary functionality of the RTOS has been implemented for proof of concept and was tested on a CortexM4 microcontroller, demonstrating its potential for a wide range of lightweight simple-to-implement social robotics applications."], "authors": "Cheng Tang"},
{"Title": "Augmented Kinesthetic Teaching: Enhancing Task Execution Efficiency through Intuitive Human Instructions", "abs": ["In this paper, we present a complete and efficient implementation of a knowledge-sharing augmented kinesthetic teaching approach for efficient task execution in robotics. Our augmented kinesthetic teaching method integrates intuitive human feedback, including verbal, gesture, gaze, and physical guidance, to facilitate the extraction of multiple layers of task information including control type, attention direction, input and output type, action state change trigger, etc., enhancing the adaptability and autonomy of robots during task execution. We propose an efficient Programming by Demonstration (PbD) framework for users with limited technical experience to teach the robot in an intuitive manner. The proposed framework provides an interface for such users to teach customized tasks using high-level commands, with the goal of achieving a smoother teaching experience and task execution. This is demonstrated with the sample task of pouring water."], "authors": "Cheng Tang"},
{"Title": "PyNeRF: Pyramidal Neural Radiance Fields", "abs": ["Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples but such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20-90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster."], "authors": "Haithem Turki"},
{"Title": "Scalable Cellular V2X Solutions: Large-Scale Deployment Challenges of Connected Vehicle Safety Networks", "abs": ["Vehicle-to-Everything (V2X) communication is expected to accomplish a long-standing goal of the Connected and Autonomous Vehicle (CAV) community to bring connected vehicles to roads on a large scale. A major challenge, and perhaps the biggest hurdle on the path towards this goal is the scalability issues associated with it, especially when vehicular safety is concerned. As a major stakeholder, 3rd Generation Partnership Project (3GPP) based Cellular V2X (C-V2X) community has long been trying to research on whether vehicular networks are able to support the safety-critical applications in high-density vehicular scenarios. This paper attempts to answer this by first presenting an overview on the scalability challenges faced by 3GPP Release 14 Long Term Evolution C-V2X (LTE-V2X) using the PC5 sidelink interface for low and heavy-density traffic scenarios. Next, it demonstrates a series of solutions that address network congestion, packet losses and other scalability issues associated with LTE-V2X to enable this communication technology for commercial deployment. In addition, a brief survey is provided into 3GPP Release 16 5G New Radio V2X (NR-V2X) that utilizes the NR sidelink interface and works as an evolution of C-V2X towards better performance for V2X communications including new enhanced V2X (eV2X) scenarios that possess ultra-low-latency and high-reliability requirements."], "authors": "Ghayoor Shah"},
{"Title": "Advancements and Trends in Ultra-High-Resolution Image Processing: An Overview", "abs": ["Currently, to further improve visual enjoyment, Ultra-High-Definition (UHD) images are catching wide attention. Here, UHD images are usually referred to as having a resolution greater than or equal to $3840 \\times 2160$. However, since the imaging equipment is subject to environmental noise or equipment jitter, UHD images are prone to contrast degradation, blurring, low dynamic range, etc. To address these issues, a large number of algorithms for UHD image enhancement have been proposed. In this paper, we introduce the current state of UHD image enhancement from two perspectives, one is the application field and the other is the technology. In addition, we briefly explore its trends."], "authors": "Zhuoran Zheng"},
{"Title": "Curvature Explains Loss of Plasticity", "abs": ["Loss of plasticity is a phenomenon in which neural networks lose their ability to learn from new experience. Despite being empirically observed in several problem settings, little is understood about the mechanisms that lead to loss of plasticity. In this paper, we offer a consistent explanation for plasticity loss, based on an assertion that neural networks lose directions of curvature during training and that plasticity loss can be attributed to this reduction in curvature. To support such a claim, we provide a systematic empirical investigation of plasticity loss across several continual supervised learning problems. Our findings illustrate that curvature loss coincides with and sometimes precedes plasticity loss, while also showing that previous explanations are insufficient to explain loss of plasticity in all settings. Lastly, we show that regularizers which mitigate loss of plasticity also preserve curvature, motivating a simple distributional regularizer that proves to be effective across the problem settings considered."], "authors": "Alex Lewandowski"},
{"Title": "SPAM: Secure & Private Aircraft Management", "abs": ["With the rising use of aircrafts for operations ranging from disaster-relief to warfare, there is a growing risk of adversarial attacks. Malicious entities often only require the location of the aircraft for these attacks. Current satellite-aircraft communication and tracking protocols put aircrafts at risk if the satellite is compromised, due to computation being done in plaintext. In this work, we present \\texttt{SPAM}, a private, secure, and accurate system that allows satellites to efficiently manage and maintain tracking angles for aircraft fleets without learning aircrafts' locations. \\texttt{SPAM} is built upon multi-party computation and zero-knowledge proofs to guarantee privacy and high efficiency. While catered towards aircrafts, \\texttt{SPAM}'s zero-knowledge fleet management can be easily extended to the IoT, with very little overhead."], "authors": "Yaman Jandali"},
{"Title": "Low Revenue in Display Ad Auctions: Algorithmic Collusion vs. Non-Quasilinear Preferences", "abs": ["The transition of display ad exchanges from second-price to first-price auctions has raised questions about its impact on revenue. Evaluating this shift empirically proves challenging. One key factor is the behavior of automated bidding agents, who are unlikely to use static game-theoretical equilibrium strategies instead of favoring dynamic realms that continuously adapt and learn independently through the process of exploration and exploitation. Thus revenue equivalence between first- and second-price auctions might not hold. Research on algorithmic collusion in display ad auctions found revenue differences between second-price and first-price auctions. First-price auctions can induce Q-learning agents to tacitly collude below the Nash equilibrium in repeated complete-information auctions with payoff-maximizing agents (i.e., agents maximizing value minus price). Our analysis explores wide-spread online learning algorithms' convergence behavior in both complete and incomplete information models, but does not find a systematic deviance from equilibrium behavior. Convergence for Q-learning depends on hyperparameters and initializations, and algorithmic collusion vanishes when competing against other learning algorithms. Apart from their learning behavior, the objectives reported in the literature extend payoff maximization, often focusing on return-on-investment or return-on-spend. We derive equilibrium bid functions for such utility models, revealing that revenue equivalence doesn't hold. In low-competition scenarios, the first-price auction often yields lower revenue than the second-price counterpart. These insights offer an alternative rationale for the potential revenue decrease in first-price auctions. Understanding the intricate interplay of auction rules, learning algorithms, and utility models is crucial in maximizing revenue in the ever-evolving world of display ad exchanges."], "authors": "Martin Bichler"},
{"Title": "Class-Incremental Continual Learning into the eXtended DER-verse", "abs": ["The staple of human intelligence is the capability of acquiring knowledge in a continuous fashion. In stark contrast, Deep Networks forget catastrophically and, for this reason, the sub-field of Class-Incremental Continual Learning fosters methods that learn a sequence of tasks incrementally, blending sequentially-gained knowledge into a comprehensive prediction.", "This work aims at assessing and overcoming the pitfalls of our previous proposal Dark Experience Replay (DER), a simple and effective approach that combines rehearsal and Knowledge Distillation. Inspired by the way our minds constantly rewrite past recollections and set expectations for the future, we endow our model with the abilities to i) revise its replay memory to welcome novel information regarding past data ii) pave the way for learning yet unseen classes.", "We show that the application of these strategies leads to remarkable improvements; indeed, the resulting method - termed eXtended-DER (X-DER) - outperforms the state of the art on both standard benchmarks (such as CIFAR-100 and miniImagenet) and a novel one here introduced. To gain a better understanding, we further provide extensive ablation studies that corroborate and extend the findings of our previous research (e.g. the value of Knowledge Distillation and flatter minima in continual learning setups)."], "authors": "Matteo Boschini"},
{"Title": "Essentials for Class Incremental Learning", "abs": ["Contemporary neural networks are limited in their ability to learn from evolving streams of training data. When trained sequentially on new or evolving tasks, their accuracy drops sharply, making them unsuitable for many real-world applications. In this work, we shed light on the causes of this well-known yet unsolved phenomenon - often referred to as catastrophic forgetting - in a class-incremental setup. We show that a combination of simple components and a loss that balances intra-task and inter-task learning can already resolve forgetting to the same extent as more complex measures proposed in literature. Moreover, we identify poor quality of the learned representation as another reason for catastrophic forgetting in class-IL. We show that performance is correlated with secondary class information (dark knowledge) learned by the model and it can be improved by an appropriate regularizer. With these lessons learned, class-incremental learning results on CIFAR-100 and ImageNet improve over the state-of-the-art by a large margin, while keeping the approach simple."], "authors": "Sudhanshu Mittal"},
{"Title": "Negotiated Representations to Prevent Forgetting in Machine Learning Applications", "abs": ["Catastrophic forgetting is a significant challenge in the field of machine learning, particularly in neural networks. When a neural network learns to perform well on a new task, it often forgets its previously acquired knowledge or experiences. This phenomenon occurs because the network adjusts its weights and connections to minimize the loss on the new task, which can inadvertently overwrite or disrupt the representations that were crucial for the previous tasks. As a result, the the performance of the network on earlier tasks deteriorates, limiting its ability to learn and adapt to a sequence of tasks. In this paper, we propose a novel method for preventing catastrophic forgetting in machine learning applications, specifically focusing on neural networks. Our approach aims to preserve the knowledge of the network across multiple tasks while still allowing it to learn new information effectively. We demonstrate the effectiveness of our method by conducting experiments on various benchmark datasets, including Split MNIST, Split CIFAR10, Split Fashion MNIST, and Split CIFAR100. These datasets are created by dividing the original datasets into separate, non overlapping tasks, simulating a continual learning scenario where the model needs to learn multiple tasks sequentially without forgetting the previous ones. Our proposed method tackles the catastrophic forgetting problem by incorporating negotiated representations into the learning process, which allows the model to maintain a balance between retaining past experiences and adapting to new tasks. By evaluating our method on these challenging datasets, we aim to showcase its potential for addressing catastrophic forgetting and improving the performance of neural networks in continual learning settings."], "authors": "Nuri Korhan"},
{"Title": "Class-incremental learning: survey and performance evaluation on image classification", "abs": ["For future learning systems, incremental learning is desirable because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored -- also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main challenge for incremental learning is catastrophic forgetting, which refers to the precipitous drop in performance on previously learned tasks after learning a new one. Incremental learning of deep neural networks has seen explosive growth in recent years. Initial work focused on task-incremental learning, where a task-ID is provided at inference time. Recently, we have seen a shift towards class-incremental learning where the learner must discriminate at inference time between all classes seen in previous tasks without recourse to a task-ID. In this paper, we provide a complete survey of existing class-incremental learning methods for image classification, and in particular, we perform an extensive experimental evaluation on thirteen class-incremental methods. We consider several new experimental scenarios, including a comparison of class-incremental methods on multiple large-scale image classification datasets, an investigation into small and large domain shifts, and a comparison of various network architectures."], "authors": "Marc Masana"},
{"Title": "Brainformer: Modeling MRI Brain Functions to Machine Vision", "abs": ["\"Perception is reality\". Human perception plays a vital role in forming beliefs and understanding reality. Exploring how the human brain works in the visual system facilitates bridging the gap between human visual perception and computer vision models. However, neuroscientists study the brain via Neuroimaging, i.e., Functional Magnetic Resonance Imaging (fMRI), to discover the brain's functions. These approaches face interpretation challenges where fMRI data can be complex and require expertise. Therefore, neuroscientists make inferences about cognitive processes based on patterns of brain activities, which can lead to potential misinterpretation or limited functional understanding. In this work, we first present a simple yet effective Brainformer approach, a novel Transformer-based framework, to analyze the patterns of fMRI in the human perception system from the machine learning perspective. Secondly, we introduce a novel mechanism incorporating fMRI, which represents the human brain activities, as the supervision for the machine vision model. This work also introduces a novel perspective on transferring knowledge from human perception to neural networks. Through our experiments, we demonstrated that by leveraging fMRI information, the machine vision model can achieve potential results compared to the current State-of-the-art methods in various image recognition tasks."], "authors": "Xuan-Bac Nguyen"},
{"Title": "Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks", "abs": ["Graph contrastive learning has shown great promise when labeled data is scarce, but large unlabeled datasets are available. However, it often does not take uncertainty estimation into account. We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance on semi-supervised node-classification tasks. Moreover, we propose a new measure of uncertainty for contrastive learning, that is based on the disagreement in likelihood due to different positive samples."], "authors": "Alexander Möllers"},
{"Title": "Unsupervised textile defect detection using convolutional neural networks", "abs": ["In this study, we propose a novel motif-based approach for unsupervised textile anomaly detection that combines the benefits of traditional convolutional neural networks with those of an unsupervised learning paradigm. It consists of five main steps: preprocessing, automatic pattern period extraction, patch extraction, features selection and anomaly detection. This proposed approach uses a new dynamic and heuristic method for feature selection which avoids the drawbacks of initialization of the number of filters (neurons) and their weights, and those of the backpropagation mechanism such as the vanishing gradients, which are common practice in the state-of-the-art methods. The design and training of the network are performed in a dynamic and input domain-based manner and, thus, no ad-hoc configurations are required. Before building the model, only the number of layers and the stride are defined. We do not initialize the weights randomly nor do we define the filter size or number of filters as conventionally done in CNN-based approaches. This reduces effort and time spent on hyperparameter initialization and fine-tuning. Only one defect-free sample is required for training and no further labeled data is needed. The trained network is then used to detect anomalies on defective fabric samples. We demonstrate the effectiveness of our approach on the Patterned Fabrics benchmark dataset. Our algorithm yields reliable and competitive results (on recall, precision, accuracy and f1- measure) compared to state-of-the-art unsupervised approaches, in less time, with efficient training in a single epoch and a lower computational cost."], "authors": "Imane Koulali"},
{"Title": "Multi-Modal Video Topic Segmentation with Dual-Contrastive Domain Adaptation", "abs": ["Video topic segmentation unveils the coarse-grained semantic structure underlying videos and is essential for other video understanding tasks. Given the recent surge in multi-modal, relying solely on a single modality is arguably insufficient. On the other hand, prior solutions for similar tasks like video scene/shot segmentation cater to short videos with clear visual shifts but falter for long videos with subtle changes, such as livestreams. In this paper, we introduce a multi-modal video topic segmenter that utilizes both video transcripts and frames, bolstered by a cross-modal attention mechanism. Furthermore, we propose a dual-contrastive learning framework adhering to the unsupervised domain adaptation paradigm, enhancing our model's adaptability to longer, more semantically complex videos. Experiments on short and long video corpora demonstrate that our proposed solution, significantly surpasses baseline methods in terms of both accuracy and transferability, in both intra- and cross-domain settings."], "authors": "Linzi Xing"},
{"Title": "Medication abortion via digital health in the United States: a systematic scoping review", "abs": ["Digital health, including telemedicine, has increased access to abortion care. The convenience, flexibility of appointment times, and ensured privacy to abortion users may make abortion services via telemedicine preferable. This scoping review systematically mapped studies conducted on abortion services via telemedicine, including their effectiveness and acceptability for abortion users and providers. All published papers included abortion services via telemedicine in the United States were considered. Articles were searched in PubMed, CINAHL, and Google Scholar databases in September 2022. The findings were synthesized narratively, and the PRISMA-ScR guidelines were used to report this study. Out of 757 retrieved articles, 33 articles were selected based on the inclusion criteria. These studies were published between 2011 and 2022, with 24 published in the last 3 years. The study found that telemedicine increased access to abortion care in the United States, especially for people in remote areas or those worried about stigma from in-person visits. The effectiveness of abortion services via telemedicine was comparable to in-clinic visits, with 6% or fewer abortions requiring surgical intervention. Both care providers and abortion seekers expressed positive perceptions of telemedicine-based abortion services. However, abortion users reported mixed emotions, with some preferring in-person visits. The most common reasons for choosing telemedicine included the distance to the abortion clinic, convenience, privacy, cost, flexibility of appointment times, and state laws imposing waiting periods or restrictive policies. Telemedicine offered a preferable option for abortion seekers and providers. The feasibility of accessing abortion services via telemedicine in low-resource settings needs further investigation."], "authors": "Fekede Asefa Kumsa"},
{"Title": "Learning active tactile perception through belief-space control", "abs": ["Robots operating in an open world will encounter novel objects with unknown physical properties, such as mass, friction, or size. These robots will need to sense these properties through interaction prior to performing downstream tasks with the objects. We propose a method that autonomously learns tactile exploration policies by developing a generative world model that is leveraged to 1) estimate the object's physical parameters using a differentiable Bayesian filtering algorithm and 2) develop an exploration policy using an information-gathering model predictive controller. We evaluate our method on three simulated tasks where the goal is to estimate a desired object property (mass, height or toppling height) through physical interaction. We find that our method is able to discover policies that efficiently gather information about the desired property in an intuitive manner. Finally, we validate our method on a real robot system for the height estimation task, where our method is able to successfully learn and execute an information-gathering policy from scratch."], "authors": "Jean-François Tremblay"},
{"Title": "Relevance-guided Neural Machine Translation", "abs": ["With the advent of the Transformer architecture, Neural Machine Translation (NMT) results have shown great improvement lately. However, results in low-resource conditions still lag behind in both bilingual and multilingual setups, due to the limited amount of available monolingual and/or parallel data; hence, the need for methods addressing data scarcity in an efficient, and explainable way, is eminent. We propose an explainability-based training approach for NMT, applied in Unsupervised and Supervised model training, for translation of three languages of varying resources, French, Gujarati, Kazakh, to and from English. Our results show our method can be promising, particularly when training in low-resource conditions, outperforming simple training baselines; though the improvement is marginal, it sets the ground for further exploration of the approach and the parameters, and its extension to other languages."], "authors": "Isidora Chara Tourni"},
{"Title": "DREAM: Diffusion Rectification and Estimation-Adaptive Models", "abs": ["We present DREAM, a novel training framework representing Diffusion Rectification and Estimation-Adaptive Models, requiring minimal code changes (just three lines) yet significantly enhancing the alignment of training with sampling in diffusion models. DREAM features two components: diffusion rectification, which adjusts training to reflect the sampling process, and estimation adaptation, which balances perception against distortion. When applied to image super-resolution (SR), DREAM adeptly navigates the tradeoff between minimizing distortion and preserving high image quality. Experiments demonstrate DREAM's superiority over standard diffusion-based SR methods, showing a $2$ to $3\\times $ faster training convergence and a $10$ to $20\\times$ reduction in necessary sampling steps to achieve comparable or superior results. We hope DREAM will inspire a rethinking of diffusion model training paradigms."], "authors": "Jinxin Zhou"},
{"Title": "EpiTESTER: Testing Autonomous Vehicles with Epigenetic Algorithm and Attention Mechanism", "abs": ["Testing autonomous vehicles (AVs) under various environmental scenarios that lead the vehicles to unsafe situations is known to be challenging. Given the infinite possible environmental scenarios, it is essential to find critical scenarios efficiently. To this end, we propose a novel testing method, named EpiTESTER, by taking inspiration from epigenetics, which enables species to adapt to sudden environmental changes. In particular, EpiTESTER adopts gene silencing as its epigenetic mechanism, which regulates gene expression to prevent the expression of a certain gene, and the probability of gene expression is dynamically computed as the environment changes. Given different data modalities (e.g., images, lidar point clouds) in the context of AV, EpiTESTER benefits from a multi-model fusion transformer to extract high-level feature representations from environmental factors and then calculates probabilities based on these features with the attention mechanism. To assess the cost-effectiveness of EpiTESTER, we compare it with a classical genetic algorithm (GA) (i.e., without any epigenetic mechanism implemented) and EpiTESTER with equal probability for each gene. We evaluate EpiTESTER with four initial environments from CARLA, an open-source simulator for autonomous driving research, and an end-to-end AV controller, Interfuser. Our results show that EpiTESTER achieved a promising performance in identifying critical scenarios compared to the baselines, showing that applying epigenetic mechanisms is a good option for solving practical problems."], "authors": "Chengjie Lu"},
{"Title": "SparseGS: Real-Time 360° Sparse View Synthesis using Gaussian Splatting", "abs": ["The problem of novel view synthesis has grown significantly in popularity recently with the introduction of Neural Radiance Fields (NeRFs) and other implicit scene representation methods. A recent advance, 3D Gaussian Splatting (3DGS), leverages an explicit representation to achieve real-time rendering with high-quality results. However, 3DGS still requires an abundance of training views to generate a coherent scene representation. In few shot settings, similar to NeRF, 3DGS tends to overfit to training views, causing background collapse and excessive floaters, especially as the number of training views are reduced. We propose a method to enable training coherent 3DGS-based radiance fields of 360 scenes from sparse training views. We find that using naive depth priors is not sufficient and integrate depth priors with generative and explicit constraints to reduce background collapse, remove floaters, and enhance consistency from unseen viewpoints. Experiments show that our method outperforms base 3DGS by up to 30.5% and NeRF-based methods by up to 15.6% in LPIPS on the MipNeRF-360 dataset with substantially less training and inference cost."], "authors": "Haolin Xiong"},
{"Title": "DNS SLAM: Dense Neural Semantic-Informed SLAM", "abs": ["In recent years, coordinate-based neural implicit representations have shown promising results for the task of Simultaneous Localization and Mapping (SLAM). While achieving impressive performance on small synthetic scenes, these methods often suffer from oversmoothed reconstructions, especially for complex real-world scenes. In this work, we introduce DNS SLAM, a novel neural RGB-D semantic SLAM approach featuring a hybrid representation. Relying only on 2D semantic priors, we propose the first semantic neural SLAM method that trains class-wise scene representations while providing stable camera tracking at the same time. Our method integrates multi-view geometry constraints with image-based feature extraction to improve appearance details and to output color, density, and semantic class information, enabling many downstream applications. To further enable real-time tracking, we introduce a lightweight coarse scene representation which is trained in a self-supervised manner in latent space. Our experimental results achieve state-of-the-art performance on both synthetic data and real-world data tracking while maintaining a commendable operational speed on off-the-shelf hardware. Further, our method outputs class-wise decomposed reconstructions with better texture capturing appearance and geometric details."], "authors": "Kunyi Li"},
{"Title": "An integrated framework for developing and evaluating an automated lecture style assessment system", "abs": ["The aim of the work presented in this paper is to develop and evaluate an integrated system that provides automated lecture style evaluation, allowing teachers to get instant feedback related to the goodness of their lecturing style. The proposed system aims to promote improvement of lecture quality, that could upgrade the overall student learning experience. The proposed application utilizes specific measurable biometric characteristics, such as facial expressions, body activity, speech rate and intonation, hand movement, and facial pose, extracted from a video showing the lecturer from the audience point of view. Measurable biometric features extracted during a lecture are combined to provide teachers with a score reflecting lecture style quality both at frame rate and by providing lecture quality metrics for the whole lecture. The acceptance of the proposed lecture style evaluation system was evaluated by chief education officers, teachers and students regarding the functionality, usefulness of the application, and possible improvements. The results indicate that participants found the application novel and useful in providing automated feedback regarding lecture quality. Furthermore, the performance evaluation of the proposed system was compared with the performance of humans in the task of lecture style evaluation. Results indicate that the proposed system not only achieves similar performance to human observers, but in some cases, it outperforms them."], "authors": "Eleni Dimitriadou"},
{"Title": "Optimal Attack and Defense for Reinforcement Learning", "abs": ["To ensure the usefulness of Reinforcement Learning (RL) in real systems, it is crucial to ensure they are robust to noise and adversarial attacks. In adversarial RL, an external attacker has the power to manipulate the victim agent's interaction with the environment. We study the full class of online manipulation attacks, which include (i) state attacks, (ii) observation attacks (which are a generalization of perceived-state attacks), (iii) action attacks, and (iv) reward attacks. We show the attacker's problem of designing a stealthy attack that maximizes its own expected reward, which often corresponds to minimizing the victim's value, is captured by a Markov Decision Process (MDP) that we call a meta-MDP since it is not the true environment but a higher level environment induced by the attacked interaction. We show that the attacker can derive optimal attacks by planning in polynomial time or learning with polynomial sample complexity using standard RL techniques. We argue that the optimal defense policy for the victim can be computed as the solution to a stochastic Stackelberg game, which can be further simplified into a partially-observable turn-based stochastic game (POTBSG). Neither the attacker nor the victim would benefit from deviating from their respective optimal policies, thus such solutions are truly robust. Although the defense problem is NP-hard, we show that optimal Markovian defenses can be computed (learned) in polynomial time (sample complexity) in many scenarios."], "authors": "Jeremy McMahan"},
{"Title": "Raising the Bar of AI-generated Image Detection with CLIP", "abs": ["Aim of this work is to explore the potential of pre-trained vision-language models (VLMs) for universal detection of AI-generated images. We develop a lightweight detection strategy based on CLIP features and study its performance in a wide variety of challenging scenarios. We find that, unlike previous belief, it is neither necessary nor convenient to use a large domain-specific dataset for training. On the contrary, by using only a handful of example images from a single generative model, a CLIP-based detector exhibits a surprising generalization ability and high robustness across several different architectures, including recent commercial tools such as Dalle-3, Midjourney v5, and Firefly. We match the SoTA on in-distribution data, and improve largely above it in terms of generalization to out-of-distribution data (+6% in terms of AUC) and robustness to impaired/laundered data (+13%). Our project is available at"], "authors": "Davide Cozzolino"},
{"Title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization", "abs": ["Distributed representations provide a vector space that captures meaningful relationships between data instances. The distributed nature of these representations, however, entangles together multiple attributes or concepts of data instances (e.g., the topic or sentiment of a text, characteristics of the author (age, gender, etc), etc). Recent work has proposed the task of concept erasure, in which rather than making a concept predictable, the goal is to remove an attribute from distributed representations while retaining other information from the original representation space as much as possible. In this paper, we propose a new distance metric learning-based objective, the Kernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure. KRaM fits a transformation of representations to match a specified distance measure (defined by a labeled concept to erase) using a modified rate-distortion function. Specifically, KRaM's objective function aims to make instances with similar concept labels dissimilar in the learned representation space while retaining other information. We find that optimizing KRaM effectively erases various types of concepts: categorical, continuous, and vector-valued variables from data representations across diverse domains. We also provide a theoretical analysis of several properties of KRaM's objective. To assess the quality of the learned representations, we propose an alignment score to evaluate their similarity with the original representation space. Additionally, we conduct experiments to showcase KRaM's efficacy in various settings, from erasing binary gender variables in word embeddings to vector-valued variables in GPT-3 representations."], "authors": "Somnath Basu Roy Chowdhury"},
{"Title": "Benchmarking and Enhancing Disentanglement in Concept-Residual Models", "abs": ["Concept bottleneck models (CBMs) are interpretable models that first predict a set of semantically meaningful features, i.e., concepts, from observations that are subsequently used to condition a downstream task. However, the model's performance strongly depends on the engineered features and can severely suffer from incomplete sets of concepts. Prior works have proposed a side channel -- a residual -- that allows for unconstrained information flow to the downstream task, thus improving model performance but simultaneously introducing information leakage, which is undesirable for interpretability. This work proposes three novel approaches to mitigate information leakage by disentangling concepts and residuals, investigating the critical balance between model performance and interpretability. Through extensive empirical analysis on the CUB, OAI, and CIFAR 100 datasets, we assess the performance of each disentanglement method and provide insights into when they work best. Further, we show how each method impacts the ability to intervene over the concepts and their subsequent impact on task performance."], "authors": "Renos Zabounidis"},
{"Title": "HeTriNet: Heterogeneous Graph Triplet Attention Network for Drug-Target-Disease Interaction", "abs": ["Modeling the interactions between drugs, targets, and diseases is paramount in drug discovery and has significant implications for precision medicine and personalized treatments. Current approaches frequently consider drug-target or drug-disease interactions individually, ignoring the interdependencies among all three entities. Within human metabolic systems, drugs interact with protein targets in cells, influencing target activities and subsequently impacting biological pathways to promote healthy functions and treat diseases. Moving beyond binary relationships and exploring tighter triple relationships is essential to understanding drugs' mechanism of action (MoAs). Moreover, identifying the heterogeneity of drugs, targets, and diseases, along with their distinct characteristics, is critical to model these complex interactions appropriately. To address these challenges, we effectively model the interconnectedness of all entities in a heterogeneous graph and develop a novel Heterogeneous Graph Triplet Attention Network (\\texttt{HeTriNet}). \\texttt{HeTriNet} introduces a novel triplet attention mechanism within this heterogeneous graph structure. Beyond pairwise attention as the importance of an entity for the other one, we define triplet attention to model the importance of pairs for entities in the drug-target-disease triplet prediction problem. Experimental results on real-world datasets show that \\texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable proficiency in uncovering novel drug-target-disease relationships."], "authors": "Farhan Tanvir"},
{"Title": "REACT: Recognize Every Action Everywhere All At Once", "abs": ["Group Activity Recognition (GAR) is a fundamental problem in computer vision, with diverse applications in sports video analysis, video surveillance, and social scene understanding. Unlike conventional action recognition, GAR aims to classify the actions of a group of individuals as a whole, requiring a deep understanding of their interactions and spatiotemporal relationships. To address the challenges in GAR, we present REACT (\\textbf{R}ecognize \\textbf{E}very \\textbf{Act}ion Everywhere All At Once), a novel architecture inspired by the transformer encoder-decoder model explicitly designed to model complex contextual relationships within videos, including multi-modality and spatio-temporal features. Our architecture features a cutting-edge Vision-Language Encoder block for integrated temporal, spatial, and multi-modal interaction modeling. This component efficiently encodes spatiotemporal interactions, even with sparsely sampled frames, and recovers essential local information. Our Action Decoder Block refines the joint understanding of text and video data, allowing us to precisely retrieve bounding boxes, enhancing the link between semantics and visual reality. At the core, our Actor Fusion Block orchestrates a fusion of actor-specific data and textual features, striking a balance between specificity and context. Our method outperforms state-of-the-art GAR approaches in extensive experiments, demonstrating superior accuracy in recognizing and understanding group activities. Our architecture's potential extends to diverse real-world applications, offering empirical evidence of its performance gains. This work significantly advances the field of group activity recognition, providing a robust framework for nuanced scene comprehension."], "authors": "Naga VS Raviteja Chappa"},
{"Title": "Galaxy Classification: A machine learning approach for classifying shapes using numerical data", "abs": ["The classification of galaxies as spirals or ellipticals is a crucial task in understanding their formation and evolution. With the arrival of large-scale astronomical surveys, such as the Sloan Digital Sky Survey (SDSS), astronomers now have access to images of a vast number of galaxies. However, the visual inspection of these images is an impossible task for humans due to the sheer number of galaxies to be analyzed. To solve this problem, the Galaxy Zoo project was created to engage thousands of citizen scientists to classify the galaxies based on their visual features. In this paper, we present a machine learning model for galaxy classification using numerical data from the Galaxy Zoo[5] project. Our model utilizes a convolutional neural network architecture to extract features from galaxy images and classify them into spirals or ellipticals. We demonstrate the effectiveness of our model by comparing its performance with that of human classifiers using a subset of the Galaxy Zoo dataset. Our results show that our model achieves high accuracy in classifying galaxies and has the potential to significantly enhance our understanding of the formation and evolution of galaxies."], "authors": "Anusha Guruprasad"},
{"Title": "RNA-KG: An ontology-based knowledge graph for representing interactions involving RNA molecules", "abs": ["The \"RNA world\" represents a novel frontier for the study of fundamental biological processes and human diseases and is paving the way for the development of new drugs tailored to the patient's biomolecular characteristics. Although scientific data about coding and non-coding RNA molecules are continuously produced and available from public repositories, they are scattered across different databases and a centralized, uniform, and semantically consistent representation of the \"RNA world\" is still lacking. We propose RNA-KG, a knowledge graph encompassing biological knowledge about RNAs gathered from more than 50 public databases, integrating functional relationships with genes, proteins, and chemicals and ontologically grounded biomedical concepts. To develop RNA-KG, we first identified, pre-processed, and characterized each data source; next, we built a meta-graph that provides an ontological description of the KG by representing all the bio-molecular entities and medical concepts of interest in this domain, as well as the types of interactions connecting them. Finally, we leveraged an instance-based semantically abstracted knowledge model to specify the ontological alignment according to which RNA-KG was generated. RNA-KG can be downloaded in different formats and also queried by a SPARQL endpoint. A thorough topological analysis of the resulting heterogeneous graph provides further insights into the characteristics of the \"RNA world\". RNA-KG can be both directly explored and visualized, and/or analyzed by applying computational methods to infer bio-medical knowledge from its heterogeneous nodes and edges. The resource can be easily updated with new experimental data, and specific views of the overall KG can be extracted according to the bio-medical problem to be studied."], "authors": "Emanuele Cavalleri"},
{"Title": "Ellora: Exploring Low-Power OFDM-based Radar Processors using Approximate Computing", "abs": ["In recent times, orthogonal frequency-division multiplexing (OFDM)-based radar has gained wide acceptance given its applicability in joint radar-communication systems. However, realizing such a system on hardware poses a huge area and power bottleneck given its complexity. Therefore it has become ever-important to explore low-power OFDM-based radar processors in order to realize energy-efficient joint radar-communication systems targeting edge devices. This paper aims to address the aforementioned challenges by exploiting approximations on hardware for early design space exploration (DSE) of trade-offs between accuracy, area and power. We present Ellora, a DSE framework for incorporating approximations in an OFDM radar processing pipeline. Ellora uses pairs of approximate adders and multipliers to explore design points realizing energy-efficient radar processors. Particularly, we incorporate approximations into the block involving periodogram based estimation and report area, power and accuracy levels. Experimental results show that at an average accuracy loss of 0.063% in the positive SNR region, we save 22.9% of on-chip area and 26.2% of power. Towards achieving the area and power statistics, we design a fully parallel Inverse Fast Fourier Transform (IFFT) core which acts as a part of periodogram based estimation and approximate the addition and multiplication operations in it. The aforementioned results show that Ellora can be used in an integrated way with various other optimization methods for generating low-power and energy-efficient radar processors."], "authors": "Rajat Bhattacharjya"},
{"Title": "Advances in soft grasping in agriculture", "abs": ["Agricultural robotics and automation are facing some challenges rooted in the high variability 9 of products, task complexity, crop quality requirement, and dense vegetation. Such a set of 10 challenges demands a more versatile and safe robotic system. Soft robotics is a young yet 11 promising field of research aimed to enhance these aspects of current rigid robots which 12 makes it a good candidate solution for that challenge. In general, it aimed to provide robots 13 and machines with adaptive locomotion (Ansari et al., 2015), safe and adaptive manipulation 14 (Arleo et al., 2020) and versatile grasping (Langowski et al., 2020). But in agriculture, soft 15 robots have been mainly used in harvesting tasks and more specifically in grasping. In this 16 chapter, we review a candidate group of soft grippers that were used for handling and 17 harvesting crops regarding agricultural challenges i.e. safety in handling and adaptability to 18 the high variation of crops. The review is aimed to show why and to what extent soft grippers 19 have been successful in handling agricultural tasks. The analysis carried out on the results 20 provides future directions for the systematic design of soft robots in agricultural tasks."], "authors": "Ali Leylavi Shoushtari"},
{"Title": "Fool the Hydra: Adversarial Attacks against Multi-view Object Detection Systems", "abs": ["Adversarial patches exemplify the tangible manifestation of the threat posed by adversarial attacks on Machine Learning (ML) models in real-world scenarios. Robustness against these attacks is of the utmost importance when designing computer vision applications, especially for safety-critical domains such as CCTV systems. In most practical situations, monitoring open spaces requires multi-view systems to overcome acquisition challenges such as occlusion handling. Multiview object systems are able to combine data from multiple views, and reach reliable detection results even in difficult environments. Despite its importance in real-world vision applications, the vulnerability of multiview systems to adversarial patches is not sufficiently investigated. In this paper, we raise the following question: Does the increased performance and information sharing across views offer as a by-product robustness to adversarial patches? We first conduct a preliminary analysis showing promising robustness against off-the-shelf adversarial patches, even in an extreme setting where we consider patches applied to all views by all persons in Wildtrack benchmark. However, we challenged this observation by proposing two new attacks: (i) In the first attack, targeting a multiview CNN, we maximize the global loss by proposing gradient projection to the different views and aggregating the obtained local gradients. (ii) In the second attack, we focus on a Transformer-based multiview framework. In addition to the focal loss, we also maximize the transformer-specific loss by dissipating its attention blocks. Our results show a large degradation in the detection performance of victim multiview systems with our first patch attack reaching an attack success rate of 73% , while our second proposed attack reduced the performance of its target detector by 62%"], "authors": "Bilel Tarchoun"},
{"Title": "Extending Rely-Guarantee thinking to handle Real-Time Scheduling", "abs": ["The reference point for developing any artefact is its specification; to develop software formally, a formal specification is required. For sequential programs, pre and post conditions (together with abstract objects) suffice; rely and guarantee conditions extend the scope of formal development approaches to tackle concurrency. In addition, real-time systems need ways of both requiring progress and relating that progress to some notion of time. This paper extends rely-guarantee ideas to cope with specifications of -- and assumptions about -- real-time schedulers. Furthermore it shows how the approach helps identify and specify fault-tolerance aspects of such schedulers by systematically challenging the assumptions."], "authors": "Cliff B. Jones"},
{"Title": "Non-uniform Online Learning: Towards Understanding Induction", "abs": ["Can a physicist make only finite errors in the endless pursuit of the law of nature? This millennium-old question of inductive inference is a fundamental, yet mysterious problem in philosophy, lacking rigorous justifications. While classic online learning theory and inductive inference share a similar sequential decision-making spirit, the former's reliance on an adaptive adversary and worst-case error bounds limits its applicability to the latter. In this work, we introduce the concept of non-uniform online learning, which we argue aligns more closely with the principles of inductive reasoning. This setting assumes a predetermined ground-truth hypothesis and considers non-uniform, hypothesis-wise error bounds. In the realizable setting, we provide a complete characterization of learnability with finite error: a hypothesis class is non-uniform learnable if and only if it's a countable union of Littlestone classes, no matter the observations are adaptively chosen or iid sampled. Additionally, we propose a necessary condition for the weaker criterion of consistency which we conjecture to be tight. To further promote our theory, we extend our result to the more realistic agnostic setting, showing that any countable union of Littlestone classes can be learnt with regret $\\tilde{O}(\\sqrt{T})$. We hope this work could offer a new perspective of interpreting the power of induction from an online learning viewpoint."], "authors": "Zhou Lu"},
{"Title": "Navigating News Narratives: A Media Bias Analysis Dataset", "abs": ["The proliferation of biased news narratives across various media platforms has become a prominent challenge, influencing public opinion on critical topics like politics, health, and climate change. This paper introduces the \"Navigating News Narratives: A Media Bias Analysis Dataset\", a comprehensive dataset to address the urgent need for tools to detect and analyze media bias. This dataset encompasses a broad spectrum of biases, making it a unique and valuable asset in the field of media studies and artificial intelligence. The dataset is available at"], "authors": "Shaina Raza"},
{"Title": "Towards Accurate Differential Diagnosis with Large Language Models", "abs": ["An accurate differential diagnosis (DDx) is a cornerstone of medical care, often reached through an iterative process of interpretation that combines clinical history, physical examination, investigations and procedures. Interactive interfaces powered by Large Language Models (LLMs) present new opportunities to both assist and automate aspects of this process. In this study, we introduce an LLM optimized for diagnostic reasoning, and evaluate its ability to generate a DDx alone or as an aid to clinicians. 20 clinicians evaluated 302 challenging, real-world medical cases sourced from the New England Journal of Medicine (NEJM) case reports. Each case report was read by two clinicians, who were randomized to one of two assistive conditions: either assistance from search engines and standard medical resources, or LLM assistance in addition to these tools. All clinicians provided a baseline, unassisted DDx prior to using the respective assistive tools. Our LLM for DDx exhibited standalone performance that exceeded that of unassisted clinicians (top-10 accuracy 59.1% vs 33.6%, [p = 0.04]). Comparing the two assisted study arms, the DDx quality score was higher for clinicians assisted by our LLM (top-10 accuracy 51.7%) compared to clinicians without its assistance (36.1%) (McNemar's Test: 45.7, p < 0.01) and clinicians with search (44.4%) (4.75, p = 0.03). Further, clinicians assisted by our LLM arrived at more comprehensive differential lists than those without its assistance. Our study suggests that our LLM for DDx has potential to improve clinicians' diagnostic reasoning and accuracy in challenging cases, meriting further real-world evaluation for its ability to empower physicians and widen patients' access to specialist-level expertise."], "authors": "Daniel McDuff"},
{"Title": "Just add $\\textit{WATER}$: WebAssembly-based Circumvention Transports", "abs": ["As Internet censors rapidly evolve new blocking techniques, circumvention tools must also adapt and roll out new strategies to remain unblocked. But new strategies can be time consuming for circumventors to develop and deploy, and usually an update to one tool often requires significant additional effort to be ported to others. Moreover, distributing the updated application across different platforms poses its own set of challenges.", "In this paper, we introduce $\\textit{WATER}$ (WebAssembly Transport Executables Runtime), a novel design that enables applications to use a WebAssembly-based application-layer to wrap network transports (e.g., TLS). Deploying a new circumvention technique with $\\textit{WATER}$ only requires distributing the WebAssembly Transport Module(WATM) binary and any transport-specific configuration, allowing dynamic transport updates without any change to the application itself. WATMs are also designed to be generic such that different applications using $\\textit{WATER}$ can use the same WATM to rapidly deploy successful circumvention techniques to their own users, facilitating rapid interoperability between independent circumvention tools."], "authors": "Erik Chi"},
{"Title": "Universal Backdoor Attacks", "abs": ["Web-scraped datasets are vulnerable to data poisoning, which can be used for backdooring deep image classifiers during training. Since training on large datasets is expensive, a model is trained once and re-used many times. Unlike adversarial examples, backdoor attacks often target specific classes rather than any class learned by the model. One might expect that targeting many classes through a naive composition of attacks vastly increases the number of poison samples. We show this is not necessarily true and more efficient, universal data poisoning attacks exist that allow controlling misclassifications from any source class into any target class with a small increase in poison samples. Our idea is to generate triggers with salient characteristics that the model can learn. The triggers we craft exploit a phenomenon we call inter-class poison transferability, where learning a trigger from one class makes the model more vulnerable to learning triggers for other classes. We demonstrate the effectiveness and robustness of our universal backdoor attacks by controlling models with up to 6,000 classes while poisoning only 0.15% of the training dataset."], "authors": "Benjamin Schneider"},
{"Title": "A Threshold Greedy Algorithm for Noisy Submodular Maximization", "abs": ["We consider the optimization problem of cardinality constrained maximization of a monotone submodular set function $f:2^U\\to\\mathbb{R}_{\\geq 0}$ (SM) with noisy evaluations of $f$. In particular, it is assumed that we do not have value oracle access to $f$, but instead for any $X\\subseteq U$ and $u\\in U$ we can take samples from a noisy distribution with expected value $f(X\\cup\\{u\\})-f(X)$. Our goal is to develop algorithms in this setting that take as few samples as possible, and return a solution with an approximation guarantee relative to the optimal with high probability. We propose the algorithm Confident Threshold Greedy (CTG), which is based on the threshold greedy algorithm of Badanidiyuru and Vondrak [1] and samples adaptively in order to produce an approximate solution with high probability. We prove that CTG achieves an approximation ratio arbitrarily close to $1-1/e$, depending on input parameters. We provide an experimental evaluation on real instances of SM and demonstrate the sample efficiency of CTG."], "authors": "Wenjing Chen"},
{"Title": "Which way is `right'?: Uncovering limitations of Vision-and-Language Navigation model", "abs": ["The challenging task of Vision-and-Language Navigation (VLN) requires embodied agents to follow natural language instructions to reach a goal location or object (e.g. `walk down the hallway and turn left at the piano'). For agents to complete this task successfully, they must be able to ground objects referenced into the instruction (e.g.`piano') into the visual scene as well as ground directional phrases (e.g.`turn left') into actions. In this work we ask the following question -- to what degree are spatial and directional language cues informing the navigation model's decisions? We propose a series of simple masking experiments to inspect the model's reliance on different parts of the instruction. Surprisingly we uncover that certain top performing models rely only on the noun tokens of the instructions. We propose two training methods to alleviate this concerning limitation."], "authors": "Meera Hahn"},
{"Title": "Pedaling, Fast and Slow: The Race Towards an Optimized Power Strategy", "abs": ["With the advent of power-meters allowing cyclists to precisely track their power outputs throughout the duration of a race, devising optimal power output strategies for races has become increasingly important in competitive cycling. To do so, the track, weather, and individual cyclist's abilities must all be considered. We propose differential equation models of fatigue and kinematics to simulate the performance of such strategies, and an innovative optimization algorithm to find the optimal strategy.", "Our model for fatigue translates a cyclist's power curve (obtained by fitting the Omni-Power Duration Model to power curve data) into a differential equation to capture which power output strategies are feasible. Our kinematics model calculates the forces on the rider, and with power output models the cyclist's velocity and position via a system of differential equations. Using track data, including the slope of the track and velocity of the wind, the model accurately computes race times given a power output strategy on the exact track being raced.", "To make power strategy optimization computationally tractable, we split the track into segments based on changes in slope and discretize the power output levels. As the space of possible strategies is large, we vectorize the differential equation model for efficient numerical integration of many simulations at once and develop a parallelized Tree Exploration with Monte-Carlo Evaluation algorithm. The algorithm is efficient, running in $O(ab\\sqrt{n})$ time and $O(n)$ space where $n$ is the number of simulations done for each choice, $a$ is the number of segments, and $b$ is the number of discrete power output levels.", "We present results of this optimization for several different tracks and athletes. As an example, the model's time for Filippo Ganna in Tokyo 2020 differs from his real time by just 18%, supporting our model's efficacy."], "authors": "Steven DiSilvio"},
{"Title": "S2ST: Image-to-Image Translation in the Seed Space of Latent Diffusion", "abs": ["Image-to-image translation (I2IT) refers to the process of transforming images from a source domain to a target domain while maintaining a fundamental connection in terms of image content. In the past few years, remarkable advancements in I2IT were achieved by Generative Adversarial Networks (GANs), which nevertheless struggle with translations requiring high precision. Recently, Diffusion Models have established themselves as the engine of choice for image generation. In this paper we introduce S2ST, a novel framework designed to accomplish global I2IT in complex photorealistic images, such as day-to-night or clear-to-rain translations of automotive scenes. S2ST operates within the seed space of a Latent Diffusion Model, thereby leveraging the powerful image priors learned by the latter. We show that S2ST surpasses state-of-the-art GAN-based I2IT methods, as well as diffusion-based approaches, for complex automotive scenes, improving fidelity while respecting the target domain's appearance across a variety of domains. Notably, S2ST obviates the necessity for training domain-specific translation networks."], "authors": "Or Greenberg"},
{"Title": "A Video is Worth 10,000 Words: Training and Benchmarking with Diverse Captions for Better Long Video Retrieval", "abs": ["Existing long video retrieval systems are trained and tested in the paragraph-to-video retrieval regime, where every long video is described by a single long paragraph. This neglects the richness and variety of possible valid descriptions of a video, which could be described in moment-by-moment detail, or in a single phrase summary, or anything in between. To provide a more thorough evaluation of the capabilities of long video retrieval systems, we propose a pipeline that leverages state-of-the-art large language models to carefully generate a diverse set of synthetic captions for long videos. We validate this pipeline's fidelity via rigorous human inspection. We then benchmark a representative set of video language models on these synthetic captions using a few long video datasets, showing that they struggle with the transformed data, especially the shortest captions. We also propose a lightweight fine-tuning method, where we use a contrastive loss to learn a hierarchical embedding loss based on the differing levels of information among the various captions. Our method improves performance both on the downstream paragraph-to-video retrieval task (+1.1% R@1 on ActivityNet), as well as for the various long video retrieval metrics we compute using our synthetic data (+3.6% R@1 for short descriptions on ActivityNet). For data access and other details, please refer to our project website at", "."], "authors": "Matthew Gwilliam"},
{"Title": "Un-EvMoSeg: Unsupervised Event-based Independent Motion Segmentation", "abs": ["Event cameras are a novel type of biologically inspired vision sensor known for their high temporal resolution, high dynamic range, and low power consumption. Because of these properties, they are well-suited for processing fast motions that require rapid reactions. Although event cameras have recently shown competitive performance in unsupervised optical flow estimation, performance in detecting independently moving objects (IMOs) is lacking behind, although event-based methods would be suited for this task based on their low latency and HDR properties. Previous approaches to event-based IMO segmentation have been heavily dependent on labeled data. However, biological vision systems have developed the ability to avoid moving objects through daily tasks without being given explicit labels. In this work, we propose the first event framework that generates IMO pseudo-labels using geometric constraints. Due to its unsupervised nature, our method can handle an arbitrary number of not predetermined objects and is easily scalable to datasets where expensive IMO labels are not readily available. We evaluate our approach on the EVIMO dataset and show that it performs competitively with supervised methods, both quantitatively and qualitatively."], "authors": "Ziyun Wang"},
{"Title": "Event-based Continuous Color Video Decompression from Single Frames", "abs": ["We present ContinuityCam, a novel approach to generate a continuous video from a single static RGB image, using an event camera. Conventional cameras struggle with high-speed motion capture due to bandwidth and dynamic range limitations. Event cameras are ideal sensors to solve this problem because they encode compressed change information at high temporal resolution. In this work, we propose a novel task called event-based continuous color video decompression, pairing single static color frames and events to reconstruct temporally continuous videos. Our approach combines continuous long-range motion modeling with a feature-plane-based synthesis neural integration model, enabling frame prediction at arbitrary times within the events. Our method does not rely on additional frames except for the initial image, increasing, thus, the robustness to sudden light changes, minimizing the prediction latency, and decreasing the bandwidth requirement. We introduce a novel single objective beamsplitter setup that acquires aligned images and events and a novel and challenging Event Extreme Decompression Dataset (E2D2) that tests the method in various lighting and motion profiles. We thoroughly evaluate our method through benchmarking reconstruction as well as various downstream tasks. Our approach significantly outperforms the event- and image- based baselines in the proposed task."], "authors": "Ziyun Wang"},
{"Title": "DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis with 3D Gaussian Splatting", "abs": ["Accurately and efficiently modeling dynamic scenes and motions is considered so challenging a task due to temporal dynamics and motion complexity. To address these challenges, we propose DynMF, a compact and efficient representation that decomposes a dynamic scene into a few neural trajectories. We argue that the per-point motions of a dynamic scene can be decomposed into a small set of explicit or learned trajectories. Our carefully designed neural framework consisting of a tiny set of learned basis queried only in time allows for rendering speed similar to 3D Gaussian Splatting, surpassing 120 FPS, while at the same time, requiring only double the storage compared to static scenes. Our neural representation adequately constrains the inherently underconstrained motion field of a dynamic scene leading to effective and fast optimization. This is done by biding each point to motion coefficients that enforce the per-point sharing of basis trajectories. By carefully applying a sparsity loss to the motion coefficients, we are able to disentangle the motions that comprise the scene, independently control them, and generate novel motion combinations that have never been seen before. We can reach state-of-the-art render quality within just 5 minutes of training and in less than half an hour, we can synthesize novel views of dynamic scenes with superior photorealistic quality. Our representation is interpretable, efficient, and expressive enough to offer real-time view synthesis of complex dynamic scene motions, in monocular and multi-view scenarios."], "authors": "Agelos Kratimenos"},
{"Title": "Multimodal Learning for Crystalline Materials", "abs": ["Artificial intelligence (AI) has revolutionized the field of materials science by improving the prediction of properties and accelerating the discovery of novel materials. In recent years, publicly available material data repositories containing data for various material properties have grown rapidly. In this work, we introduce Multimodal Learning for Crystalline Materials (MLCM), a new method for training a foundation model for crystalline materials via multimodal alignment, where high-dimensional material properties (i.e. modalities) are connected in a shared latent space to produce highly useful material representations. We show the utility of MLCM on multiple axes: (i) MLCM achieves state-of-the-art performance for material property prediction on the challenging Materials Project database; (ii) MLCM enables a novel, highly accurate method for inverse design, allowing one to screen for stable material with desired properties; and (iii) MLCM allows the extraction of interpretable emergent features that may provide insight to material scientists. Further, we explore several novel methods for aligning an arbitrary number of modalities, improving upon prior art in multimodal learning that focuses on bimodal alignment. Our work brings innovations from the ongoing AI revolution into the domain of materials science and identifies materials as a testbed for the next generation of AI."], "authors": "Viggo Moro"},
{"Title": "CLIP-QDA: An Explainable Concept Bottleneck Model", "abs": ["In this paper, we introduce an explainable algorithm designed from a multi-modal foundation model, that performs fast and explainable image classification. Drawing inspiration from CLIP-based Concept Bottleneck Models (CBMs), our method creates a latent space where each neuron is linked to a specific word. Observing that this latent space can be modeled with simple distributions, we use a Mixture of Gaussians (MoG) formalism to enhance the interpretability of this latent space. Then, we introduce CLIP-QDA, a classifier that only uses statistical values to infer labels from the concepts. In addition, this formalism allows for both local and global explanations. These explanations come from the inner design of our architecture, our work is part of a new family of greybox models, combining performances of opaque foundation models and the interpretability of transparent models. Our empirical findings show that in instances where the MoG assumption holds, CLIP-QDA achieves similar accuracy with state-of-the-art methods CBMs. Our explanations compete with existing XAI methods while being faster to compute."], "authors": "Rémi Kazmierczak"},
{"Title": "Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering", "abs": ["Neural rendering methods have significantly advanced photo-realistic 3D scene rendering in various academic and industrial applications. The recent 3D Gaussian Splatting method has achieved the state-of-the-art rendering quality and speed combining the benefits of both primitive-based representations and volumetric representations. However, it often leads to heavily redundant Gaussians that try to fit every training view, neglecting the underlying scene geometry. Consequently, the resulting model becomes less robust to significant view changes, texture-less area and lighting effects. We introduce Scaffold-GS, which uses anchor points to distribute local 3D Gaussians, and predicts their attributes on-the-fly based on viewing direction and distance within the view frustum. Anchor growing and pruning strategies are developed based on the importance of neural Gaussians to reliably improve the scene coverage. We show that our method effectively reduces redundant Gaussians while delivering high-quality rendering. We also demonstrates an enhanced capability to accommodate scenes with varying levels-of-detail and view-dependent observations, without sacrificing the rendering speed."], "authors": "Tao Lu"},
{"Title": "Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training", "abs": ["Most real-world applications that employ deep neural networks (DNNs) quantize them to low precision to reduce the compute needs. We present a method to improve the robustness of quantized DNNs to white-box adversarial attacks. We first tackle the limitation of deterministic quantization to fixed ``bins'' by introducing a differentiable Stochastic Quantizer (SQ). We explore the hypothesis that different quantizations may collectively be more robust than each quantized DNN. We formulate a training objective to encourage different quantized DNNs to learn different representations of the input image. The training objective captures diversity and accuracy via mutual information between ensemble members. Through experimentation, we demonstrate substantial improvement in robustness against $L_\\infty$ attacks even if the attacker is allowed to backpropagate through SQ (e.g., > 50\\% accuracy to PGD(5/255) on CIFAR10 without adversarial training), compared to vanilla DNNs as well as existing ensembles of quantized DNNs. We extend the method to detect attacks and generate robustness profiles in the adversarial information plane (AIP), towards a unified analysis of different threat models by correlating the MI and accuracy."], "authors": "Saurabh Farkya"},
{"Title": "A Metadata Generation System with Semantic Understanding for Video Retrieval in Film Production", "abs": ["In film production, metadata plays an important role in original raw video indexing and classification within the industrial post-production software. Inspired by deep visual-semantic methods, we propose an automated image information extraction process to extend the diversity of metadata entities for massive large-scale raw video searching and retrieval. In this paper, we introduce the proposed system architecture and modules, integrating semantic annotation models and user-demand-oriented information fusion. We conducted experiments to validate the effectiveness of our system on Film Raw Video Semantic Annotation Dataset (Film-RVSAD) and Slate Board Template Dataset (SBTD), two benchmark datasets built for cinematography-related semantic annotation and slate detection. Experimental results show that the proposed system provides an effective strategy to improve the efficiency of metadata generation and transformation, which is necessary and convenient for collaborative work in the filmmaking process."], "authors": "Feilin Han"},
{"Title": "Unveiling Energy Efficiency in Deep Learning: Measurement, Prediction, and Scoring across Edge Devices", "abs": ["Today, deep learning optimization is primarily driven by research focused on achieving high inference accuracy and reducing latency. However, the energy efficiency aspect is often overlooked, possibly due to a lack of sustainability mindset in the field and the absence of a holistic energy dataset. In this paper, we conduct a threefold study, including energy measurement, prediction, and efficiency scoring, with an objective to foster transparency in power and energy consumption within deep learning across various edge devices. Firstly, we present a detailed, first-of-its-kind measurement study that uncovers the energy consumption characteristics of on-device deep learning. This study results in the creation of three extensive energy datasets for edge devices, covering a wide range of kernels, state-of-the-art DNN models, and popular AI applications. Secondly, we design and implement the first kernel-level energy predictors for edge devices based on our kernel-level energy dataset. Evaluation results demonstrate the ability of our predictors to provide consistent and accurate energy estimations on unseen DNN models. Lastly, we introduce two scoring metrics, PCS and IECS, developed to convert complex power and energy consumption data of an edge device into an easily understandable manner for edge device end-users. We hope our work can help shift the mindset of both end-users and the research community towards sustainability in edge computing, a principle that drives our research. Find data, code, and more up-to-date information at", "."], "authors": "Xiaolong Tu"},
{"Title": "DeepEn2023: Energy Datasets for Edge Artificial Intelligence", "abs": ["Climate change poses one of the most significant challenges to humanity. As a result of these climatic changes, the frequency of weather, climate, and water-related disasters has multiplied fivefold over the past 50 years, resulting in over 2 million deaths and losses exceeding $3.64 trillion USD. Leveraging AI-powered technologies for sustainable development and combating climate change is a promising avenue. Numerous significant publications are dedicated to using AI to improve renewable energy forecasting, enhance waste management, and monitor environmental changes in real time. However, very few research studies focus on making AI itself environmentally sustainable. This oversight regarding the sustainability of AI within the field might be attributed to a mindset gap and the absence of comprehensive energy datasets. In addition, with the ubiquity of edge AI systems and applications, especially on-device learning, there is a pressing need to measure, analyze, and optimize their environmental sustainability, such as energy efficiency. To this end, in this paper, we propose large-scale energy datasets for edge AI, named DeepEn2023, covering a wide range of kernels, state-of-the-art deep neural network models, and popular edge AI applications. We anticipate that DeepEn2023 will improve transparency in sustainability in on-device deep learning across a range of edge AI systems and applications. For more information, including access to the dataset and code, please visit", "."], "authors": "Xiaolong Tu"},
{"Title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation", "abs": ["Federated learning (FL) is an emerging paradigm for decentralized training of machine learning models on distributed clients, without revealing the data to the central server. The learning scheme may be horizontal, vertical or hybrid (both vertical and horizontal). Most existing research work with deep neural network (DNN) modelling is focused on horizontal data distributions, while vertical and hybrid schemes are much less studied. In this paper, we propose a generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based learning. The idea of our algorithm is characterised by higher inference accuracy, stronger privacy-preserving properties, and lower client-server communication bandwidth demands as compared with existing work. The experimental results show that FedEmb is an effective method to tackle both split feature & subject space decentralized problems, shows 0.3% to 4.2% inference accuracy improvement with limited privacy revealing for datasets stored in local clients, and reduces 88.9 % time complexity over vertical baseline method."], "authors": "Fanfei Meng"},
{"Title": "Towards Unsupervised Representation Learning: Learning, Evaluating and Transferring Visual Representations", "abs": ["Unsupervised representation learning aims at finding methods that learn representations from data without annotation-based signals. Abstaining from annotations not only leads to economic benefits but may - and to some extent already does - result in advantages regarding the representation's structure, robustness, and generalizability to different tasks. In the long run, unsupervised methods are expected to surpass their supervised counterparts due to the reduction of human intervention and the inherently more general setup that does not bias the optimization towards an objective originating from specific annotation-based signals. While major advantages of unsupervised representation learning have been recently observed in natural language processing, supervised methods still dominate in vision domains for most tasks. In this dissertation, we contribute to the field of unsupervised (visual) representation learning from three perspectives: (i) Learning representations: We design unsupervised, backpropagation-free Convolutional Self-Organizing Neural Networks (CSNNs) that utilize self-organization- and Hebbian-based learning rules to learn convolutional kernels and masks to achieve deeper backpropagation-free models. (ii) Evaluating representations: We build upon the widely used (non-)linear evaluation protocol to define pretext- and target-objective-independent metrics for measuring and investigating the objective function mismatch between various unsupervised pretext tasks and target tasks. (iii) Transferring representations: We contribute CARLANE, the first 3-way sim-to-real domain adaptation benchmark for 2D lane detection, and a method based on prototypical self-supervised learning. Finally, we contribute a content-consistent unpaired image-to-image translation method that utilizes masks, global and local discriminators, and similarity sampling to mitigate content inconsistencies."], "authors": "Bonifaz Stuhr"},
{"Title": "Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines", "abs": ["Rhetoric, both spoken and written, involves not only content but also style. One common stylistic tool is $\\textit{parallelism}$: the juxtaposition of phrases which have the same sequence of linguistic ($\\textit{e.g.}$, phonological, syntactic, semantic) features. Despite the ubiquity of parallelism, the field of natural language processing has seldom investigated it, missing a chance to better understand the nature of the structure, meaning, and intent that humans convey. To address this, we introduce the task of $\\textit{rhetorical parallelism detection}$. We construct a formal definition of it; we provide one new Latin dataset and one adapted Chinese dataset for it; we establish a family of metrics to evaluate performance on it; and, lastly, we create baseline systems and novel sequence labeling schemes to capture it. On our strictest metric, we attain $F_{1}$ scores of $0.40$ and $0.43$ on our Latin and Chinese datasets, respectively."], "authors": "Stephen Bothwell"},
{"Title": "Online Influence Maximization: Concept and Algorithm", "abs": ["In this survey, we offer an extensive overview of the Online Influence Maximization (IM) problem by covering both theoretical aspects and practical applications. For the integrity of the article and because the online algorithm takes an offline oracle as a subroutine, we first make a clear definition of the Offline IM problem and summarize those commonly used Offline IM algorithms, which include traditional approximation or heuristic algorithms and ML-based algorithms. Then, we give a standard definition of the Online IM problem and a basic Combinatorial Multi-Armed Bandit (CMAB) framework, CMAB-T. Here, we summarize three types of feedback in the CMAB model and discuss in detail how to study the Online IM problem based on the CMAB-T model. This paves the way for solving the Online IM problem by using online learning methods. Furthermore, we have covered almost all Online IM algorithms up to now, focusing on characteristics and theoretical guarantees of online algorithms for different feedback types. Here, we elaborately explain their working principle and how to obtain regret bounds. Besides, we also collect plenty of innovative ideas about problem definition and algorithm designs and pioneering works for variants of the Online IM problem and their corresponding algorithms. Finally, we encapsulate current challenges and outline prospective research directions from four distinct perspectives."], "authors": "Jianxiong Guo"},
{"Title": "Identifying tourist destinations from movie scenes using Deep Learning", "abs": ["Movies wield significant influence in our lives, playing a pivotal role in the tourism industry of any country. The inclusion of picturesque landscapes, waterfalls, and mountains as backdrops in films serves to enhance the allure of specific scenarios. Recognizing the impact of movies on tourism, this paper introduces a method for identifying tourist destinations featured in films. We propose the development of a deep learning model capable of recognizing these locations during movie viewing. The model is trained on a dataset comprising major tourism destinations worldwide. Through this research, the goal is to enable viewers to identify the real-world locations depicted in movie scenes, offering a novel way to connect cinema with global travel experiences."], "authors": "Mahendran Narayanan"},
{"Title": "SparseDC: Depth Completion from sparse and non-uniform inputs", "abs": ["We propose SparseDC, a model for Depth Completion of Sparse and non-uniform depth inputs. Unlike previous methods focusing on completing fixed distributions on benchmark datasets (e.g., NYU with 500 points, KITTI with 64 lines), SparseDC is specifically designed to handle depth maps with poor quality in real usage. The key contributions of SparseDC are two-fold. First, we design a simple strategy, called SFFM, to improve the robustness under sparse input by explicitly filling the unstable depth features with stable image features. Second, we propose a two-branch feature embedder to predict both the precise local geometry of regions with available depth values and accurate structures in regions with no depth. The key of the embedder is an uncertainty-based fusion module called UFFM to balance the local and long-term information extracted by CNNs and ViTs. Extensive indoor and outdoor experiments demonstrate the robustness of our framework when facing sparse and non-uniform input depths. The pre-trained model and code are available at", "."], "authors": "Chen Long"},
{"Title": "OST: Refining Text Knowledge with Optimal Spatio-Temporal Descriptor for General Video Recognition", "abs": ["Due to the resource-intensive nature of training vision-language models on expansive video data, a majority of studies have centered on adapting pre-trained image-language models to the video domain. Dominant pipelines propose to tackle the visual discrepancies with additional temporal learners while overlooking the substantial discrepancy for web-scaled descriptive narratives and concise action category names, leading to less distinct semantic space and potential performance limitations. In this work, we prioritize the refinement of text knowledge to facilitate generalizable video recognition. To address the limitations of the less distinct semantic space of category names, we prompt a large language model (LLM) to augment action class names into Spatio-Temporal Descriptors thus bridging the textual discrepancy and serving as a knowledge base for general recognition. Moreover, to assign the best descriptors with different video instances, we propose Optimal Descriptor Solver, forming the video recognition problem as solving the optimal matching flow across frame-level representations and descriptors. Comprehensive evaluations in zero-shot, few-shot, and fully supervised video recognition highlight the effectiveness of our approach. Our best model achieves a state-of-the-art zero-shot accuracy of 75.1% on Kinetics-600."], "authors": "Tongjia Chen"},
{"Title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps", "abs": ["Sampling from diffusion models can be treated as solving the corresponding ordinary differential equations (ODEs), with the aim of obtaining an accurate solution with as few number of function evaluations (NFE) as possible. Recently, various fast samplers utilizing higher-order ODE solvers have emerged and achieved better performance than the initial first-order one. However, these numerical methods inherently result in certain approximation errors, which significantly degrades sample quality with extremely small NFE (e.g., around 5). In contrast, based on the geometric observation that each sampling trajectory almost lies in a two-dimensional subspace embedded in the ambient space, we propose Approximate MEan-Direction Solver (AMED-Solver) that eliminates truncation errors by directly learning the mean direction for fast diffusion sampling. Besides, our method can be easily used as a plugin to further improve existing ODE-based samplers. Extensive experiments on image synthesis with the resolution ranging from 32 to 256 demonstrate the effectiveness of our method. With only 5 NFE, we achieve 7.14 FID on CIFAR-10, 13.75 FID on ImageNet 64$\\times$64, and 12.79 FID on LSUN Bedroom. Our code is available at", "."], "authors": "Zhenyu Zhou"},
{"Title": "Textual-Knowledge-Guided Numerical Feature Discovery Method for Power Demand Forecasting", "abs": ["Power demand forecasting is a crucial and challenging task for new power system and integrated energy system. However, as public feature databases and the theoretical mechanism of power demand changes are unavailable, the known features of power demand fluctuation are much limited. Recently, multimodal learning approaches have shown great vitality in machine learning and AIGC. In this paper, we interact two modal data and propose a textual-knowledge-guided numerical feature discovery (TKNFD) method for short-term power demand forecasting. TKNFD extensively accumulates qualitative textual knowledge, expands it into a candidate feature-type set, collects numerical data of these features, and eventually builds four-dimensional multivariate source-tracking databases (4DM-STDs). Next, TKNFD presents a two-level quantitative feature identification strategy independent of forecasting models, finds 43-48 features, and systematically analyses feature contribution and dependency correlation. Benchmark experiments in two different regions around the world demonstrate that the forecasting accuracy of TKNFD-discovered features reliably outperforms that of SoTA feature schemes by 16.84% to 36.36% MAPE. In particular, TKNFD reveals many unknown features, especially several dominant features in the unknown energy and astronomical dimensions, which extend the knowledge on the origin of strong randomness and non-linearity in power demand fluctuation. Besides, 4DM-STDs can serve as public baseline databases."], "authors": "Zifan Ning"},
{"Title": "GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs", "abs": ["As pretrained text-to-image diffusion models become increasingly powerful, recent efforts have been made to distill knowledge from these text-to-image pretrained models for optimizing a text-guided 3D model. Most of the existing methods generate a holistic 3D model from a plain text input. This can be problematic when the text describes a complex scene with multiple objects, because the vectorized text embeddings are inherently unable to capture a complex description with multiple entities and relationships. Holistic 3D modeling of the entire scene further prevents accurate grounding of text entities and concepts. To address this limitation, we propose GraphDreamer, a novel framework to generate compositional 3D scenes from scene graphs, where objects are represented as nodes and their interactions as edges. By exploiting node and edge information in scene graphs, our method makes better use of the pretrained text-to-image diffusion model and is able to fully disentangle different objects without image-level supervision. To facilitate modeling of object-wise relationships, we use signed distance fields as representation and impose a constraint to avoid inter-penetration of objects. To avoid manual scene graph creation, we design a text prompt for ChatGPT to generate scene graphs based on text inputs. We conduct both qualitative and quantitative experiments to validate the effectiveness of GraphDreamer in generating high-fidelity compositional 3D scenes with disentangled object entities."], "authors": "Gege Gao"},
{"Title": "Mixture of Gaussian-distributed Prototypes with Generative Modelling for Interpretable Image Classification", "abs": ["Prototypical-part interpretable methods, e.g., ProtoPNet, enhance interpretability by connecting classification predictions to class-specific training prototypes, thereby offering an intuitive insight into their decision-making. Current methods rely on a discriminative classifier trained with point-based learning techniques that provide specific values for prototypes. Such prototypes have relatively low representation power due to their sparsity and potential redundancy, with each prototype containing no variability measure. In this paper, we present a new generative learning of prototype distributions, named Mixture of Gaussian-distributed Prototypes (MGProto), which are represented by Gaussian mixture models (GMM). Such an approach enables the learning of more powerful prototype representations since each learned prototype will own a measure of variability, which naturally reduces the sparsity given the spread of the distribution around each prototype, and we also integrate a prototype diversity objective function into the GMM optimisation to reduce redundancy. Incidentally, the generative nature of MGProto offers a new and effective way for detecting out-of-distribution samples. To improve the compactness of MGProto, we further propose to prune Gaussian-distributed prototypes with a low prior. Experiments on CUB-200-2011, Stanford Cars, Stanford Dogs, and Oxford-IIIT Pets datasets show that MGProto achieves state-of-the-art classification and OoD detection performances with encouraging interpretability results."], "authors": "Chong Wang"},
{"Title": "Sound Terminology Describing Production and Perception of Sonification", "abs": ["Sonification research is intrinsically interdisciplinary. Consequently, a proper documentation of, and interdisciplinary discourse about a sonification is often hindered by terminology discrepancies between involved disciplines, i.e., the lack of a common sound terminology in sonification research. Without a common ground, a researcher from one discipline may have troubles understanding the implementation and imagining the resulting sound perception of a sonification, if the sonification is described by a researcher from another discipline. To find a common ground, I consulted literature on interdisciplinary research and discourse, identified problems that occur in sonification, and applied the recommended solutions. As a result, I recommend considering three aspects of sonification individually, namely 1.) Sound Design Concept, 2.) Objective and 3.) Method, clarifying which discipline is involved in which aspect, and sticking to this discipline's terminology. As two requirements of sonifications are that they are a) reproducible and b) interpretable, I recommend documenting and discussing every sonification design once using audio engineering terminology, and once using psychoacoustic terminology. The appendix provides comprehensive lists of sound terms from both disciplines, together with relevant literature and a clarification of often misunderstood and misused terms."], "authors": "Tim Ziemer"},
{"Title": "Tree-based Forecasting of Day-ahead Solar Power Generation from Granular Meteorological Features", "abs": ["Accurate forecasts for day-ahead photovoltaic (PV) power generation are crucial to support a high PV penetration rate in the local electricity grid and to assure stability in the grid. We use state-of-the-art tree-based machine learning methods to produce such forecasts and, unlike previous studies, we hereby account for (i) the effects various meteorological as well as astronomical features have on PV power production, and this (ii) at coarse as well as granular spatial locations. To this end, we use data from Belgium and forecast day-ahead PV power production at an hourly resolution. The insights from our study can assist utilities, decision-makers, and other stakeholders in optimizing grid operations, economic dispatch, and in facilitating the integration of distributed PV power into the electricity grid."], "authors": "Nick Berlanger"},
{"Title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing", "abs": ["In this paper, we address the problem of detecting anomalies among a given set of binary processes via learning-based controlled sensing. Each process is parameterized by a binary random variable indicating whether the process is anomalous. To identify the anomalies, the decision-making agent is allowed to observe a subset of the processes at each time instant. Also, probing each process has an associated cost. Our objective is to design a sequential selection policy that dynamically determines which processes to observe at each time with the goal to minimize the delay in making the decision and the total sensing cost. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes. This formulation utilizes both a Bayesian log-likelihood ratio-based reward and an entropy-based reward. The problem is then solved using two approaches: 1) a deep reinforcement learning-based approach where we design both deep Q-learning and policy gradient actor-critic algorithms; and 2) a deep active inference-based approach. Using numerical experiments, we demonstrate the efficacy of our algorithms and show that our algorithms adapt to any unknown statistical dependence pattern of the processes."], "authors": "Geethu Joseph"},
{"Title": "Generative Artificial Intelligence in Learning Analytics: Contextualising Opportunities and Challenges through the Learning Analytics Cycle", "abs": ["Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow's generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future."], "authors": "Lixiang Yan"},
{"Title": "X-Dreamer: Creating High-quality 3D Content by Bridging the Domain Gap Between Text-to-2D and Text-to-3D Generation", "abs": ["In recent times, automatic text-to-3D content creation has made significant progress, driven by the development of pretrained 2D diffusion models. Existing text-to-3D methods typically optimize the 3D representation to ensure that the rendered image aligns well with the given text, as evaluated by the pretrained 2D diffusion model. Nevertheless, a substantial domain gap exists between 2D images and 3D assets, primarily attributed to variations in camera-related attributes and the exclusive presence of foreground objects. Consequently, employing 2D diffusion models directly for optimizing 3D representations may lead to suboptimal outcomes. To address this issue, we present X-Dreamer, a novel approach for high-quality text-to-3D content creation that effectively bridges the gap between text-to-2D and text-to-3D synthesis. The key components of X-Dreamer are two innovative designs: Camera-Guided Low-Rank Adaptation (CG-LoRA) and Attention-Mask Alignment (AMA) Loss. CG-LoRA dynamically incorporates camera information into the pretrained diffusion models by employing camera-dependent generation for trainable parameters. This integration enhances the alignment between the generated 3D assets and the camera's perspective. AMA loss guides the attention map of the pretrained diffusion model using the binary mask of the 3D object, prioritizing the creation of the foreground object. This module ensures that the model focuses on generating accurate and detailed foreground objects. Extensive evaluations demonstrate the effectiveness of our proposed method compared to existing text-to-3D approaches. Our project webpage:", "."], "authors": "Yiwei Ma"},
{"Title": "Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?", "abs": ["Stable Diffusion has established itself as a foundation model in generative AI artistic applications, receiving widespread research and application. Some recent fine-tuning methods have made it feasible for individuals to implant personalized concepts onto the basic Stable Diffusion model with minimal computational costs on small datasets. However, these innovations have also given rise to issues like facial privacy forgery and artistic copyright infringement. In recent studies, researchers have explored the addition of imperceptible adversarial perturbations to images to prevent potential unauthorized exploitation and infringements when personal data is used for fine-tuning Stable Diffusion. Although these studies have demonstrated the ability to protect images, it is essential to consider that these methods may not be entirely applicable in real-world scenarios. In this paper, we systematically evaluate the use of perturbations to protect images within a practical threat model. The results suggest that these approaches may not be sufficient to safeguard image privacy and copyright effectively. Furthermore, we introduce a purification method capable of removing protected perturbations while preserving the original image structure to the greatest extent possible. Experiments reveal that Stable Diffusion can effectively learn from purified images over all protective methods."], "authors": "Zhengyue Zhao"},
{"Title": "BAM-DETR: Boundary-Aligned Moment Detection Transformer for Temporal Sentence Grounding in Videos", "abs": ["Temporal sentence grounding aims to localize moments relevant to a language description. Recently, DETR-like approaches have shown notable progress by decoding the center and length of a target moment from learnable queries. However, they suffer from the issue of center misalignment raised by the inherent ambiguity of moment centers, leading to inaccurate predictions. To remedy this problem, we introduce a novel boundary-oriented moment formulation. In our paradigm, the model no longer needs to find the precise center but instead suffices to predict any anchor point within the interval, from which the onset and offset are directly estimated. Based on this idea, we design a Boundary-Aligned Moment Detection Transformer (BAM-DETR), equipped with a dual-pathway decoding process. Specifically, it refines the anchor and boundaries within parallel pathways using global and boundary-focused attention, respectively. This separate design allows the model to focus on desirable regions, enabling precise refinement of moment predictions. Further, we propose a quality-based ranking method, ensuring that proposals with high localization qualities are prioritized over incomplete ones. Extensive experiments verify the advantages of our methods, where our model records new state-of-the-art results on three benchmarks. Code is at", "."], "authors": "Pilhyeon Lee"},
{"Title": "Synthesize, Diagnose, and Optimize: Towards Fine-Grained Vision-Language Understanding", "abs": ["Vision language models (VLM) have demonstrated remarkable performance across various downstream tasks. However, understanding fine-grained visual-linguistic concepts, such as attributes and inter-object relationships, remains a significant challenge. While several benchmarks aim to evaluate VLMs in finer granularity, their primary focus remains on the linguistic aspect, neglecting the visual dimension. Here, we highlight the importance of evaluating VLMs from both a textual and visual perspective. We introduce a progressive pipeline to synthesize images that vary in a specific attribute while ensuring consistency in all other aspects. Utilizing this data engine, we carefully design a benchmark, SPEC, to diagnose the comprehension of object size, position, existence, and count. Subsequently, we conduct a thorough evaluation of four leading VLMs on SPEC. Surprisingly, their performance is close to random guess, revealing significant limitations. With this in mind, we propose a simply yet effective approach to optimize VLMs in fine-grained understanding, achieving significant improvements on SPEC without compromising the zero-shot performance. Results on two additional fine-grained benchmarks also show consistent improvements, further validating the transferability of our approach."], "authors": "Wujian Peng"},
{"Title": "HiFi Tuner: High-Fidelity Subject-Driven Fine-Tuning for Diffusion Models", "abs": ["This paper explores advancements in high-fidelity personalized image generation through the utilization of pre-trained text-to-image diffusion models. While previous approaches have made significant strides in generating versatile scenes based on text descriptions and a few input images, challenges persist in maintaining the subject fidelity within the generated images. In this work, we introduce an innovative algorithm named HiFi Tuner to enhance the appearance preservation of objects during personalized image generation. Our proposed method employs a parameter-efficient fine-tuning framework, comprising a denoising process and a pivotal inversion process. Key enhancements include the utilization of mask guidance, a novel parameter regularization technique, and the incorporation of step-wise subject representations to elevate the sample fidelity. Additionally, we propose a reference-guided generation approach that leverages the pivotal inversion of a reference image to mitigate unwanted subject variations and artifacts. We further extend our method to a novel image editing task: substituting the subject in an image through textual manipulations. Experimental evaluations conducted on the DreamBooth dataset using the Stable Diffusion model showcase promising results. Fine-tuning solely on textual embeddings improves CLIP-T score by 3.6 points and improves DINO score by 9.6 points over Textual Inversion. When fine-tuning all parameters, HiFi Tuner improves CLIP-T score by 1.2 points and improves DINO score by 1.2 points over DreamBooth, establishing a new state of the art."], "authors": "Zhonghao Wang"},
{"Title": "Cross-domain Augmentation Networks for Click-Through Rate Prediction", "abs": ["Data sparsity is an important issue for click-through rate (CTR) prediction, particularly when user-item interactions is too sparse to learn a reliable model. Recently, many works on cross-domain CTR (CDCTR) prediction have been developed in an effort to leverage meaningful data from a related domain. However, most existing CDCTR works have an impractical limitation that requires homogeneous inputs (\\textit{i.e.} shared feature fields) across domains, and CDCTR with heterogeneous inputs (\\textit{i.e.} varying feature fields) across domains has not been widely explored but is an urgent and important research problem. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform knowledge transfer between two domains with \\textit{heterogeneous inputs}. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network is able to compute features from two domains with heterogeneous inputs separately by designing two independent branches, and then learn meaningful cross-domain knowledge using a designed cross-supervised feature translator. Later the augmentation network encodes the learned cross-domain knowledge via feature translation performed in the latent space and fine-tune the model for final CTR prediction. Through extensive experiments on two public benchmarks and one industrial production dataset, we show CDAnet can learn meaningful translated features and largely improve the performance of CTR prediction. CDAnet has been conducted online A/B test in image2product retrieval at Taobao app over 20days, bringing an absolute \\textbf{0.11 point} CTR improvement and a relative \\textbf{1.26\\%} GMV increase."], "authors": "Xu Chen"},
{"Title": "Enhancing Cross-domain Click-Through Rate Prediction via Explicit Feature Augmentation", "abs": ["Cross-domain CTR (CDCTR) prediction is an important research topic that studies how to leverage meaningful data from a related domain to help CTR prediction in target domain. Most existing CDCTR works design implicit ways to transfer knowledge across domains such as parameter-sharing that regularizes the model training in target domain. More effectively, recent researchers propose explicit techniques to extract user interest knowledge and transfer this knowledge to target domain. However, the proposed method mainly faces two issues: 1) it usually requires a super domain, i.e. an extremely large source domain, to cover most users or items of target domain, and 2) the extracted user interest knowledge is static no matter what the context is in target domain. These limitations motivate us to develop a more flexible and efficient technique to explicitly transfer knowledge. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform explicit knowledge transfer between two domains. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network computes latent features from two domains and learns meaningful cross-domain knowledge of each input in target domain by using a designed cross-supervised feature translator. Later the augmentation network employs the explicit cross-domain knowledge as augmented information to boost the target domain CTR prediction. Through extensive experiments on two public benchmarks and one industrial production dataset, we show CDAnet can learn meaningful translated features and largely improve the performance of CTR prediction. CDAnet has been conducted online A/B test in image2product retrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, a relative 0.64% deal growth and a relative 1.26% GMV increase."], "authors": "Xu Chen"},
{"Title": "Towards A Foundation Model For Trajectory Intelligence", "abs": ["We present the results of training a large trajectory model using real-world user check-in data. Our approach follows a pre-train and fine-tune paradigm, where a base model is pre-trained via masked trajectory modeling and then adapted through fine-tuning for various downstream tasks. To address challenges posed by noisy data and large spatial vocabularies, we propose a novel spatial tokenization block. Our empirical analysis utilizes a comprehensive dataset of over 2 billion check-ins generated by more than 6 million users. Through fine-tuning on 3 downstream tasks we demonstrate that our base model has effectively learned valuable underlying patterns in raw data, enabling its application in meaningful trajectory intelligence tasks. Despite some limitations, we believe this work represents an important step forward in the realization of a foundation model for trajectory intelligence."], "authors": "Alameen Najjar"},
{"Title": "Accelerating Neural Field Training via Soft Mining", "abs": ["We present an approach to accelerate Neural Field training by efficiently selecting sampling locations. While Neural Fields have recently become popular, it is often trained by uniformly sampling the training domain, or through handcrafted heuristics. We show that improved convergence and final training quality can be achieved by a soft mining technique based on importance sampling: rather than either considering or ignoring a pixel completely, we weigh the corresponding loss by a scalar. To implement our idea we use Langevin Monte-Carlo sampling. We show that by doing so, regions with higher error are being selected more frequently, leading to more than 2x improvement in convergence speed. The code and related resources for this study are publicly available at", "."], "authors": "Shakiba Kheradmand"},
{"Title": "CRAFT: Contextual Re-Activation of Filters for face recogntion Training", "abs": ["The first layer of a deep CNN backbone applies filters to an image to extract the basic features available to later layers. During training, some filters may go inactive, mean ing all weights in the filter approach zero. An inactive fil ter in the final model represents a missed opportunity to extract a useful feature. This phenomenon is especially prevalent in specialized CNNs such as for face recogni tion (as opposed to, e.g., ImageNet). For example, in one the most widely face recognition model (ArcFace), about half of the convolution filters in the first layer are inactive. We propose a novel approach designed and tested specif ically for face recognition networks, known as \"CRAFT: Contextual Re-Activation of Filters for Face Recognition Training\". CRAFT identifies inactive filters during training and reinitializes them based on the context of strong filters at that stage in training. We show that CRAFT reduces fraction of inactive filters from 44% to 32% on average and discovers filter patterns not found by standard training. Compared to standard training without reactivation, CRAFT demonstrates enhanced model accuracy on standard face-recognition benchmark datasets including AgeDB-30, CPLFW, LFW, CALFW, and CFP-FP, as well as on more challenging datasets like IJBB and IJBC."], "authors": "Aman Bhatta"},
{"Title": "SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters", "abs": ["The availability of well-curated datasets has driven the success of Machine Learning (ML) models. Despite greater access to earth observation data in agriculture, there is a scarcity of curated and labelled datasets, which limits the potential of its use in training ML models for remote sensing (RS) in agriculture. To this end, we introduce a first-of-its-kind dataset called SICKLE, which constitutes a time-series of multi-resolution imagery from 3 distinct satellites: Landsat-8, Sentinel-1 and Sentinel-2. Our dataset constitutes multi-spectral, thermal and microwave sensors during January 2018 - March 2021 period. We construct each temporal sequence by considering the cropping practices followed by farmers primarily engaged in paddy cultivation in the Cauvery Delta region of Tamil Nadu, India; and annotate the corresponding imagery with key cropping parameters at multiple resolutions (i.e. 3m, 10m and 30m). Our dataset comprises 2,370 season-wise samples from 388 unique plots, having an average size of 0.38 acres, for classifying 21 crop types across 4 districts in the Delta, which amounts to approximately 209,000 satellite images. Out of the 2,370 samples, 351 paddy samples from 145 plots are annotated with multiple crop parameters; such as the variety of paddy, its growing season and productivity in terms of per-acre yields. Ours is also one among the first studies that consider the growing season activities pertinent to crop phenology (spans sowing, transplanting and harvesting dates) as parameters of interest. We benchmark SICKLE on three tasks: crop type, crop phenology (sowing, transplanting, harvesting), and yield prediction"], "authors": "Depanshu Sani"},
{"Title": "GLiDR: Topologically Regularized Graph Generative Network for Sparse LiDAR Point Clouds", "abs": ["Sparse LiDAR point clouds cause severe loss of detail of static structures and reduce the density of static points available for navigation. Reduced density can be detrimental to navigation under several scenarios. We observe that despite high sparsity, in most cases, the global topology of LiDAR outlining the static structures can be inferred. We utilize this property to obtain a backbone skeleton of a static LiDAR scan in the form of a single connected component that is a proxy to its global topology. We utilize the backbone to augment new points along static structures to overcome sparsity. Newly introduced points could correspond to existing static structures or to static points that were earlier obstructed by dynamic objects. To the best of our knowledge, we are the first to use this strategy for sparse LiDAR point clouds. Existing solutions close to our approach fail to identify and preserve the global static LiDAR topology and generate sub-optimal points. We propose GLiDR, a Graph Generative network that is topologically regularized using 0-dimensional Persistent Homology (PH) constraints. This enables GLiDR to introduce newer static points along a topologically consistent global static LiDAR backbone. GLiDR generates precise static points using 32x sparser dynamic scans and performs better than the baselines across three datasets. The newly introduced static points allow GLiDR to outperform LiDAR-based navigation using SLAM in several settings. GLiDR generates a valuable byproduct - an accurate binary segmentation mask of static and dynamic objects that is helpful for navigation planning and safety in constrained environments."], "authors": "Prashant Kumar"},
{"Title": "Exploring Factors Affecting Pedestrian Crash Severity Using TabNet: A Deep Learning Approach", "abs": ["This study presents the first investigation of pedestrian crash severity using the TabNet model, a novel tabular deep learning method exceptionally suited for analyzing the tabular data inherent in transportation safety research. Through the application of TabNet to a comprehensive dataset from Utah covering the years 2010 to 2022, we uncover intricate factors contributing to pedestrian crash severity. The TabNet model, capitalizing on its compatibility with structured data, demonstrates remarkable predictive accuracy, eclipsing that of traditional models. It identifies critical variables, such as pedestrian age, involvement in left or right turns, lighting conditions, and alcohol consumption, which significantly influence crash outcomes. The utilization of SHapley Additive exPlanations (SHAP) enhances our ability to interpret the TabNet model's predictions, ensuring transparency and understandability in our deep learning approach. The insights derived from our analysis provide a valuable compass for transportation safety engineers and policymakers, enabling the identification of pivotal factors that affect pedestrian crash severity. Such knowledge is instrumental in formulating precise, data-driven interventions aimed at bolstering pedestrian safety across diverse urban and rural settings."], "authors": "Amir Rafe"},
{"Title": "Unsupervised Keypoints from Pretrained Diffusion Models", "abs": ["Unsupervised learning of keypoints and landmarks has seen significant progress with the help of modern neural network architectures, but performance is yet to match the supervised counterpart, making their practicability questionable. We leverage the emergent knowledge within text-to-image diffusion models, towards more robust unsupervised keypoints. Our core idea is to find text embeddings that would cause the generative model to consistently attend to compact regions in images (i.e. keypoints). To do so, we simply optimize the text embedding such that the cross-attention maps within the denoising network are localized as Gaussians with small standard deviations. We validate our performance on multiple datasets: the CelebA, CUB-200-2011, Tai-Chi-HD, DeepFashion, and Human3.6m datasets. We achieve significantly improved accuracy, sometimes even outperforming supervised ones, particularly for data that is non-aligned and less curated. Our code is publicly available and can be found through our project page:"], "authors": "Eric Hedlin"},
{"Title": "MoMask: Generative Masked Modeling of 3D Human Motions", "abs": ["We introduce MoMask, a novel masked modeling framework for text-driven 3D human motion generation. In MoMask, a hierarchical quantization scheme is employed to represent human motion as multi-layer discrete motion tokens with high-fidelity details. Starting at the base layer, with a sequence of motion tokens obtained by vector quantization, the residual tokens of increasing orders are derived and stored at the subsequent layers of the hierarchy. This is consequently followed by two distinct bidirectional transformers. For the base-layer motion tokens, a Masked Transformer is designated to predict randomly masked motion tokens conditioned on text input at training stage. During generation (i.e. inference) stage, starting from an empty sequence, our Masked Transformer iteratively fills up the missing tokens; Subsequently, a Residual Transformer learns to progressively predict the next-layer tokens based on the results from current layer. Extensive experiments demonstrate that MoMask outperforms the state-of-art methods on the text-to-motion generation task, with an FID of 0.045 (vs e.g. 0.141 of T2M-GPT) on the HumanML3D dataset, and 0.228 (vs 0.514) on KIT-ML, respectively. MoMask can also be seamlessly applied in related tasks without further model fine-tuning, such as text-guided temporal inpainting."], "authors": "Chuan Guo"},
{"Title": "Open data ecosystems: what models to co-create service innovations in smart cities?", "abs": ["While smart cities are recently providing open data, how to organise the collective creation of data, knowledge and related products and services produced from this collective resource, still remains to be thought. This paper aims at gathering the literature review on open data ecosystems to tackle the following research question: what models can be imagined to stimulate the collective co-creation of services between smart cities' stakeholders acting as providers and users of open data? Such issue is currently at stake in many municipalities such as Lisbon which decided to position itself as a platform (O'Reilly, 2010) in the local digital ecosystem. With the implementation of its City Operation Center (COI), Lisbon's municipality provides an Information Infrastructure (Bowker et al., 2009) to many different types of actors such as telecom companies, municipalities, energy utilities or transport companies. Through this infrastructure, Lisbon encourages such actors to gather, integrate and release heterogeneous datasets and tries to orchestrate synergies among them so data-driven solution to urban problems can emerge (Carvalho and Vale, 2018). The remaining question being: what models for the municipalities such as Lisbon to lean on so as to drive this cutting-edge type of service innovation?"], "authors": "Arthur Sarazin"},
{"Title": "Probabilistic Copyright Protection Can Fail for Text-to-Image Generative Models", "abs": ["The booming use of text-to-image generative models has raised concerns about their high risk of producing copyright-infringing content. While probabilistic copyright protection methods provide a probabilistic guarantee against such infringement, in this paper, we introduce Virtually Assured Amplification Attack (VA3), a novel online attack framework that exposes the vulnerabilities of these protection mechanisms. The proposed framework significantly amplifies the probability of generating infringing content on the sustained interactions with generative models and a lower-bounded success probability of each engagement. Our theoretical and experimental results demonstrate the effectiveness of our approach and highlight the potential risk of implementing probabilistic copyright protection in practical applications of text-to-image generative models. Code is available at", "."], "authors": "Xiang Li"},
{"Title": "LEAP: LLM-Generation of Egocentric Action Programs", "abs": ["We introduce LEAP (illustrated in Figure 1), a novel method for generating video-grounded action programs through use of a Large Language Model (LLM). These action programs represent the motoric, perceptual, and structural aspects of action, and consist of sub-actions, pre- and post-conditions, and control flows. LEAP's action programs are centered on egocentric video and employ recent developments in LLMs both as a source for program knowledge and as an aggregator and assessor of multimodal video information. We apply LEAP over a majority (87\\%) of the training set of the EPIC Kitchens dataset, and release the resulting action programs as a publicly available dataset here (", "). We employ LEAP as a secondary source of supervision, using its action programs in a loss term applied to action recognition and anticipation networks. We demonstrate sizable improvements in performance in both tasks due to training with the LEAP dataset. Our method achieves 1st place on the EPIC Kitchens Action Recognition leaderboard as of November 17 among the networks restricted to RGB-input (see Supplementary Materials)."], "authors": "Eadom Dessalene"},
{"Title": "Anti-Sexism Alert System: Identification of Sexist Comments on Social Media Using AI Techniques", "abs": ["Social relationships in the digital sphere are becoming more usual and frequent, and they constitute a very important aspect for all of us. {Violent interactions in this sphere are very frequent, and have serious effects on the victims}. Within this global scenario, there is one kind of digital violence that is becoming really worrying: sexism against women. Sexist comments that are publicly posted in social media (newspaper comments, social networks, etc.), usually obtain a lot of attention and become viral, with consequent damage to the persons involved. In this paper, we introduce an anti-sexism alert system, based on natural language processing (NLP) and artificial intelligence (AI), that analyzes any public post, and decides if it could be considered a sexist comment or not. Additionally, this system also works on analyzing all the public comments linked to any multimedia content (piece of news, video, tweet, etc.) and decides, using a color-based system similar to traffic lights, if there is sexism in the global set of posts. We have created a labeled data set in Spanish, since the majority of studies focus on English, to train our system, which offers a very good performance after the validation experiments."], "authors": "Rebeca P. Díaz Redondo"},
{"Title": "A Case for Competent AI Systems $-$ A Concept Note", "abs": ["The efficiency of an AI system is contingent upon its ability to align with the specified requirements of a given task. How-ever, the inherent complexity of tasks often introduces the potential for harmful implications or adverse actions. This note explores the critical concept of capability within AI systems, representing what the system is expected to deliver. The articulation of capability involves specifying well-defined out-comes. Yet, the achievement of this capability may be hindered by deficiencies in implementation and testing, reflecting a gap in the system's competency (what it can do vs. what it does successfully).", "A central challenge arises in elucidating the competency of an AI system to execute tasks effectively. The exploration of system competency in AI remains in its early stages, occasionally manifesting as confidence intervals denoting the probability of success. Trust in an AI system hinges on the explicit modeling and detailed specification of its competency, connected intricately to the system's capability. This note explores this gap by proposing a framework for articulating the competency of AI systems.", "Motivated by practical scenarios such as the Glass Door problem, where an individual inadvertently encounters a glass obstacle due to a failure in their competency, this research underscores the imperative of delving into competency dynamics. Bridging the gap between capability and competency at a detailed level, this note contributes to advancing the discourse on bolstering the reliability of AI systems in real-world applications."], "authors": "Kamalakar Karlapalem"},
{"Title": "MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning", "abs": ["The membership inference attack (MIA) is a popular paradigm for compromising the privacy of a machine learning (ML) model. MIA exploits the natural inclination of ML models to overfit upon the training data. MIAs are trained to distinguish between training and testing prediction confidence to infer membership information. Federated Learning (FL) is a privacy-preserving ML paradigm that enables multiple clients to train a unified model without disclosing their private data. In this paper, we propose an enhanced Membership Inference Attack with the Batch-wise generated Attack Dataset (MIA-BAD), a modification to the MIA approach. We investigate that the MIA is more accurate when the attack dataset is generated batch-wise. This quantitatively decreases the attack dataset while qualitatively improving it. We show how training an ML model through FL, has some distinct advantages and investigate how the threat introduced with the proposed MIA-BAD approach can be mitigated with FL approaches. Finally, we demonstrate the qualitative effects of the proposed MIA-BAD methodology by conducting extensive experiments with various target datasets, variable numbers of federated clients, and training batch sizes."], "authors": "Soumya Banerjee"},
{"Title": "Elijah: Eliminating Backdoors Injected in Diffusion Models via Distribution Shift", "abs": ["Diffusion models (DM) have become state-of-the-art generative models because of their capability to generate high-quality images from noises without adversarial training. However, they are vulnerable to backdoor attacks as reported by recent studies. When a data input (e.g., some Gaussian noise) is stamped with a trigger (e.g., a white patch), the backdoored model always generates the target image (e.g., an improper photo). However, effective defense strategies to mitigate backdoors from DMs are underexplored. To bridge this gap, we propose the first backdoor detection and removal framework for DMs. We evaluate our framework Elijah on hundreds of DMs of 3 types including DDPM, NCSN and LDM, with 13 samplers against 3 existing backdoor attacks. Extensive experiments show that our approach can have close to 100% detection accuracy and reduce the backdoor effects to close to zero without significantly sacrificing the model utility."], "authors": "Shengwei An"},
{"Title": "Tokenized Model: A Blockchain-Empowered Decentralized Model Ownership Verification Platform", "abs": ["With the development of practical deep learning models like generative AI, their excellent performance has brought huge economic value. For instance, ChatGPT has attracted more than 100 million users in three months. Since the model training requires a lot of data and computing power, a well-performing deep learning model is behind a huge effort and cost. Facing various model attacks, unauthorized use and abuse from the network that threaten the interests of model owners, in addition to considering legal and other administrative measures, it is equally important to protect the model's copyright from the technical means. By using the model watermarking technology, we point out the possibility of building a unified platform for model ownership verification. Given the application history of blockchain in copyright verification and the drawbacks of a centralized third-party, this paper considers combining model watermarking technology and blockchain to build a unified model copyright protection platform. By a new solution we called Tokenized Model, it protects the model's copyright by reliable ownership record and verification mechanism. It also promotes the financial value of model by constructing the model's transaction process and contribution shares of a model. In the typical case study, we also study the various performance under usual scenario to verify the effectiveness of this platform."], "authors": "Yihao Li"},
{"Title": "chatGPT for generating questions and assessments based on accreditations", "abs": ["This research aims to take advantage of artificial intelligence techniques in producing students assessment that is compatible with the different academic accreditations of the same program. The possibility of using generative artificial intelligence technology was studied to produce an academic accreditation compliant test the National Center for Academic Accreditation of Kingdom of Saudi Arabia and Accreditation Board for Engineering and Technology. A novel method was introduced to map the verbs used to create the questions introduced in the tests. The method allows a possibility of using the generative artificial intelligence technology to produce and check the validity of questions that measure educational outcomes. A questionnaire was distributed to ensure that the use of generative artificial intelligence to create exam questions is acceptable by the faculty members, as well as to ask about the acceptance of assistance in validating questions submitted by faculty members and amending them in accordance with academic accreditations. The questionnaire was distributed to faculty members of different majors in the Kingdom of Saudi Arabias universities. one hundred twenty responses obtained with eight five percentile approval percentage for generate complete exam questions by generative artificial intelligence . Whereas ninety eight percentage was the approval percentage for editing and improving already existed questions."], "authors": "Rania Anwar Aboalela"},
{"Title": "Retail Analytics in the New Normal: The Influence of Artificial Intelligence and the Covid-19 Pandemic", "abs": ["The COVID-19 pandemic has severely disrupted the retail landscape and has accelerated the adoption of innovative technologies. A striking example relates to the proliferation of online grocery orders and the technology deployed to facilitate such logistics. In fact, for many retailers, this disruption was a wake-up call after which they started recognizing the power of data analytics and artificial intelligence (AI). In this article, we discuss the opportunities that AI can offer to retailers in the new normal retail landscape. Some of the techniques described have been applied at scale to adapt previously deployed AI models, whereas in other instances, fresh solutions needed to be developed to help retailers cope with recent disruptions, such as unexpected panic buying, retraining predictive models, and leveraging online-offline synergies."], "authors": "Yossiri Adulyasak"},
{"Title": "AI-driven E-Liability Knowledge Graphs: A Comprehensive Framework for Supply Chain Carbon Accounting and Emissions Liability Management", "abs": ["While carbon accounting plays a fundamental role in our fight against climate change, it is not without its challenges. We begin the paper with a critique of the conventional carbon accounting practices, after which we proceed to introduce the E-liability carbon accounting methodology and Emissions Liability Management (ELM) originally proposed by Kaplan and Ramanna, highlighting their strengths. Recognizing the immense value of this novel approach for real-world carbon accounting improvement, we introduce a novel data-driven integrative framework that leverages AI and computation - the E-Liability Knowledge Graph framework - to achieve real-world implementation of the E-liability carbon accounting methodology. In addition to providing a path-to-implementation, our proposed framework brings clarity to the complex environmental interactions within supply chains, thus enabling better informed and more responsible decision-making. We analyze the implementation aspects of this framework and conclude with a discourse on the role of this AI-aided knowledge graph in ensuring the transparency and decarbonization of global supply chains."], "authors": "Olamide Oladeji"},
{"Title": "Who is leading in AI? An analysis of industry AI research", "abs": ["AI research is increasingly industry-driven, making it crucial to understand company contributions to this field. We compare leading AI companies by research publications, citations, size of training runs, and contributions to algorithmic innovations. Our analysis reveals the substantial role played by Google, OpenAI and Meta. We find that these three companies have been responsible for some of the largest training runs, developed a large fraction of the algorithmic innovations that underpin large language models, and led in various metrics of citation impact. In contrast, leading Chinese companies such as Tencent and Baidu had a lower impact on many of these metrics compared to US counterparts. We observe many industry labs are pursuing large training runs, and that training runs from relative newcomers -- such as OpenAI and Anthropic -- have matched or surpassed those of long-standing incumbents such as Google. The data reveals a diverse ecosystem of companies steering AI progress, though US labs such as Google, OpenAI and Meta lead across critical metrics."], "authors": "Ben Cottier"},
{"Title": "Presentation Attack Detection using Convolutional Neural Networks and Local Binary Patterns", "abs": ["The use of biometrics to authenticate users and control access to secure areas has become extremely popular in recent years, and biometric access control systems are frequently used by both governments and private corporations. However, these systems may represent risks to security when deployed without considering the possibility of biometric presentation attacks (also known as spoofing). Presentation attacks are a serious threat because they do not require significant time, expense, or skill to carry out while remaining effective against many biometric systems in use today. This research compares three different software-based methods for facial and iris presentation attack detection in images. The first method uses Inception-v3, a pre-trained deep Convolutional Neural Network (CNN) made by Google for the ImageNet challenge, which is retrained for this problem. The second uses a shallow CNN based on a modified Spoofnet architecture, which is trained normally. The third is a texture-based method using Local Binary Patterns (LBP). The datasets used are the ATVS-FIr dataset, which contains real and fake iris images, and the CASIA Face Anti-Spoofing Dataset, which contains real images as well as warped photos, cut photos, and video replay presentation attacks. We also present a third set of results, based on cropped versions of the CASIA images."], "authors": "Justin Spencer"},
{"Title": "Presentation Attack detection using Wavelet Transform and Deep Residual Neural Net", "abs": ["Biometric authentication is becoming more prevalent for secured authentication systems. However, the biometric substances can be deceived by the imposters in several ways. Among other imposter attacks, print attacks, mask attacks, and replay attacks fall under the presentation attack category. The bio-metric images, especially the iris and face, are vulnerable to different presentation attacks. This research applies deep learning approaches to mitigate presentation attacks in a biometric access control system. Our contribution in this paper is two-fold: First, we applied the wavelet transform to extract the features from the biometric images. Second, we modified the deep residual neural net and applied it to the spoof datasets in an attempt to detect the presentation attacks. This research applied the proposed approach to biometric spoof datasets, namely ATVS, CASIA two class, and CASIA cropped image sets. The datasets used in this research contain images that are captured in both a controlled and uncontrolled environment along with different resolutions and sizes. We obtained the best accuracy of 93% on the ATVS Iris datasets. For CASIA two class and CASIA cropped datasets, we achieved test accuracies of 91% and 82%, respectively."], "authors": "Prosenjit Chatterjee"},
{"Title": "Acoustic Cybersecurity: Exploiting Voice-Activated Systems", "abs": ["In this study, we investigate the emerging threat of inaudible acoustic attacks targeting digital voice assistants, a critical concern given their projected prevalence to exceed the global population by 2024. Our research extends the feasibility of these attacks across various platforms like Amazon's Alexa, Android, iOS, and Cortana, revealing significant vulnerabilities in smart devices. The twelve attack vectors identified include successful manipulation of smart home devices and automotive systems, potential breaches in military communication, and challenges in critical infrastructure security. We quantitatively show that attack success rates hover around 60%, with the ability to activate devices remotely from over 100 feet away. Additionally, these attacks threaten critical infrastructure, emphasizing the need for multifaceted defensive strategies combining acoustic shielding, advanced signal processing, machine learning, and robust user authentication to mitigate these risks."], "authors": "Forrest McKee"},
{"Title": "Privacy-Preserving Load Forecasting via Personalized Model Obfuscation", "abs": ["The widespread adoption of smart meters provides access to detailed and localized load consumption data, suitable for training building-level load forecasting models. To mitigate privacy concerns stemming from model-induced data leakage, federated learning (FL) has been proposed. This paper addresses the performance challenges of short-term load forecasting models trained with FL on heterogeneous data, emphasizing privacy preservation through model obfuscation. Our proposed algorithm, Privacy Preserving Federated Learning (PPFL), incorporates personalization layers for localized training at each smart meter. Additionally, we employ a differentially private mechanism to safeguard against data leakage from shared layers. Simulations on the NREL ComStock dataset corroborate the effectiveness of our approach."], "authors": "Shourya Bose"},
{"Title": "FBChain: A Blockchain-based Federated Learning Model with Efficiency and Secure Communication", "abs": ["Privacy and security in the parameter transmission process of federated learning are currently among the most prominent concerns. However, there are two thorny problems caused by unprotected communication methods: \"parameter-leakage\" and \"inefficient-communication\". This article proposes Blockchain-based Federated Learning (FBChain) model for federated learning parameter communication to overcome the above two problems. First, we utilize the immutability of blockchain to store the global model and hash value of local model parameters in case of tampering during the communication process, protect data privacy by encrypting parameters, and verify data consistency by comparing the hash values of local parameters, thus addressing the \"parameter-leakage\" problem. Second, the Proof of Weighted Link Speed (PoWLS) consensus algorithm comprehensively selects nodes with the higher weighted link speed to aggregate global model and package blocks, thereby solving the \"inefficient-communication\" problem. Experimental results demonstrate the effectiveness of our proposed FBChain model and its ability to improve model communication efficiency in federated learning."], "authors": "Yang Li"},
{"Title": "Enhancing IoT Security via Automatic Network Traffic Analysis: The Transition from Machine Learning to Deep Learning", "abs": ["This work provides a comparative analysis illustrating how Deep Learning (DL) surpasses Machine Learning (ML) in addressing tasks within Internet of Things (IoT), such as attack classification and device-type identification. Our approach involves training and evaluating a DL model using a range of diverse IoT-related datasets, allowing us to gain valuable insights into how adaptable and practical these models can be when confronted with various IoT configurations. We initially convert the unstructured network traffic data from IoT networks, stored in PCAP files, into images by processing the packet data. This conversion process adapts the data to meet the criteria of DL classification methods. The experiments showcase the ability of DL to surpass the constraints tied to manually engineered features, achieving superior results in attack detection and maintaining comparable outcomes in device-type identification. Additionally, a notable feature extraction time difference becomes evident in the experiments: traditional methods require around 29 milliseconds per data packet, while DL accomplishes the same task in just 2.9 milliseconds. The significant time gap, DL's superior performance, and the recognized limitations of manually engineered features, presents a compelling call to action within the IoT community. This encourages us to shift from exploring new IoT features for each dataset to addressing the challenges of integrating DL into IoT, making it a more efficient solution for real-world IoT scenarios."], "authors": "Mounia Hamidouche"},
{"Title": "DeFi Security: Turning The Weakest Link Into The Strongest Attraction", "abs": ["The primary innovation we pioneer -- focused on blockchain information security -- is called the Safe-House. The Safe-House is badly needed since there are many ongoing hacks and security concerns in the DeFi space right now. The Safe-House is a piece of engineering sophistication that utilizes existing blockchain principles to bring about greater security when customer assets are moved around. The Safe-House logic is easily implemented as smart contracts on any decentralized system. The amount of funds at risk from both internal and external parties -- and hence the maximum one time loss -- is guaranteed to stay within the specified limits based on cryptographic fundamentals.", "To improve the safety of the Safe-House even further, we adapt the one time password (OPT) concept to operate using blockchain technology. Well suited to blockchain cryptographic nuances, our secondary advancement can be termed the one time next time password (OTNTP) mechanism. The OTNTP is designed to complement the Safe-House making it even more safe.", "We provide a detailed threat assessment model -- discussing the risks faced by DeFi protocols and the specific risks that apply to blockchain fund management -- and give technical arguments regarding how these threats can be overcome in a robust manner. We discuss how the Safe-House can participate with other external yield generation protocols in a secure way. We provide reasons for why the Safe-House increases safety without sacrificing the efficiency of operation. We start with a high level intuitive description of the landscape, the corresponding problems and our solutions. We then supplement this overview with detailed discussions including the corresponding mathematical formulations and pointers for technological implementation. This approach ensures that the article is accessible to a broad audience."], "authors": "Ravi Kashyap"},
{"Title": "Revolutionizing Forensic Toolmark Analysis: An Objective and Transparent Comparison Algorithm", "abs": ["Forensic toolmark comparisons are currently performed subjectively by humans, which leads to a lack of consistency and accuracy. There is little evidence that examiners can determine whether pairs of marks were made by the same tool or different tools. There is also little evidence that they can make this classification when marks are made under different conditions, such as different angles of attack or direction of mark generation. We generate original toolmark data in 3D, extract the signal from each toolmarks, and train an algorithm to compare toolmark signals objectively. We find that toolmark signals cluster by tool, and not by angle or direction. That is, the variability within tool, regardless of angle/direction, is smaller than the variability between tools. The known-match and known-non-match densities of the similarities of pairs of marks have a small overlap, even when accounting for dependencies in the data, making them a useful instrument for determining whether a new pair of marks was made by the same tool. We provide a likelihood ratio approach as a formal method for comparing toolmark signals with a measure of uncertainty. This empirically trained, open-source method can be used by forensic examiners to compare toolmarks objectively and thus improve the reliability of toolmark comparisons. This can, in turn, reduce miscarriages of justice in the criminal justice system."], "authors": "Maria Cuellar"},
{"Title": "Crypto analysis of the key distribution scheme using noise-free resistances", "abs": ["Known key exchange schemes offering information-theoretic (unconditional) security are complex and costly to implement. Nonetheless, they remain the only known methods for achieving unconditional security in key exchange. Therefore, the explorations for simpler solutions for information-theoretic security are highly justified. Lin et al. [1] proposed an interesting hardware key distribution scheme that utilizes thermal-noise-free resistances and DC voltages.", "A crypto analysis of this system is presented. It is shown that, if Eve gains access to the initial shared secret at any time in the past or future, she can successfully crack all the generated keys in the past and future, even retroactively, using passively obtained and recorded voltages and currents. Therefore, the scheme is not a secure key exchanger, but it is rather a key expander with no more information entropy than the originally shared secret at the beginning.", "We also point out that the proposed defense methods against active attacks do not function when the original shared secret is compromised because then the communication cannot be efficiently authenticated. However, they do work when an unconditionally secure key exchanger is applied to enable the authenticated communication protocol."], "authors": "Laszlo B. Kish"},
{"Title": "A Quality-of-Service Compliance System using Federated Learning and Optimistic Rollups", "abs": ["Edge computing brings a new paradigm in which the sharing of computing, storage, and bandwidth resources as close as possible to the mobile devices or sensors generating a large amount of data. A parallel trend is the rise of phones and tablets as primary computing devices for many people. The powerful sensors present on these devices combined with the fact that they are mobile, mean they have access to data of an unprecedentedly diverse and private nature. Models learned on such data hold the promise of greatly improving usability by powering more intelligent applications, but the sensitive nature of the data means there are risks and responsibilities to storing it in a centralized location. To address the data privacy required for some data in these devices we propose the use of Federated Learning (FL) so that specific data about services performed by clients do not leave the source machines. Instead of sharing data, users collaboratively train a model by only sending weight updates to a server. However, the naive use of FL in those scenarios exposes it to a risk of corruption, whether intentional or not, during the training phase. To improve the security of the FL structure, we propose a decentralized Blockchain-based FL in an edge computing scenario. We also apply blockchain to create a reward mechanism in FL to enable incentive strategy for trainers."], "authors": "Joao Paulo de Brito Goncalves"},
{"Title": "Secure Transformer Inference", "abs": ["We present a three-party protocol that can protect both Transformer parameters and user data during the inference phase. For each feedforward inference process, our protocol only introduces permutation computation of input and output data on the user side. Our protocol, Secure Transformer Inference Protocol (STIP), can be applied to real-world services like ChatGPT."], "authors": "Mu Yuan"},
{"Title": "Can LLMs Patch Security Issues?", "abs": ["Large Language Models (LLMs) have shown impressive proficiency in code generation. Nonetheless, similar to human developers, these models might generate code that contains security vulnerabilities and flaws. Writing secure code remains a substantial challenge, as vulnerabilities often arise during interactions between programs and external systems or services, such as databases and operating systems. In this paper, we propose a novel approach, Feedback-Driven Solution Synthesis (FDSS), designed to explore the use of LLMs in receiving feedback from Bandit, which is a static code analysis tool, and then the LLMs generate potential solutions to resolve security vulnerabilities. Each solution, along with the vulnerable code, is then sent back to the LLM for code refinement. Our approach shows a significant improvement over the baseline and outperforms existing approaches. Furthermore, we introduce a new dataset, PythonSecurityEval, collected from real-world scenarios on Stack Overflow to evaluate the LLMs' ability to generate secure code. Code and data are available at \\url{", "}"], "authors": "Kamel Alrashedy"},
{"Title": "Hypergraph Topological Features for Autoencoder-Based Intrusion Detection for Cybersecurity Data", "abs": ["In this position paper, we argue that when hypergraphs are used to capture multi-way local relations of data, their resulting topological features describe global behaviour. Consequently, these features capture complex correlations that can then serve as high fidelity inputs to autoencoder-driven anomaly detection pipelines. We propose two such potential pipelines for cybersecurity data, one that uses an autoencoder directly to determine network intrusions, and one that de-noises input data for a persistent homology system, PHANTOM. We provide heuristic justification for the use of the methods described therein for an intrusion detection pipeline for cyber data. We conclude by showing a small example over synthetic cyber attack data."], "authors": "Bill Kay"},
{"Title": "Technical Report relating to CVE-2022-46480, CVE-2023-26941, CVE-2023-26942, and CVE-2023-26943", "abs": ["The following technical report provides background information relating to four CVEs found in the following products: Ultraloq UL3 BT (CVE-2022-46480); Yale Conexis L1 Smart Lock (CVE-2023-26941); Yale IA-210 Intruder Alarm (CVE-2023-26942); Yale Keyless Smart Lock (CVE-2023-26943). The work discussed here was carried out by Ash Allen, Dr. Alexios Mylonas, and Dr. Stilianos Vidalis as part of a wider research project into smart device security. Responsible disclosure of all four issues has been made with the appropriate vendors, and they have been acknowledged as vulnerabilities."], "authors": "Ashley Allen"},
{"Title": "Security Challenges in Autonomous Systems Design", "abs": ["Autonomous systems are emerging in many application domains. With the recent advancements in artificial intelligence and machine learning, sensor technology, perception algorithms and robotics, scenarios previously requiring strong human involvement can be handled by autonomous systems. With the independence from human control, cybersecurity of such systems becomes even more critical as no human intervention in case of undesired behavior is possible. In this context, this paper discusses emerging security challenges in autonomous systems design which arise in many domains such as autonomous incident response, risk assessment, data availability, systems interaction, trustworthiness, updatability, access control, as well as the reliability and explainability of machine learning methods. In all these areas, this paper thoroughly discusses the state of the art, identifies emerging security challenges and proposes research directions to address these challenges for developing secure autonomous systems."], "authors": "Mohammad Hamad"},
{"Title": "Preserving The Safety And Confidentiality Of Data Mining Information In Health Care: A literature review", "abs": ["Daily, massive volume of data are produced due to the internet of things' rapid development, which has now permeated the healthcare industry. Recent advances in data mining have spawned a new field of a study dubbed privacy-preserving data mining (PPDM). PPDM technique or approach enables the extraction of actionable insight from enormous volume of data while safeguarding the privacy of individual information and benefiting the entire society Medical research has taken a new course as a result of data mining with healthcare data to detect diseases earlier and improve patient care. Data integration necessitates the sharing of sensitive patient information. However, substantial privacy issues are raised in connection with the storage and transmission of potentially sensitive information. Disclosing sensitive information infringes on patients' privacy. This paper aims to conduct a review of related work on privacy-preserving mechanisms, data protection regulations, and mitigating tactics. The review concluded that no single strategy outperforms all others. Hence, future research should focus on adequate techniques for privacy solutions in the age of massive medical data and the standardization of evaluation standards."], "authors": "Robinson Onyemechi Oturugbum"},
{"Title": "Biometric Technologies and the Law: Developing a Taxonomy for Guiding Policymakers", "abs": ["Despite the increasing adoption of biometric technologies, their regulation has not kept up with the same pace, particularly with regard to safeguarding individuals' privacy and personal data. Policymakers may struggle to comprehend the technology behind biometric systems and their potential impact on fundamental rights, resulting in insufficient or inadequate legal regulation. This study seeks to bridge this gap by proposing a taxonomy of biometric technologies that can aid in their effective deployment and supervision. Through a literature review, the technical characteristics of biometric systems were identified and categorised. The resulting taxonomy can enhance the understanding of biometric technologies and facilitate the development of regulation that prioritises privacy and personal data protection."], "authors": "Luis Felipe M. Ramos"},
{"Title": "Risk-Aware and Explainable Framework for Ensuring Guaranteed Coverage in Evolving Hardware Trojan Detection", "abs": ["As the semiconductor industry has shifted to a fabless paradigm, the risk of hardware Trojans being inserted at various stages of production has also increased. Recently, there has been a growing trend toward the use of machine learning solutions to detect hardware Trojans more effectively, with a focus on the accuracy of the model as an evaluation metric. However, in a high-risk and sensitive domain, we cannot accept even a small misclassification. Additionally, it is unrealistic to expect an ideal model, especially when Trojans evolve over time. Therefore, we need metrics to assess the trustworthiness of detected Trojans and a mechanism to simulate unseen ones. In this paper, we generate evolving hardware Trojans using our proposed novel conformalized generative adversarial networks and offer an efficient approach to detecting them based on a non-invasive algorithm-agnostic statistical inference framework that leverages the Mondrian conformal predictor. The method acts like a wrapper over any of the machine learning models and produces set predictions along with uncertainty quantification for each new detected Trojan for more robust decision-making. In the case of a NULL set, a novel method to reject the decision by providing a calibrated explainability is discussed. The proposed approach has been validated on both synthetic and real chip-level benchmarks and proven to pave the way for researchers looking to find informed machine learning solutions to hardware security problems."], "authors": "Rahul Vishwakarma"},
{"Title": "Enhancing ML-Based DoS Attack Detection Through Combinatorial Fusion Analysis", "abs": ["Mitigating Denial-of-Service (DoS) attacks is vital for online service security and availability. While machine learning (ML) models are used for DoS attack detection, new strategies are needed to enhance their performance. We suggest an innovative method, combinatorial fusion, which combines multiple ML models using advanced algorithms. This includes score and rank combinations, weighted techniques, and diversity strength of scoring systems. Through rigorous evaluations, we demonstrate the effectiveness of this fusion approach, considering metrics like precision, recall, and F1-score. We address the challenge of low-profiled attack classification by fusing models to create a comprehensive solution. Our findings emphasize the potential of this approach to improve DoS attack detection and contribute to stronger defense mechanisms."], "authors": "Evans Owusu"},
{"Title": "Classification Utility, Fairness, and Compactness via Tunable Information Bottleneck and Rényi Measures", "abs": ["Designing machine learning algorithms that are accurate yet fair, not discriminating based on any sensitive attribute, is of paramount importance for society to accept AI for critical applications. In this article, we propose a novel fair representation learning method termed the Rényi Fair Information Bottleneck Method (RFIB) which incorporates constraints for utility, fairness, and compactness (compression) of representation, and apply it to image and tabular data classification. A key attribute of our approach is that we consider - in contrast to most prior work - both demographic parity and equalized odds as fairness constraints, allowing for a more nuanced satisfaction of both criteria. Leveraging a variational approach, we show that our objectives yield a loss function involving classical Information Bottleneck (IB) measures and establish an upper bound in terms of two Rényi measures of order $\\alpha$ on the mutual information IB term measuring compactness between the input and its encoded embedding. We study the influence of the $\\alpha$ parameter as well as two other tunable IB parameters on achieving utility/fairness trade-off goals, and show that the $\\alpha$ parameter gives an additional degree of freedom that can be used to control the compactness of the representation. Experimenting on three different image datasets (EyePACS, CelebA, and FairFace) and two tabular datasets (Adult and COMPAS), using both binary and categorical sensitive attributes, we show that on various utility, fairness, and compound utility/fairness metrics RFIB outperforms current state-of-the-art approaches."], "authors": "Adam Gronowski"},
{"Title": "Enhanced Cross Z-Complementary Set and Its Application in Generalized Spatial Modulation", "abs": ["Generalized spatial modulation (GSM) is a novel multiple-antenna technique offering flexibility among spectral efficiency, energy efficiency, and the cost of RF chains. In this paper, a novel class of sequence sets, called enhanced cross Zcomplementary set (E-CZCS), is proposed for efficient training sequence design in broadband GSM systems. Specifically, an E-CZCS consists of multiple CZCSs possessing front-end and tail-end zero-correlation zones (ZCZs), whereby any two distinct CZCSs have a tail-end ZCZ when a novel type of cross-channel aperiodic correlation sums is considered. The theoretical upper bound on the ZCZ width is first derived, upon which optimal E-CZCSs with flexible parameters are constructed. For optimal channel estimation over frequency-selective channels, we introduce and evaluate a novel GSM training framework employing the proposed E-CZCSs."], "authors": "Zhen-Ming Huang"},
{"Title": "Empirical Validation of the Impedance-Based RIS Channel Model in an Indoor Scattering Environment", "abs": ["Ensuring the precision of channel modeling plays a pivotal role in the development of wireless communication systems, and this requirement remains a persistent challenge within the realm of networks supported by Reconfigurable Intelligent Surfaces (RIS). Achieving a comprehensive and reliable understanding of channel behavior in RIS-aided networks is an ongoing and complex issue that demands further exploration. In this paper, we empirically validate a recently-proposed impedance-based RIS channel model that accounts for the mutual coupling at the antenna array and precisely models the presence of scattering objects within the environment as a discrete array of loaded dipoles. To this end, we exploit real-life channel measurements collected in an office environment to demonstrate the validity of such a model and its applicability in a practical scenario. Finally, we provide numerical results demonstrating that designing the RIS configuration based upon such model leads to superior performance as compared to reference schemes."], "authors": "Placido Mursia"},
{"Title": "Diffusion Models for Wireless Communications", "abs": ["Innovative foundation models, such as GPT-4 and stable diffusion models, have made a paradigm shift in the realm of artificial intelligence (AI) towards generative AI-based systems. AI and machine learning (AI/ML) algorithms are envisioned to be pervasively incorporated into the future wireless communications systems. In this article, we outline the applications of diffusion models in wireless communication systems, which are a new family of probabilistic generative models that have showcased state-of-the-art performance. The key idea is to decompose data generation process over \"denoising\" steps, gradually generating samples out of noise. Based on two case studies presented, we show how diffusion models can be employed for the development of resilient AI-native communication systems. Specifically, we propose denoising diffusion probabilistic models (DDPM) for a wireless communication scheme with non-ideal transceivers, where 30% improvement is achieved in terms of bit error rate. In the other example, DDPM is employed at the transmitter to shape the constellation symbols, highlighting a robust out-of-distribution performance."], "authors": "Mehdi Letafati"},
{"Title": "Algorithmic Information Forecastability", "abs": ["The outcome of all time series cannot be forecast, e.g. the flipping of a fair coin. Others, like the repeated {01} sequence {010101...} can be forecast exactly. Algorithmic information theory can provide a measure of forecastability that lies between these extremes. The degree of forecastability is a function of only the data. For prediction (or classification) of labeled data, we propose three categories for forecastability: oracle forecastability for predictions that are always exact, precise forecastability for errors up to a bound, and probabilistic forecastability for any other predictions. Examples are given in each case."], "authors": "Glauco Amigo"},
{"Title": "A Theory for Semantic Channel Coding With Many-to-one Source", "abs": ["As one of the potential key technologies of 6G, semantic communication is still in its infancy and there are many open problems, such as semantic entropy definition and semantic channel coding theory. To address these challenges, we investigate semantic information measures and semantic channel coding theorem. Specifically, we propose a semantic entropy definition as the uncertainty in the semantic interpretation of random variable symbols in the context of knowledge bases, which can be transformed into existing semantic entropy definitions under given conditions. Moreover, different from traditional communications, semantic communications can achieve accurate transmission of semantic information under a non-zero bit error rate. Based on this property, we derive a semantic channel coding theorem for a typical semantic communication with many-to-one source (i.e., multiple source sequences express the same meaning), and prove its achievability and converse based on a generalized Fano's inequality. Finally, numerical results verify the effectiveness of the proposed semantic entropy and semantic channel coding theorem."], "authors": "Shuai Ma"},
{"Title": "Beamforming and Device Selection Design in Federated Learning with Over-the-air Aggregation", "abs": ["Federated learning (FL) with over-the-air computation can efficiently utilize the communication bandwidth but is susceptible to analog aggregation error. Excluding those devices with weak channel conditions can reduce the aggregation error, but it also limits the amount of local training data for FL, which can reduce the training convergence rate. In this work, we jointly design uplink receiver beamforming and device selection for over-the-air FL over time-varying wireless channels to maximize the training convergence rate. We reformulate this stochastic optimization problem into a mixed-integer program using an upper bound on the global training loss over communication rounds. We then propose a Greedy Spatial Device Selection (GSDS) approach, which uses a sequential procedure to select devices based on a measure capturing both the channel strength and the channel correlation to the selected devices. We show that given the selected devices, the receiver beamforming optimization problem is equivalent to downlink single-group multicast beamforming. To reduce the computational complexity, we also propose an Alternating-optimization-based Device Selection and Beamforming (ADSBF) approach, which solves the receiver beamforming and device selection subproblems alternatingly. In particular, despite the device selection being an integer problem, we are able to develop an efficient algorithm to find its optimal solution.", "Simulation results with real-world image classification demonstrate that our proposed methods achieve faster convergence with significantly lower computational complexity than existing alternatives. Furthermore, although ADSBF shows marginally inferior performance to GSDS, it offers the advantage of lower computational complexity when the number of devices is large."], "authors": "Faeze Moradi Kalarde"},
{"Title": "Investing in the Quantum Future : State of Play and Way Forward for Quantum Venture Capital", "abs": ["Building on decades of fundamental research, new applications of Quantum Science have started to emerge in the fields of computing, sensing and networks. In the current phase of deployment, in which quantum technology is not yet in routine use but is still transitioning out of the laboratory, Venture Capital (VC) is critical. In association with public funding programs, VC supports startups born in academic institutions and has a role to play in structuring the priorities of the ecosystem, guiding it towards applications with the greatest impact on society. This paper illustrates this thesis with a case-study: the experience of the first dedicated quantum fund, Quantonation I, chronicling its impacts on the production of scientific knowledge, job creation and funding of the industry. The paper introduces concepts to support the emergence of new startups and advocates for funding of scale-up quantum companies. The paper concludes with proposals to improve the impact of the industry by taking steps to better involve society-at-large and with a call for collaboration on projects focused on the applications with a large societal benefit."], "authors": "Christophe Jurczak"},
{"Title": "Some explicit cocycles on the Furstenberg boundary for products of isometries of hyperbolic spaces and $\\mathrm{SL}(3,\\mathbb{K})$", "abs": ["Nicolas Monod showed that the evaluation map $H^*_m(G\\curvearrowright G/P)\\longrightarrow H^*_m(G)$ between the measurable cohomology of the action of a connected semisimple Lie group $G$ on its Furstenberg boundary $G/P$ and the measurable cohomology of $G$ is surjective with a kernel that can be entirely described in terms of invariants in the cohomology of the maximal split torus $A<G$. In a recent paper the authors refine Monod's result and show in particular that the cohomology of non-alternating cocycles on $G/P$, namely those lying in the kernel of the alternation map, is in general not trivial and lies in the kernel of the evaluation. In this paper we describe explicitly such non-alternating and alternating cocycles on $G/P$ in low degrees when $G$ is either a product of isometries of real hyperbolic spaces or $G=\\mathrm{SL}(3,\\mathbb{K})$, where $\\mathbb{K}$ is either the real or the complex field. As a consequence, we deduce that the comparison map $H^*_{m,b}(G)\\rightarrow H^*_m(G)$ from the measurable bounded cohomology is injective in degree $3$, which is new for nontrivial products of isometries of hyperbolic spaces."], "authors": "Michelle Bucher"},
{"Title": "Alternating cochains on Furstenberg boundaries and measurable cohomology", "abs": ["Nicolas Monod showed that the evaluation map $$H^*_m(G\\curvearrowright G/P)\\longrightarrow H^*_m(G)$$ between the measurable cohomology of the action of a connected semisimple Lie group $G$ on its Furstenberg boundary $G/P$ and the measurable cohomology of $G$ is surjective with a non-trivial kernel in all degrees below a constant depending on $G$ and less than or equal to the rank of $G$ plus $2$. In contrast, we show that $H^*_m(G)$ is isomorphic to the alternating measurable cohomology of $G$ on $G/P$ in all even degrees $$H^{2k}_{m,\\mathrm{alt}}(G\\curvearrowright G/P)\\cong H^{2k}_m(G),$$ for a majority of Lie groups, namely those for which the longest element of the Weyl group acts as $-1$ on the Lie algebra of a maximal split torus $A$ in $G$. Furthermore, we show that the cohomology of the cocomplex of non-alternating measurable functions on the Furstenberg boundary $G/P$ is isomorphic to the invariant cohomology of $A$ shifted by two, thus it is non-trivial in general. Similarly, we show that the cohomology of the cocomplex of alternating measurable functions on $G/P$ surjects on the measurable cohomology of $G$ with a kernel given by the invariant cohomology of $A$ shifted by one.", "This analysis of the kernel sheds some light on a conjecture by Monod. In particular, we show that the comparison map $H^\\ast_{m,b}(G) \\rightarrow H^\\ast_m(G)$ from the measurable bounded cohomology is injective in degree 3 for $G=\\mathrm{SL}(3,\\mathbb{R}),G=\\mathrm{SL}(2,\\mathbb{C})$ or $G=\\mathrm{Isom}(\\mathbb{H}^n) \\times \\mathrm{Isom}(\\mathbb{H}^m)$ where $n,m \\geq 2$."], "authors": "Michelle Bucher"},
{"Title": "DroidDissector: A Static and Dynamic Analysis Tool for Android Malware Detection", "abs": ["DroidDissector is an extraction tool for both static and dynamic features. The aim is to provide Android malware researchers and analysts with an integrated tool that can extract all of the most widely used features in Android malware detection from one location. The static analysis module extracts features from both the manifest file and the source code of the application to obtain a broad array of features that include permissions, API call graphs and opcodes. The dynamic analysis module runs on the latest version of Android and analyses the complete behaviour of an application by tracking the system calls used, network traffic generated, API calls used and log files produced by the application."], "authors": "Ali Muzaffar"},
{"Title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs", "abs": ["Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identifying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10-20% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TpuGraphs, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compilation configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures, e.g., ResNet, EfficientNet, Mask R-CNN, and Transformer. TpuGraphs provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality."], "authors": "Phitchaya Mangpo Phothilimthana"},
{"Title": "SPIRE-SIES: A Spontaneous Indian English Speech Corpus", "abs": ["In this paper, we present a 170.83 hour Indian English spontaneous speech dataset. Lack of Indian English speech data is one of the major hindrances in developing robust speech systems which are adapted to the Indian speech style. Moreover this scarcity is even more for spontaneous speech. This corpus is crowd sourced over varied Indian nativities, genders and age groups. Traditional spontaneous speech collection strategies involve capturing of speech during interviewing or conversations. In this study, we use images as stimuli to induce spontaneity in speech. Transcripts for 23 hours is generated and validated which can serve as a spontaneous speech ASR benchmark. Quality of the corpus is validated with voice activity detection based segmentation, gender verification and image semantic correlation. Which determines a relationship between image stimulus and recorded speech using caption keywords derived from Image2Text model and high occurring words derived from whisper ASR generated transcripts."], "authors": "Abhayjeet Singh"},
{"Title": "A WINNER+ Based 3-D Non-Stationary Wideband MIMO Channel Model", "abs": ["In this paper, a three-dimensional (3-D) non-stationary wideband multiple-input multiple-output (MIMO) channel model based on the WINNER+ channel model is proposed. The angular distributions of clusters in both the horizontal and vertical planes are jointly considered. The receiver and clusters can be moving, which makes the model more general. Parameters including number of clusters, powers, delays, azimuth angles of departure (AAoDs), azimuth angles of arrival (AAoAs), elevation angles of departure (EAoDs), and elevation angles of arrival (EAoAs) are time-variant. The cluster time evolution is modeled using a birth-death process. Statistical properties, including spatial cross-correlation function (CCF), temporal autocorrelation function (ACF), Doppler power spectrum density (PSD), level-crossing rate (LCR), average fading duration (AFD), and stationary interval are investigated and analyzed. The LCR, AFD, and stationary interval of the proposed channel model are validated against the measurement data. Numerical and simulation results show that the proposed channel model has the ability to reproduce the main properties of real non-stationary channels. Furthermore, the proposed channel model can be adapted to various communication scenarios by adjusting different parameter values."], "authors": "Ji Bian"},
{"Title": "Technical description of the EPFL submission to the JPEG DNA CfP", "abs": ["This document provides a technical description of the codec proposed by EPFL to the JPEG DNA Call for Proposals. The codec we refer to as V-DNA for its versatility, enables the encoding of raw images and already compressed JPEG 1 bitstreams, but the underlying algorithm could be used to encode and transcode any kind of data. The codec is composed of two main modules: the image compression module, handled by the state-of-the-art JPEG XL codec, and the DNA encoding module, implemented using a modified Raptor Code implementation following the RU10 (Raptor Unsystematic) description. The code for encoding and decoding, as well as the objective metrics results, plots and biochemical constraints analysis are available on ISO Documents system with document number WG1M101013-ICQ-EPFL submission to the JPEG DNA CfP."], "authors": "Davi Lazzarotto"},
{"Title": "Novel 3D Geometry-Based Stochastic Models for Non-Isotropic MIMO Vehicle-to-Vehicle Channels", "abs": ["This paper proposes a novel three-dimensional (3D) theoretical regular-shaped geometry-based stochastic model (RS-GBSM) and the corresponding sum-of-sinusoids (SoS) simulation model for non-isotropic multiple-input multiple-output (MIMO) vehicle-to-vehicle (V2V) Ricean fading channels. The proposed RS-GBSM, combining line-of-sight (LoS) components, a two-sphere model, and an elliptic-cylinder model, has the ability to study the impact of the vehicular traffic density (VTD) on channel statistics, and jointly considers the azimuth and elevation angles by using the von Mises Fisher distribution. Moreover, a novel parameter computation method is proposed for jointly calculating the azimuth and elevation angles in the SoS channel simulator. Based on the proposed 3D theoretical RS-GBSM and its SoS simulation model, statistical properties are derived and thoroughly investigated. The impact of the elevation angle in the 3D model on key statistical properties is investigated by comparing with those of the corresponding two-dimensional (2D) model. It is demonstrated that the 3D model is more accurate to characterize real V2V channels, in particular for pico cell scenarios. Finally, close agreement is achieved between the theoretical model, SoS simulation model, and simulation results, demonstrating the utility of the proposed models."], "authors": "Yi Yuan"},
{"Title": "Broad Beam Reflection for RIS-Assisted MIMO Systems with Planar Arrays", "abs": ["While reconfigurable intelligent surface (RIS)-aided user-specific beamforming has been vastly investigated, the aspect of utilizing RISs for assisting cell-specific transmission has been largely unattended. Aiming to fill this gap, we study a downlink broadcasting scenario where a base station (BS) sends a cell-specific signal to all the users located in a wide angular area with the assistance of a dual-polarized RIS. We utilize the polarization degree of freedom offered by this type of RIS and design the phase configurations in the two polarizations in such a way that the RIS can radiate a broad beam, thereby uniformly covering all azimuth and elevation angles where the users might reside. Specifically, the per-polarization configuration matrices are designed in such a way that the total power-domain array factor becomes spatially flat over all observation angles implying that the RIS can preserve the broad radiation pattern of a single element while boosting its gain proportionally to its aperture size. We validate the mathematical analyses via numerical simulations."], "authors": "Parisa Ramezani"},
{"Title": "EEG-Based Reaction Time Prediction with Fuzzy Common Spatial Patterns and Phase Cohesion using Deep Autoencoder Based Data Fusion", "abs": ["Drowsiness state of a driver is a topic of extensive discussion due to its significant role in causing traffic accidents. This research presents a novel approach that combines Fuzzy Common Spatial Patterns (CSP) optimised Phase Cohesive Sequence (PCS) representations and fuzzy CSP-optimized signal amplitude representations. The research aims to examine alterations in Electroencephalogram (EEG) synchronisation between a state of alertness and drowsiness, forecast drivers' reaction times by analysing EEG data, and subsequently identify the presence of drowsiness. The study's findings indicate that this approach successfully distinguishes between alert and drowsy mental states. By employing a Deep Autoencoder-based data fusion technique and a regression model such as Support Vector Regression (SVR) or Least Absolute Shrinkage and Selection Operator (LASSO), the proposed method outperforms using individual feature sets in combination with a regressor model. This superiority is measured by evaluating the Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and Correlation Coefficient (CC). In other words, the fusion of autoencoder-based amplitude EEG power features and PCS features, when used in regression, outperforms using either of these features alone in a regressor model. Specifically, the proposed data fusion method achieves a 14.36% reduction in RMSE, a 25.12% reduction in MAPE, and a 10.12% increase in CC compared to the baseline model using only individual amplitude EEG power features and regression."], "authors": "Vivek Singh"},
{"Title": "Investigation on data fusion of sun-induced chlorophyll fluorescence and reflectance for photosynthetic capacity of rice", "abs": ["Studying crop photosynthesis is crucial for improving yield, but current methods are labor-intensive. This research aims to enhance accuracy by combining leaf reflectance and sun-induced chlorophyll fluorescence (SIF) signals to estimate key photosynthetic traits in rice. The study analyzes 149 leaf samples from two rice cultivars, considering reflectance, SIF, chlorophyll, carotenoids, and CO2 response curves. After noise removal, SIF and reflectance spectra are used for data fusion at different levels (raw, feature, and decision). Competitive adaptive reweighted sampling (CARS) extracts features, and partial least squares regression (PLSR) builds regression models. Results indicate that using either reflectance or SIF alone provides modest estimations for photosynthetic traits. However, combining these data sources through measurement-level data fusion significantly improves accuracy, with mid-level and decision-level fusion also showing positive outcomes. In particular, decision-level fusion enhances predictive capabilities, suggesting the potential for efficient crop phenotyping. Overall, sun-induced chlorophyll fluorescence spectra effectively predict rice's photosynthetic capacity, and data fusion methods contribute to increased accuracy, paving the way for high-throughput crop phenotyping."], "authors": "Yu-an Zhou"},
{"Title": "Acoustic Prompt Tuning: Empowering Large Language Models with Audition Capabilities", "abs": ["The auditory system plays a substantial role in shaping the overall human perceptual experience. While prevailing large language models (LLMs) and visual language models (VLMs) have shown their promise in solving a wide variety of vision and language understanding tasks, only a few of them can be generalised to the audio domain without compromising their domain-specific capacity. In this work, we introduce Acoustic Prompt Turning (APT), a new adapter extending LLMs and VLMs to the audio domain by soft prompting only. Specifically, APT applies an instruction-aware audio aligner to generate soft prompts, conditioned on both input text and sounds, as language model inputs. To mitigate the data scarcity in the audio domain, a multi-task learning strategy is proposed by formulating diverse audio tasks in a sequence-to-sequence manner. Moreover, we improve the framework of audio language model by using interleaved audio-text embeddings as the input sequence. This improved framework imposes zero constraints on the input format and thus is capable of tackling more understanding tasks, such as few-shot audio classification and audio reasoning. To further evaluate the reasoning ability of audio networks, we propose natural language audio reasoning (NLAR), a new task that analyses across two audio clips by comparison and summarization. Experiments show that APT-enhanced LLMs (namely APT-LLMs) achieve competitive results compared to the expert models (i.e., the networks trained on the targeted datasets) across various tasks. We finally demonstrate the APT's ability in extending frozen VLMs to the audio domain without finetuning, achieving promising results in the audio-visual question and answering task. Our code and model weights are released at", "."], "authors": "Jinhua Liang"},
{"Title": "Learning domain-invariant classifiers for infant cry sounds", "abs": ["The issue of domain shift remains a problematic phenomenon in most real-world datasets and clinical audio is no exception. In this work, we study the nature of domain shift in a clinical database of infant cry sounds acquired across different geographies. We find that though the pitches of infant cries are similarly distributed regardless of the place of birth, other characteristics introduce peculiar biases into the data. We explore methodologies for mitigating the impact of domain shift in a model for identifying neurological injury from cry sounds. We adapt unsupervised domain adaptation methods from computer vision which learn an audio representation that is domain-invariant to hospitals and is task discriminative. We also propose a new approach, target noise injection (TNI), for unsupervised domain adaptation which requires neither labels nor training data from the target domain. Our best-performing model significantly improves target accuracy by 7.2%, without negatively affecting the source domain."], "authors": "Charles C. Onu"},
{"Title": "Intrinsically motivated graph exploration using network theories of human curiosity", "abs": ["Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by nodes visited in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to longer exploratory walks and larger environments than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bear particular relevance for recommender systems. We demonstrate that next-node recommendations considering curiosity are more predictive of human choices than PageRank centrality in several real-world graph environments."], "authors": "Shubhankar P. Patankar"},
{"Title": "A Novel Patent Similarity Measurement Methodology: Semantic Distance and Technological Distance", "abs": ["Patent similarity analysis plays a crucial role in evaluating the risk of patent infringement. Nonetheless, this analysis is predominantly conducted manually by legal experts, often resulting in a time-consuming process. Recent advances in natural language processing technology offer a promising avenue for automating this process. However, methods for measuring similarity between patents still rely on experts manually classifying patents. Due to the recent development of artificial intelligence technology, a lot of research is being conducted focusing on the semantic similarity of patents using natural language processing technology. However, it is difficult to accurately analyze patent data, which are legal documents representing complex technologies, using existing natural language processing technologies. To address these limitations, we propose a hybrid methodology that takes into account bibliographic similarity, measures the similarity between patents by considering the semantic similarity of patents, the technical similarity between patents, and the bibliographic information of patents. Using natural language processing techniques, we measure semantic similarity based on patent text and calculate technical similarity through the degree of coexistence of International patent classification (IPC) codes. The similarity of bibliographic information of a patent is calculated using the special characteristics of the patent: citation information, inventor information, and assignee information. We propose a model that assigns reasonable weights to each similarity method considered. With the help of experts, we performed manual similarity evaluations on 420 pairs and evaluated the performance of our model based on this data. We have empirically shown that our method outperforms recent natural language processing techniques."], "authors": "Yongmin Yoo"},
{"Title": "Causally estimating the effect of YouTube's recommender system using counterfactual bots", "abs": ["In recent years, critics of online platforms have raised concerns about the ability of recommendation algorithms to amplify problematic content, with potentially radicalizing consequences. However, attempts to evaluate the effect of recommenders have suffered from a lack of appropriate counterfactuals -- what a user would have viewed in the absence of algorithmic recommendations -- and hence cannot disentangle the effects of the algorithm from a user's intentions. Here we propose a method that we call ``counterfactual bots'' to causally estimate the role of algorithmic recommendations on the consumption of highly partisan content. By comparing bots that replicate real users' consumption patterns with ``counterfactual'' bots that follow rule-based trajectories, we show that, on average, relying exclusively on the recommender results in less partisan consumption, where the effect is most pronounced for heavy partisan consumers. Following a similar method, we also show that if partisan consumers switch to moderate content, YouTube's sidebar recommender ``forgets'' their partisan preference within roughly 30 videos regardless of their prior history, while homepage recommendations shift more gradually towards moderate content. Overall, our findings indicate that, at least since the algorithm changes that YouTube implemented in 2019, individual consumption patterns mostly reflect individual preferences, where algorithmic recommendations play, if anything, a moderating role."], "authors": "Homa Hosseinmardi"},
{"Title": "Rooted America: Immobility and Segregation of the Intercounty Migration Network", "abs": ["Despite the popular narrative that the United States is a \"land of mobility,\" the country may have become a \"rooted America\" after a decades-long decline in migration rates. This article interrogates the lingering question about the social forces that limit migration, with an empirical focus on internal migration in the United States. We propose a systemic, network model of migration flows, combining demographic, economic, political, and geographic factors and network dependence structures that reflect the internal dynamics of migration systems. Using valued temporal exponential-family random graph models, we model the network of intercounty migration flows from 2011 to 2015. Our analysis reveals a pattern of segmented immobility, where fewer people migrate between counties with dissimilar political contexts, levels of urbanization, and racial compositions. Probing our model using \"knockout experiments\" suggests one would have observed approximately 4.6 million (27 percent) more intercounty migrants each year were the segmented immobility mechanisms inoperative. This article offers a systemic view of internal migration and reveals the social and political cleavages that underlie geographic immobility in the United States."], "authors": "Peng Huang"},
{"Title": "Learning common structures in a collection of networks. An application to food webs", "abs": ["Let a collection of networks represent interactions within several (social or ecological) systems. We pursue two objectives: identifying similarities in the topological structures that are held in common between the networks and clustering the collection into sub-collections of structurally homogeneous networks. We tackle these two questions with a probabilistic model based approach. We propose an extension of the Stochastic Block Model (SBM) adapted to the joint modeling of a collection of networks. The networks in the collection are assumed to be independent realizations of SBMs. The common connectivity structure is imposed through the equality of some parameters. The model parameters are estimated with a variational Expectation-Maximization (EM) algorithm. We derive an ad-hoc penalized likelihood criterion to select the number of blocks and to assess the adequacy of the consensus found between the structures of the different networks. This same criterion can also be used to cluster networks on the basis of their connectivity structure. It thus provides a partition of the collection into subsets of structurally homogeneous networks. The relevance of our proposition is assessed on two collections of ecological networks. First, an application to three stream food webs reveals the homogeneity of their structures and the correspondence between groups of species in different ecosystems playing equivalent ecological roles. Moreover, the joint analysis allows a finer analysis of the structure of smaller networks. Second, we cluster 67 food webs according to their connectivity structures and demonstrate that five mesoscale structures are sufficient to describe this collection."], "authors": "Saint-Clair Chabert-Liddell"},
{"Title": "A Stochastic Block Model Approach for the Analysis of Multilevel Networks: an Application to the Sociology of Organizations", "abs": ["A multilevel network is defined as the junction of two interaction networks, one level representing the interactions between individuals and the other the interactions between organizations. The levels are linked by an affiliation relationship, each individual belonging to a unique organization. A new Stochastic Block Model is proposed as a unified probalistic framework tailored for multilevel networks. This model contains latent blocks accounting for heterogeneity in the patterns of connection within each level and introducing dependencies between the levels. The sought connection patterns are not specified a priori which makes this approach flexible. Variational methods are used for the model inference and an Integrated Classified Likelihood criterion is developed for choosing the number of blocks and also for deciding whether the two levels are dependent or not. A comprehensive simulation study exhibits the benefit of considering this approach, illustrates the robustness of the clustering and highlights the reliability of the criterion used for model selection. This approach is applied on a sociological dataset collected during a television program trade fair, the inter-organizational level being the economic network between companies and the inter-individual level being the informal network between their representatives. It brings a synthetic representation of the two networks unraveling their intertwined structure and confirms the coopetition at stake."], "authors": "Saint-Clair Chabert-Liddell"},
{"Title": "Large Language Models of Code Fail at Completing Code with Potential Bugs", "abs": ["Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs -- anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CODEGEN-2B-MONO on test cases of buggy-HumanEval drop more than 50% given a single potential bug in the context. Finally, we investigate several post-hoc methods for mitigating the adverse effect of potential bugs and find that there remains a significant gap in post-mitigation performance."], "authors": "Tuan Dinh"},
{"Title": "A Comparative Study of Text Embedding Models for Semantic Text Similarity in Bug Reports", "abs": ["Bug reports are an essential aspect of software development, and it is crucial to identify and resolve them quickly to ensure the consistent functioning of software systems. Retrieving similar bug reports from an existing database can help reduce the time and effort required to resolve bugs. In this paper, we compared the effectiveness of semantic textual similarity methods for retrieving similar bug reports based on a similarity score. We explored several embedding models such as TF-IDF (Baseline), FastText, Gensim, BERT, and ADA. We used the Software Defects Data containing bug reports for various software projects to evaluate the performance of these models. Our experimental results showed that BERT generally outperformed the rest of the models regarding recall, followed by ADA, Gensim, FastText, and TFIDF. Our study provides insights into the effectiveness of different embedding methods for retrieving similar bug reports and highlights the impact of selecting the appropriate one for this task. Our code is available on GitHub."], "authors": "Avinash Patil"},
{"Title": "On the Benefits of Semi-Supervised Test Case Generation for Simulation Models", "abs": ["Testing complex simulation models can be expensive and time consuming. Current state-of-the-art methods that explore this problem are fully-supervised; i.e. they require that all examples are labeled. On the other hand, the GenClu system (introduced in this paper) takes a semi-supervised approach; i.e. (a) only a small subset of information is actually labeled (via simulation) and (b) those labels are then spread across the rest of the data. When applied to five open-source simulation models of cyber-physical systems, GenClu's test generation can be multiple orders of magnitude faster than the prior state of the art. Further, when assessed via mutation testing, tests generated by GenClu were as good or better than anything else tested here. Hence, we recommend semi-supervised methods over prior methods (evolutionary search and fully-supervised learning)."], "authors": "Xiao Ling"},
{"Title": "SmartChoices: Augmenting Software with Learned Implementations", "abs": ["We are living in a golden age of machine learning. Powerful models perform many tasks far better than is possible using traditional software engineering approaches alone. However, developing and deploying these models in existing software systems remains challenging. In this paper, we present SmartChoices, a novel approach to incorporating machine learning into mature software stacks easily, safely, and effectively. We highlight key design decisions and present case studies applying SmartChoices within a range of large-scale industrial systems."], "authors": "Daniel Golovin"},
{"Title": "CodeScore: Evaluating Code Generation by Learning Code Execution", "abs": ["A proper code evaluation metric (CEM) profoundly impacts the evolution of code generation, which is an important research field in NLP and software engineering. Prevailing match-based CEMs (e.g., BLEU, Accuracy, and CodeBLEU) suffer from two significant drawbacks. 1. They primarily measure the surface differences between codes without considering their functional equivalence. However, functional equivalence is pivotal in evaluating the effectiveness of code generation, as different codes can perform identical operations. 2. They are predominantly designed for the Ref-only input format. However, code evaluation necessitates versatility in input formats. Aside from Ref-only, there are NL-only and Ref\\&NL formats, which existing match-based CEMs cannot effectively accommodate. In this paper, we propose CodeScore, a large language model (LLM)-based CEM, which estimates the functional correctness of generated code on three input types. To acquire CodeScore, we present UniCE, a unified code generation learning framework, for LLMs to learn code execution (i.e., learning PassRatio and Executability of generated code) with unified input. Extensive experimental results on multiple code evaluation datasets demonstrate that CodeScore absolutely improves up to 58.87% correlation with functional correctness compared to other CEMs, achieves state-of-the-art performance, and effectively handles three input formats."], "authors": "Yihong Dong"},
{"Title": "ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised representations", "abs": ["We present ParrotTTS, a modularized text-to-speech synthesis model leveraging disentangled self-supervised speech representations. It can train a multi-speaker variant effectively using transcripts from a single speaker. ParrotTTS adapts to a new language in low resource setup and generalizes to languages not seen while training the self-supervised backbone. Moreover, without training on bilingual or parallel examples, ParrotTTS can transfer voices across languages while preserving the speaker specific characteristics, e.g., synthesizing fluent Hindi speech using a French speaker's voice and accent. We present extensive results in monolingual and multi-lingual scenarios. ParrotTTS outperforms state-of-the-art multi-lingual TTS models using only a fraction of paired data as latter."], "authors": "Neil Shah"},
{"Title": "H_eval: A new hybrid evaluation metric for automatic speech recognition tasks", "abs": ["Many studies have examined the shortcomings of word error rate (WER) as an evaluation metric for automatic speech recognition (ASR) systems. Since WER considers only literal word-level correctness, new evaluation metrics based on semantic similarity such as semantic distance (SD) and BERTScore have been developed. However, we found that these metrics have their own limitations, such as a tendency to overly prioritise keywords. We propose H_eval, a new hybrid evaluation metric for ASR systems that considers both semantic correctness and error rate and performs significantly well in scenarios where WER and SD perform poorly. Due to lighter computation compared to BERTScore, it offers 49 times reduction in metric computation time. Furthermore, we show that H_eval correlates strongly with downstream NLP tasks. Also, to reduce the metric calculation time, we built multiple fast and lightweight models using distillation techniques"], "authors": "Zitha Sasindran"},
{"Title": "Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR", "abs": ["In this paper, we aim to create weak alignment supervision from an existing hybrid system to aid the end-to-end modeling of automatic speech recognition. Towards this end, we use the existing hybrid ASR system to produce triphone alignments of the training audios. We then create a cross-entropy loss at a certain layer of the encoder using the derived alignments. In contrast to the general one-hot cross-entropy losses, here we use a cross-entropy loss with a label smoothing parameter to regularize the supervision. As a comparison, we also conduct the experiments with one-hot cross-entropy losses and CTC losses with loss weighting. The results show that placing the weak alignment supervision with the label smoothing parameter of 0.5 at the third encoder layer outperforms the other two approaches and leads to about 5\\% relative WER reduction on the TED-LIUM 2 dataset over the baseline. We see similar improvements when applying the method out-of-the-box on a Tagalog end-to-end ASR system."], "authors": "Jintao Jiang"},
{"Title": "MDSC: Towards Evaluating the Style Consistency Between Music and Dance", "abs": ["We propose MDSC(Music-Dance-Style Consistency), the first evaluation metric that assesses to what degree the dance moves and music match. Existing metrics can only evaluate the motion fidelity and diversity and the degree of rhythmic matching between music and dance. MDSC measures how stylistically correlated the generated dance motion sequences and the conditioning music sequences are. We found that directly measuring the embedding distance between motion and music is not an optimal solution. We instead tackle this through modeling it as a clustering problem. Specifically, 1) we pre-train a music encoder and a motion encoder, then 2) we learn to map and align the motion and music embedding in joint space by jointly minimizing the intra-cluster distance and maximizing the inter-cluster distance, and 3) for evaluation purposes, we encode the dance moves into embedding and measure the intra-cluster and inter-cluster distances, as well as the ratio between them. We evaluate our metric on the results of several music-conditioned motion generation methods, combined with user study, we found that our proposed metric is a robust evaluation metric in measuring the music-dance style correlation."], "authors": "Zixiang Zhou"},
{"Title": "Active Admission Control in a P2P Distributed Environment for Capacity Efficient Livestreaming in Mobile Wireless Networks", "abs": ["In this study, the Active Control in an Intelligent and Distributed Environment (ACIDE) media distribution model solution and algorithms are proposed for livestreaming in capacity efficient mobile wireless networks. The elements of the ACIDE model are a base station and a cluster formed by a number of peers able to establish peer to peer communications. The cluster peers are selected from a group of users interested in livestreaming the same media. The ACIDE model solution minimizes the bandwidth allocated to a cluster of n peers such that an uninterrupted media play for all peers is guaranteed. The livestream media is sent to the peers in packages and every media package is divided into n blocks. The blocks are distributed to the n peers of a cluster in two phases, such that the base station bandwidth is utilized during first phase only. The allocated bandwidth, the amount of bandwidth the base station has to allocate to a cluster, is minimized and its lower bound is equal to the bandwidth required for multicasting. In this study, the ACIDE model is used to address the problem of how to find the maximum number of peers n, chosen from a group of N users, that can be admitted to a cluster knowing the given allocated bandwidth, the amount of bandwidth that a base station allocates to a cluster in advance, prior to admitting users. When users become peers of an ACIDE cluster, the network capacity, the total number of users who are able to access live media, increases meaning that network resources are used more efficiently. The problem of finding the maximum number of peers n is addressed as an optimization problem, with the objective of having the entire given allocated bandwidth used by the peers admitted to the cluster. This problem is NP-complete and a non-optimal solution is proposed for peers selection such that all admitted peers play media continuously."], "authors": "Andrei Negulescu"},
{"Title": "Vision-Based Uncertainty-Aware Motion Planning based on Probabilistic Semantic Segmentation", "abs": ["For safe operation, a robot must be able to avoid collisions in uncertain environments. Existing approaches for motion planning under uncertainties often assume parametric obstacle representations and Gaussian uncertainty, which can be inaccurate. While visual perception can deliver a more accurate representation of the environment, its use for safe motion planning is limited by the inherent miscalibration of neural networks and the challenge of obtaining adequate datasets. To address these limitations, we propose to employ ensembles of deep semantic segmentation networks trained with massively augmented datasets to ensure reliable probabilistic occupancy information. To avoid conservatism during motion planning, we directly employ the probabilistic perception in a scenario-based path planning approach. A velocity scheduling scheme is applied to the path to ensure a safe motion despite tracking inaccuracies. We demonstrate the effectiveness of the massive data augmentation in combination with deep ensembles and the proposed scenario-based planning approach in comparisons to state-of-the-art methods and validate our framework in an experiment with a human hand as an obstacle."], "authors": "Ralf Römer"},
{"Title": "Distance-coupling as an Approach to Position and Formation Control", "abs": ["Studies of coordinated motion in autonomous vehicle groups have become a significant topic of interest in recent years. In this paper, we study the case when the agents are limited to distance measurements from predetermined reference points, or anchors. A novel approach, referred to as distance-coupling, is proposed for approximating agent positions from anchor distances. By taking the difference between squared distance functions, we cancel out the quadratic term and obtain a linear function of the position for the point of interest. We apply this method to the homing problem and prove Lyapunov stability with and without anchor placement error; defining bounds on the region of attraction when the anchors are linearly transformed from their desired positions. To further increase complexity, we show how the policy can be implemented on the formation control problem for a set of autonomous agents. In this context, we prove the existence of the set of equilibria for the distance-coupled formation controller and make preliminary claims on its convergence. The performance for both controllers are subsequently validated through simulation."], "authors": "Michael Napoli"},
{"Title": "Towards an Efficient Simulation Approach for Transmission Systems with ICT Infrastructures", "abs": ["With the transition towards a smart grid, Information and Communications Technology (ICT) infrastructures play a growing role in the operation of transmission systems. Cyber-physical systems are usually studied using co-simulation. The latter allows to leverage existing simulators and models for both power systems and communication networks. A major drawback of co-simulation is however the computation time. Indeed, simulators have to be frequently paused in order to stay synchronised and to exchange information. This is especially true for large systems for which lots of interactions between the two domains occur. We thus propose a self-consistent simulation approach as an alternative to co-simulation. We compare the two approaches on the IEEE 39-bus test system equipped with an all-PMU state estimator. We show that our approach can reach the same accuracy as co-simulation, while using drastically less computer resources."], "authors": "Frédéric Sabot"},
{"Title": "Security Defense of Large Scale Networks Under False Data Injection Attacks: An Attack Detection Scheduling Approach", "abs": ["In large-scale networks, communication links between nodes are easily injected with false data by adversaries. This paper proposes a novel security defense strategy from the perspective of attack detection scheduling to ensure the security of the network. Based on the proposed strategy, each sensor can directly exclude suspicious sensors from its neighboring set. First, the problem of selecting suspicious sensors is formulated as a combinatorial optimization problem, which is non-deterministic polynomial-time hard (NP-hard). To solve this problem, the original function is transformed into a submodular function. Then, we propose a distributed attack detection scheduling algorithm based on the sequential submodular optimization theory, which incorporates \\emph{expert problem} to better utilize historical information to guide the sensor selection task at the current moment. For different attack strategies, theoretical results show that the average optimization rate of the proposed algorithm has a lower bound, and the error expectation for any subset is bounded. In addition, under two kinds of insecurity conditions, the proposed algorithm can guarantee the security of the entire network from the perspective of the augmented estimation error. Finally, the effectiveness of the proposed method is verified by the numerical simulation and practical experiment."], "authors": "Yuhan Suo"},
{"Title": "A historical review of the Cauchy-Riemann equations and the Cauchy Theorem", "abs": ["In this article we take a historical tour through the Cauchy-Riemann equations and their relationship with Cauchy's theorem on the independence with respect to the path of the integral of a holomorphic function. Because of its importance we do a detailed and updated study of the contributions of d'Alembert and Euler to these topics. We also review the Cauchy works about the passage from the real to imaginary by paying attention to some arguments he uses that are not clear enough. At the end we comment briefly the evolution of Green's formula and its relation with the above problems."], "authors": "Julià Cufí"},
{"Title": "Harnessing Large Language Models to Enhance Self-Regulated Learning via Formative Feedback", "abs": ["Effectively supporting students in mastering all facets of self-regulated learning is a central aim of teachers and educational researchers. Prior research could demonstrate that formative feedback is an effective way to support students during self-regulated learning (SRL). However, for formative feedback to be effective, it needs to be tailored to the learners, requiring information about their learning progress. In this work, we introduce LEAP, a novel platform that utilizes advanced large language models (LLMs), such as ChatGPT, to provide formative feedback to students. LEAP empowers teachers with the ability to effectively pre-prompt and assign tasks to the LLM, thereby stimulating students' cognitive and metacognitive processes and promoting self-regulated learning. We demonstrate that a systematic prompt design based on theoretical principles can provide a wide range of types of scaffolds to students, including sense-making, elaboration, self-explanation, partial task-solution scaffolds, as well as metacognitive and motivational scaffolds. In this way, we emphasize the critical importance of synchronizing educational technological advances with empirical research and theoretical frameworks."], "authors": "Steffen Steinert"},
{"Title": "A student experiment on error analysis and uncertainties based on mobile--device sensors", "abs": ["Science students must deal with the errors inherent to all physical measurements and be conscious of the necessity to express their as a best estimate and a range of uncertainty. Errors are routinely classified as statistical or systematic. Although statistical errors are usually dealt with in the first years of science studies, the typical approaches are based on performing manually repetitive observations. Here, based on data recorded with the sensors present in many mobile devices a set of laboratory experiments to teach error and uncertainties is proposed. The main aspects addressed are the physical meaning of the mean value and standard deviation, and the interpretation of histograms and distributions. Other activities focus on the intensity of the fluctuations in different situations, such as placing the device on a table or held in the hand in different ways and the number of measurements in an interval centered on the mean value as a function of the width expressed in terms of the standard deviation. As applications to every day situations we discuss the smoothness of a road or the different positions to take photographs both of them quantified in terms of the fluctuations registered by the accelerometer. This kind of experiments contributes to gaining a deep insight into modern technologies and statistical errors and, finally, to motivate and encourage engineering and science students."], "authors": "Martin Monteiro"},
{"Title": "Using mobile-device sensors to teach students error analysis", "abs": ["Science students must deal with the errors inherent to all physical measurements and be conscious of the need to expressvthem as a best estimate and a range of uncertainty. Errors are routinely classified as statistical or systematic. Although statistical errors are usually dealt with in the first years of science studies, the typical approaches are based on manually performing repetitive observations. Our work proposes a set of laboratory experiments to teach error and uncertainties based on data recorded with the sensors available in many mobile devices. The main aspects addressed are the physical meaning of the mean value and standard deviation, and the interpretation of histograms and distributions. The normality of the fluctuations is analyzed qualitatively comparing histograms with normal curves and quantitatively comparing the number of observations in intervals to the number expected according to a normal distribution and also performing a Chi-squared test. We show that the distribution usually follows a normal distribution, however, when the sensor is placed on top of a loudspeaker playing a pure tone significant differences with a normal distribution are observed. As applications to every day situations we discuss the intensity of the fluctuations in different situations, such as placing the device on a table or holding it with the hands in different ways. Other activities are focused on the smoothness of a road quantified in terms of the fluctuations registered by the accelerometer. The present proposal contributes to gaining a deep insight into modern technologies and statistical errors and, finally, motivating and encouraging engineering and science students."], "authors": "Martin Monteiro"},
{"Title": "A home-lab to study uncertainties using smartphone sensors and determine the optimal number of measurements", "abs": ["We present a home-lab experimental activity, successfully proposed to our students during covid19 pandemic, based on \\textit{state-of-the-art} technologies to teach error analysis and uncertainties to science and engineering students. In the last decade the appearance of smartphones considerably affected our daily life. Thanks to their built-in sensors, this revolution has impacted in many areas and, in particular, the educational field. Here we show how to use smartphone sensors to teach fundamental concepts for science students such as any measurement is useless unless a confidence interval is specified or how to determine if a result agrees with a model, or to discern a new phenomenon from others already known. We explain how to obtain and analyse experimental fluctuations and discuss in relation with the Gaussian distribution. In another application we show how to determine the optimal number of measurements as a function of the standard error and the digital resolution of a given sensor."], "authors": "Martin Monteiro"},
{"Title": "Augmented Reality Technology in Teaching about Physics: A systematic review of opportunities and challenges", "abs": ["The use of augmented reality (AR) allows for the integration of digital information onto our perception of the physical world. In this article, we present a comprehensive review of previously published literature on the implementation of augmented reality in physics education, at the school and the university level. Our review includes an analysis of 96 papers from the Scopus and Eric databases, all of which were published between January 1st, 2012 and January 1st, 2023. We evaluated how AR has been used for facilitating learning about physics. Potential AR-based learning activities for different physics topics have been summarized and opportunities, as well as challenges associated with AR-based learning of physics have been reported. It has been shown that AR technologies may facilitate physics learning by: providing complementary visualizations, optimizing cognitive load, allowing for haptic learning, reducing task completion time and promoting collaborative inquiry. The potential disadvantages of using AR in physics teaching are mainly related to the shortcomings of software and hardware technologies (e.g., camera freeze, visualization delay) and extraneous cognitive load (e.g., paying more attention to secondary details than to constructing target knowledge)."], "authors": "A. Vidak"},
{"Title": "Powers of the Universe: Empowering primary school students with the powers of ten notation", "abs": ["Numbers, both very large and very small, are crucially important for understanding the modern world. This paper assesses trials of a mathematics and physics module called Powers of the Universe in which arithmetic with extreme numbers (large and small) is developed through early learning of the powers of ten notation. We trialled a 6-hour progression of lessons based on activities and group learning with students aged 7-13 years. We measured students' ability to estimate, compare, and calculate extreme numbers using pre and post-tests to evaluate the program. Results demonstrated students' strong enthusiasm and positive learning outcomes in areas normally assumed to be beyond the capability of students in this age group. We discuss the age dependence of some results and suggest an optimum strategy for enhancing primary school mathematics. The module has been delivered, as part of a broader five-module program called Maths for Einstein's Universe, that aims to reduce maths anxiety through programs with direct relevance to the modern world and reduced emphasis on exactness."], "authors": "Anastasia Lonshakova"},
{"Title": "Wordification: A New Way of Teaching English Spelling Patterns", "abs": ["Literacy, or the ability to read and write, is a crucial indicator of success in life and greater society. It is estimated that 85% of people in juvenile delinquent systems cannot adequately read or write, that more than half of those with substance abuse issues have complications in reading or writing and that two-thirds of those who do not complete high school lack proper literacy skills. Furthermore, young children who do not possess reading skills matching grade level by the fourth grade are approximately 80% likely to not catch up at all. Many may believe that in a developed country such as the United States, literacy fails to be an issue; however, this is a dangerous misunderstanding. Globally an estimated 1.19 trillion dollars are lost every year due to issues in literacy; in the USA, the loss is an estimated 300 billion. To put it in more shocking terms, one in five American adults still fail to comprehend basic sentences. Making matters worse, the only tools available now to correct a lack of reading and writing ability are found in expensive tutoring or other programs that oftentimes fail to be able to reach the required audience. In this paper, our team puts forward a new way of teaching English spelling and word recognitions to grade school students in the United States: Wordification. Wordification is a web application designed to teach English literacy using principles of linguistics applied to the orthographic and phonological properties of words in a manner not fully utilized previously in any computer-based teaching application."], "authors": "Lexington Whalen"},
{"Title": "Telescope: Telemetry at Terabyte Scale", "abs": ["Data-hungry applications that require terabytes of memory have become widespread in recent years. To meet the memory needs of these applications, data centers are embracing tiered memory architectures with near and far memory tiers. Precise, efficient, and timely identification of hot and cold data and their placement in appropriate tiers is critical for performance in such systems. Unfortunately, the existing state-of-the-art telemetry techniques for hot and cold data detection are ineffective at the terabyte scale.", "We propose Telescope, a novel technique that profiles different levels of the application's page table tree for fast and efficient identification of hot and cold data. Telescope is based on the observation that, for a memory- and TLB-intensive workload, higher levels of a page table tree are also frequently accessed during a hardware page table walk. Hence, the hotness of the higher levels of the page table tree essentially captures the hotness of its subtrees or address space sub-regions at a coarser granularity. We exploit this insight to quickly converge on even a few megabytes of hot data and efficiently identify several gigabytes of cold data in terabyte-scale applications. Importantly, such a technique can seamlessly scale to petabyte-scale applications.", "Telescope's telemetry achieves 90%+ precision and recall at just 0.009% single CPU utilization for microbenchmarks with a 5 TB memory footprint. Memory tiering based on Telescope results in 5.6% to 34% throughput improvement for real-world benchmarks with a 1-2 TB memory footprint compared to other state-of-the-art telemetry techniques."], "authors": "Alan Nair"},
{"Title": "Large scale deployment of C-ITS: Impact assessment results of the C-Roads Greece pilots", "abs": ["This paper aims to provide insights related to the impact assessment and evaluation results from the use of CITS services in the Greek pilot of the CRoads Greece project, i.e., Attica Tollway and Egnatia Odos Tollway. The impact assessment and evaluation of the CITS services includes aspects related to user acceptance, real world pilot logs collected from the two pilots, and simulation experiments that were conducted for the impact assessment of the CITS services. The paper concludes with a roadmap and guidelines for the extended deployment of CITS services in the Greek highway and urban road networks."], "authors": "Areti Kotsi"},
{"Title": "\"Just a little bit on the outside for the whole time\": Social belonging confidence and the persistence of Machine Learning and Artificial Intelligence students", "abs": ["The growing field of machine learning (ML) and artificial intelligence (AI) presents a unique and unexplored case within persistence research, meaning it is unclear how past findings from engineering will apply to this developing field. We conduct an exploratory study to gain an initial understanding of persistence in this field and identify fruitful directions for future work. One factor that has been shown to predict persistence in engineering is belonging; we study belonging through the lens of confidence, and discuss how attention to social belonging confidence may help to increase diversity in the profession. In this research paper, we conduct a small set of interviews with students in ML/AI courses. Thematic analysis of these interviews revealed initial differences in how students see a career in ML/AI, which diverge based on interest and programming confidence. We identified how exposure and initiation, the interpretation of ML and AI field boundaries, and beliefs of the skills required to succeed might influence students' intentions to persist. We discuss differences in how students describe being motivated by social belonging and the importance of close mentorship. We motivate further persistence research in ML/AI with particular focus on social belonging and close mentorship, the role of intersectional identity, and introductory ML/AI courses."], "authors": "Katherine Mao"},
{"Title": "Measuring the Prevalence of WiFi Bottlenecks in Home Access Networks", "abs": ["As broadband Internet speeds continue to increase, the home wireless (\"WiFi\") network may more frequently become a performance bottleneck. Past research, now nearly a decade old, initially documented this phenomenon through indirect inference techniques, noting the prevalence of WiFi bottlenecks but never directly measuring them. In the intervening years, access network (and WiFi) speeds have increased, warranting a re-appraisal of this important question, particularly with renewed private and federal investment in access network infrastructure. This paper studies this question, developing a new system and measurement technique to perform direct measurements of WiFi and access network performance, ultimately collecting and analyzing a first-of-its-kind dataset of more than 13,000 joint measurements of WiFi and access network throughputs, in a real-world deployment spanning more than 50 homes, for nearly two years. Using this dataset, we re-examine the question of whether, when, and to what extent a user's home wireless network may be a performance bottleneck, particularly relative to their access connection. We do so by directly and continuously measuring the user's Internet performance along two separate components of the Internet path -- from a wireless client inside the home network to the wired point of access (e.g., the cable modem), and from the wired point of access to the user's ISP. Confirming and revising results from more than a decade ago, we find that a user's home wireless network is often the throughput bottleneck. In particular, for users with access links that exceed 800~Mbps, the user's home wireless network was the performance bottleneck 100% of the time."], "authors": "Ranya Sharma"},
{"Title": "SLAM for Multiple Extended Targets using 5G Signal", "abs": ["5th Generation (5G) mobile communication systems operating at around 28 GHz have the potential to be applied to simultaneous localization and mapping (SLAM). Most existing 5G SLAM studies estimate environment as many point targets, instead of extended targets. In this paper, we focus on the performance analysis of 5G SLAM for multiple extended targets. To evaluate the mapping performance of multiple extended targets, a new mapping error metric, named extended targets generalized optimal sub-pattern assignment (ET-GOPSA), is proposed in this paper. Compared with the existing metrics, ET-GOPSA not only considers the accuracy error of target estimation, the cost of missing detection, the cost of false detection, but also the cost of matching the estimated point with the extended target. To evaluate the performance of 5G signal in SLAM, we analyze and simulate the mapping error of 5G signal sensing by ET-GOPSA. Simulation results show that, under the condition of SNR = 10 dB, 5G signal sensing can barely meet to meet the requirements of SLAM for multiple extended targets with the carrier frequency of 28 GHz, the bandwidth of 1.23 GHz, and the antenna size of 32."], "authors": "Wangjun Jiang"},
{"Title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models", "abs": ["Large Language Models (LLMs) have seen great advance in both academia and industry, and their popularity results in numerous open-source frameworks and techniques in accelerating LLM pre-training, fine-tuning, and inference. Training and deploying LLMs are expensive as it requires considerable computing resources and memory, hence many efficient approaches have been developed for improving system pipelines as well as operators. However, the runtime performance can vary significantly across hardware and software stacks, which makes it difficult to choose the best configuration. In this work, we aim to benchmark the performance from both macro and micro perspectives. First, we benchmark the end-to-end performance of pre-training, fine-tuning, and serving LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and 70B) on three 8-GPU platforms with and without individual optimization techniques, including ZeRO, quantization, recomputation, FlashAttention. Then, we dive deeper to provide a detailed runtime analysis of the sub-modules, including computing and communication operators in LLMs. For end users, our benchmark and findings help better understand different optimization techniques, training and inference frameworks, together with hardware platforms in choosing configurations for deploying LLMs. For researchers, our in-depth module-wise analyses discover potential opportunities for future work to further optimize the runtime performance of LLMs."], "authors": "Longteng Zhang"},
{"Title": "Syntactically and semantically regular languages of lambda-terms coincide through logical relations", "abs": ["A fundamental theme in automata theory is regular languages of words and trees, and their many equivalent definitions. Salvati has proposed a generalization to regular languages of simply typed $\\lambda$-terms, defined using denotational semantics in finite sets.", "We provide here some evidence for its robustness. First, we give an equivalent syntactic characterization that naturally extends the seminal work of Hillebrand and Kanellakis connecting regular languages of words and syntactic $\\lambda$-definability. Second, we show that any finitary extensional model of the simply typed $\\lambda$-calculus, when used in Salvati's definition, recognizes exactly the same class of languages of $\\lambda$-terms as the category of finite sets does.", "The proofs of these two results rely on logical relations and can be seen as instances of a more general construction of a categorical nature, inspired by previous categorical accounts of logical relations using the gluing construction."], "authors": "Vincent Moreau"},
{"Title": "Efficient Human Pose Estimation via 3D Event Point Cloud", "abs": ["Human Pose Estimation (HPE) based on RGB images has experienced a rapid development benefiting from deep learning. However, event-based HPE has not been fully studied, which remains great potential for applications in extreme scenes and efficiency-critical conditions. In this paper, we are the first to estimate 2D human pose directly from 3D event point cloud. We propose a novel representation of events, the rasterized event point cloud, aggregating events on the same position of a small time slice. It maintains the 3D features from multiple statistical cues and significantly reduces memory consumption and computation complexity, proved to be efficient in our work. We then leverage the rasterized event point cloud as input to three different backbones, PointNet, DGCNN, and Point Transformer, with two linear layer decoders to predict the location of human keypoints. We find that based on our method, PointNet achieves promising results with much faster speed, whereas Point Transfomer reaches much higher accuracy, even close to previous event-frame-based methods. A comprehensive set of results demonstrates that our proposed method is consistently effective for these 3D backbone models in event-driven human pose estimation. Our method based on PointNet with 2048 points input achieves 82.46mm in MPJPE3D on the DHP19 dataset, while only has a latency of 12.29ms on an NVIDIA Jetson Xavier NX edge computing platform, which is ideally suitable for real-time detection with event cameras. Code is available at", "."], "authors": "Jiaan Chen"},
{"Title": "Rethinking Event-based Human Pose Estimation with 3D Event Representations", "abs": ["Human pose estimation is a fundamental and appealing task in computer vision. Traditional frame-based cameras and videos are commonly applied, yet, they become less reliable in scenarios under high dynamic range or heavy motion blur. In contrast, event cameras offer a robust solution for navigating these challenging contexts. Predominant methodologies incorporate event cameras into learning frameworks by accumulating events into event frames. However, such methods tend to marginalize the intrinsic asynchronous and high temporal resolution characteristics of events. This disregard leads to a loss in essential temporal dimension data, crucial for discerning distinct actions. To address this issue and to unlock the 3D potential of event information, we introduce two 3D event representations: the Rasterized Event Point Cloud (RasEPC) and the Decoupled Event Voxel (DEV). The RasEPC collates events within concise temporal slices at identical positions, preserving 3D attributes with statistical cues and markedly mitigating memory and computational demands. Meanwhile, the DEV representation discretizes events into voxels and projects them across three orthogonal planes, utilizing decoupled event attention to retrieve 3D cues from the 2D planes. Furthermore, we develop and release EV-3DPW, a synthetic event-based dataset crafted to facilitate training and quantitative analysis in outdoor scenes. On the public real-world DHP19 dataset, our event point cloud technique excels in real-time mobile predictions, while the decoupled event voxel method achieves the highest accuracy. Experiments on EV-3DPW demonstrate that the robustness of our proposed 3D representation methods compared to traditional RGB images and event frame techniques under the same backbones. Our code and dataset have been made publicly available at", "."], "authors": "Xiaoting Yin"},
{"Title": "Denoising Heat-inspired Diffusion with Insulators for Collision Free Motion Planning", "abs": ["Diffusion models have risen as a powerful tool in robotics due to their flexibility and multi-modality. While some of these methods effectively address complex problems, they often depend heavily on inference-time obstacle detection and require additional equipment. Addressing these challenges, we present a method that, during inference time, simultaneously generates only reachable goals and plans motions that avoid obstacles, all from a single visual input. Central to our approach is the novel use of a collision-avoiding diffusion kernel for training. Through evaluations against behavior-cloning and classical diffusion models, our framework has proven its robustness. It is particularly effective in multi-modal environments, navigating toward goals and avoiding unreachable ones blocked by obstacles, while ensuring collision avoidance."], "authors": "Junwoo Chang"},
{"Title": "Decentralized policy learning with partial observation and mechanical constraints for multiperson modeling", "abs": ["Extracting the rules of real-world multi-agent behaviors is a current challenge in various scientific and engineering fields. Biological agents independently have limited observation and mechanical constraints; however, most of the conventional data-driven models ignore such assumptions, resulting in lack of biological plausibility and model interpretability for behavioral analyses. Here we propose sequential generative models with partial observation and mechanical constraints in a decentralized manner, which can model agents' cognition and body dynamics, and predict biologically plausible behaviors. We formulate this as a decentralized multi-agent imitation-learning problem, leveraging binary partial observation and decentralized policy models based on hierarchical variational recurrent neural networks with physical and biomechanical penalties. Using real-world basketball and soccer datasets, we show the effectiveness of our method in terms of the constraint violations, long-term trajectory prediction, and partial observation. Our approach can be used as a multi-agent simulator to generate realistic trajectories using real-world data."], "authors": "Keisuke Fujii"},
{"Title": "Defense Against Smart Invaders with Swarms of Sweeping Agents", "abs": ["The goal of this research is to devise guaranteed defense policies that allow to protect a given region from the entrance of smart mobile invaders by detecting them using a team of defending agents equipped with identical line sensors. By designing cooperative defense strategies that ensure all invaders are detected, conditions on the defenders' speed are derived. Successful accomplishment of the defense task implies invaders with a known limit on their speed cannot slip past the defenders and enter the guarded region undetected. The desired outcome of the defense protocols is to defend the area and additionally to expand it as much as possible. Expansion becomes possible if the defenders' speed exceeds a critical speed that is necessary to only defend the initial region. We present results on the total search time, critical speeds and maximal expansion possible for two types of novel pincer-movement defense processes, circular and spiral, for any even number of defenders. The proposed spiral process allows to detect invaders at nearly the lowest theoretically optimal speed, and if this speed is exceeded, it also allows to expand the protected region almost to the maximal area."], "authors": "Roee M. Francos"},
{"Title": "Breaking the VLB Barrier for Oblivious Reconfigurable Networks", "abs": ["In a landmark 1981 paper, Valiant and Brebner gave birth to the study of oblivious routing and, simultaneously, introduced its most powerful and ubiquitous method: Valiant load balancing (VLB). By routing messages through a randomly sampled intermediate node, VLB lengthens routing paths by a factor of two but gains the crucial property of obliviousness. Forty years later, with datacenters handling workloads whose communication pattern varies too rapidly to allow centralized coordination, VLB continues to take center stage as a widely used - and in some cases provably optimal - way to balance load in the network obliviously to the traffic demands. However, the ability of the network to rapidly reconfigure its interconnection topology gives rise to new possibilities.", "In this work we revisit the question of whether VLB remains optimal in the novel setting of reconfigurable networks. Prior work showed that VLB achieves the optimal tradeoff between latency and guaranteed throughput. In this work we show that a strictly superior latency-throughput tradeoff is achievable when the throughput bound is relaxed to hold with high probability. The same improved tradeoff is also achievable with guaranteed throughput under time-stationary demands, provided the latency bound is relaxed to hold with high probability and that the network is allowed to be semi-oblivious, using an oblivious (randomized) connection schedule but demand-aware routing. We prove that the latter result is not achievable by any fully-oblivious reconfigurable network design, marking a rare case in which semi-oblivious routing has a provable asymptotic advantage over oblivious routing. To analyze our routing scheme we prove an exponential tail bound which may be of independent interest, concerning the distribution of values of a bilinear form on an orbit of a permutation group action."], "authors": "Tegan Wilson"},
{"Title": "UAV-assisted Semantic Communication with Hybrid Action Reinforcement Learning", "abs": ["In this paper, we aim to explore the use of uplink semantic communications with the assistance of UAV in order to improve data collection effiicency for metaverse users in remote areas. To reduce the time for uplink data collection while balancing the trade-off between reconstruction quality and computational energy cost, we propose a hybrid action reinforcement learning (RL) framework to make decisions on semantic model scale, channel allocation, transmission power, and UAV trajectory. The variables are classified into discrete type and continuous type, which are optimized by two different RL agents to generate the combined action. Simulation results indicate that the proposed hybrid action reinforcement learning framework can effectively improve the efficiency of uplink semantic data collection under different parameter settings and outperforms the benchmark scenarios."], "authors": "Peiyuan Si"},
{"Title": "Linking QKD testbeds across Europe", "abs": ["Quantum-key-distribution (QKD) networks are gaining importance and it has become necessary to analyze the most appropriate methods for their long-distance interconnection. In this paper, four different methods of interconnecting remote QKD networks are proposed. The methods are used to link three different QKD testbeds in Europe, located in Berlin, Madrid, and Poznan. Although long-distance QKD links are only emulated, the used methods can serve as a blueprint for a secure interconnection of distant QKD networks in the future. Specifically, the presented approaches combine, in a transparent way, different fiber and satellite physical media, as well as common standards of key-delivery interfaces. The testbed interconnections are designed to increase the security by utilizing multipath techniques and multiple hybridizations of QKD and post quantum cryptography (PQC) algorithms."], "authors": "Max Brauer"},
{"Title": "A survey of trends and motivations regarding Communication Service Providers' metro area network implementations", "abs": ["Relevance of research on telecommunications networks is predicated upon the implementations which it explicitly claims or implicitly subsumes. This paper supports researchers through a survey of Communications Service Providers current implementations within the metro area, and trends that are expected to shape the next-generation metro area network. The survey is composed of a quantitative component, complemented by a qualitative component carried out among field experts. Among the several findings, it has been found that service providers with large subscriber base sizes, are less agile in their response to technological change than those with smaller subscriber base sizes: thus, copper media are still an important component in the set of access network technologies. On the other hand, service providers with large subscriber base sizes are strongly committed to deploying distributed access architectures, notably using remote access nodes like remote OLT and remote MAC-PHY. This study also shows that the extent of remote node deployment for multi-access edge computing is about the same as remote node deployment for distributed access architectures, indicating that these two aspects of metro area networks are likely to be co-deployed."], "authors": "Etienne-Victor Depasquale"},
{"Title": "Digital Twin for Non-Terrestrial Networks: Vision, Challenges, and Enabling Technologies", "abs": ["This paper explores the transformative potential of digital twin (DT) technology in the context of non-terrestrial networks (NTNs). NTNs, encompassing both airborne and space-borne elements, present unique challenges in network control, management, and optimization. DT is a novel approach to design and manage complicated cyber-physical systems with a high degree of automation, intelligence, and resilience. The adoption of DTs within NTNs offers a dynamic and detailed virtual representation of the entire ecosystem, enabling real-time monitoring, simulations, and data-driven decision-making. This paper delves into the envisioned integration of DTs in NTNs, discussing the technical challenges and highlighting key enabling technologies. Emphasis is placed on technologies such as Internet of things (IoT), artificial intelligence (AI), space-based cloud computing, quantum computing, and others, providing a comprehensive overview of their potentials in empowering DT development for NTNs. In closing, we present a case study involving the implementation of a data-driven DT model to facilitate dynamic and service-oriented network slicing within an open radio access network (O-RAN) architecture for NTNs. This work contributes to shaping the future of network control and management in the dynamic and evolving landscape of non-terrestrial communication systems."], "authors": "Hayder Al-Hraishawi"},
{"Title": "Linear Oscillation: A Novel Activation Function for Vision Transformer", "abs": ["Activation functions are the linchpins of deep learning, profoundly influencing both the representational capacity and training dynamics of neural networks. They shape not only the nature of representations but also optimize convergence rates and enhance generalization potential. Appreciating this critical role, we present the Linear Oscillation (LoC) activation function, defined as $f(x) = x \\times \\sin(\\alpha x + \\beta)$. Distinct from conventional activation functions which primarily introduce non-linearity, LoC seamlessly blends linear trajectories with oscillatory deviations. The nomenclature \"Linear Oscillation\" is a nod to its unique attribute of infusing linear activations with harmonious oscillations, capturing the essence of the \"Importance of Confusion\". This concept of \"controlled confusion\" within network activations is posited to foster more robust learning, particularly in contexts that necessitate discerning subtle patterns. Our empirical studies reveal that, when integrated into diverse neural architectures, the LoC activation function consistently outperforms established counterparts like ReLU and Sigmoid. The stellar performance exhibited by the avant-garde Vision Transformer model using LoC further validates its efficacy. This study illuminates the remarkable benefits of the LoC over other prominent activation functions. It champions the notion that intermittently introducing deliberate complexity or \"confusion\" during training can spur more profound and nuanced learning. This accentuates the pivotal role of judiciously selected activation functions in shaping the future of neural network training."], "authors": "Juyoung Yun"},
{"Title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings", "abs": ["Spiking Neural Networks (SNNs) are a promising research direction for building power-efficient information processing systems, especially for temporal tasks such as speech recognition. In SNNs, delays refer to the time needed for one spike to travel from one neuron to another. These delays matter because they influence the spike arrival times, and it is well-known that spiking neurons respond more strongly to coincident input spikes. More formally, it has been shown theoretically that plastic delays greatly increase the expressivity in SNNs. Yet, efficient algorithms to learn these delays have been lacking. Here, we propose a new discrete-time algorithm that addresses this issue in deep feedforward SNNs using backpropagation, in an offline manner. To simulate delays between consecutive layers, we use 1D convolutions across time. The kernels contain only a few non-zero weights - one per synapse - whose positions correspond to the delays. These positions are learned together with the weights using the recently proposed Dilated Convolution with Learnable Spacings (DCLS). We evaluated our method on three datasets: the Spiking Heidelberg Dataset (SHD), the Spiking Speech Commands (SSC) and its non-spiking version Google Speech Commands v0.02 (GSC) benchmarks, which require detecting temporal patterns. We used feedforward SNNs with two or three hidden fully connected layers, and vanilla leaky integrate-and-fire neurons. We showed that fixed random delays help and that learning them helps even more. Furthermore, our method outperformed the state-of-the-art in the three datasets without using recurrent connections and with substantially fewer parameters. Our work demonstrates the potential of delay learning in developing accurate and precise models for temporal data processing. Our code is based on PyTorch / SpikingJelly and available at:"], "authors": "Ilyass Hammouamri"},
{"Title": "MLLMs-Augmented Visual-Language Representation Learning", "abs": ["Visual-language pre-training (VLP) has achieved remarkable success in multi-modal tasks, largely attributed to the availability of large-scale image-text datasets. In this work, we demonstrate that multi-modal large language models (MLLMs) can enhance visual-language representation learning by improving data quality. Our approach is simple, utilizing MLLMs to extend multiple captions for each image. To prevent the bias introduced by MLLMs' hallucinations and intrinsic caption styles, we propose \"text shearing\" to maintain the same length for extended captions as that of the original captions. In image-text retrieval, our method consistently obtains 5.6 ~ 35.0% and 16.8 ~ 46.1% improvement on R@1 under the fine-tuning and zero-shot settings, respectively. Notably, we obtain zero-shot results that are comparable to fine-tuning on target datasets, which encourages more exploration of the versatile use of MLLMs."], "authors": "Yanqing Liu"},
{"Title": "Llemma: An Open Language Model For Mathematics", "abs": ["We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments."], "authors": "Zhangir Azerbayev"},
{"Title": "Quantum Circuit Completeness: Extensions and Simplifications", "abs": ["Although quantum circuits have been ubiquitous for decades in quantum computing, the first complete equational theory for quantum circuits has only recently been introduced. Completeness guarantees that any true equation on quantum circuits can be derived from the equational theory. We improve this completeness result in two ways: (i) We simplify the equational theory by proving that several rules can be derived from the remaining ones. In particular, two out of the three most intricate rules are removed, the third one being slightly simplified. (ii) The complete equational theory can be extended to quantum circuits with ancillae or qubit discarding, to represent respectively quantum computations using an additional workspace, and hybrid quantum computations. We show that the remaining intricate rule can be greatly simplified in these more expressive settings, leading to equational theories where all equations act on a bounded number of qubits. The development of simple and complete equational theories for expressive quantum circuit models opens new avenues for reasoning about quantum circuits. It provides strong formal foundations for various compiling tasks such as circuit optimisation, hardware constraint satisfaction and verification."], "authors": "Alexandre Clément"},
{"Title": "Describing weighted safety with weighted LTL over product $ω$-valuation monoids", "abs": ["We define the notion of $k$-safe infinitary series over idempotent ordered totally generalized product $\\omega $-valuation monoids that satisfy specific properties. For each element $k$ of the underlying structure (different from the neutral elements of the additive, and the multiplicative operation) we determine two syntactic fragments of the weighted $LTL$ with the property that the semantics of the formulas in these fragments are $k$ -safe infinitary series. For specific idempotent ordered totally generalized product $\\omega $-valuation monoids we provide algorithms that given a weighted Büchi automaton and a weighted $LTL$ formula in these fragments, decide whether the behavior of the automaton coincides with the semantics of the formula."], "authors": "Eleni Mandrali"},
{"Title": "Robust Basket Recommendation via Noise-tolerated Graph Contrastive Learning", "abs": ["The growth of e-commerce has seen a surge in popularity of platforms like Amazon, eBay, and Taobao. This has given rise to a unique shopping behavior involving baskets - sets of items purchased together. As a less studied interaction mode in the community, the question of how should shopping basket complement personalized recommendation systems remains under-explored. While previous attempts focused on jointly modeling user purchases and baskets, the distinct semantic nature of these elements can introduce noise when directly integrated. This noise negatively impacts the model's performance, further exacerbated by significant noise (e.g., a user is misled to click an item or recognizes it as uninteresting after consuming it) within both user and basket behaviors. In order to cope with the above difficulties, we propose a novel Basket recommendation framework via Noise-tolerated Contrastive Learning, named BNCL, to handle the noise existing in the cross-behavior integration and within-behavior modeling. First, we represent the basket-item interactions as the hypergraph to model the complex basket behavior, where all items appearing in the same basket are treated as a single hyperedge. Second, cross-behavior contrastive learning is designed to suppress the noise during the fusion of diverse behaviors. Next, to further inhibit the within-behavior noise of the user and basket interactions, we propose to exploit invariant properties of the recommenders w.r.t augmentations through within-behavior contrastive learning. A novel consistency-aware augmentation approach is further designed to better identify noisy interactions with the consideration of the above two types of interactions. Our framework BNCL offers a generic training paradigm that is applicable to different backbones. Extensive experiments on three shopping transaction datasets verify the effectiveness of our proposed method."], "authors": "Xinrui He"},
{"Title": "SatCLIP: Global, General-Purpose Location Embeddings with Satellite Imagery", "abs": ["Geographic location is essential for modeling tasks in fields ranging from ecology to epidemiology to the Earth system sciences. However, extracting relevant and meaningful characteristics of a location can be challenging, often entailing expensive data fusion or data distillation from global imagery datasets. To address this challenge, we introduce Satellite Contrastive Location-Image Pretraining (SatCLIP), a global, general-purpose geographic location encoder that learns an implicit representation of locations from openly available satellite imagery. Trained location encoders provide vector embeddings summarizing the characteristics of any given location for convenient usage in diverse downstream tasks. We show that SatCLIP embeddings, pretrained on globally sampled multi-spectral Sentinel-2 satellite data, can be used in various predictive tasks that depend on location information but not necessarily satellite imagery, including temperature prediction, animal recognition in imagery, and population density estimation. Across tasks, SatCLIP embeddings consistently outperform embeddings from existing pretrained location encoders, ranging from models trained on natural images to models trained on semantic context. SatCLIP embeddings also help to improve geographic generalization. This demonstrates the potential of general-purpose location encoders and opens the door to learning meaningful representations of our planet from the vast, varied, and largely untapped modalities of geospatial data."], "authors": "Konstantin Klemmer"},
{"Title": "Fast Controllable Diffusion Models for Undersampled MRI Reconstruction", "abs": ["Supervised deep learning methods have shown promise in undersampled Magnetic Resonance Imaging (MRI) reconstruction, but their requirement for paired data limits their generalizability to the diverse MRI acquisition parameters. Recently, unsupervised controllable generative diffusion models have been applied to undersampled MRI reconstruction, without paired data or model retraining for different MRI acquisitions. However, diffusion models are generally slow in sampling and state-of-the-art acceleration techniques can lead to sub-optimal results when directly applied to the controllable generation process. This study introduces a new algorithm called Predictor-Projector-Noisor (PPN), which enhances and accelerates controllable generation of diffusion models for undersampled MRI reconstruction. Our results demonstrate that PPN produces high-fidelity MR images that conform to undersampled k-space measurements with significantly shorter reconstruction time than other controllable sampling methods. In addition, the unsupervised PPN accelerated diffusion models are adaptable to different MRI acquisition parameters, making them more practical for clinical use than supervised learning techniques."], "authors": "Wei Jiang"},
{"Title": "Token-Level Adaptation of LoRA Adapters for Downstream Task Generalization", "abs": ["This paper introduces a method for adapting LoRA adapters in smaller-sized language models to arbitrary downstream tasks. Unlike standard mixture-of-expert architectures, our method employs a gradient-free routing function to choose a weighted combination of experts without increasing the compute requirements for training or inference. The results show that token-level adaptation of LoRA adapters outperforms the base Llama-2-7b model across mathematical (GSM8K), scientific (ARC-Challenge), reading comprehension (SQuAD), and coding (CodeAlpaca-20k) tasks. Further evaluations also show that the average performance of token-level adaptation outperforms individual models fine-tuned for each of the tasks with the best performance observed in adaptation of every-other token during inference. The code for this study is made available through a public repository."], "authors": "Joshua Belofsky"},
{"Title": "Harnessing machine learning for accurate treatment of overlapping opacity species in GCMs", "abs": ["To understand high precision observations of exoplanets and brown dwarfs, we need detailed and complex general circulation models (GCMs) that incorporate hydrodynamics, chemistry, and radiation. In this study, we specifically examine the coupling between chemistry and radiation in GCMs and compare different methods for mixing opacities of different chemical species in the correlated-k assumption, when equilibrium chemistry cannot be assumed. We propose a fast machine learning method based on DeepSets (DS), which effectively combines individual correlated-k opacities (k-tables). We evaluate the DS method alongside other published methods like adaptive equivalent extinction (AEE) and random overlap with rebinning and resorting (RORR). We integrate these mixing methods into our GCM (expeRT/MITgcm) and assess their accuracy and performance for the example of the hot Jupiter HD~209458 b. Our findings indicate that the DS method is both accurate and efficient for GCM usage, whereas RORR is too slow. Additionally, we observe that the accuracy of AEE depends on its specific implementation and may introduce numerical issues in achieving radiative transfer solution convergence. We then apply the DS mixing method in a simplified chemical disequilibrium situation, where we model the rainout of TiO and VO, and confirm that the rainout of TiO and VO would hinder the formation of a stratosphere. To further expedite the development of consistent disequilibrium chemistry calculations in GCMs, we provide documentation and code for coupling the DS mixing method with correlated-k radiative transfer solvers. The DS method has been extensively tested to be accurate enough for GCMs, however, other methods might be needed for accelerating atmospheric retrievals."], "authors": "Aaron David Schneider"},
{"Title": "Universal representation by Boltzmann machines with Regularised Axons", "abs": ["It is widely known that Boltzmann machines are capable of representing arbitrary probability distributions over the values of their visible neurons, given enough hidden ones. However, sampling -- and thus training -- these models can be numerically hard. Recently we proposed a regularisation of the connections of Boltzmann machines, in order to control the energy landscape of the model, paving a way for efficient sampling and training. Here we formally prove that such regularised Boltzmann machines preserve the ability to represent arbitrary distributions. This is in conjunction with controlling the number of energy local minima, thus enabling easy \\emph{guided} sampling and training. Furthermore, we explicitly show that regularised Boltzmann machines can store exponentially many arbitrarily correlated visible patterns with perfect retrieval, and we connect them to the Dense Associative Memory networks."], "authors": "Przemysław R. Grzybowski"},
{"Title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "abs": ["Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent input contexts with a graph traversal algorithm. Our experiments show In-Context Pretraining offers a simple and scalable approach to significantly enhance LMs'performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%)."], "authors": "Weijia Shi"},
{"Title": "Distributional PAC-Learning from Nisan's Natural Proofs", "abs": ["Carmosino et al. (2016) demonstrated that natural proofs of circuit lower bounds for $\\Lambda$ imply efficient algorithms for learning $\\Lambda$-circuits, but only over \\textit{the uniform distribution}, with \\textit{membership queries}, and provided $\\AC^0[p] \\subseteq \\Lambda$. We consider whether this implication can be generalized to $\\Lambda \\not\\supseteq \\AC^0[p]$, and to learning algorithms which use only random examples and learn over arbitrary example distributions (Valiant's PAC-learning model).", "We first observe that, if, for any circuit class $\\Lambda$, there is an implication from natural proofs for $\\Lambda$ to PAC-learning for $\\Lambda$, then standard assumptions from lattice-based cryptography do not hold. In particular, we observe that depth-2 majority circuits are a (conditional) counter example to the implication, since Nisan (1993) gave a natural proof, but Klivans and Sherstov (2009) showed hardness of PAC-learning under lattice-based assumptions. We thus ask: what learning algorithms can we reasonably expect to follow from Nisan's natural proofs?", "Our main result is that all natural proofs arising from a type of communication complexity argument, including Nisan's, imply PAC-learning algorithms in a new \\textit{distributional} variant (i.e., an ``average-case'' relaxation) of Valiant's PAC model. Our distributional PAC model is stronger than the average-case prediction model of Blum et al. (1993) and the heuristic PAC model of Nanashima (2021), and has several important properties which make it of independent interest, such as being \\textit{boosting-friendly}. The main applications of our result are new distributional PAC-learning algorithms for depth-2 majority circuits, polytopes and DNFs over natural target distributions, as well as the nonexistence of encoded-input weak PRFs that can be evaluated by depth-2 majority circuits."], "authors": "Ari Karchmer"},
{"Title": "Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational Sentence Scoring", "abs": ["Recent advances in machine learning and deep learning have led to the widespread use of Conversational AI in many practical applications. However, it is still very challenging to leverage auxiliary information that can provide conversational context or personalized tuning to improve the quality of conversations. For example, there has only been limited research on using an individuals persona information to improve conversation quality, and even state-of-the-art conversational AI techniques are unable to effectively leverage signals from heterogeneous sources of auxiliary data, such as multi-modal interaction data, demographics, SDOH data, etc. In this paper, we present a novel Persona-Coded Poly-Encoder method that leverages persona information in a multi-stream encoding scheme to improve the quality of response generation for conversations. To show the efficacy of the proposed method, we evaluate our method on two different persona-based conversational datasets, and compared against two state-of-the-art methods. Our experimental results and analysis demonstrate that our method can improve conversation quality over the baseline method Poly-Encoder by 3.32% and 2.94% in terms of BLEU score and HR@1, respectively. More significantly, our method offers a path to better utilization of multi-modal data in conversational tasks. Lastly, our study outlines several challenges and future research directions for advancing personalized conversational AI technology."], "authors": "Junfeng Liu"},
{"Title": "PathLDM: Text conditioned Latent Diffusion Model for Histopathology", "abs": ["To achieve high-quality results, diffusion models must be trained on large datasets. This can be notably prohibitive for models in specialized domains, such as computational pathology. Conditioning on labeled data is known to help in data-efficient model training. Therefore, histopathology reports, which are rich in valuable clinical information, are an ideal choice as guidance for a histopathology generative model. In this paper, we introduce PathLDM, the first text-conditioned Latent Diffusion Model tailored for generating high-quality histopathology images. Leveraging the rich contextual information provided by pathology text reports, our approach fuses image and textual data to enhance the generation process. By utilizing GPT's capabilities to distill and summarize complex text reports, we establish an effective conditioning mechanism. Through strategic conditioning and necessary architectural enhancements, we achieved a SoTA FID score of 7.64 for text-to-image generation on the TCGA-BRCA dataset, significantly outperforming the closest text-conditioned competitor with FID 30.1."], "authors": "Srikar Yellapragada"},
{"Title": "QuantEase: Optimization-based Quantization for Language Models", "abs": ["With the rising popularity of Large Language Models (LLMs), there has been an increasing interest in compression techniques that enable their efficient deployment. This study focuses on the Post-Training Quantization (PTQ) of LLMs. Drawing from recent advances, our work introduces QuantEase, a layer-wise quantization framework where individual layers undergo separate quantization. The problem is framed as a discrete-structured non-convex optimization, prompting the development of algorithms rooted in Coordinate Descent (CD) techniques. These CD-based methods provide high-quality solutions to the complex non-convex layer-wise quantization problems. Notably, our CD-based approach features straightforward updates, relying solely on matrix and vector operations, circumventing the need for matrix inversion or decomposition. We also explore an outlier-aware variant of our approach, allowing for retaining significant weights (outliers) with complete precision. Our proposal attains state-of-the-art performance in terms of perplexity and zero-shot accuracy in empirical evaluations across various LLMs and datasets, with relative improvements up to 15% over methods such as GPTQ. Leveraging careful linear algebra optimizations, QuantEase can quantize models like Falcon-180B on a single NVIDIA A100 GPU in $\\sim$3 hours. Particularly noteworthy is our outlier-aware algorithm's capability to achieve near or sub-3-bit quantization of LLMs with an acceptable drop in accuracy, obviating the need for non-uniform quantization or grouping techniques, improving upon methods such as SpQR by up to two times in terms of perplexity."], "authors": "Kayhan Behdin"},
{"Title": "Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks", "abs": ["Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (the task of neurological prognostication) could help with treatment decisions. In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients' available EEG time series could vary in length. Predictions are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient's probability of awakening or of dying across multiple time horizons. Our framework uses any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient's static features and summary statistics from the patient's latest hour's worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient's EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks)."], "authors": "Xiaobin Shen"},
{"Title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback", "abs": ["Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences. However, gathering high-quality human preference labels can be a time-consuming and expensive endeavor. RL from AI Feedback (RLAIF), introduced by Bai et al., offers a promising alternative that leverages a powerful off-the-shelf LLM to generate preferences in lieu of human annotators. Across the tasks of summarization, helpful dialogue generation, and harmless dialogue generation, RLAIF achieves comparable or superior performance to RLHF, as rated by human evaluators. Furthermore, RLAIF demonstrates the ability to outperform a supervised fine-tuned baseline even when the LLM preference labeler is the same size as the policy. In another experiment, directly prompting the LLM for reward scores achieves superior performance to the canonical RLAIF setup, where LLM preference labels are first distilled into a reward model. Finally, we conduct extensive studies on techniques for generating aligned AI preferences. Our results suggest that RLAIF can achieve human-level performance, offering a potential solution to the scalability limitations of RLHF."], "authors": "Harrison Lee"},
{"Title": "Constructing Custom Thermodynamics Using Deep Learning", "abs": ["One of the most exciting applications of artificial intelligence (AI) is automated scientific discovery based on previously amassed data, coupled with restrictions provided by known physical principles, including symmetries and conservation laws. Such automated hypothesis creation and verification can assist scientists in studying complex phenomena, where traditional physical intuition may fail. Here we develop a platform based on a generalized Onsager principle to learn macroscopic dynamical descriptions of arbitrary stochastic dissipative systems directly from observations of their microscopic trajectories. Our method simultaneously constructs reduced thermodynamic coordinates and interprets the dynamics on these coordinates. We demonstrate its effectiveness by studying theoretically and validating experimentally the stretching of long polymer chains in an externally applied field. Specifically, we learn three interpretable thermodynamic coordinates and build a dynamical landscape of polymer stretching, including the identification of stable and transition states and the control of the stretching rate. Our general methodology can be used to address a wide range of scientific and technological applications."], "authors": "Xiaoli Chen"},
{"Title": "Duet: efficient and scalable hybriD neUral rElation undersTanding", "abs": ["Learned cardinality estimation methods have achieved high precision compared to traditional methods. Among learned methods, query-driven approaches have faced the workload drift problem for a long time. Although both data-driven and hybrid methods are proposed to avoid this problem, most of them suffer from high training and estimation costs, limited scalability, instability, and long-tail distribution problems on high-dimensional tables, which seriously affects the practical application of learned cardinality estimators. In this paper, we prove that most of these problems are directly caused by the widely used progressive sampling. We solve this problem by introducing predicate information into the autoregressive model and propose Duet, a stable, efficient, and scalable hybrid method to estimate cardinality directly without sampling or any non-differentiable process, which can not only reduce the inference complexity from $O(n)$ to $O(1)$ compared to Naru and UAE but also achieve higher accuracy on high cardinality and high-dimensional tables. Experimental results show that Duet can achieve all the design goals above and be much more practical. Besides, Duet even has a lower inference cost on CPU than that of most learned methods on GPU."], "authors": "Kaixin Zhang"},
{"Title": "Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey", "abs": ["Deep learning has successfully solved a wide range of tasks in 2D vision as a dominant AI technique. Recently, deep learning on 3D point clouds is becoming increasingly popular for addressing various tasks in this field. Despite remarkable achievements, deep learning algorithms are vulnerable to adversarial attacks. These attacks are imperceptible to the human eye but can easily fool deep neural networks in the testing and deployment stage. To encourage future research, this survey summarizes the current progress on adversarial attack and defense techniques on point cloud classification.This paper first introduces the principles and characteristics of adversarial attacks and summarizes and analyzes adversarial example generation methods in recent years. Additionally, it provides an overview of defense strategies, organized into data-focused and model-focused methods. Finally, it presents several current challenges and potential future research directions in this domain."], "authors": "Hanieh Naderi"},
{"Title": "Action valuation of on- and off-ball soccer players based on multi-agent deep reinforcement learning", "abs": ["Analysis of invasive sports such as soccer is challenging because the game situation changes continuously in time and space, and multiple agents individually recognize the game situation and make decisions. Previous studies using deep reinforcement learning have often considered teams as a single agent and valued the teams and players who hold the ball in each discrete event. Then it was challenging to value the actions of multiple players, including players far from the ball, in a spatiotemporally continuous state space. In this paper, we propose a method of valuing possible actions for on- and off-ball soccer players in a single holistic framework based on multi-agent deep reinforcement learning. We consider a discrete action space in a continuous state space that mimics that of Google research football and leverages supervised learning for actions in reinforcement learning. In the experiment, we analyzed the relationships with conventional indicators, season goals, and game ratings by experts, and showed the effectiveness of the proposed method. Our approach can assess how multiple players move continuously throughout the game, which is difficult to be discretized or labeled but vital for teamwork, scouting, and fan engagement."], "authors": "Hiroshi Nakahara"},
{"Title": "Generating high-quality 3DMPCs by adaptive data acquisition and NeREF-based radiometric calibration with UGV plant phenotyping system", "abs": ["Fusion of 3D and MS imaging data has a great potential for high-throughput plant phenotyping of structural and biochemical as well as physiological traits simultaneously, which is important for decision support in agriculture and for crop breeders in selecting the best genotypes. However, lacking of 3D data integrity of various plant canopy structures and low-quality of MS images caused by the complex illumination effects make a great challenge, especially at the proximal imaging scale. Therefore, this study proposed a novel approach for adaptive data acquisition and radiometric calibration to generate high-quality 3DMPCs of plants. An efficient NBV planning method based on an UGV plant phenotyping system with a multi-sensor-equipped robotic arm was proposed to achieve adaptive data acquisition. The NeREF was employed to predict the DN values of the hemispherical reference for radiometric calibration. For NBV planning, the average total time for single plant at a joint speed of 1.55 rad/s was about 62.8 s, with an average reduction of 18.0% compared to the unplanned. The integrity of the whole-plant data was improved by an average of 23.6% compared to the fixed viewpoints alone. Compared with the ASD measurements, the RMSE of the reflectance spectra obtained from 3DMPCs at different regions of interest was 0.08 with an average decrease of 58.93% compared to the results obtained from the single-frame of MS images without 3D radiometric calibration. The 3D-calibrated plant 3DMPCs improved the predictive accuracy of PLSR for chlorophyll content, with an average increase of 0.07 in R2 and an average decrease of 21.25% in RMSE. Our approach introduced a fresh perspective on generating high-quality 3DMPCs of plants under the natural light condition, enabling more precise analysis of plant morphological and physiological parameters."], "authors": "Pengyao Xie"},
{"Title": "Uncertainty Estimation and Out-of-Distribution Detection for Deep Learning-Based Image Reconstruction using the Local Lipschitz", "abs": ["Accurate image reconstruction is at the heart of diagnostics in medical imaging. Supervised deep learning-based approaches have been investigated for solving inverse problems including image reconstruction. However, these trained models encounter unseen data distributions that are widely shifted from training data during deployment. Therefore, it is essential to assess whether a given input falls within the training data distribution for diagnostic purposes. Uncertainty estimation approaches exist but focus on providing an uncertainty map to radiologists, rather than assessing the training distribution fit. In this work, we propose a method based on the local Lipschitz-based metric to distinguish out-of-distribution images from in-distribution with an area under the curve of 99.94%. Empirically, we demonstrate a very strong relationship between the local Lipschitz value and mean absolute error (MAE), supported by a high Spearman's rank correlation coefficient of 0.8475, which determines the uncertainty estimation threshold for optimal model performance. Through the identification of false positives, the local Lipschitz and MAE relationship was used to guide data augmentation and reduce model uncertainty. Our study was validated using the AUTOMAP architecture for sensor-to-image Magnetic Resonance Imaging (MRI) reconstruction. We compare our proposed approach with baseline methods: Monte-Carlo dropout and deep ensembles, and further analysis included MRI denoising and Computed Tomography (CT) sparse-to-full view reconstruction using UNET architectures. We show that our approach is applicable to various architectures and learned functions, especially in the realm of medical image reconstruction, where preserving the diagnostic accuracy of reconstructed images remains paramount."], "authors": "Danyal F. Bhutto"},
{"Title": "On the Identifiability of Switching Dynamical Systems", "abs": ["In the realm of interpretability and out-of-distribution generalisation, the identifiability of latent variable models has emerged as a captivating field of inquiry. In this work, we delve into the identifiability of Switching Dynamical Systems, taking an initial stride toward extending identifiability analysis to sequential latent variable models. We first prove the identifiability of Markov Switching Models, which commonly serve as the prior distribution for the continuous latent variables in Switching Dynamical Systems. We present identification conditions for first-order Markov dependency structures, whose transition distribution is parametrised via non-linear Gaussians. We then establish the identifiability of the latent variables and non-linear mappings in Switching Dynamical Systems up to affine transformations, by leveraging identifiability analysis techniques from identifiable deep latent variable models. We finally develop estimation algorithms for identifiable Switching Dynamical Systems. Throughout empirical studies, we demonstrate the practicality of identifiable Switching Dynamical Systems for segmenting high-dimensional time series such as videos, and showcase the use of identifiable Markov Switching Models for regime-dependent causal discovery in climate data."], "authors": "Carles Balsells-Rodas"},
{"Title": "Contrastive losses as generalized models of global epistasis", "abs": ["Fitness functions map large combinatorial spaces of biological sequences to properties of interest. Inferring these multimodal functions from experimental data is a central task in modern protein engineering. Global epistasis models are an effective and physically-grounded class of models for estimating fitness functions from observed data. These models assume that a sparse latent function is transformed by a monotonic nonlinearity to emit measurable fitness. Here we demonstrate that minimizing contrastive loss functions, such as the Bradley-Terry loss, is a simple and flexible technique for extracting the sparse latent function implied by global epistasis. We argue by way of a fitness-epistasis uncertainty principle that the nonlinearities in global epistasis models can produce observed fitness functions that do not admit sparse representations, and thus may be inefficient to learn from observations when using a Mean Squared Error (MSE) loss (a common practice). We show that contrastive losses are able to accurately estimate a ranking function from limited data even in regimes where MSE is ineffective. We validate the practical utility of this insight by showing contrastive loss functions result in consistently improved performance on benchmark tasks."], "authors": "David H. Brookes"},
{"Title": "Phylo2Vec: a vector representation for binary trees", "abs": ["Binary phylogenetic trees inferred from biological data are central to understanding the shared evolutionary history of organisms. Inferring the placement of latent nodes in a tree by any optimality criterion (e.g., maximum likelihood) is an NP-hard problem, propelling the development of myriad heuristic approaches. Yet, these heuristics often lack a systematic means of uniformly sampling random trees or effectively exploring a tree space that grows factorially, which are crucial to optimisation problems such as machine learning. Accordingly, we present Phylo2Vec, a new parsimonious representation of a phylogenetic tree. Phylo2Vec maps any binary tree with $n$ leaves to an integer vector of length $n$. We prove that Phylo2Vec is both well-defined and bijective to the space of phylogenetic trees. The advantages of Phylo2Vec are twofold: i) easy uniform sampling of binary trees and ii) systematic ability to traverse tree space in very large or small jumps. As a proof of concept, we use Phylo2Vec for maximum likelihood inference on five real-world datasets and show that a simple hill climbing-based optimisation efficiently traverses the vastness of tree space from a random to an optimal tree."], "authors": "Matthew J Penn"},
{"Title": "ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness", "abs": ["Multi-step reasoning ability is fundamental to many natural language tasks, yet it is unclear what constitutes a good reasoning chain and how to evaluate them. Most existing methods focus solely on whether the reasoning chain leads to the correct conclusion, but this answer-oriented view may confound reasoning quality with other spurious shortcuts to predict the answer. To bridge this gap, we evaluate reasoning chains by viewing them as informal proofs that derive the final answer. Specifically, we propose ReCEval (Reasoning Chain Evaluation), a framework that evaluates reasoning chains via two key properties: (1) correctness, i.e., each step makes a valid inference based on information contained within the step, preceding steps, and input context, and (2) informativeness, i.e., each step provides new information that is helpful towards deriving the generated answer. We evaluate these properties by developing metrics using natural language inference models and V-Information. On multiple datasets, we show that ReCEval effectively identifies various error types and yields notable improvements compared to prior methods. We analyze the impact of step boundaries, and previous steps on evaluating correctness and demonstrate that our informativeness metric captures the expected flow of information in high-quality reasoning chains. Finally, we show that scoring reasoning chains based on ReCEval improves downstream task performance. Our code is publicly available at:"], "authors": "Archiki Prasad"},
{"Title": "A machine-learning approach to thunderstorm forecasting through post-processing of simulation data", "abs": ["Thunderstorms pose a major hazard to society and economy, which calls for reliable thunderstorm forecasts. In this work, we introduce SALAMA, a feedforward neural network model for identifying thunderstorm occurrence in numerical weather prediction (NWP) data. The model is trained on convection-resolving ensemble forecasts over Central Europe and lightning observations. Given only a set of pixel-wise input parameters that are extracted from NWP data and related to thunderstorm development, SALAMA infers the probability of thunderstorm occurrence in a reliably calibrated manner. For lead times up to eleven hours, we find a forecast skill superior to classification based only on NWP reflectivity. Varying the spatiotemporal criteria by which we associate lightning observations with NWP data, we show that the time scale for skillful thunderstorm predictions increases linearly with the spatial scale of the forecast."], "authors": "Kianusch Vahid Yousefnia"},
{"Title": "Bayesian CART models for insurance claims frequency", "abs": ["Accuracy and interpretability of a (non-life) insurance pricing model are essential qualities to ensure fair and transparent premiums for policy-holders, that reflect their risk. In recent years, the classification and regression trees (CARTs) and their ensembles have gained popularity in the actuarial literature, since they offer good prediction performance and are relatively easily interpretable. In this paper, we introduce Bayesian CART models for insurance pricing, with a particular focus on claims frequency modelling. Additionally to the common Poisson and negative binomial (NB) distributions used for claims frequency, we implement Bayesian CART for the zero-inflated Poisson (ZIP) distribution to address the difficulty arising from the imbalanced insurance claims data. To this end, we introduce a general MCMC algorithm using data augmentation methods for posterior tree exploration. We also introduce the deviance information criterion (DIC) for the tree model selection. The proposed models are able to identify trees which can better classify the policy-holders into risk groups. Some simulations and real insurance data will be discussed to illustrate the applicability of these models."], "authors": "Yaojun Zhang"},
{"Title": "CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac Anatomy", "abs": ["Two key questions in cardiac image analysis are to assess the anatomy and motion of the heart from images; and to understand how they are associated with non-imaging clinical factors such as gender, age and diseases. While the first question can often be addressed by image segmentation and motion tracking algorithms, our capability to model and to answer the second question is still limited. In this work, we propose a novel conditional generative model to describe the 4D spatio-temporal anatomy of the heart and its interaction with non-imaging clinical factors. The clinical factors are integrated as the conditions of the generative modelling, which allows us to investigate how these factors influence the cardiac anatomy. We evaluate the model performance in mainly two tasks, anatomical sequence completion and sequence generation. The model achieves a high performance in anatomical sequence completion, comparable to or outperforming other state-of-the-art generative models. In terms of sequence generation, given clinical conditions, the model can generate realistic synthetic 4D sequential anatomies that share similar distributions with the real data."], "authors": "Mengyun Qiao"},
{"Title": "Timewarp: Transferable Acceleration of Molecular Dynamics by Learning Time-Coarsened Dynamics", "abs": ["Molecular dynamics (MD) simulation is a widely used technique to simulate molecular systems, most commonly at the all-atom resolution where equations of motion are integrated with timesteps on the order of femtoseconds ($1\\textrm{fs}=10^{-15}\\textrm{s}$). MD is often used to compute equilibrium properties, which requires sampling from an equilibrium distribution such as the Boltzmann distribution. However, many important processes, such as binding and folding, occur over timescales of milliseconds or beyond, and cannot be efficiently sampled with conventional MD. Furthermore, new MD simulations need to be performed for each molecular system studied. We present Timewarp, an enhanced sampling method which uses a normalising flow as a proposal distribution in a Markov chain Monte Carlo method targeting the Boltzmann distribution. The flow is trained offline on MD trajectories and learns to make large steps in time, simulating the molecular dynamics of $10^{5} - 10^{6}\\:\\textrm{fs}$. Crucially, Timewarp is transferable between molecular systems: once trained, we show that it generalises to unseen small peptides (2-4 amino acids) at all-atom resolution, exploring their metastable states and providing wall-clock acceleration of sampling compared to standard MD. Our method constitutes an important step towards general, transferable algorithms for accelerating MD."], "authors": "Leon Klein"},
{"Title": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection Systems", "abs": ["In autonomous driving, LiDAR and radar play important roles in the perception of the surrounding environment. LiDAR provides accurate 3D spatial sensing information but cannot work in adverse weather like fog. On the other hand, the radar signal can be diffracted when encountering raindrops or mist particles thanks to its wavelength, but it suffers from large noise. Recent state-of-the-art works reveal that fusion of radar and LiDAR can lead to robust detection in adverse weather. The existing works adopt convolutional neural network architecture to extract features from each sensor data, then align and aggregate the two branch features to predict object detection results. However, these methods have low accuracy of bounding box estimations due to a simple design of label assignment and fusion strategies. In this paper, we propose a bird's-eye view fusion learning-based anchor box-free object detection system, which fuses the feature derived from the radar range-azimuth heatmap and the LiDAR point cloud to estimate possible objects. Different label assignment strategies have been designed to facilitate the consistency between the classification of foreground or background anchor points and the corresponding bounding box regressions. Furthermore, the performance of the proposed object detector is further enhanced by employing a novel interactive transformer module. The superior performance of the methods proposed in this paper has been demonstrated using the recently published Oxford Radar RobotCar dataset. Our system's average precision significantly outperforms the state-of-the-art method by 13.1% and 19.0% at IoU of 0.8 under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing, respectively."], "authors": "Yanlong Yang"},
{"Title": "Automatic Diagnosis of Myocarditis Disease in Cardiac MRI Modality using Deep Transformers and Explainable Artificial Intelligence", "abs": ["Myocarditis is a significant cardiovascular disease (CVD) that poses a threat to the health of many individuals by causing damage to the myocardium. The occurrence of microbes and viruses, including the likes of HIV, plays a crucial role in the development of myocarditis disease (MCD). The images produced during cardiac magnetic resonance imaging (CMRI) scans are low contrast, which can make it challenging to diagnose cardiovascular diseases. In other hand, checking numerous CMRI slices for each CVD patient can be a challenging task for medical doctors. To overcome the existing challenges, researchers have suggested the use of artificial intelligence (AI)-based computer-aided diagnosis systems (CADS). The presented paper outlines a CADS for the detection of MCD from CMR images, utilizing deep learning (DL) methods. The proposed CADS consists of several steps, including dataset, preprocessing, feature extraction, classification, and post-processing. First, the Z-Alizadeh dataset was selected for the experiments. Subsequently, the CMR images underwent various preprocessing steps, including denoising, resizing, as well as data augmentation (DA) via CutMix and MixUp techniques. In the following, the most current deep pre-trained and transformer models are used for feature extraction and classification on the CMR images. The findings of our study reveal that transformer models exhibit superior performance in detecting MCD as opposed to pre-trained architectures. In terms of DL architectures, the Turbulence Neural Transformer (TNT) model exhibited impressive accuracy, reaching 99.73% utilizing a 10-fold cross-validation approach. Additionally, to pinpoint areas of suspicion for MCD in CMRI images, the Explainable-based Grad Cam method was employed."], "authors": "Mahboobeh Jafari"},
{"Title": "Bandwidth Selection for Gaussian Kernel Ridge Regression via Jacobian Control", "abs": ["Most machine learning methods require tuning of hyper-parameters. For kernel ridge regression with the Gaussian kernel, the hyper-parameter is the bandwidth. The bandwidth specifies the length scale of the kernel and has to be carefully selected to obtain a model with good generalization. The default methods for bandwidth selection, cross-validation and marginal likelihood maximization, often yield good results, albeit at high computational costs. Inspired by Jacobian regularization, we formulate an approximate expression for how the derivatives of the functions inferred by kernel ridge regression with the Gaussian kernel depend on the kernel bandwidth. We use this expression to propose a closed-form, computationally feather-light, bandwidth selection heuristic, based on controlling the Jacobian. In addition, the Jacobian expression illuminates how the bandwidth selection is a trade-off between the smoothness of the inferred function and the conditioning of the training data kernel matrix. We show on real and synthetic data that compared to cross-validation and marginal likelihood maximization, our method is on pair in terms of model performance, but up to six orders of magnitude faster."], "authors": "Oskar Allerbo"},
{"Title": "Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural Networks", "abs": ["In the field of deep learning, the prevalence of models initially trained with 32-bit precision is a testament to its robustness and accuracy. However, the continuous evolution of these models often demands further training, which can be resource-intensive. This study introduces a novel approach where we continue the training of these pre-existing 32-bit models using 16-bit precision. This technique not only caters to the need for efficiency in computational resources but also significantly improves the speed of additional training phases. By adopting 16-bit precision for ongoing training, we are able to substantially decrease memory requirements and computational burden, thereby accelerating the training process in a resource-limited setting. Our experiments show that this method maintains the high standards of accuracy set by the original 32-bit training while providing a much-needed boost in training speed. This approach is especially pertinent in today's context, where most models are initially trained in 32-bit and require periodic updates and refinements. The findings from our research suggest that this strategy of 16-bit continuation training can be a key solution for sustainable and efficient deep learning, offering a practical way to enhance pre-trained models rapidly and in a resource-conscious manner."], "authors": "Juyoung Yun"},
{"Title": "Domain Generalization Strategy to Train Classifiers Robust to Spatial-Temporal Shift", "abs": ["Deep learning-based weather prediction models have advanced significantly in recent years. However, data-driven models based on deep learning are difficult to apply to real-world applications because they are vulnerable to spatial-temporal shifts. A weather prediction task is especially susceptible to spatial-temporal shifts when the model is overfitted to locality and seasonality. In this paper, we propose a training strategy to make the weather prediction model robust to spatial-temporal shifts. We first analyze the effect of hyperparameters and augmentations of the existing training strategy on the spatial-temporal shift robustness of the model. Next, we propose an optimal combination of hyperparameters and augmentation based on the analysis results and a test-time augmentation. We performed all experiments on the W4C22 Transfer dataset and achieved the 1st performance."], "authors": "Minseok Seo"},
{"Title": "VMAF Re-implementation on PyTorch: Some Experimental Results", "abs": ["Based on the standard VMAF implementation we propose an implementation of VMAF using PyTorch framework. For this implementation comparisons with the standard (libvmaf) show the discrepancy $\\lesssim 10^{-2}$ in VMAF units. We investigate gradients computation when using VMAF as an objective function and demonstrate that training using this function does not result in ill-behaving gradients. The implementation is then used to train a preprocessing filter. It is demonstrated that its performance is superior to the unsharp masking filter. The resulting filter is also easy for implementation and can be applied in video processing tasks for video copression improvement. This is confirmed by the results of numerical experiments."], "authors": "Kirill Aistov"},
{"Title": "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning", "abs": ["Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models $\\textit{on-demand}$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models."], "authors": "Jannik Deuschel"},
{"Title": "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting", "abs": ["The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformers are challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the embedding for each temporal token fuses multiple variates that represent potential delayed events and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any modification to the basic components. We propose iTransformer that simply applies the attention and feed-forward network on the inverted dimensions. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The iTransformer model achieves state-of-the-art on challenging real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting."], "authors": "Yong Liu"},
{"Title": "MuseChat: A Conversational Music Recommendation System for Videos", "abs": ["Music recommendation for videos attracts growing interest in multi-modal research. However, existing systems focus primarily on content compatibility, often ignoring the users' preferences. Their inability to interact with users for further refinements or to provide explanations leads to a less satisfying experience. We address these issues with MuseChat, a first-of-its-kind dialogue-based recommendation system that personalizes music suggestions for videos. Our system consists of two key functionalities with associated modules: recommendation and reasoning. The recommendation module takes a video along with optional information including previous suggested music and user's preference as inputs and retrieves an appropriate music matching the context. The reasoning module, equipped with the power of Large Language Model (Vicuna-7B) and extended to multi-modal inputs, is able to provide reasonable explanation for the recommended music. To evaluate the effectiveness of MuseChat, we build a large-scale dataset, conversational music recommendation for videos, that simulates a two-turn interaction between a user and a recommender based on accurate music track information. Experiment results show that MuseChat achieves significant improvements over existing video-based music retrieval methods as well as offers strong interpretability and interactability."], "authors": "Zhikang Dong"},
{"Title": "HyperAttention: Long-context Attention in Near-Linear Time", "abs": ["We present an approximate attention mechanism named HyperAttention to address the computational challenges posed by the growing complexity of long contexts used in Large Language Models (LLMs). Recent work suggests that in the worst-case scenario, quadratic time is necessary unless the entries of the attention matrix are bounded or the matrix has low stable rank. We introduce two parameters which measure: (1) the max column norm in the normalized attention matrix, and (2) the ratio of row norms in the unnormalized attention matrix after detecting and removing large entries. We use these fine-grained parameters to capture the hardness of the problem. Despite previous lower bounds, we are able to achieve a linear time sampling algorithm even when the matrix has unbounded entries or a large stable rank, provided the above parameters are small. HyperAttention features a modular design that easily accommodates integration of other fast low-level implementations, particularly FlashAttention. Empirically, employing Locality Sensitive Hashing (LSH) to identify large entries, HyperAttention outperforms existing methods, giving significant speed improvements compared to state-of-the-art solutions like FlashAttention. We validate the empirical performance of HyperAttention on a variety of different long-context length datasets. For example, HyperAttention makes the inference time of ChatGLM2 50\\% faster on 32k context length while perplexity increases from 5.6 to 6.3. On larger context length, e.g., 131k, with causal masking, HyperAttention offers 5-fold speedup on a single attention layer."], "authors": "Insu Han"},
{"Title": "Beta Diffusion", "abs": ["We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, further supports the efficacy of KLUBs for optimization. Experimental results on both synthetic data and natural images demonstrate the unique capabilities of beta diffusion in generative modeling of range-bounded data and validate the effectiveness of KLUBs in optimizing diffusion models, thereby making them valuable additions to the family of diffusion-based generative models and the optimization techniques used to train them."], "authors": "Mingyuan Zhou"},
{"Title": "Symplectic Structure-Aware Hamiltonian (Graph) Embeddings", "abs": ["In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs have been proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. We present Symplectic Structure-Aware Hamiltonian GNN (SAH-GNN), a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian approaches, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training meaning the implicit Hamiltonian system is physically meaningful. Finally, we empirically validate SAH-GNN's superiority and adaptability in node classification tasks across multiple types of graph datasets."], "authors": "Jiaxu Liu"},
{"Title": "Hessian-Aware Bayesian Optimization for Decision Making Systems", "abs": ["Many approaches for optimizing decision making systems rely on gradient based methods requiring informative feedback from the environment. However, in the case where such feedback is sparse or uninformative, such approaches may result in poor performance. Derivative-free approaches such as Bayesian Optimization mitigate the dependency on the quality of gradient feedback, but are known to scale poorly in the high-dimension setting of complex decision making systems. This problem is exacerbated if the system requires interactions between several actors cooperating to accomplish a shared goal. To address the dimensionality challenge, we propose a compact multi-layered architecture modeling the dynamics of actor interactions through the concept of role. We introduce Hessian-aware Bayesian Optimization to efficiently optimize the multi-layered architecture parameterized by a large number of parameters, and give the first improved regret bound in additive high-dimensional Bayesian Optimization since Mutny & Krause (2018). Our approach shows strong empirical results under malformed or sparse reward."], "authors": "Mohit Rajpal"},
{"Title": "Understanding Forward Process of Convolutional Neural Network", "abs": ["This paper reveal the selective rotation in the CNNs' forward processing. It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern."], "authors": "Peixin Tian"},
{"Title": "A Definition of Continual Reinforcement Learning", "abs": ["In a standard view of the reinforcement learning problem, an agent's goal is to efficiently identify a policy that maximizes long-term reward. However, this perspective is based on a restricted view of learning as finding a solution, rather than treating learning as endless adaptation. In contrast, continual reinforcement learning refers to the setting in which the best agents never stop learning. Despite the importance of continual reinforcement learning, the community lacks a simple definition of the problem that highlights its commitments and makes its primary concepts precise and clear. To this end, this paper is dedicated to carefully defining the continual reinforcement learning problem. We formalize the notion of agents that \"never stop learning\" through a new mathematical language for analyzing and cataloging agents. Using this new language, we define a continual learning agent as one that can be understood as carrying out an implicit search process indefinitely, and continual reinforcement learning as the setting in which the best agents are all continual learning agents. We provide two motivating examples, illustrating that traditional views of multi-task reinforcement learning and continual supervised learning are special cases of our definition. Collectively, these definitions and perspectives formalize many intuitive concepts at the heart of learning, and open new research pathways surrounding continual learning agents."], "authors": "David Abel"},
{"Title": "G-NM: A Group of Numerical Time Series Prediction Models", "abs": ["In this study, we focus on the development and implementation of a comprehensive ensemble of numerical time series forecasting models, collectively referred to as the Group of Numerical Time Series Prediction Model (G-NM). This inclusive set comprises traditional models such as Autoregressive Integrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector Regression (SVR), in addition to modern neural network models including Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is explicitly constructed to augment our predictive capabilities related to patterns and trends inherent in complex natural phenomena. By utilizing time series data relevant to these events, G-NM facilitates the prediction of such phenomena over extended periods. The primary objective of this research is to both advance our understanding of such occurrences and to significantly enhance the accuracy of our forecasts. G-NM encapsulates both linear and non-linear dependencies, seasonalities, and trends present in time series data. Each of these models contributes distinct strengths, from ARIMA's resilience in handling linear trends and seasonality, SVR's proficiency in capturing non-linear patterns, to LSTM's adaptability in modeling various components of time series data. Through the exploitation of the G-NM potential, we strive to advance the state-of-the-art in large-scale time series forecasting models. We anticipate that this research will represent a significant stepping stone in our ongoing endeavor to comprehend and forecast the complex events that constitute the natural world."], "authors": "Juyoung Yun"},
{"Title": "Learning Robust Precipitation Forecaster by Temporal Frame Interpolation", "abs": ["Recent advances in deep learning have significantly elevated weather prediction models. However, these models often falter in real-world scenarios due to their sensitivity to spatial-temporal shifts. This issue is particularly acute in weather forecasting, where models are prone to overfit to local and temporal variations, especially when tasked with fine-grained predictions. In this paper, we address these challenges by developing a robust precipitation forecasting model that demonstrates resilience against such spatial-temporal discrepancies. We introduce Temporal Frame Interpolation (TFI), a novel technique that enhances the training dataset by generating synthetic samples through interpolating adjacent frames from satellite imagery and ground radar data, thus improving the model's robustness against frame noise. Moreover, we incorporate a unique Multi-Level Dice (ML-Dice) loss function, leveraging the ordinal nature of rainfall intensities to improve the model's performance. Our approach has led to significant improvements in forecasting precision, culminating in our model securing \\textit{1st place} in the transfer learning leaderboard of the \\textit{Weather4cast'23} competition. This achievement not only underscores the effectiveness of our methodologies but also establishes a new standard for deep learning applications in weather forecasting. Our code and weights have been public on \\url{", "}."], "authors": "Lu Han"},
{"Title": "GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies", "abs": ["Phylogenetic inference, grounded in molecular evolution models, is essential for understanding the evolutionary relationships in biological data. Accounting for the uncertainty of phylogenetic tree variables, which include tree topologies and evolutionary distances on branches, is crucial for accurately inferring species relationships from molecular data and tasks requiring variable marginalization. Variational Bayesian methods are key to developing scalable, practical models; however, it remains challenging to conduct phylogenetic inference without restricting the combinatorially vast number of possible tree topologies. In this work, we introduce a novel, fully differentiable formulation of phylogenetic inference that leverages a unique representation of topological distributions in continuous geometric spaces. Through practical considerations on design spaces and control variates for gradient estimations, our approach, GeoPhy, enables variational inference without limiting the topological candidates. In experiments using real benchmark datasets, GeoPhy significantly outperformed other approximate Bayesian methods that considered whole topologies."], "authors": "Takahiro Mimori"},
{"Title": "On the Adversarial Robustness of Graph Contrastive Learning Methods", "abs": ["Contrastive learning (CL) has emerged as a powerful framework for learning representations of images and text in a self-supervised manner while enhancing model robustness against adversarial attacks. More recently, researchers have extended the principles of contrastive learning to graph-structured data, giving birth to the field of graph contrastive learning (GCL). However, whether GCL methods can deliver the same advantages in adversarial robustness as their counterparts in the image and text domains remains an open question. In this paper, we introduce a comprehensive robustness evaluation protocol tailored to assess the robustness of GCL models. We subject these models to adaptive adversarial attacks targeting the graph structure, specifically in the evasion scenario. We evaluate node and graph classification tasks using diverse real-world datasets and attack strategies. With our work, we aim to offer insights into the robustness of GCL methods and hope to open avenues for potential future research directions."], "authors": "Filippo Guerranti"},
{"Title": "A density estimation perspective on learning from pairwise human preferences", "abs": ["Learning from human feedback (LHF) -- and in particular learning from pairwise preferences -- has recently become a crucial ingredient in training large language models (LLMs), and has been the subject of much research. Most recent works frame it as a reinforcement learning problem, where a reward function is learned from pairwise preference data and the LLM is treated as a policy which is adapted to maximize the rewards, often under additional regularization constraints. We propose an alternative interpretation which centers on the generative process for pairwise preferences and treats LHF as a density estimation problem. We provide theoretical and empirical results showing that for a family of generative processes defined via preference behavior distribution equations, training a reward function on pairwise preferences effectively models an annotator's implicit preference distribution. Finally, we discuss and present findings on \"annotator misspecification\" -- failure cases where wrong modeling assumptions are made about annotator behavior, resulting in poorly-adapted models -- suggesting that approaches that learn from pairwise human preferences could have trouble learning from a population of annotators with diverse viewpoints."], "authors": "Vincent Dumoulin"},
{"Title": "Matched Pair Calibration for Ranking Fairness", "abs": ["We propose a test of fairness in score-based ranking systems called matched pair calibration. Our approach constructs a set of matched item pairs with minimal confounding differences between subgroups before computing an appropriate measure of ranking error over the set. The matching step ensures that we compare subgroup outcomes between identically scored items so that measured performance differences directly imply unfairness in subgroup-level exposures. We show how our approach generalizes the fairness intuitions of calibration from a binary classification setting to ranking and connect our approach to other proposals for ranking fairness measures. Moreover, our strategy shows how the logic of marginal outcome tests extends to cases where the analyst has access to model scores. Lastly, we provide an example of applying matched pair calibration to a real-word ranking data set to demonstrate its efficacy in detecting ranking bias."], "authors": "Hannah Korevaar"},
{"Title": "Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms", "abs": ["Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demonstrate that our framework induces highly disentangled causal factors, improves interventional robustness, and is compatible with counterfactual generation."], "authors": "Aneesh Komanduri"},
{"Title": "A rule-general abductive learning by rough sets", "abs": ["In real-world tasks, there is usually a large amount of unlabeled data and labeled data. The task of combining the two to learn is known as semi-supervised learning. Experts can use logical rules to label unlabeled data, but this operation is costly. The combination of perception and reasoning has a good effect in processing such semi-supervised tasks with domain knowledge. However, acquiring domain knowledge and the correction, reduction and generation of rules remain complex problems to be solved. Rough set theory is an important method for solving knowledge processing in information systems. In this paper, we propose a rule general abductive learning by rough set (RS-ABL). By transforming the target concept and sub-concepts of rules into information tables, rough set theory is used to solve the acquisition of domain knowledge and the correction, reduction and generation of rules at a lower cost. This framework can also generate more extensive negative rules to enhance the breadth of the knowledge base. Compared with the traditional semi-supervised learning method, RS-ABL has higher accuracy in dealing with semi-supervised tasks."], "authors": "Xu-chang Guo"},
{"Title": "Mixture of Experts with Uncertainty Voting for Imbalanced Deep Regression Problems", "abs": ["Data imbalance is ubiquitous when applying machine learning to real-world problems, particularly regression problems. If training data are imbalanced, the learning is dominated by the densely covered regions of the target distribution, consequently, the learned regressor tends to exhibit poor performance in sparsely covered regions. Beyond standard measures like over-sampling or re-weighting, there are two main directions to handle learning from imbalanced data. For regression, recent work relies on the continuity of the distribution; whereas for classification there has been a trend to employ mixture-of-expert models and let some ensemble members specialize in predictions for the sparser regions. In our method, dubbed MOUV, we propose to leverage recent work on probabilistic deep learning and integrate it in a mixture-of-experts approach for imbalanced regression. We replace traditional regression losses with negative log-likelihood which also predicts sample-wise aleatoric uncertainty. We show experimentally that such a loss handles the imbalance better. Secondly, we use the readily available aleatoric uncertainty values to fuse the predictions of a mixture-of-experts model, thus obviating the need for a separate aggregation module. We compare our method with existing alternatives on multiple public benchmarks and show that MOUV consistently outperforms the prior art, while at the same time producing better calibrated uncertainty estimates. Our code is available at link-upon-publication."], "authors": "Yuchang Jiang"},
{"Title": "On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training", "abs": ["Pre-training datasets are critical for building state-of-the-art machine learning models, motivating rigorous study on their impact on downstream tasks. In this work, we study the impact of the trade-off between the intra-class diversity (the number of samples per class) and the inter-class diversity (the number of classes) of a supervised pre-training dataset. Empirically, we found that with the size of the pre-training dataset fixed, the best downstream performance comes with a balance on the intra-/inter-class diversity. To understand the underlying mechanism, we show theoretically that the downstream performance depends monotonically on both types of diversity. Notably, our theory reveals that the optimal class-to-sample ratio (#classes / #samples per class) is invariant to the size of the pre-training dataset, which motivates an application of predicting the optimal number of pre-training classes. We demonstrate the effectiveness of this application by an improvement of around 2 points on the downstream tasks when using ImageNet as the pre-training dataset."], "authors": "Jieyu Zhang"},
{"Title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment", "abs": ["Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially serious consequences. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) to address this problem, where generative models are fine-tuned with RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generative models effectively. Utilizing a reward model and a sufficient number of samples, our approach selects the high-quality samples, discarding those that exhibit undesired behavior, and subsequently enhancing the model by fine-tuning on these filtered samples. Our studies show that RAFT can effectively improve the model performance in both reward learning and other automated metrics in both large language models and diffusion models."], "authors": "Hanze Dong"},
{"Title": "HarsanyiNet: Computing Accurate Shapley Values in a Single Forward Propagation", "abs": ["The Shapley value is widely regarded as a trustworthy attribution metric. However, when people use Shapley values to explain the attribution of input variables of a deep neural network (DNN), it usually requires a very high computational cost to approximate relatively accurate Shapley values in real-world applications. Therefore, we propose a novel network architecture, the HarsanyiNet, which makes inferences on the input sample and simultaneously computes the exact Shapley values of the input variables in a single forward propagation. The HarsanyiNet is designed on the theoretical foundation that the Shapley value can be reformulated as the redistribution of Harsanyi interactions encoded by the network."], "authors": "Lu Chen"},
{"Title": "Use Perturbations when Learning from Explanations", "abs": ["Machine learning from explanations (MLX) is an approach to learning that uses human-provided explanations of relevant or irrelevant features for each input to ensure that model predictions are right for the right reasons. Existing MLX approaches rely on local model interpretation methods and require strong model smoothing to align model and human explanations, leading to sub-optimal performance. We recast MLX as a robustness problem, where human explanations specify a lower dimensional manifold from which perturbations can be drawn, and show both theoretically and empirically how this approach alleviates the need for strong model smoothing. We consider various approaches to achieving robustness, leading to improved performance over prior MLX methods. Finally, we show how to combine robustness with an earlier MLX method, yielding state-of-the-art results on both synthetic and real-world benchmarks."], "authors": "Juyeon Heo"},
{"Title": "Enhancing the Performance of Neural Networks Through Causal Discovery and Integration of Domain Knowledge", "abs": ["In this paper, we develop a generic methodology to encode hierarchical causality structure among observed variables into a neural network in order to improve its predictive performance. The proposed methodology, called causality-informed neural network (CINN), leverages three coherent steps to systematically map the structural causal knowledge into the layer-to-layer design of neural network while strictly preserving the orientation of every causal relationship. In the first step, CINN discovers causal relationships from observational data via directed acyclic graph (DAG) learning, where causal discovery is recast as a continuous optimization problem to avoid the combinatorial nature. In the second step, the discovered hierarchical causality structure among observed variables is systematically encoded into neural network through a dedicated architecture and customized loss function. By categorizing variables in the causal DAG as root, intermediate, and leaf nodes, the hierarchical causal DAG is translated into CINN with a one-to-one correspondence between nodes in the causal DAG and units in the CINN while maintaining the relative order among these nodes. Regarding the loss function, both intermediate and leaf nodes in the DAG graph are treated as target outputs during CINN training so as to drive co-learning of causal relationships among different types of nodes. As multiple loss components emerge in CINN, we leverage the projection of conflicting gradients to mitigate gradient interference among the multiple learning tasks. Computational experiments across a broad spectrum of UCI data sets demonstrate substantial advantages of CINN in predictive performance over other state-of-the-art methods. In addition, an ablation study underscores the value of integrating structural and quantitative causal knowledge in enhancing the neural network's predictive performance incrementally."], "authors": "Xiaoge Zhang"},
{"Title": "Decision Tree Psychological Risk Assessment in Currency Trading", "abs": ["This research paper focuses on the integration of Artificial Intelligence (AI) into the currency trading landscape, positing the development of personalized AI models, essentially functioning as intelligent personal assistants tailored to the idiosyncrasies of individual traders. The paper posits that AI models are capable of identifying nuanced patterns within the trader's historical data, facilitating a more accurate and insightful assessment of psychological risk dynamics in currency trading. The PRI is a dynamic metric that experiences fluctuations in response to market conditions that foster psychological fragility among traders. By employing sophisticated techniques, a classifying decision tree is crafted, enabling clearer decision-making boundaries within the tree structure. By incorporating the user's chronological trade entries, the model becomes adept at identifying critical junctures when psychological risks are heightened. The real-time nature of the calculations enhances the model's utility as a proactive tool, offering timely alerts to traders about impending moments of psychological risks. The implications of this research extend beyond the confines of currency trading, reaching into the realms of other industries where the judicious application of personalized modeling emerges as an efficient and strategic approach. This paper positions itself at the intersection of cutting-edge technology and the intricate nuances of human psychology, offering a transformative paradigm for decision making support in dynamic and high-pressure environments."], "authors": "Jai Pal"},
{"Title": "Active Learning and Bayesian Optimization: a Unified Perspective to Learn with a Goal", "abs": ["Science and Engineering applications are typically associated with expensive optimization problem to identify optimal design solutions and states of the system of interest. Bayesian optimization and active learning compute surrogate models through efficient adaptive sampling schemes to assist and accelerate this search task toward a given optimization goal. Both those methodologies are driven by specific infill/learning criteria which quantify the utility with respect to the set goal of evaluating the objective function for unknown combinations of optimization variables. While the two fields have seen an exponential growth in popularity in the past decades, their dualism and synergy have received relatively little attention to date. This paper discusses and formalizes the synergy between Bayesian optimization and active learning as symbiotic adaptive sampling methodologies driven by common principles. In particular, we demonstrate this unified perspective through the formalization of the analogy between the Bayesian infill criteria and active learning criteria as driving principles of both the goal-driven procedures. To support our original perspective, we propose a general classification of adaptive sampling techniques to highlight similarities and differences between the vast families of adaptive sampling, active learning, and Bayesian optimization. Accordingly, the synergy is demonstrated mapping the Bayesian infill criteria with the active learning criteria, and is formalized for searches informed by both a single information source and multiple levels of fidelity. In addition, we provide guidelines to apply those learning criteria investigating the performance of different Bayesian schemes for a variety of benchmark problems to highlight benefits and limitations over mathematical properties that characterize real-world applications."], "authors": "Francesco Di Fiore"},
{"Title": "Bayesian Neural Networks Avoid Encoding Complex and Perturbation-Sensitive Concepts", "abs": ["In this paper, we focus on mean-field variational Bayesian Neural Networks (BNNs) and explore the representation capacity of such BNNs by investigating which types of concepts are less likely to be encoded by the BNN. It has been observed and studied that a relatively small set of interactive concepts usually emerge in the knowledge representation of a sufficiently-trained neural network, and such concepts can faithfully explain the network output. Based on this, our study proves that compared to standard deep neural networks (DNNs), it is less likely for BNNs to encode complex concepts. Experiments verify our theoretical proofs. Note that the tendency to encode less complex concepts does not necessarily imply weak representation power, considering that complex concepts exhibit low generalization power and high adversarial vulnerability. The code is available at", "."], "authors": "Qihan Ren"},
{"Title": "Does a Neural Network Really Encode Symbolic Concepts?", "abs": ["Recently, a series of studies have tried to extract interactions between input variables modeled by a DNN and define such interactions as concepts encoded by the DNN. However, strictly speaking, there still lacks a solid guarantee whether such interactions indeed represent meaningful concepts. Therefore, in this paper, we examine the trustworthiness of interaction concepts from four perspectives. Extensive empirical studies have verified that a well-trained DNN usually encodes sparse, transferable, and discriminative concepts, which is partially aligned with human intuition."], "authors": "Mingjie Li"},
{"Title": "Transfer Learning Enhanced Full Waveform Inversion", "abs": ["We propose a way to favorably employ neural networks in the field of non-destructive testing using Full Waveform Inversion (FWI). The presented methodology discretizes the unknown material distribution in the domain with a neural network within an adjoint optimization. To further increase efficiency of the FWI, pretrained neural networks are used to provide a good starting point for the inversion. This reduces the number of iterations in the Full Waveform Inversion for specific, yet generalizable settings."], "authors": "Stefan Kollmannsberger"},
{"Title": "Improving Open-Set Semi-Supervised Learning with Self-Supervision", "abs": ["Open-set semi-supervised learning (OSSL) embodies a practical scenario within semi-supervised learning, wherein the unlabeled training set encompasses classes absent from the labeled set. Many existing OSSL methods assume that these out-of-distribution data are harmful and put effort into excluding data belonging to unknown classes from the training objective. In contrast, we propose an OSSL framework that facilitates learning from all unlabeled data through self-supervision. Additionally, we utilize an energy-based score to accurately recognize data belonging to the known classes, making our method well-suited for handling uncurated data in deployment. We show through extensive experimental evaluations that our method yields state-of-the-art results on many of the evaluated benchmark problems in terms of closed-set accuracy and open-set recognition when compared with existing methods for OSSL. Our code is available at", "."], "authors": "Erik Wallin"},
{"Title": "Adaptive Deep Neural Network Inference Optimization with EENet", "abs": ["Well-trained deep neural networks (DNNs) treat all test samples equally during prediction. Adaptive DNN inference with early exiting leverages the observation that some test examples can be easier to predict than others. This paper presents EENet, a novel early-exiting scheduling framework for multi-exit DNN models. Instead of having every sample go through all DNN layers during prediction, EENet learns an early exit scheduler, which can intelligently terminate the inference earlier for certain predictions, which the model has high confidence of early exit. As opposed to previous early-exiting solutions with heuristics-based methods, our EENet framework optimizes an early-exiting policy to maximize model accuracy while satisfying the given per-sample average inference budget. Extensive experiments are conducted on four computer vision datasets (CIFAR-10, CIFAR-100, ImageNet, Cityscapes) and two NLP datasets (SST-2, AgNews). The results demonstrate that the adaptive inference by EENet can outperform the representative existing early exit techniques. We also perform a detailed visualization analysis of the comparison results to interpret the benefits of EENet."], "authors": "Fatih Ilhan"},
{"Title": "Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense", "abs": ["We present a new algorithm to learn a deep neural network model robust against adversarial attacks. Previous algorithms demonstrate an adversarially trained Bayesian Neural Network (BNN) provides improved robustness. We recognize the adversarial learning approach for approximating the multi-modal posterior distribution of a Bayesian model can lead to mode collapse; consequently, the model's achievements in robustness and performance are sub-optimal. Instead, we first propose preventing mode collapse to better approximate the multi-modal posterior distribution. Second, based on the intuition that a robust model should ignore perturbations and only consider the informative content of the input, we conceptualize and formulate an information gain objective to measure and force the information learned from both benign and adversarial training instances to be similar. Importantly. we prove and demonstrate that minimizing the information gain objective allows the adversarial risk to approach the conventional empirical risk. We believe our efforts provide a step toward a basis for a principled method of adversarially training BNNs. Our model demonstrate significantly improved robustness--up to 20%--compared with adversarial training and Adv-BNN under PGD attacks with 0.035 distortion on both CIFAR-10 and STL-10 datasets."], "authors": "Bao Gia Doan"},
{"Title": "Identify ambiguous tasks combining crowdsourced labels by weighting Areas Under the Margin", "abs": ["In supervised learning - for instance in image classification - modern massive datasets are commonly labeled by a crowd of workers. The obtained labels in this crowdsourcing setting are then aggregated for training, generally leveraging a per-worker trust score. Yet, such workers oriented approaches discard the tasks' ambiguity. Ambiguous tasks might fool expert workers, which is often harmful for the learning step. In standard supervised learning settings - with one label per task - the Area Under the Margin (AUM) was tailored to identify mislabeled data. We adapt the AUM to identify ambiguous tasks in crowdsourced learning scenarios, introducing the Weighted Areas Under the Margin (WAUM). The WAUM is an average of AUMs weighted according to task-dependent scores. We show that the WAUM can help discarding ambiguous tasks from the training set, leading to better generalization performance. We report improvements over existing strategies for learning with a crowd, both on simulated settings, and on real datasets such as CIFAR-10H (a crowdsourced dataset with a high number of answered labels),LabelMe and Music (two datasets with few answered votes)."], "authors": "Tanguy Lefort"},
{"Title": "Defects of Convolutional Decoder Networks in Frequency Representation", "abs": ["In this paper, we prove the representation defects of a cascaded convolutional decoder network, considering the capacity of representing different frequency components of an input sample. We conduct the discrete Fourier transform on each channel of the feature map in an intermediate layer of the decoder network. Then, we extend the 2D circular convolution theorem to represent the forward and backward propagations through convolutional layers in the frequency domain. Based on this, we prove three defects in representing feature spectrums. First, we prove that the convolution operation, the zero-padding operation, and a set of other settings all make a convolutional decoder network more likely to weaken high-frequency components. Second, we prove that the upsampling operation generates a feature spectrum, in which strong signals repetitively appear at certain frequencies. Third, we prove that if the frequency components in the input sample and frequency components in the target output for regression have a small shift, then the decoder usually cannot be effectively learned."], "authors": "Ling Tang"},
{"Title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "abs": ["In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability."], "authors": "Xin Wang"},
{"Title": "Interpreting and Disentangling Feature Components of Various Complexity from DNNs", "abs": ["This paper aims to define, quantify, and analyze the feature complexity that is learned by a DNN. We propose a generic definition for the feature complexity. Given the feature of a certain layer in the DNN, our method disentangles feature components of different complexity orders from the feature. We further design a set of metrics to evaluate the reliability, the effectiveness, and the significance of over-fitting of these feature components. Furthermore, we successfully discover a close relationship between the feature complexity and the performance of DNNs. As a generic mathematical tool, the feature complexity and the proposed metrics can also be used to analyze the success of network compression and knowledge distillation."], "authors": "Jie Ren"},
{"Title": "Stability-Informed Initialization of Neural Ordinary Differential Equations", "abs": ["This paper addresses the training of Neural Ordinary Differential Equations (neural ODEs), and in particular explores the interplay between numerical integration techniques, stability regions, step size, and initialization techniques. It is shown how the choice of integration technique implicitly regularizes the learned model, and how the solver's corresponding stability region affects training and prediction performance. From this analysis, a stability-informed parameter initialization technique is introduced. The effectiveness of the initialization method is displayed across several learning benchmarks and industrial applications."], "authors": "Theodor Westny"},
{"Title": "Fast Deep Mixtures of Gaussian Process Experts", "abs": ["Mixtures of experts have become an indispensable tool for flexible modelling in a supervised learning context, allowing not only the mean function but the entire density of the output to change with the inputs. Sparse Gaussian processes (GP) have shown promise as a leading candidate for the experts in such models, and in this article, we propose to design the gating network for selecting the experts from such mixtures of sparse GPs using a deep neural network (DNN). Furthermore, a fast one pass algorithm called Cluster-Classify-Regress (CCR) is leveraged to approximate the maximum a posteriori (MAP) estimator extremely quickly. This powerful combination of model and algorithm together delivers a novel method which is flexible, robust, and extremely efficient. In particular, the method is able to outperform competing methods in terms of accuracy and uncertainty quantification. The cost is competitive on low-dimensional and small data sets, but is significantly lower for higher-dimensional and big data sets. Iteratively maximizing the distribution of experts given allocations and allocations given experts does not provide significant improvement, which indicates that the algorithm achieves a good approximation to the local MAP estimator very fast. This insight can be useful also in the context of other mixture of experts models."], "authors": "Clement Etienam"},
{"Title": "Domain Adaptation: Learning Bounds and Algorithms", "abs": ["This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data. Building on previous work by Ben-David et al. (2007), we introduce a novel distance between distributions, discrepancy distance, that is tailored to adaptation problems with arbitrary loss functions. We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions. Using this distance, we derive novel generalization bounds for domain adaptation for a wide family of loss functions. We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy. This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give novel algorithms. We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation."], "authors": "Yishay Mansour"},
{"Title": "Scale Ratio Tuning of Group Based Job Scheduling in HPC Systems", "abs": ["During the initialization of a supercomputer job, no useful calculations are performed. A high proportion of initialization time results in idle computing resources and less computational efficiency. Certain methods and algorithms combining jobs into groups are used to optimize scheduling of jobs with high initialization proportion. The article considers the influence of the scale ratio setting in algorithm for the job groups formation, on the performance metrics of the workload manager. The study was carried out on the developed by authors Aleabased workload manager model. The model makes it possible to conduct a large number of experiments in reasonable time without losing the accuracy of the simulation. We performed a series of experiments involving various characteristics of the workload. The article represents the results of a study of the scale ratio influence on efficiency metrics for different initialization time proportions and input workflows with varying intensity and homogeneity. The presented results allow the workload managers administrators to set a scale ratio that provides an appropriate balance with contradictory efficiency metrics."], "authors": "Lyakhovets D. S."},
{"Title": "Lineax: unified linear solves and linear least-squares in JAX and Equinox", "abs": ["We introduce Lineax, a library bringing linear solves and linear least-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses general linear operators, and unifies linear solves and least-squares into a single, autodifferentiable API. Solvers and operators are user-extensible, without requiring the user to implement any custom derivative rules to get differentiability. Lineax is available at", "."], "authors": "Jason Rader"},
{"Title": "Selectively Providing Reliance Calibration Cues With Reliance Prediction", "abs": ["For effective collaboration between humans and intelligent agents that employ machine learning for decision-making, humans must understand what agents can and cannot do to avoid over/under-reliance. A solution to this problem is adjusting human reliance through communication using reliance calibration cues (RCCs) to help humans assess agents' capabilities. Previous studies typically attempted to calibrate reliance by continuously presenting RCCs, and when an agent should provide RCCs remains an open question. To answer this, we propose Pred-RC, a method for selectively providing RCCs. Pred-RC uses a cognitive reliance model to predict whether a human will assign a task to an agent. By comparing the prediction results for both cases with and without an RCC, Pred-RC evaluates the influence of the RCC on human reliance. We tested Pred-RC in a human-AI collaboration task and found that it can successfully calibrate human reliance with a reduced number of RCCs."], "authors": "Yosuke Fukuchi"},
{"Title": "Generative Escher Meshes", "abs": ["This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher. In contrast to the standard concept of a seamless texture, i.e., square images that are seamless when tiled, our method generates non-square tilings which comprise solely of repeating copies of the same object. It achieves this by optimizing both geometry and color of a 2D mesh, in order to generate a non-square tile in the shape and appearance of the desired object, with close to no additional background details. We enable geometric optimization of tilings by our key technical contribution: an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. Namely, we prove that modifying the laplacian used in a 2D mesh-mapping technique - Orbifold Tutte Embedding - can achieve all possible tiling configurations for a chosen planar symmetry group. We thus consider both the mesh's tile-shape and its texture as optimizable parameters, rendering the textured mesh via a differentiable renderer. We leverage a trained image diffusion model to define a loss on the resulting image, thereby updating the mesh's parameters based on its appearance matching the text prompt. We show our method is able to produce plausible, appealing results, with non-trivial tiles, for a variety of different periodic tiling patterns."], "authors": "Noam Aigerman"},
{"Title": "A natural bijection for contiguous pattern avoidance in words", "abs": ["Two words $p$ and $q$ are avoided by the same number of length-$n$ words, for all $n$, precisely when $p$ and $q$ have the same set of border lengths. Previous proofs of this theorem use generating functions but do not provide an explicit bijection. We give a bijective proof for all pairs $p, q$ that have the same set of proper borders, establishing a natural bijection from the set of words avoiding $p$ to the set of words avoiding $q$."], "authors": "Julia Carrigan"},
{"Title": "65 GOPS/neuron Photonic Tensor Core with Thin-film Lithium Niobate Photonics", "abs": ["Photonics offers a transformative approach to artificial intelligence (AI) and neuromorphic computing by providing low latency, high bandwidth, and energy-efficient computations. Here, we introduce a photonic tensor core processor enabled by time-multiplexed inputs and charge-integrated outputs. This fully integrated processor, comprising only two thin-film lithium niobate (TFLN) modulators, a III-V laser, and a charge-integration photoreceiver, can implement an entire layer of a neural network. It can execute 65 billion operations per second (GOPS) per neuron, including simultaneous weight updates-a hitherto unachieved speed. Our processor stands out from conventional photonic processors, which have static weights set during training, as it supports fast \"hardware-in-the-loop\" training, and can dynamically adjust the inputs (fan-in) and outputs (fan-out) within a layer, thereby enhancing its versatility. Our processor can perform large-scale dot-product operations with vector dimensions up to 131,072. Furthermore, it successfully classifies (supervised learning) and clusters (unsupervised learning) 112*112-pixel images after \"hardware-in-the-loop\" training. To handle \"hardware-in-the-loop\" training for clustering AI tasks, we provide a solution for multiplications involving two negative numbers based on our processor."], "authors": "Zhongjin Lin"},
{"Title": "Is stochastic thermodynamics the key to understanding the energy costs of computation?", "abs": ["The relationship between the thermodynamic and computational characteristics of dynamical physical systems has been a major theoretical interest since at least the 19th century, and has been of increasing practical importance as the energetic cost of digital devices has exploded over the last half century. One of the most important thermodynamic features of real-world computers is that they operate very far from thermal equilibrium, in finite time, with many quickly (co-)evolving degrees of freedom. Such computers also must almost always obey multiple physical constraints on how they work. For example, all modern digital computers are periodic processes, governed by a global clock. Another example is that many computers are modular, hierarchical systems, with strong restrictions on the connectivity of their subsystems. This properties hold both for naturally occurring computers, like brains or Eukaryotic cells, as well as digital systems. These features of real-world computers are absent in 20th century analyses of the thermodynamics of computational processes, which focused on quasi-statically slow processes. However, the field of stochastic thermodynamics has been developed in the last few decades - and it provides the formal tools for analyzing systems that have exactly these features of real-world computers. We argue here that these tools, together with other tools currently being developed in stochastic thermodynamics, may help us understand at a far deeper level just how the fundamental physical properties of dynamic systems are related to the computation that they perform."], "authors": "David Wolpert"},
{"Title": "Analyzing Robustness of Angluin's L* Algorithm in Presence of Noise", "abs": ["Angluin's L* algorithm learns the minimal (complete) deterministic finite automaton (DFA) of a regular language using membership and equivalence queries. Its probabilistic approximatively correct (PAC) version substitutes an equivalence query by a large enough set of random membership queries to get a high level confidence to the answer. Thus it can be applied to any kind of (also non-regular) device and may be viewed as an algorithm for synthesizing an automaton abstracting the behavior of the device based on observations.  Here we are interested on how Angluin's PAC learning algorithm behaves for devices which are obtained from a DFA by introducing some noise. More precisely we study whether Angluin's algorithm reduces the noise and produces a DFA closer to the original one than the noisy device.  We propose several ways to introduce the noise: (1) the noisy device inverts the classification of words w.r.t. the DFA with a small probability, (2) the noisy device modifies with a small probability the letters of the word before asking its classification w.r.t. the DFA, and (3) the noisy device combines the classification of a word w.r.t. the DFA and its classification w.r.t. a counter automaton.  Our experiments were performed on several hundred DFAs.", "Our main contributions, bluntly stated, consist in showing that: (1) Angluin's algorithm behaves well whenever the noisy device is produced by a random process, (2) but poorly with a structured noise, and, that (3) almost surely randomness yields systems with non-recursively enumerable languages."], "authors": "Igor Khmelnitsky"},
{"Title": "Analyzing Robustness of Angluin's L$^*$ Algorithm in Presence of Noise", "abs": ["Angluin's L$^*$ algorithm learns the minimal deterministic finite automaton (DFA) of a regular language using membership and equivalence queries. Its probabilistic approximatively correct (PAC) version substitutes an equivalence query by numerous random membership queries to get a high level confidence to the answer. Thus it can be applied to any kind of device and may be viewed as an algorithm for synthesizing an automaton abstracting the behavior of the device based on observations. Here we are interested on how Angluin's PAC learning algorithm behaves for devices which are obtained from a DFA by introducing some noise. More precisely we study whether Angluin's algorithm reduces the noise and produces a DFA closer to the original one than the noisy device. We propose several ways to introduce the noise: (1) the noisy device inverts the classification of words w.r.t. the DFA with a small probability, (2) the noisy device modifies with a small probability the letters of the word before asking its classification w.r.t. the DFA, (3) the noisy device combines the classification of a word w.r.t. the DFA and its classification w.r.t. a counter automaton, and (4) the noisy DFA is obtained by a random process from two DFA such that the language of the first one is included in the second one. Then when a word is accepted (resp. rejected) by the first (resp. second) one, it is also accepted (resp. rejected) and in the remaining cases, it is accepted with probability 0.5. Our main experimental contributions consist in showing that: (1) Angluin's algorithm behaves well whenever the noisy device is produced by a random process, (2) but poorly with a structured noise, and, that (3) is able to eliminate pathological behaviours specified in a regular way. Theoretically, we show that randomness almost surely yields systems with non-recursively enumerable languages."], "authors": "Lina Ye"},
{"Title": "Data Science from 1963 to 2012", "abs": ["Consensus on the definition of data science remains low despite the widespread establishment of academic programs in the field and continued demand for data scientists in industry. Definitions range from rebranded statistics to data-driven science to the science of data to simply the application of machine learning to so-called big data to solve real-world problems. Current efforts to trace the history of the field in order to clarify its definition, such as Donoho's \"50 Years of Data Science\" (Donoho 2017), tend to focus on a short period when a small group of statisticians adopted the term in an unsuccessful attempt to rebrand their field in the face of the overshadowing effects of computational statistics and data mining. Using textual evidence from primary sources, this essay traces the history of the term to the 1960s, when it was first used by the US Air Force in a surprisingly similar way to its current usage, to 2012, the year that Harvard Business Review published the enormously influential article \"Data Scientist: The Sexiest Job of the 21st Century\" (Davenport and Patil 2012), while the American Statistical Association acknowledged a profound disconnect between statistics and data science. Among the themes that emerge from this review are (1) the long-standing opposition between data analysts and data miners that continues to animate the field, (2) an established definition of the term as the practice of managing and processing scientific data that has been occluded by recent usage, and (3) the phenomenon of data impedance -- the disproportion between surplus data, indexed by phrases like data deluge and big data, and the limitations of computational machinery and methods to process them. This persistent condition appears to have motivated the use of the term and the field itself since its beginnings."], "authors": "Rafael C. Alvarado"},
{"Title": "The 4+1 Model of Data Science", "abs": ["Data Science is a complex and evolving field, but most agree that it can be defined as a combination of expertise drawn from three broad areascomputer science and technology, math and statistics, and domain knowledge -- with the purpose of extracting knowledge and value from data. Beyond this, the field is often defined as a series of practical activities ranging from the cleaning and wrangling of data, to its analysis and use to infer models, to the visual and rhetorical representation of results to stakeholders and decision-makers. This essay proposes a model of data science that goes beyond laundry-list definitions to get at the specific nature of data science and help distinguish it from adjacent fields such as computer science and statistics. We define data science as an interdisciplinary field comprising four broad areas of expertise: value, design, systems, and analytics. A fifth area, practice, integrates the other four in specific contexts of domain knowledge. We call this the 4+1 model of data science. Together, these areas belong to every data science project, even if they are often unconnected and siloed in the academy."], "authors": "Rafael C. Alvarado"},
{"Title": "A causal convolutional neural network for multi-subject motion modeling and generation", "abs": ["Inspired by the success of WaveNet in multi-subject speech synthesis, we propose a novel neural network based on causal convolutions for multi-subject motion modeling and generation. The network can capture the intrinsic characteristics of the motion of different subjects, such as the influence of skeleton scale variation on motion style. Moreover, after fine-tuning the network using a small motion dataset for a novel skeleton that is not included in the training dataset, it is able to synthesize high-quality motions with a personalized style for the novel skeleton. The experimental results demonstrate that our network can model the intrinsic characteristics of motions well and can be applied to various motion modeling and synthesis tasks."], "authors": "Shuaiying Hou"},
{"Title": "Practical Blind Image Denoising via Swin-Conv-UNet and Data Synthesis", "abs": ["While recent years have witnessed a dramatic upsurge of exploiting deep neural networks toward solving image denoising, existing methods mostly rely on simple noise assumptions, such as additive white Gaussian noise (AWGN), JPEG compression noise and camera sensor noise, and a general-purpose blind denoising method for real images remains unsolved. In this paper, we attempt to solve this problem from the perspective of network architecture design and training data synthesis. Specifically, for the network architecture design, we propose a swin-conv block to incorporate the local modeling ability of residual convolutional layer and non-local modeling ability of swin transformer block, and then plug it as the main building block into the widely-used image-to-image translation UNet architecture. For the training data synthesis, we design a practical noise degradation model which takes into consideration different kinds of noise (including Gaussian, Poisson, speckle, JPEG compression, and processed camera sensor noises) and resizing, and also involves a random shuffle strategy and a double degradation strategy. Extensive experiments on AGWN removal and real image denoising demonstrate that the new network architecture design achieves state-of-the-art performance and the new degradation model can help to significantly improve the practicability. We believe our work can provide useful insights into current denoising research."], "authors": "Kai Zhang"},
{"Title": "An HCAI Methodological Framework: Putting It Into Action to Enable Human-Centered AI", "abs": ["Human-centered AI (HCAI), as a design philosophy, advocates prioritizing humans in designing, developing, and deploying intelligent systems, aiming to maximize the benefits of AI technology to humans and avoid its potential adverse effects. While HCAI has gained momentum, the lack of guidance on methodology in its implementation makes its adoption challenging. After assessing the needs for a methodological framework for HCAI, this paper first proposes a comprehensive and interdisciplinary HCAI methodological framework integrated with seven components, including design goals, design principles, implementation approaches, design paradigms, interdisciplinary teams, methods, and processes. THe implications of the framework are also discussed. This paper also presents a \"three-layer\" approach to facilitate the implementation of the framework. We believe the proposed framework is systematic and executable, which can overcome the weaknesses in current frameworks and the challenges currently faced in implementing HCAI. Thus, the framework can help put it into action to develop, transfer, and implement HCAI in practice, eventually enabling the design, development, and deployment of HCAI-based intelligent systems."], "authors": "Wei Xu"},
{"Title": "BIASeD: Bringing Irrationality into Automated System Design", "abs": ["Human perception, memory and decision-making are impacted by tens of cognitive biases and heuristics that influence our actions and decisions. Despite the pervasiveness of such biases, they are generally not leveraged by today's Artificial Intelligence (AI) systems that model human behavior and interact with humans. In this theoretical paper, we claim that the future of human-machine collaboration will entail the development of AI systems that model, understand and possibly replicate human cognitive biases. We propose the need for a research agenda on the interplay between human cognitive biases and Artificial Intelligence. We categorize existing cognitive biases from the perspective of AI systems, identify three broad areas of interest and outline research directions for the design of AI systems that have a better understanding of our own biases."], "authors": "Aditya Gulati"},
{"Title": "Iceberg Sensemaking: A Process Model for Critical Data Analysis and Visualization", "abs": ["We offer a new model of the sensemaking process for data analysis and visualization. Whereas past sensemaking models have been grounded in positivist assumptions about the nature of knowledge, we reframe data sensemaking in critical, humanistic terms by approaching it through an interpretivist lens. Our three-phase process model uses the analogy of an iceberg, where data is the visible tip of underlying schemas. In the Add phase, the analyst acquires data, incorporates explicit schemas from the data, and absorbs the tacit schemas of both data and people. In the Check phase, the analyst interprets the data with respect to the current schemas and evaluates whether the schemas match the data. In the Refine phase, the analyst considers the role of power, articulates what was tacit into explicitly stated schemas, updates data, and formulates findings. Our model has four important distinguishing features: Tacit and Explicit Schemas, Schemas First and Always, Data as a Schematic Artifact, and Schematic Multiplicity. We compare the roles of schemas in past sensemaking models and draw conceptual distinctions based on a historical review of schemas in different academic traditions. We validate the descriptive and prescriptive power of our model through four analysis scenarios: noticing uncollected data, learning to wrangle data, downplaying inconvenient data, and measuring with sensors. We conclude by discussing the value of interpretivism, the virtue of epistemic humility, and the pluralism this sensemaking model can foster."], "authors": "Charles Berret"},
{"Title": "Polynomial-delay Enumeration Kernelizations for Cuts of Bounded Degree", "abs": ["Enumeration kernelization was first proposed by Creignou et al. [TOCS 2017] and was later refined by Golovach et al. [JCSS 2022] into two different variants: fully-polynomial enumeration kernelization and polynomial-delay enumeration kernelization. In this paper, we consider the DEGREE-d-CUT problem from the perspective of (polynomial-delay) enumeration kenrelization. Given an undirected graph G = (V, E), a cut F = E(A, B) is a degree-d-cut of G if every $u \\in A$ has at most d neighbors in B and every $v \\in B$ has at most d neighbors in A. Checking the existence of a degree-d-cut in a graph is a well-known NP-hard problem and is well-studied in parameterized complexity [Algorithmica 2021, IWOCA 2021]. This problem also generalizes a well-studied problem MATCHING CUT (set d = 1) that has been a central problem in the literature of polynomial-delay enumeration kernelization. In this paper, we study three different enumeration variants of this problem, ENUM DEGREE-d-CUT, ENUM MIN-DEGREE-d-CUT and ENUM MAX-DEGREE-d-CUT that intends to enumerate all the d-cuts, all the minimal d-cuts and all the maximal degree-d-cuts respectively. We consider various structural parameters of the input and provide polynomial-delay enumeration kernels for ENUM DEGREE-d-CUT and ENUM MAX-DEGREE-d-CUT and fully-polynomial enumeration kernels of polynomial size for ENUM MIN-DEGREE-d-CUT."], "authors": "Diptapriyo Majumdar"},
{"Title": "An Explorative Study on Document Type Assignment of Review Articles in Web of Science, Scopus and Journals' Website", "abs": ["Accurately assigning the document type of review articles in citation index databases like Web of Science(WoS) and Scopus is important. This study aims to investigate the document type assignation of review articles in web of Science, Scopus and Journals' website in a large scale. 27,616 papers from 160 journals from 10 review journal series indexed in SCI are analyzed. The document types of these papers labeled on journals' website, and assigned by WoS and Scopus are retrieved and compared to determine the assigning accuracy and identify the possible reasons of wrongly assigning. For the document type labeled on the website, we further differentiate them into explicit review and implicit review based on whether the website directly indicating it is review or not. We find that WoS and Scopus performed similarly, with an average precision of about 99% and recall of about 80%. However, there were some differences between WoS and Scopus across different journal series and within the same journal series. The assigning accuracy of WoS and Scopus for implicit reviews dropped significantly. This study provides a reference for the accuracy of document type assigning of review articles in WoS and Scopus, and the identified pattern for assigning implicit reviews may be helpful to better labeling on website, WoS and Scopus."], "authors": "Manman Zhu"},
{"Title": "Variations in Web of Science and Scopus Journal Coverage, Visibility and Prestige between 2001 and 2020", "abs": ["Purpose: This study focuses on the changes in differences in the journal coverage, visibility and prestige of journals from top twenty countries in Web of Science and Scopus in the twenty-year timeframe-2001-2020. Methodology: Using Web of Science and Scopus journal data from Journal Citation Reports and Scimago Journal Rank, respectively, top twenty countries by number of journals indexed in the two databases were identified. Analysis of the changes that occurred in the number of journals from the top twenty countries, the citations they received and their prestige were analyzed. Findings: USA and UK continued their dominance of the journals indexed in Web of Science and Scopus, but their dominance waned gradually in the course of the twenty-year period. The rate of growth of journals indexed by the databases is steeper among the countries outside the top. In Web of Science, journals from the UK were the most prestigious until 2010 when China emerged as the most prestigious journals. USA continues to take the leading spot in terms of most prestigious journals in Scopus, followed by UK. Research Limitations: This investigation relied on third-party datasets sourced from the Scimago Journal Rank repository for the compilation of the Scopus journal list. Practical implications: This study suggests an inclination towards diversity by Web of Science and Scopus, though North America and Europe continue to dominate journal coverage. However, the gulf in the prestige and visibility of journals from North America, Europe and other parts of the world remains, suggesting the researchers from the peripheral may continue to gravitate towards the core. Originality/Value: While studies have provided singular-year analyses of journal coverages of Web of Science and Scopus, this study provides an analysis of 20 years."], "authors": "Toluwase Victor Asubiaro"},
{"Title": "Expressivity and Complexity of the Conjunctive Core of the SIGNAL Process Query Language", "abs": ["This paper presents a formalisation and expressivity and complexity analysis of SIGNAL, an industry-scale query language for analysing business process event logs. The formal analysis shows that the core capabilities of SIGNAL, which we refer to as the SIGNAL Conjunctive Core, are more expressive than relational algebra and thus not captured by standard relational databases. We do provide an upper-bound on the expressiveness via a reduction to semi-positive Datalog, which also leads to an upper bound of P-hard for the data complexity of evaluating SIGNAL Conjunctive Core queries. The findings provide first insights into how real-world process query languages are fundamentally different from the more generally prevalent structured query languages for querying relational databases and provide a rigorous foundation for extending the existing capabilities of the industry-scale state-of-the-art of process data querying."], "authors": "Timotheus Kampik"},
{"Title": "Task-Specific Alignment and Multiple Level Transformer for Few-Shot Action Recognition", "abs": ["In the research field of few-shot learning, the main difference between image-based and video-based is the additional temporal dimension. In recent years, some works have used the Transformer to deal with frames, then get the attention feature and the enhanced prototype, and the results are competitive. However, some video frames may relate little to the action, and only using single frame-level or segment-level features may not mine enough information. We address these problems sequentially through an end-to-end method named \"Task-Specific Alignment and Multiple-level Transformer Network (TSA-MLT)\". The first module (TSA) aims at filtering the action-irrelevant frames for action duration alignment. Affine Transformation for frame sequence in the time dimension is used for linear sampling. The second module (MLT) focuses on the Multiple-level feature of the support prototype and query sample to mine more information for the alignment, which operates on different level features. We adopt a fusion loss according to a fusion distance that fuses the L2 sequence distance, which focuses on temporal order alignment, and the Optimal Transport distance, which focuses on measuring the gap between the appearance and semantics of the videos. Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something 2-something V2 datasets. Our code is available at the URL:"], "authors": "Fei Guo"},
{"Title": "Coboundary and cosystolic expansion without dependence on dimension or degree", "abs": ["We give new bounds on the cosystolic expansion constants of several families of high dimensional expanders, and the known coboundary expansion constants of order complexes of homogeneous geometric lattices, including the spherical building of $SL_n(F_q)$. The improvement applies to the high dimensional expanders constructed by Lubotzky, Samuels and Vishne, and by Kaufman and Oppenheim.", "Our new expansion constants do not depend on the degree of the complex nor on its dimension, nor on the group of coefficients. This implies improved bounds on Gromov's topological overlap constant, and on Dinur and Meshulam's cover stability, which may have applications for agreement testing. In comparison, existing bounds decay exponentially with the ambient dimension (for spherical buildings) and in addition decay linearly with the degree (for all known bounded-degree high dimensional expanders). Our results are based on several new techniques:", "* We develop a new \"color-restriction\" technique which enables proving dimension-free expansion by restricting a multi-partite complex to small random subsets of its color classes.", "* We give a new \"spectral\" proof for Evra and Kaufman's local-to-global theorem, deriving better bounds and getting rid of the dependence on the degree. This theorem bounds the cosystolic expansion of a complex using coboundary expansion and spectral expansion of the links.", "* We derive absolute bounds on the coboundary expansion of the spherical building (and any order complex of a homogeneous geometric lattice) by constructing a novel family of very short cones."], "authors": "Yotam Dikstein"},
{"Title": "Faster Matroid Partition Algorithms", "abs": ["In the matroid partitioning problem, we are given $k$ matroids $\\mathcal{M}_1 = (V, \\mathcal{I}_1), \\dots , \\mathcal{M}_k = (V, \\mathcal{I}_k)$ defined over a common ground set $V$ of $n$ elements, and we need to find a partitionable set $S \\subseteq V$ of largest possible cardinality, denoted by $p$. Here, a set $S \\subseteq V$ is called partitionable if there exists a partition $(S_1, \\dots , S_k)$ of $S$ with $S_i \\in \\mathcal{I}_i$ for $i = 1, \\ldots, k$. In 1986, Cunningham [SICOMP 1986] presented a matroid partition algorithm that uses $O(n p^{3/2} + k n)$ independence oracle queries, which was the previously known best algorithm. This query complexity is $O(n^{5/2})$ when $k \\leq n$.", "Our main result is to present a matroid partition algorithm that uses $\\tilde{O}(k'^{1/3} n p + k n)$ independence oracle queries, where $k' = \\min\\{k, p\\}$. This query complexity is $\\tilde{O}(n^{7/3})$ when $k \\leq n$, and this improves upon the one of previous Cunningham's algorithm. To obtain this, we present a new approach \\emph{edge recycling augmentation}, which can be attained through new ideas: an efficient utilization of the binary search technique by Nguyen [2019] and Chakrabarty-Lee-Sidford-Singla-Wong [FOCS 2019] and a careful analysis of the independence oracle query complexity. Our analysis differs significantly from the one for matroid intersection algorithms, because of the parameter $k$. We also present a matroid partition algorithm that uses $\\tilde{O}((n + k) \\sqrt{p})$ rank oracle queries."], "authors": "Tatsuya Terao"},
{"Title": "Sumplete is Hard, Even with Two Different Numbers", "abs": ["Sumplete is a logic puzzle famous for being developed by ChatGPT. The puzzle consists of a rectangular grid, with each cell containing a number. The player has to cross out some numbers such that the sum of uncrossed numbers in each row and column is equal to a given integer assigned to that row or column. In this paper, we prove that deciding solvability of a given Sumplete puzzle is NP-complete, even if the grid contains only two different numbers."], "authors": "Suthee Ruangwises"},
{"Title": "Galloping in fast-growth natural merge sorts", "abs": ["We study the impact of merging routines in merge-based sorting algorithms. More precisely, we focus on the galloping routine that TimSort uses to merge monotonic sub-arrays, hereafter called runs, and on the impact on the number of element comparisons performed if one uses this routine instead of a naïve merging routine.", "This routine was introduced in order to make TimSort more efficient on arrays with few distinct values. Alas, we prove that, although it makes TimSort sort array with two values in linear time, it does not prevent TimSort from requiring up to $\\Theta(n \\log(n))$ element comparisons to sort arrays of length~$n$ with three distinct values. However, we also prove that slightly modifying TimSort's galloping routine results in requiring only $\\mathcal{O}(n + n \\log(\\sigma))$ element comparisons in the worst case, when sorting arrays of length $n$ with $\\sigma$ distinct values.", "We do so by focusing on the notion of dual runs, which was introduced in the 1990s, and on the associated dual run-length entropy. This notion is both related to the number of distinct values and to the number of runs in an array, which came with its own run-length entropy that was used to explain TimSort's otherwise \"supernatural\" efficiency. We also introduce new notions of fast- and middle-growth for natural merge sorts (i.e., algorithms based on merging runs), which are found in several merge sorting algorithms similar to TimSort.", "We prove that algorithms with the fast- or middle-growth property, provided that they use our variant of TimSort's galloping routine for merging runs, are as efficient as possible at sorting arrays with low run-induced or dual-run-induced complexities."], "authors": "Elahe Ghasemi"},
{"Title": "Is decentralized finance actually decentralized? A social network analysis of the Aave protocol on the Ethereum blockchain", "abs": ["Decentralized finance (DeFi) has the potential to disrupt centralized finance by validating peer-to-peer transactions through tamper-proof smart contracts, thus significantly lowering the transaction cost charged by financial intermediaries. However, the actual realization of peer-to-peer transactions and the levels and effects of decentralization are largely unknown. Our research pioneers a blockchain network study that applies social network analysis to measure the level, dynamics, and impacts of decentralization in DeFi token transactions on the Ethereum blockchain. First, we find a significant core-periphery structure in the AAVE token transaction network where the cores include the two largest centralized crypto exchanges. Second, we provide evidence that multiple network features consistently characterize decentralization dynamics. Finally, we document that a more decentralized network significantly predicts a higher return and lower volatility of the decentralized market of AAVE tokens on the Ethereum blockchain. We point out that our approach is seminal for inspiring future extensions related to the facets of application scenarios, research questions, and methodologies on the mechanics of blockchain decentralization."], "authors": "Ziqiao Ao"},
{"Title": "Devising and Detecting Phishing: Large Language Models vs. Smaller Human Models", "abs": ["AI programs, built using large language models, make it possible to automatically create phishing emails based on a few data points about a user. They stand in contrast to traditional phishing emails that hackers manually design using general rules gleaned from experience. The V-Triad is an advanced set of rules for manually designing phishing emails to exploit our cognitive heuristics and biases. In this study, we compare the performance of phishing emails created automatically by GPT-4 and manually using the V-Triad. We also combine GPT-4 with the V-Triad to assess their combined potential. A fourth group, exposed to generic phishing emails, was our control group. We utilized a factorial approach, sending emails to 112 randomly selected participants recruited for the study. The control group emails received a click-through rate between 19-28%, the GPT-generated emails 30-44%, emails generated by the V-Triad 69-79%, and emails generated by GPT and the V-Triad 43-81%. Each participant was asked to explain why they pressed or did not press a link in the email. These answers often contradict each other, highlighting the need for personalized content. The cues that make one person avoid phishing emails make another person fall for them. Next, we used four popular large language models (GPT, Claude, PaLM, and LLaMA) to detect the intention of phishing emails and compare the results to human detection. The language models demonstrated a strong ability to detect malicious intent, even in non-obvious phishing emails. They sometimes surpassed human detection, although often being slightly less accurate than humans. Finally, we make an analysis of the economic aspects of AI-enabled phishing attacks, showing how large language models can increase the incentives of phishing and spear phishing by reducing their costs."], "authors": "Fredrik Heiding"},
{"Title": "Decentralized Finance (DeFi): A Survey", "abs": ["Decentralized Finance (DeFi) is a new paradigm in the creation, distribution, and utilization of financial services via the integration of blockchain technology. Our research conducts a comprehensive introduction and meticulous classification of various DeFi applications. Beyond that, we thoroughly analyze these risks from both technical and economic perspectives, spanning multiple layers. We point out research gaps and revenues, covering technical advancements, innovative economics, and sociology and ecology optimization."], "authors": "Erya Jiang"},
{"Title": "Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition", "abs": ["Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts."], "authors": "Sander Schulhoff"},
{"Title": "Printing Protocol: Physical ZKPs for Decomposition Puzzles", "abs": ["Decomposition puzzles are pencil-and-paper logic puzzles that involve partitioning a rectangular grid into several regions to satisfy certain rules. In this paper, we construct a generic card-based protocol called printing protocol, which can be used to physically verify solutions of decompositon puzzles. We apply the printing protocol to develop card-based zero-knowledge proof protocols for two such puzzles: Five Cells and Meadows. These protocols allow a prover to physically show that he/she knows solutions of the puzzles without revealing them."], "authors": "Suthee Ruangwises"},
{"Title": "Physical Zero-Knowledge Proof for Ball Sort Puzzle", "abs": ["Ball sort puzzle is a popular logic puzzle consisting of several bins containing balls of multiple colors. Each bin works like a stack; a ball has to follow the last-in first-out order. The player has to sort the balls by color such that each bin contains only balls of a single color. In this paper, we propose a physical zero-knowledge proof protocol for the ball sort puzzle using a deck of playing cards, which enables a prover to physically show that he/she knows a solution with $t$ moves of the ball sort puzzle without revealing it. Our protocol is the first zero-knowledge proof protocol for an interactive puzzle involving moving objects."], "authors": "Suthee Ruangwises"},
{"Title": "SmartOTPs: An Air-Gapped 2-Factor Authentication for Smart-Contract Wallets (Extended Version)", "abs": ["With the recent rise of cryptocurrencies' popularity, the security and management of crypto-tokens have become critical. We have witnessed many attacks on users and providers, which have resulted in significant financial losses. To remedy these issues, several wallet solutions have been proposed. However, these solutions often lack either essential security features, usability, or do not allow users to customize their spending rules.", "In this paper, we propose SmartOTPs, a smart-contract wallet framework that gives a flexible, usable, and secure way of managing crypto-tokens in a self-sovereign fashion. The proposed framework consists of four components (i.e., an authenticator, a client, a hardware wallet, and a smart contract), and it provides 2-factor authentication (2FA) performed in two stages of interaction with the blockchain. To the best of our knowledge, our framework is the first one that utilizes one-time passwords (OTPs) in the setting of the public blockchain. In SmartOTPs, the OTPs are aggregated by a Merkle tree and hash chains whereby for each authentication only a short OTP (e.g., 16B-long) is transferred from the authenticator to the client. Such a novel setting enables us to make a fully air-gapped authenticator by utilizing small QR codes or a few mnemonic words, while additionally offering resilience against quantum cryptanalysis. We have made a proof-of-concept based on the Ethereum platform. Our cost analysis shows that the average cost of a transfer operation is comparable to existing 2FA solutions using smart contracts with multi-signatures."], "authors": "Ivan Homoliak"},
{"Title": "Assessment of Deep Learning Segmentation for Real-Time Free-Breathing Cardiac Magnetic Resonance Imaging", "abs": ["In recent years, a variety of deep learning networks for cardiac MRI (CMR) segmentation have been developed and analyzed. However, nearly all of them are focused on cine CMR under breathold. In this work, accuracy of deep learning methods is assessed for volumetric analysis (via segmentation) of the left ventricle in real-time free-breathing CMR at rest and under exercise stress. Data from healthy volunteers (n=15) for cine and real-time free-breathing CMR were analyzed retrospectively. Segmentations of a commercial software (comDL) and a freely available neural network (nnU-Net), were compared to a reference created via the manual correction of comDL segmentation. Segmentation of left ventricular endocardium (LV), left ventricular myocardium (MYO), and right ventricle (RV) is evaluated for both end-systolic and end-diastolic phases and analyzed with Dice's coefficient (DC). The volumetric analysis includes LV end-diastolic volume (EDV), LV end-systolic volume (ESV), and LV ejection fraction (EF). For cine CMR, nnU-Net and comDL achieve a DC above 0.95 for LV and 0.9 for MYO, and RV. For real-time CMR, the accuracy of nnU-Net exceeds that of comDL overall. For real-time CMR at rest, nnU-Net achieves a DC of 0.94 for LV, 0.89 for MYO, and 0.90 for RV; mean absolute differences between nnU-Net and reference are 2.9mL for EDV, 3.5mL for ESV and 2.6% for EF. For real-time CMR under exercise stress, nnU-Net achieves a DC of 0.92 for LV, 0.85 for MYO, and 0.83 for RV; mean absolute differences between nnU-Net and reference are 11.4mL for EDV, 2.9mL for ESV and 3.6% for EF. Deep learning methods designed or trained for cine CMR segmentation can perform well on real-time CMR. For real-time free-breathing CMR at rest, the performance of deep learning methods is comparable to inter-observer variability in cine CMR and is usable or fully automatic segmentation."], "authors": "Martin Schilling"},
{"Title": "AG-CRC: Anatomy-Guided Colorectal Cancer Segmentation in CT with Imperfect Anatomical Knowledge", "abs": ["When delineating lesions from medical images, a human expert can always keep in mind the anatomical structure behind the voxels. However, although high-quality (though not perfect) anatomical information can be retrieved from computed tomography (CT) scans with modern deep learning algorithms, it is still an open problem how these automatically generated organ masks can assist in addressing challenging lesion segmentation tasks, such as the segmentation of colorectal cancer (CRC). In this paper, we develop a novel Anatomy-Guided segmentation framework to exploit the auto-generated organ masks to aid CRC segmentation from CT, namely AG-CRC. First, we obtain multi-organ segmentation (MOS) masks with existing MOS models (e.g., TotalSegmentor) and further derive a more robust organ of interest (OOI) mask that may cover most of the colon-rectum and CRC voxels. Then, we propose an anatomy-guided training patch sampling strategy by optimizing a heuristic gain function that considers both the proximity of important regions (e.g., the tumor or organs of interest) and sample diversity. Third, we design a novel self-supervised learning scheme inspired by the topology of tubular organs like the colon to boost the model performance further. Finally, we employ a masked loss scheme to guide the model to focus solely on the essential learning region. We extensively evaluate the proposed method on two CRC segmentation datasets, where substantial performance improvement (5% to 9% in Dice) is achieved over current state-of-the-art medical image segmentation models, and the ablation studies further evidence the efficacy of every proposed component."], "authors": "Rongzhao Zhang"},
{"Title": "Spatio-Angular Convolutions for Super-resolution in Diffusion MRI", "abs": ["Diffusion MRI (dMRI) is a widely used imaging modality, but requires long scanning times to acquire high resolution datasets. By leveraging the unique geometry present within this domain, we present a novel approach to dMRI angular super-resolution that extends upon the parametric continuous convolution (PCConv) framework. We introduce several additions to the operation including a Fourier feature mapping, global coordinates, and domain specific context. Using this framework, we build a fully parametric continuous convolution network (PCCNN) and compare against existing models. We demonstrate the PCCNN performs competitively while using significantly less parameters. Moreover, we show that this formulation generalises well to clinically relevant downstream analyses such as fixel-based analysis, and neurite orientation dispersion and density imaging."], "authors": "Matthew Lyon"},
{"Title": "ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model", "abs": ["The advent of large language models, enabling flexibility through instruction-driven approaches, has revolutionized many traditional generative tasks, but large models for 3D data, particularly in comprehensively handling 3D shapes with other modalities, are still under-explored. By achieving instruction-based shape generations, versatile multimodal generative shape models can significantly benefit various fields like 3D virtual construction and network-aided design. In this work, we present ShapeGPT, a shape-included multi-modal framework to leverage strong pre-trained language models to address multiple shape-relevant tasks. Specifically, ShapeGPT employs a word-sentence-paragraph framework to discretize continuous shapes into shape words, further assembles these words for shape sentences, as well as integrates shape with instructional text for multi-modal paragraphs. To learn this shape-language model, we use a three-stage training scheme, including shape representation, multimodal alignment, and instruction-based generation, to align shape-language codebooks and learn the intricate correlations among these modalities. Extensive experiments demonstrate that ShapeGPT achieves comparable performance across shape-relevant tasks, including text-to-shape, shape-to-text, shape completion, and shape editing."], "authors": "Fukun Yin"},
{"Title": "Reshaping and Enzymatic Activity allow Viruses to move through the Mucus", "abs": ["Filamentous viruses like influenza and torovirus often display systematic bends and arcs of mysterious physical origin. We propose that such viruses undergo an instability from a cylindrically symmetric to a toroidally curved state. This \"toro-elastic\" state emerges via a spontaneous symmetry breaking under prestress, induced via short range spike protein interactions and magnified by the filament's surface topography. Once surface stresses become sufficiently large, the filament buckles and the toroidal, curved state constitutes a soft mode that can propagate through the filament's material frame around a \"mexican-hat\" potential. In the mucus of our airways, glycan chains are omnipresent that influenza's spike proteins can bind to and cut. We show that when coupled to such a non-equilibrium chemical reaction, the curved toro-elastic state can attain a spontaneous rotation for sufficiently strong enzymatic activity, leading to a whole body reshaping propulsion similar to -- but different from -- eukaryotic flagella and spirochetes."], "authors": "Falko Ziebert"},
{"Title": "Unsupervised high-throughput segmentation of cells and cell nuclei in quantitative phase images", "abs": ["In the effort to aid cytologic diagnostics by establishing automatic single cell screening using high throughput digital holographic microscopy for clinical studies thousands of images and millions of cells are captured. The bottleneck lies in an automatic, fast, and unsupervised segmentation technique that does not limit the types of cells which might occur. We propose an unsupervised multistage method that segments correctly without confusing noise or reflections with cells and without missing cells that also includes the detection of relevant inner structures, especially the cell nucleus in the unstained cell. In an effort to make the information reasonable and interpretable for cytopathologists, we also introduce new cytoplasmic and nuclear features of potential help for cytologic diagnoses which exploit the quantitative phase information inherent to the measurement scheme. We show that the segmentation provides consistently good results over many experiments on patient samples in a reasonable per cell analysis time."], "authors": "Julia Sistermanns"},
{"Title": "Gene regulatory interactions limit the gene expression diversity", "abs": ["The diversity of expressed genes plays a critical role in cellular specialization, adaptation to environmental changes, and overall cell functionality. This diversity varies dramatically across cell types and is orchestrated by intricate, dynamic, and cell type-specific gene regulatory networks (GRNs). Despite extensive research on GRNs, their governing principles, as well as the underlying forces that have shaped them, remain largely unknown. Here, we investigated whether there is a tradeoff between the diversity of expressed genes and the intensity of GRN interactions. We have developed a computational framework that evaluates GRN interaction intensity from scRNA-seq data and used it to analyze simulated and real scRNA-seq data collected from different tissues in humans, mice, fruit flies, and C. elegans. We find a significant tradeoff between diversity and interaction intensity, driven by stability constraints, where the GRN could be stable up to a critical level of complexity - a product of gene expression diversity and interaction intensity. Furthermore, we analyzed hematopoietic stem cell differentiation data and find that the overall complexity of unstable transition states cells is higher than that of stem cells and fully differentiated cells. Our results suggest that GRNs are shaped by stability constraints which limit the diversity of gene expression."], "authors": "Orr Levy"},
{"Title": "Generation of a Compendium of Transcription Factor Cascades and Identification of Potential Therapeutic Targets using Graph Machine Learning", "abs": ["Transcription factors (TFs) play a vital role in the regulation of gene expression thereby making them critical to many cellular processes. In this study, we used graph machine learning methods to create a compendium of TF cascades using data extracted from the STRING database. A TF cascade is a sequence of TFs that regulate each other, forming a directed path in the TF network. We constructed a knowledge graph of 81,488 unique TF cascades, with the longest cascade consisting of 62 TFs. Our results highlight the complex and intricate nature of TF interactions, where multiple TFs work together to regulate gene expression. We also identified 10 TFs with the highest regulatory influence based on centrality measurements, providing valuable information for researchers interested in studying specific TFs. Furthermore, our pathway enrichment analysis revealed significant enrichment of various pathways and functional categories, including those involved in cancer and other diseases, as well as those involved in development, differentiation, and cell signaling. The enriched pathways identified in this study may have potential as targets for therapeutic intervention in diseases associated with dysregulation of transcription factors. We have released the dataset, knowledge graph, and graphML methods for the TF cascades, and created a website to display the results, which can be accessed by researchers interested in using this dataset. Our study provides a valuable resource for understanding the complex network of interactions between TFs and their regulatory roles in cellular processes."], "authors": "Sonish Sivarajkumar"},
{"Title": "Exploring the Relationship Between COVID-19 Induced Economic Downturn and Women's Nutritional Health Disparities", "abs": ["This study explores how the COVID-19 pandemic's economic impact has exacerbated nutritional health disparities among women. It sought to understand the effects of economic challenges on women's dietary choices and access to nutritious food across different socioeconomic groups. Using a mixed-methods approach, the research combined quantitative data from health and economic records with qualitative insights from interviews with diverse women. The study analyzed trends in nutritional health and economic factors before and after the pandemic and gathered personal accounts regarding nutrition and economic difficulties during this period. Findings showed a clear link between the economic downturn and deteriorating nutritional health, particularly in low-income and marginalized groups. These women reported decreased access to healthy foods and an increased dependence on less nutritious options due to budget constraints, leading to a decline in dietary quality. This trend was less evident in higher-income groups, highlighting stark disparities. The pandemic intensified pre-existing nutritional inequalities, with the most vulnerable groups facing greater adverse effects. However, community support and public health measures provided some relief. In summary, the pandemic's economic repercussions have indirectly impaired women's nutritional health, especially among the socioeconomically disadvantaged. This highlights the necessity for tailored nutritional interventions and economic policies focused on safeguarding women's health."], "authors": "Alaa M. Sadeq"},
{"Title": "Trial matching: capturing variability with data-constrained spiking neural networks", "abs": ["Simultaneous behavioral and electrophysiological recordings call for new methods to reveal the interactions between neural activity and behavior. A milestone would be an interpretable model of the co-variability of spiking activity and behavior across trials. Here, we model a mouse cortical sensory-motor pathway in a tactile detection task reported by licking with a large recurrent spiking neural network (RSNN), fitted to the recordings via gradient-based optimization. We focus specifically on the difficulty to match the trial-to-trial variability in the data. Our solution relies on optimal transport to define a distance between the distributions of generated and recorded trials. The technique is applied to artificial data and neural recordings covering six cortical areas. We find that the resulting RSNN can generate realistic cortical activity and predict jaw movements across the main modes of trial-to-trial variability. Our analysis also identifies an unexpected mode of variability in the data corresponding to task-irrelevant movements of the mouse."], "authors": "Christos Sourmpis"},
{"Title": "A Geometric Tension Dynamics Model of Epithelial Convergent Extension", "abs": ["Epithelial tissue elongation by convergent extension is a key motif of animal morphogenesis. On a coarse scale, cell motion resembles laminar fluid flow; yet in contrast to a fluid, epithelial cells adhere to each other and maintain the tissue layer under actively generated internal tension. To resolve this apparent paradox, we formulate a model in which tissue flow occurs through adiabatic remodelling of the cellular force balance causing local cell rearrangement. We propose that the gradual shifting of the force balance is caused by positive feedback on myosin-generated cytoskeletal tension. Shifting force balance within a tension network causes active T1s oriented by the global anisotropy of tension. Rigidity of cells against shape changes converts the oriented internal rearrangements into net tissue deformation. Strikingly, we find that the total amount of tissue extension depends on the initial magnitude of anisotropy and on cellular packing order. T1s degrade this order so that tissue flow is self-limiting. We explain these findings by showing that coordination of T1s depends on coherence in local tension configurations, quantified by a certain order parameter in tension space. Our model reproduces the salient tissue- and cell-scale features of germ band elongation during Drosophila gastrulation, in particular the slowdown of tissue flow after approximately twofold extension concomitant with a loss of order in tension configurations. This suggests local cell geometry contains morphogenetic information and yields predictions testable in future experiments. Furthermore, our focus on defining biologically controlled active tension dynamics on the manifold of force-balanced states may provide a general approach to the description of morphogenetic flow."], "authors": "Nikolas H. Claussen"},
{"Title": "Geometry-sensitive protrusion growth directs confined cell migration", "abs": ["The migratory dynamics of cells can be influenced by the complex micro-environment through which they move. It remains unclear how the motility machinery of confined cells responds and adapts to their micro-environment. Here, we propose a biophysical mechanism for a geometry-dependent coupling between cellular protrusions and the nucleus that leads to directed migration. We apply our model to geometry-guided cell migration to obtain insights into the origin of directed migration on asymmetric adhesive micro-patterns and the polarization enhancement of cells observed under strong confinement. Remarkably, for cells that can choose between channels of different size, our model predicts an intricate dependence for cellular decision making as a function of the two channel widths, which we confirm experimentally."], "authors": "Johannes Flommersfeld"},
{"Title": "Shaping dynamical neural computations using spatiotemporal constraints", "abs": ["Dynamics play a critical role in computation. The principled evolution of states over time enables both biological and artificial networks to represent and integrate information to make decisions. In the past few decades, significant multidisciplinary progress has been made in bridging the gap between how we understand biological versus artificial computation, including how insights gained from one can translate to the other. Research has revealed that neurobiology is a key determinant of brain network architecture, which gives rise to spatiotemporally constrained patterns of activity that underlie computation. Here, we discuss how neural systems use dynamics for computation, and claim that the biological constraints that shape brain networks may be leveraged to improve the implementation of artificial neural networks. To formalize this discussion, we consider a natural artificial analog of the brain that has been used extensively to model neural computation: the recurrent neural network (RNN). In both the brain and the RNN, we emphasize the common computational substrate atop which dynamics occur -- the connectivity between neurons -- and we explore the unique computational advantages offered by biophysical constraints such as resource efficiency, spatial embedding, and neurodevelopment."], "authors": "Jason Z. Kim"},
{"Title": "Deep Explainability: Spin-Geometrical Neural Meta-Structures", "abs": ["We face up to the challenge of explainability in multimodal artificial intelligence. At the nexus of neuroscience-inspired and quantum computing, interpretable and transparent spin-geometrical meta-architectures for early fusion of large-scale, heterogeneous, graph-structured data are envisioned, harnessing recent evidence for relativistic quantum neural coding of (co-)behavioral states in the self-organizing brain, under competitive, multidimensional dynamics. The designs draw on a self-dual classical description - via special Clifford-Lipschitz operations - of spinorial quantum states within registers of at most 16 qubits for efficient encoding of exponentially large neural structures. Formally 'trained', Lorentz neural architectures with precisely one lateral layer of exclusively inhibitory interneurons accounting for anti-modalities, as well as their co-architectures with intra-layer connections are highlighted. In principle, the approach accommodates the fusion of up to 16 time-invariant interconnected (anti-)modalities and the explicit recognition of underlying multidimensional patterns. Comprehensive insights are expected to be gained through applications to multimodal big data, under real-world scenarios."], "authors": "Sofia Karamintziou"},
{"Title": "Statistical Field Theory and Neural Structures Dynamics I: Action Functionals, Background States and External Perturbations", "abs": ["This series of papers models the dynamics of a large set of interacting neurons within the framework of statistical field theory. The system is described using a two-field model. The first field represents the neuronal activity, while the second field accounts for the interconnections between cells. This model is derived by translating a probabilistic model involving a large number of interacting cells into a field formalism. The current paper focuses on deriving the background fields of the system, which describe the potential equilibria in terms of interconnected groups. Dynamically, we explore the perturbation of these background fields, leading to processes such as activation, association, and reactivation of groups of cells."], "authors": "Pierre Gosselin"},
{"Title": "Auditory cortex and beyond: Deficits in congenital amusia", "abs": ["Congenital amusia is a neuro-developmental disorder of music perception and production, with the observed deficits contrasting with the sophisticated music processing reported for the general population. Musical deficits within amusia have been hypothesized to arise from altered pitch processing, with impairments in pitch discrimination and, notably, short-term memory. We here review research investigating its behavioral and neural correlates, in particular the impairments at encoding, retention, and recollection of pitch information, as well as how these impairments extend to the processing of pitch cues in speech and emotion. The impairments have been related to altered brain responses in a distributed fronto-temporal network, which can be observed also at rest. Neuroimaging studies revealed changes in connectivity patterns within this network and beyond, shedding light on the brain dynamics underlying auditory cognition. Interestingly, some studies revealed spared implicit pitch processing in congenital amusia, showing the power of implicit cognition in the music domain. Building on these findings, together with audiovisual integration and other beneficial mechanisms, we outline perspectives for training and rehabilitation and the future directions of this research domain."], "authors": "Barbara Tillmann"},
{"Title": "Testing Assumptions Underlying a Unified Theory for the Origin of Grid Cells", "abs": ["Representing and reasoning about physical space is fundamental to animal survival, and the mammalian lineage expresses a wealth of specialized neural representations that encode space. Grid cells, whose discovery earned a Nobel prize, are a striking example: a grid cell is a neuron that fires if and only if the animal is spatially located at the vertices of a regular triangular lattice that tiles all explored two-dimensional environments. Significant theoretical work has gone into understanding why mammals have learned these particular representations, and recent work has proposed a ``unified theory for the computational and mechanistic origin of grid cells,\" claiming to answer why the mammalian lineage has learned grid cells. However, the Unified Theory makes a series of highly specific assumptions about the target readouts of grid cells - putatively place cells. In this work, we explicitly identify what these mathematical assumptions are, then test two of the critical assumptions using biological place cell data. At both the population and single-cell levels, we find evidence suggesting that neither of the assumptions are likely true in biological neural representations. These results call the Unified Theory into question, suggesting that biological grid cells likely have a different origin than those obtained in trained artificial neural networks."], "authors": "Rylan Schaeffer"},
{"Title": "Statistical Field Theory and Neural Structures Dynamics II: Signals Propagation, Interferences, Bound States", "abs": ["We continue our study of a field formalism for large sets of interacting neurons, together with their connectivity functions. Expanding upon the foundation laid in ([9]), we formulate an effective formalism for the connectivity field in the presence of external sources. We proceed to deduce the propagation of external signals within the system. This enables us to investigate the activation and association of groups of bound cells."], "authors": "Pierre Gosselin"},
{"Title": "Information theoretic study of the neural geometry induced by category learning", "abs": ["Categorization is an important topic both for biological and artificial neural networks. Here, we take an information theoretic approach to assess the efficiency of the representations induced by category learning. We show that one can decompose the relevant Bayesian cost into two components, one for the coding part and one for the decoding part. Minimizing the coding cost implies maximizing the mutual information between the set of categories and the neural activities. We analytically show that this mutual information can be written as the sum of two terms that can be interpreted as (i) finding an appropriate representation space, and, (ii) building a representation with the appropriate metrics, based on the neural Fisher information on this space. One main consequence is that category learning induces an expansion of neural space near decision boundaries. Finally, we provide numerical illustrations that show how Fisher information of the coding neural population aligns with the boundaries between categories."], "authors": "Laurent Bonnasse-Gahot"},
{"Title": "Statistical Field Theory and Neural Structures Dynamics IV: Field-Theoretic Formalism for Interacting Collective States", "abs": ["Building upon the findings presented in the first three papers of this series, we formulate an effective field theory for interacting collective states. These states consist of a large number of interconnected neurons and are distinguished by their intrinsic activity. The field theory encompasses an infinite set of fields, each of which characterizes the dynamics of a specific type of collective state. Interaction terms within the theory drive transitions between various collective states, allowing us to describe processes such as activation, association, and deactivation of these states."], "authors": "Pierre Gosselin"},
{"Title": "High throughput interactome determination via sulfur anomalous scattering", "abs": ["We propose a novel approach to detect the binding between proteins making use of the anomalous diffraction of natively present heavy elements inside the molecule 3D structure. In particular, we suggest considering sulfur atoms contained in protein structures at lower percentages than the other atomic species. Here, we run an extensive preliminary investigation to probe both the feasibility and the range of usage of the proposed protocol. In particular, we (i) analytically and numerically show that the diffraction patterns produced by the anomalous scattering of the sulfur atoms in a given direction depend additively on the relative distances between all couples of sulfur atoms. Thus the differences in the patterns produced by bound proteins with respect to their non-bonded states can be exploited to rapidly assess protein complex formation. Next, we (ii) carried out analyses on the abundances of sulfurs in the different proteomes and molecular dynamics simulations on a representative set of protein structures to probe the typical motion of sulfur atoms. Finally, we (iii) suggest a possible experimental procedure to detect protein-protein binding. Overall, the completely label-free and rapid method we propose may be readily extended to probe interactions on a large scale even between other biological molecules, thus paving the way to the development of a novel field of research based on a synchrotron light source."], "authors": "Mattia Miotto"},
{"Title": "Statistical Field Theory and Neural Structures Dynamics III: Effective Action for Connectivities, Interactions and Emerging Collective States", "abs": ["This paper elaborates on the effective field theory for the connectivity field previously introduced in ([7]). We demonstrate that dynamic interactions among connectivities induce modifications in the background state. These modifications can be understood as the emergence of interacting collective states above the background state. The emergence of such states is contingent on both interactions and the shape of the static or quasi-static background, which acts as a conditioning factor for potential emerging states."], "authors": "Pierre Gosselin"},
{"Title": "Enhancing EEG Dataset Resources for Schizophrenia Diagnosis: Inaugural West-African (Nigerian) Endeavor", "abs": ["This work has been carried out to improve the dearth of high-quality EEG datasets used for schizophrenia diagnostic tools development and studies from populations of developing and underdeveloped regions of the world. To this aim, the presented dataset contains international 10/20 system EEG recordings from West African subjects of Nigerian origin under rest conditions, in restful states, mental arithmetic task execution states and while passively reacting to auditory stimuli. The subjects are divided into cases and healthy controls and recorded from 36 cases and 21 healthy conTrol subjects identified by the Mini International Schizophrenia Interview (MINI) and also assessed by the Positive and Negative Symptoms Scale (PANSS) and the World Health Organization Disability Assessment Schedule (WHODAS). All cases are admitted schizophrenia patients of the Mental Health Ward, Medical Outpatient Department of the Obafemi Awolowo University Teaching Hospital Complex (OAUTHC, Ile-Ife) and its subsidiary Wesley Guild Hospital Unit (OAUTHC, Ilesa). Controls are drawn from students who volunteered to participate in the study at the Mental Health Ward of OAUTHC and the Wesley Guild Hospital Unit. The recordings are available at Datasets. This dataset can be used by the neuroscience and computational psychiatry research community studying the diagnosis and prognosis of schizophrenia using the electroencephalogram signal modality."], "authors": "E.O. Olateju"},
{"Title": "An Algorithm Based on a Cable-Nernst Planck Model Predicting Synaptic Activity throughout the Dendritic Arbor with Micron Specificity", "abs": ["Recent technological advances have enabled the recording of neurons in intact circuits with a high spatial and temporal resolution, creating the need for modeling with the same precision. In particular, the development of ultra-fast two-photon microscopy combined with fluorescence-based genetically-encoded Ca2+-indicators allows capture of full-dendritic arbor and somatic responses associated with synaptic input and action potential output. The complexity of dendritic arbor structures and distributed patterns of activity over time results in the generation of incredibly rich 4D datasets that are challenging to analyze (Sakaki, 2020). Interpreting neural activity from fluorescence-based Ca2+ biosensors is challenging due to non-linear interactions between several factors influencing intracellular calcium ion concentration and its binding to sensors, including the ionic dynamics driven by diffusion, electrical gradients and voltage-gated", "investigate those dynamics, we designed a model based on a Cable-like equation coupled to the Nernst-Planck equations for ionic fluxes in electrolytes. We employ this model to simulate signal propagation and ionic electrodiffusion across a dendritic arbor. Using these simulation results, we then designed an algorithm to detect synapses from Ca2+ imaging datasets. We finally apply this algorithm to experimental Ca2+-indicator datasets from neurons expressing jGCaMP7s (Dana et al., 2019), using full-dendritic arbor sampling in vivo in the Xenopus laevis optic tectum using fast random-access two-photon microscopy.Our model reproduces the dynamics of visual stimulus-evoked jGCaMP7s-mediated calcium signals observed experimentally, and the resulting algorithm allows prediction of the location of synapses across the dendritic arbor.Our study provides a way to predict synaptic activity and location on dendritic arbors, from fluorescence data in the full dendritic arbor of a neuron recorded in the intact and awake developing vertebrate brain."], "authors": "Claire Guerrier"},
{"Title": "DiffBind: A SE(3) Equivariant Network for Accurate Full-Atom Semi-Flexible Protein-Ligand Docking", "abs": ["Molecular docking, a key technique in structure-based drug design (SBDD), plays a pivotal role in hit identification for specific targets. Accurate prediction of protein-ligand binding mode is important for precise scoring and rational molecular optimization. Notwithstanding its significance, modelling precise and physically plausible binding conformations is a largely unsolved problem in the real-world docking scenario. Flexible docking is a daunting task as modeling protein conformation changes upon ligand binding is extremely computationally expensive and inaccurate. Currently available deep learning docking methods ignore protein flexibility and fail to ensure the physical plausibility and detailed interactions. In this study, we present DiffBind, a comprehensive full-atom diffusion-based semi-flexible docking model that operates over the product space of ligand movements (translation, rotation, and torsion) and pocket side chain torsion changes. Evaluations reveal that DiffBind has considerably higher accuracy in producing native-like binding structures with physically plausible and detailed interactions than traditional docking methods and other deep learning-based approaches. Even in the AlphaFold2 modeled structures, DiffBind still demonstrates superior advantages in accurate pose prediction and structure refinement. DiffBind should be useful for modeling the pocket-ligand binding structure with significant side chain flexibility and virtual screening."], "authors": "Jintao Zhu"},
{"Title": "Efficient high-resolution refinement in cryo-EM with stochastic gradient descent", "abs": ["Electron cryomicroscopy (cryo-EM) is an imaging technique widely used in structural biology to determine the three-dimensional structure of biological molecules from noisy two-dimensional projections with unknown orientations. As the typical pipeline involves processing large amounts of data, efficient algorithms are crucial for fast and reliable results. The stochastic gradient descent (SGD) algorithm has been used to improve the speed of ab initio reconstruction, which results in a first, low-resolution estimation of the volume representing the molecule of interest, but has yet to be applied successfully in the high-resolution regime, where expectation-maximization algorithms achieve state-of-the-art results, at a high computational cost. In this article, we investigate the conditioning of the optimization problem and show that the large condition number prevents the successful application of gradient descent-based methods at high resolution. Our results include a theoretical analysis of the condition number of the optimization problem in a simplified setting where the individual projection directions are known, an algorithm based on computing a diagonal preconditioner using Hutchinson's diagonal estimator, and numerical experiments showing the improvement in the convergence speed when using the estimated preconditioner with SGD. The preconditioned SGD approach can potentially enable a simple and unified approach to ab initio reconstruction and high-resolution refinement with faster convergence speed and higher flexibility, and our results are a promising step in this direction."], "authors": "Bogdan Toader"},
{"Title": "The basement membrane in epidermal polarity, stemness, and regeneration", "abs": ["The epidermis is a specialized epithelium that constitutes the outermost layer of the skin, and it provides a protective barrier against environmental assaults. Primarily consisting of multilayered keratinocytes, the epidermis is continuously renewed by proliferation of stem cells and the differentiation of their progeny, which undergo terminal differentiation as they leave the basal layer and move upward toward the surface, where they die and slough off. Basal keratinocytes rest on a basement membrane at the dermal-epidermal junction that is composed of specific extracellular matrix proteins organized into interactive and mechanically supportive networks. Firm attachment of basal keratinocytes, and their dynamic regulation via focal adhesions and hemidesmosomes, is essential for maintaining major skin processes, such as self-renewal, barrier function, and resistance to physical and chemical stresses. The adhesive integrin receptors expressed by epidermal cells serve structural, signaling, and mechanosensory roles that are critical for epidermal cell anchorage and tissue homeostasis. More specifically, the basement membrane components play key roles in preserving the stem cell pool, and establishing cell polarity cues enabling asymmetric cell divisions, which result in the transition from a proliferative basal cell layer to suprabasal cells committed to terminal differentiation. Finally, through a well-regulated sequence of synthesis and remodeling, the components of the dermal-epidermal junction play an essential role in regeneration of the epidermis during skin healing. Here too, they provide biological and mechanical signals that are essential to the restoration of barrier function."], "authors": "Patricia Rousselle"},
{"Title": "Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for Molecule Generation", "abs": ["We present Symphony, an $E(3)$-equivariant autoregressive generative model for 3D molecular geometries that iteratively builds a molecule from molecular fragments. Existing autoregressive models such as G-SchNet and G-SphereNet for molecules utilize rotationally invariant features to respect the 3D symmetries of molecules. In contrast, Symphony uses message-passing with higher-degree $E(3)$-equivariant features. This allows a novel representation of probability distributions via spherical harmonic signals to efficiently model the 3D geometry of molecules. We show that Symphony is able to accurately generate small molecules from the QM9 dataset, outperforming existing autoregressive models and approaching the performance of diffusion models."], "authors": "Ameya Daigavane"},
{"Title": "MultiModal-Learning for Predicting Molecular Properties: A Framework Based on Image and Graph Structures", "abs": ["The quest for accurate prediction of drug molecule properties poses a fundamental challenge in the realm of Artificial Intelligence Drug Discovery (AIDD). An effective representation of drug molecules emerges as a pivotal component in this pursuit. Contemporary leading-edge research predominantly resorts to self-supervised learning (SSL) techniques to extract meaningful structural representations from large-scale, unlabeled molecular data, subsequently fine-tuning these representations for an array of downstream tasks. However, an inherent shortcoming of these studies lies in their singular reliance on one modality of molecular information, such as molecule image or SMILES representations, thus neglecting the potential complementarity of various molecular modalities. In response to this limitation, we propose MolIG, a novel MultiModaL molecular pre-training framework for predicting molecular properties based on Image and Graph structures. MolIG model innovatively leverages the coherence and correlation between molecule graph and molecule image to execute self-supervised tasks, effectively amalgamating the strengths of both molecular representation forms. This holistic approach allows for the capture of pivotal molecular structural characteristics and high-level semantic information. Upon completion of pre-training, Graph Neural Network (GNN) Encoder is used for the prediction of downstream tasks. In comparison to advanced baseline models, MolIG exhibits enhanced performance in downstream tasks pertaining to molecular property prediction within benchmark groups such as MoleculeNet Benchmark Group and ADMET Benchmark Group."], "authors": "Zhuoyuan Wang"},
{"Title": "Protein-ligand binding representation learning from fine-grained interactions", "abs": ["The binding between proteins and ligands plays a crucial role in the realm of drug discovery. Previous deep learning approaches have shown promising results over traditional computationally intensive methods, but resulting in poor generalization due to limited supervised data. In this paper, we propose to learn protein-ligand binding representation in a self-supervised learning manner. Different from existing pre-training approaches which treat proteins and ligands individually, we emphasize to discern the intricate binding patterns from fine-grained interactions. Specifically, this self-supervised learning problem is formulated as a prediction of the conclusive binding complex structure given a pocket and ligand with a Transformer based interaction module, which naturally emulates the binding process. To ensure the representation of rich binding information, we introduce two pre-training tasks, i.e.~atomic pairwise distance map prediction and mask ligand reconstruction, which comprehensively model the fine-grained interactions from both structure and feature space. Extensive experiments have demonstrated the superiority of our method across various binding tasks, including protein-ligand affinity prediction, virtual screening and protein-ligand docking."], "authors": "Shikun Feng"},
{"Title": "A novel RNA pseudouridine site prediction model using Utility Kernel and data-driven parameters", "abs": ["RNA protein Interactions (RPIs) play an important role in biological systems. Recently, we have enumerated the RPIs at the residue level and have elucidated the minimum structural unit (MSU) in these interactions to be a stretch of five residues (Nucleotides/amino acids). Pseudouridine is the most frequent modification in RNA. The conversion of uridine to pseudouridine involves interactions between pseudouridine synthase and RNA. The existing models to predict the pseudouridine sites in a given RNA sequence mainly depend on user-defined features such as mono and dinucleotide composition/propensities of RNA sequences. Predicting pseudouridine sites is a non-linear classification problem with limited data points. Deep Learning models are efficient discriminators when the data set size is reasonably large and fail when there is a paucity of data ($<1000$ samples). To mitigate this problem, we propose a Support Vector Machine (SVM) Kernel based on utility theory from Economics, and using data-driven parameters (i.e. MSU) as features. For this purpose, we have used position-specific tri/quad/pentanucleotide composition/propensity (PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs are known to work well in small data regimes and kernels in SVM are designed to classify non-linear data. The proposed model outperforms the existing state-of-the-art models significantly (10%-15% on average)."], "authors": "Sourabh Patil"},
{"Title": "A Hierarchical Training Paradigm for Antibody Structure-sequence Co-design", "abs": ["Therapeutic antibodies are an essential and rapidly expanding drug modality. The binding specificity between antibodies and antigens is decided by complementarity-determining regions (CDRs) at the tips of these Y-shaped proteins. In this paper, we propose a hierarchical training paradigm (HTP) for the antibody sequence-structure co-design. HTP consists of four levels of training stages, each corresponding to a specific protein modality within a particular protein domain. Through carefully crafted tasks in different stages, HTP seamlessly and effectively integrates geometric graph neural networks (GNNs) with large-scale protein language models to excavate evolutionary information from not only geometric structures but also vast antibody and non-antibody sequence databases, which determines ligand binding pose and strength. Empirical experiments show that HTP sets the new state-of-the-art performance in the co-design problem as well as the fix-backbone design. Our research offers a hopeful path to unleash the potential of deep generative architectures and seeks to illuminate the way forward for the antibody sequence and structure co-design challenge."], "authors": "Fang Wu"},
{"Title": "InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery", "abs": ["The rapid evolution of artificial intelligence in drug discovery encounters challenges with generalization and extensive training, yet Large Language Models (LLMs) offer promise in reshaping interactions with complex molecular data. Our novel contribution, InstructMol, a multi-modal LLM, effectively aligns molecular structures with natural language via an instruction-tuning approach, utilizing a two-stage training strategy that adeptly combines limited domain-specific data with molecular and textual information. InstructMol showcases substantial performance improvements in drug discovery-related molecular tasks, surpassing leading LLMs and significantly reducing the gap with specialized models, thereby establishing a robust foundation for a versatile and dependable drug discovery assistant."], "authors": "He Cao"},
{"Title": "Community recommendations on cryoEM data archiving and validation", "abs": ["In January 2020, a workshop was held at EMBL-EBI (Hinxton, UK) to discuss data requirements for deposition and validation of cryoEM structures, with a focus on single-particle analysis. The meeting was attended by 45 experts in data processing, model building and refinement, validation, and archiving of such structures. This report describes the workshop's motivation and history, the topics discussed, and consensus recommendations resulting from the workshop. Some challenges for future methods-development efforts in this area are also highlighted, as is the implementation to date of some of the recommendations."], "authors": "Gerard J. Kleywegt"},
{"Title": "Experimental and Theoretical Brownian Dynamics Analysis of Ion Transport During Cellular Electroporation of E. coli Bacteria", "abs": ["Escherichia coli bacterium is a rod-shaped organism composed of a complex double membrane structure. Knowledge of electric field driven ion transport through both membranes and the evolution of their induced permeabilization has important applications in biomedical engineering, delivery of genes and antibacterial agents. However, few studies have been conducted on Gram-negative bacteria in this regard considering the contribution of all ion types. To address this gap in knowledge, we have developed a deterministic and stochastic Brownian dynamics model to simulate in 3D space the motion of ions through pores formed in the plasma membranes of E. coli cells during electroporation. The diffusion coefficient, mobility, and translation time of Ca$^{2+}$, Mg$^{2+}$, Na$^+$, K$^+$, and Cl$^-$ ions within the pore region are estimated from the numerical model. Calculations of pore's conductance have been validated with experiments conducted at Gustave Roussy. From the simulations, it was found that the main driving force of ionic uptake during the pulse is the one due to the externally applied electric field. The results from this work provide a better understanding of ion transport during electroporation, aiding in the design of electrical pulses for maximizing ion throughput, primarily for application in cancer treatment."], "authors": "Juan González-Cuevas"},
{"Title": "Identification of urinary biomarkers of food intake for onion by untargeted LC-MS metabolomics", "abs": ["Scope: Biomarkers of food intake (BFIs) are useful tools for objective assessment of food intake and compliance. The aim of this study was to discover and identify urinary BFIs for onion. Methods and results: In a randomized controlled cross-over trial, 6 overweight participants (age 24-62 years) consumed meals with 20 g/d onion powder or no onion for 2 weeks. Untargeted UPLC-qTOF-MS metabolic profiling analysis was performed on urine samples and the profiles were analysed by multilevel-PLSDA, modified PLS, and nearest shrunken centroid to select features associated with onion intake. Eight biomarkers were tentatively identified; six of them originated from S-substituted cysteine derivatives such as isoalliin and propiin, which are considered the most specific for onion intake. Most of the biomarkers were completely excreted within 24 hours and no accumulation was observed during 2 weeks indicating their ability to reflect only recent intake of onions. Receiver-operator curves were made to evaluate the performance of individual biomarkers for predicting onion intake. The area under the curve values for these biomarkers ranged from 0.81 to 1. Conclusion: Promising biomarkers of recent onion intake have been identified in human urine. Further studies with complex diets are needed to validate the robustness of these biomarkers."], "authors": "Qian Gao"},
{"Title": "NMR Spectroscopy Can Help Accelerate Antiviral Drug Discovery Programs", "abs": ["Small molecule drugs have an important role to play in combating viral infections, and biophysics support has been central for contributing to the discovery and design of direct acting antivirals. Perhaps one of the most successful biophysical tools for this purpose is NMR spectroscopy when utilized strategically and pragmatically within team workflows and timelines. This report describes some clear examples of how NMR applications contributed to the design of antivirals when combined with medicinal chemistry, biochemistry, X-ray crystallography and computational chemistry. Overall, these multidisciplinary approaches allowed teams to reveal and expose compound physical properties from which design ideas were spawned and tested to achieve the desired successes. Examples are discussed for the discovery of antivirals that target HCV, HIV and SARS-CoV-2."], "authors": "Steven R. Laplante"},
{"Title": "Transfer Learning across Different Chemical Domains: Virtual Screening of Organic Materials with Deep Learning Models Pretrained on Small Molecule and Chemical Reaction Data", "abs": ["Machine learning prediction of organic materials properties is an efficient virtual screening method ahead of more expensive screening methods. However, this approach has suffered from insufficient labeled data on organic materials to train state-of-the-art machine learning models. In this study, we demonstrate that drug-like small molecule and chemical reaction databases can be used to pretrain the BERT model for the virtual screening of organic materials. Among the BERT models fine-tuned by five virtual screening tasks on organic materials, the USPTO-SMILES pretrained BERT model had R2 > 0.90 for two tasks and R2 > 0.82 for one, which was generally superior to the same models pretrained by the small molecule or organic materials databases, as well as to the other three traditional machine learning models trained directly on the virtual screening task data. The superior performance of the USPTO-SMILES pretrained BERT model is due to the greater variety of organic building blocks in the USPTO database and the broader coverage of the chemical space. The even better performance of the BERT model pretrained externally from a chemical reaction database with additional sources of chemical reactions strengthens our proof of concept that transfer learning across different chemical domains is practical for the virtual screening of organic materials."], "authors": "Chengwei Zhang"},
{"Title": "Emergence of multiphase condensates from a limited set of chemical building blocks", "abs": ["Biomolecules composed of a limited set of chemical building blocks can co-localize into distinct, spatially segregated compartments known as biomolecular condensates. Although recent studies of intracellular condensates have shown that coexisting, immiscible condensates can form spontaneously via phase separation, it has remained unclear how coexisting and multiphase condensates assemble from chemical building blocks with limited specificity. Here we establish a connection between the interdependencies among biomolecular interactions and the thermodynamic stability of multiphase condensates. We then introduce an inverse design approach for computing the minimum interaction specificity required to assemble condensates with prescribed molecular compositions in a multicomponent biomolecular mixture. As a proof of principle, we apply our theory to design mixtures of model heteropolymers using a minimal number of distinct monomer types, and we use molecular simulations to verify that our designs produce coexisting condensates with the target molecular compositions. Our theoretical approach explains how multiphase condensates arise in naturally occurring biomolecular mixtures and provides a rational algorithm for engineering complex artificial condensates from simple chemical building blocks."], "authors": "Fan Chen"},
{"Title": "Segment-Based Wall Treatment Model for Heat Transfer Rate in Smoothed Particle Hydrodynamics", "abs": ["In this study, a smoothed particle hydrodynamics (SPH) model that applies a segment-based boundary treatment is used to simulate natural convection. In a natural convection simulated using an SPH model, the wall boundary treatment is a major issue because accurate heat transfer from boundaries should be calculated. The boundary particle method, which models the boundary by placing multiple layers of particles on and behind the wall boundary, is the most widely used boundary treatment method. Although this method can impose accurate boundary conditions, boundary modeling for complex shapes is challenging and requires excessive computational costs depending on the boundary shape. In this study, we utilize a segment-based boundary treatment method to model the wall boundary and apply this method to the energy conservation equation for the wall heat transfer model. The proposed method solves the problems arising from the use of boundary particles and simultaneously provides accurate heat transfer calculation results for the wall. In various numerical examples, the proposed method is verified through a comparison with available experimental results, SPH results using the boundary particle method, and finite volume method (FVM) results."], "authors": "Hyung-Jun Park"},
{"Title": "Spectrum Sharing between UAV-based Wireless Mesh Networks and Ground Networks", "abs": ["The unmanned aerial vehicle (UAV)-based wireless mesh networks can economically provide wireless services for the areas with disasters. However, the capacity of air-to-air communications is limited due to the multi-hop transmissions. In this paper, the spectrum sharing between UAV-based wireless mesh networks and ground networks is studied to improve the capacity of the UAV networks. Considering the distribution of UAVs as a three-dimensional (3D) homogeneous Poisson point process (PPP) within a vertical range, the stochastic geometry is applied to analyze the impact of the height of UAVs, the transmit power of UAVs, the density of UAVs and the vertical range, etc., on the coverage probability of ground network user and UAV network user, respectively. The optimal height of UAVs is numerically achieved in maximizing the capacity of UAV networks with the constraint of the coverage probability of ground network user. This paper provides a basic guideline for the deployment of UAV-based wireless mesh networks."], "authors": "Zhiqing Wei"},
{"Title": "Development of a Chemistry Dynamic Load Balancing Solver with Sparse Analytical Jacobian Approach for Rapid and Accurate Reactive Flow Simulations", "abs": ["In addressing the demands of industrial high-fidelity computation, the present study introduces a rapid and accurate customized solver developed on the OpenFOAM platform. To enhance computational efficiency, a novel integrated acceleration strategy is introduced. Initially, a sparse analytical Jacobian approach utilizing the SpeedCHEM chemistry library was implemented to increase the efficiency of the ODE solver. Subsequently, the Dynamic Load Balancing (DLB) code was employed to uniformly distribute the computational workload for chemistry among multiple processes. Further optimization was achieved through the introduction of the Open Multi-Processing (OpenMP) method to enhance parallel computing efficiency. Lastly, the Local Time Stepping (LTS) scheme was integrated to maximize the individual time step for each computational cell, resulting in a noteworthy minimum speed-up of over 31 times. The effectiveness and robustness of this customized solver were systematically validated against three distinct partially turbulent premixed flames, Sandia Flames D, E, and F. Additionally, a comparative analysis was conducted, encompassing different turbulence models, turbulent Prandtl numbers, and model constants, resulting in the recommendation of optimal numerical parameters for various conditions. The present study offers one viable solution for rapid and accurate calculations in the OpenFOAM platform, while also providing insights into the selection of turbulence models and parameters for industrial numerical simulation."], "authors": "Yinan Yang"},
{"Title": "Mathematical Modelling and a Numerical Solution for High Precision Satellite Ephemeris Determination", "abs": ["In this paper, we develop a high-precision satellite orbit determination model for satellites orbiting the Earth. Solving this model entails numerically integrating the differential equation of motion governing a two-body system, employing Fehlberg's formulation and the Runge-Kutta class of embedded integrators with adaptive stepsize control. Relevant primary perturbing forces included in this mathematical model are the full force gravitational field model, Earth's atmospheric drag, third body gravitational effects and solar radiation pressure. Development of the high-precision model required accounting for the perturbing influences of Earth radiation pressure, Earth tides and relativistic effects. The model is then implemented to obtain a high-fidelity Earth orbiting satellite propagator, namely the Satellite Ephemeris Determiner (SED), which is comparable to the popular High Precision Orbit Propagator (HPOP). The architecture of SED, the methodology employed, and the numerical results obtained are presented."], "authors": "Aravind Gundakaram"},
{"Title": "Bias-Variance Trade-off in Physics-Informed Neural Networks with Randomized Smoothing for High-Dimensional PDEs", "abs": ["While physics-informed neural networks (PINNs) have been proven effective for low-dimensional partial differential equations (PDEs), the computational cost remains a hurdle in high-dimensional scenarios. This is particularly pronounced when computing high-order and high-dimensional derivatives in the physics-informed loss. Randomized Smoothing PINN (RS-PINN) introduces Gaussian noise for stochastic smoothing of the original neural net model, enabling Monte Carlo methods for derivative approximation, eliminating the need for costly auto-differentiation. Despite its computational efficiency in high dimensions, RS-PINN introduces biases in both loss and gradients, negatively impacting convergence, especially when coupled with stochastic gradient descent (SGD). We present a comprehensive analysis of biases in RS-PINN, attributing them to the nonlinearity of the Mean Squared Error (MSE) loss and the PDE nonlinearity. We propose tailored bias correction techniques based on the order of PDE nonlinearity. The unbiased RS-PINN allows for a detailed examination of its pros and cons compared to the biased version. Specifically, the biased version has a lower variance and runs faster than the unbiased version, but it is less accurate due to the bias. To optimize the bias-variance trade-off, we combine the two approaches in a hybrid method that balances the rapid convergence of the biased version with the high accuracy of the unbiased version. In addition, we present an enhanced implementation of RS-PINN. Extensive experiments on diverse high-dimensional PDEs, including Fokker-Planck, HJB, viscous Burgers', Allen-Cahn, and Sine-Gordon equations, illustrate the bias-variance trade-off and highlight the effectiveness of the hybrid RS-PINN. Empirical guidelines are provided for selecting biased, unbiased, or hybrid versions, depending on the dimensionality and nonlinearity of the specific PDE problem."], "authors": "Zheyuan Hu"},
{"Title": "Reduced Augmentation Implicit Low-rank (RAIL) integrators for advection-diffusion and Fokker-Planck models", "abs": ["This paper introduces a novel computational approach termed the Reduced Augmentation Implicit Low-rank (RAIL) method by investigating two predominant research directions in low-rank solutions to time-dependent partial differential equations (PDEs): dynamical low-rank (DLR), and step and truncation (SAT) tensor methods. The RAIL method, along with the development of the SAT approach, is designed to enhance the efficiency of traditional full-rank implicit solvers from method-of-lines discretizations of time-dependent PDEs, while maintaining accuracy and stability. We consider spectral methods for spatial discretization, and diagonally implicit Runge-Kutta (DIRK) and implicit-explicit (IMEX) RK methods for time discretization. The efficiency gain is achieved by investigating low-rank structures within solutions at each RK stage using a singular value decomposition (SVD). In particular, we develop a reduced augmentation procedure to predict the basis functions to construct projection subspaces. This procedure balances algorithm accuracy and efficiency by incorporating as many bases as possible from previous RK stages and predictions, and by optimizing the basis representation through SVD truncation. As such, one can form implicit schemes for updating basis functions in a dimension-by-dimension manner, similar in spirit to the K-L step in the DLR framework. We also apply a globally mass conservative post-processing step at the end of each RK stage. We validate the RAIL method through numerical simulations of advection-diffusion problems and a Fokker-Planck model, showcasing its ability to efficiently handle time-dependent PDEs while maintaining global mass conservation. Our approach generalizes and bridges the DLR and SAT approaches, offering a comprehensive framework for efficiently and accurately solving time-dependent PDEs with implicit treatment."], "authors": "Joseph Nakao"},
{"Title": "Asymptotically Compatible Schemes for Nonlocal Ohta Kawasaki Model", "abs": ["We study the asymptotical compatibility of the Fourier spectral method in multidimensional space for the Nonlocal Ohta-Kawasaka (NOK) model, which is proposed in our previous work. By introducing the Fourier collocation discretization for the spatial variable, we show that the asymptotical compatibility holds in 2D and 3D over a periodic domain. For the temporal discretization, we adopt the second-order backward differentiation formula (BDF) method. We prove that for certain nonlocal kernels, the proposed time discretization schemes inherit the energy dissipation law. In the numerical experiments, we verify the asymptotical compatibility, the second-order temporal convergence rate, and the energy stability of the proposed schemes. More importantly, we discover a novel square lattice pattern when certain nonlocal kernel are applied in the model. In addition, our numerical experiments confirm the existence of an upper bound for the optimal number of bubbles in 2D for some specific nonlocal kernels. Finally, we numerically explore the promotion/demotion effect induced by the nonlocal horizon, which is consistent with the theoretical studies presented in our earlier work."], "authors": "Wangbo Luo"},
{"Title": "Singular layer Physics Informed Neural Network method for Plane Parallel Flows", "abs": ["We construct in this article the semi-analytic Physics Informed Neural Networks (PINNs), called {\\em singular layer PINNs} (or {\\em sl-PINNs}), that are suitable to predict the stiff solutions of plane-parallel flows at a small viscosity. Recalling the boundary layer analysis, we first find the corrector for the problem which describes the singular behavior of the viscous flow inside boundary layers. Then, using the components of the corrector and its curl, we build our new {\\em sl-PINN} predictions for the velocity and the vorticity by either embedding the explicit expression of the corrector (or its curl) in the structure of PINNs or by training the implicit parts of the corrector (or its curl) together with the PINN predictions. Numerical experiments confirm that our new {\\em sl-PINNs} produce stable and accurate predicted solutions for the plane-parallel flows at a small viscosity."], "authors": "Teng-Yuan Chang"},
{"Title": "Learning Coarse Propagators in Parareal Algorithm", "abs": ["The parareal algorithm represents an important class of parallel-in-time algorithms for solving evolution equations and has been widely applied in practice. To achieve effective speedup, the choice of the coarse propagator in the algorithm is vital. In this work, we investigate the use of learned coarse propagators. Building upon the error estimation framework, we present a systematic procedure for constructing coarse propagators that enjoy desirable stability and consistent order. Additionally, we provide preliminary mathematical guarantees for the resulting parareal algorithm. Numerical experiments on a variety of settings, e.g., linear diffusion model, Allen-Cahn model, and viscous Burgers model, show that learning can significantly improve parallel efficiency when compared with the more ad hoc choice of some conventional and widely used coarse propagators."], "authors": "Bangti Jin"},
{"Title": "Model-based reconstructions for quantitative imaging in photoacoustic tomography", "abs": ["The reconstruction task in photoacoustic tomography can vary a lot depending on measured targets, geometry, and especially the quantity we want to recover. Specifically, as the signal is generated due to the coupling of light and sound by the photoacoustic effect, we have the possibility to recover acoustic as well as optical tissue parameters. This is referred to as quantitative imaging, i.e, correct recovery of physical parameters and not just a qualitative image. In this chapter, we aim to give an overview on established reconstruction techniques in photoacoustic tomography. We start with modelling of the optical and acoustic phenomena, necessary for a reliable recovery of quantitative values. Furthermore, we give an overview of approaches for the tomographic reconstruction problem with an emphasis on the recovery of quantitative values, from direct and fast analytic approaches to computationally involved optimisation based techniques and recent data-driven approaches."], "authors": "Andreas Hauptmann"},
{"Title": "Closing the ODE-SDE gap in score-based diffusion models through the Fokker-Planck equation", "abs": ["Score-based diffusion models have emerged as one of the most promising frameworks for deep generative modelling, due to their state-of-the art performance in many generation tasks while relying on mathematical foundations such as stochastic differential equations (SDEs) and ordinary differential equations (ODEs). Empirically, it has been reported that ODE based samples are inferior to SDE based samples. In this paper we rigorously describe the range of dynamics and approximations that arise when training score-based diffusion models, including the true SDE dynamics, the neural approximations, the various approximate particle dynamics that result, as well as their associated Fokker--Planck equations and the neural network approximations of these Fokker--Planck equations. We systematically analyse the difference between the ODE and SDE dynamics of score-based diffusion models, and link it to an associated Fokker--Planck equation. We derive a theoretical upper bound on the Wasserstein 2-distance between the ODE- and SDE-induced distributions in terms of a Fokker--Planck residual. We also show numerically that conventional score-based diffusion models can exhibit significant differences between ODE- and SDE-induced distributions which we demonstrate using explicit comparisons. Moreover, we show numerically that reducing the Fokker--Planck residual by adding it as an additional regularisation term leads to closing the gap between ODE- and SDE-induced distributions. Our experiments suggest that this regularisation can improve the distribution generated by the ODE, however that this can come at the cost of degraded SDE sample quality."], "authors": "Teo Deveney"},
{"Title": "RTSMS: Randomized Tucker with single-mode sketching", "abs": ["We propose RTSMS (Randomized Tucker via Single-Mode-Sketching), a randomized algorithm for approximately computing a low-rank Tucker decomposition of a given tensor. It uses sketching and least-squares to compute the Tucker decomposition in a sequentially truncated manner. The algorithm only sketches one mode at a time, so the sketch matrices are significantly smaller than alternative approaches. The algorithm is demonstrated to be competitive with existing methods, sometimes outperforming them by a large margin."], "authors": "Behnam Hashemi"},
{"Title": "Nodal Hydraulic Head Estimation through Unscented Kalman Filter for Data-driven Leak Localization in Water Networks", "abs": ["In this paper, we present a nodal hydraulic head estimation methodology for water distribution networks (WDN) based on an Unscented Kalman Filter (UKF) scheme with application to leak localization. The UKF refines an initial estimation of the hydraulic state by considering the prediction model, as well as available pressure and demand measurements. To this end, it provides customized prediction and data assimilation steps. Additionally, the method is enhanced by dynamically updating the prediction function weight matrices. Performance testing on the Modena benchmark under realistic conditions demonstrates the method's effectiveness in enhancing state estimation and data-driven leak localization."], "authors": "Luis Romero-Ben"},
{"Title": "Half-Precision Kronecker Product SVD Preconditioner for Structured Inverse Problems", "abs": ["In this paper we investigate the use of half-precision Kronecker product singular value decomposition (SVD) approximations as preconditioners for large-scale Tikhonov regularized least squares problems. Half precision reduces storage requirements and has the potential to greatly speedup computations on certain GPU architectures. We consider both standard PCG and flexible PCG algorithms, and investigate, through numerical experiments on image deblurring problems, the trade-offs between potentially faster convergence with the additional cost per iteration when using this preconditioning approach. Moreover, we also investigate the use of several regularization parameter choice methods, including generalized cross validation and the discrepancy principle."], "authors": "Yizhou Chen"},
{"Title": "Frobenius-Type Norms and Inner Products of Matrices and Linear Maps with Applications to Neural Network Training", "abs": ["The Frobenius norm is a frequent choice of norm for matrices. In particular, the underlying Frobenius inner product is typically used to evaluate the gradient of an objective with respect to matrix variable, such as those occuring in the training of neural networks. We provide a broader view on the Frobenius norm and inner product for linear maps or matrices, and establish their dependence on inner products in the domain and co-domain spaces. This shows that the classical Frobenius norm is merely one special element of a family of more general Frobenius-type norms. The significant extra freedom furnished by this realization can be used, among other things, to precondition neural network training."], "authors": "Roland Herzog"},
{"Title": "An efficient class of increasingly high-order ENO schemes with multi-resolution", "abs": ["We construct an efficient class of increasingly high-order (up to 17th-order) essentially non-oscillatory schemes with multi-resolution (ENO-MR) for solving hyperbolic conservation laws. The candidate stencils for constructing ENO-MR schemes range from first-order one-point stencil increasingly up to the designed very high-order stencil. The proposed ENO-MR schemes adopt a very simple and efficient strategy that only requires the computation of the highest-order derivatives of a part of candidate stencils. Besides simplicity and high efficiency, ENO-MR schemes are completely parameter-free and essentially scale-invariant. Theoretical analysis and numerical computations show that ENO-MR schemes achieve designed high-order convergence in smooth regions which may contain high-order critical points (local extrema) and retain ENO property for strong shocks. In addition, ENO-MR schemes could capture complex flow structures very well."], "authors": "Hua Shen"},
{"Title": "Distributional Hessian and divdiv complexes on triangulation and cohomology", "abs": ["In this paper, we construct discrete versions of some Bernstein-Gelfand-Gelfand (BGG) complexes, i.e., the Hessian and the divdiv complexes, on triangulations in 2D and 3D. The sequences consist of finite elements with local polynomial shape functions and various types of Dirac measure on subsimplices. The construction generalizes Whitney forms (canonical conforming finite elements) for the de Rham complex and Regge calculus/finite elements for the elasticity (Riemannian deformation) complex from discrete topological and Discrete Exterior Calculus perspectives. We show that the cohomology of the resulting complexes is isomorphic to the continuous versions, and thus isomorphic to the de~Rham cohomology with coefficients."], "authors": "Kaibo Hu"},
{"Title": "Calderón Strategies for the Convolution Quadrature Time Domain Electric Field Integral Equation", "abs": ["In this work, we introduce new integral formulations based on the convolution quadrature method for the time-domain modeling of perfectly electrically conducting scatterers that overcome some of the most critical issues of the standard schemes based on the electric field integral equation (EFIE). The standard time-domain EFIE-based approaches typically yield matrices that become increasingly ill-conditioned as the time-step or the mesh discretization density increase and suffer from the well-known DC instability. This work presents solutions to these issues that are based both on new Calderón strategies and quasi-Helmholtz projectors regularizations. In addition, to ensure an efficient computation of the marching-on-in-time, the proposed schemes leverage properties of the Z-transform -- involved in the convolution quadrature discretization scheme -- when computing the stabilized operators. The two resulting formulations compare favorably with standard, well-established schemes. The properties and practical relevance of these new formulations will be showcased through relevant numerical examples that include canonical geometries and more complex structures."], "authors": "Pierrick Cordel"},
{"Title": "A nodally bound-preserving finite element method for reaction-convection-diffusion equations", "abs": ["This paper introduces a novel approach to approximate a broad range of reaction-convection-diffusion equations using conforming finite element methods while providing a discrete solution respecting the physical bounds given by the underlying differential equation. The main result of this work demonstrates that the numerical solution achieves accuracy of $O(h^k)$ in the energy norm, where $k$ represents the underlying polynomial degree. To validate the approach, a series of numerical experiments is conducted for various problem instances. Comparisons with the linear continuous interior penalty stabilised method, and the algebraic flux-correction scheme (for the piecewise linear finite element case) have been carried out, where we can observe the favourable performance of the current approach."], "authors": "Abdolreza Amiri"},
{"Title": "Unfitted finite element method for the quad-curl interface problem", "abs": ["In this paper, we introduce a novel unfitted finite element method to solve the quad-curl interface problem. We adapt Nitsche's method for curlcurl-conforming elements and double the degrees of freedom on interface elements. To ensure stability, we incorporate ghost penalty terms and a discrete divergence-free term. We establish the well-posedness of our method and demonstrate an optimal error bound in the discrete energy norm. We also analyze the stiffness matrix's condition number. Our numerical tests back up our theory on convergence rates and condition numbers."], "authors": "Hailong Guo"},
{"Title": "Robust discontinuous Galerkin-based scheme for the fully-coupled non-linear thermo-hydro-mechanical problem", "abs": ["We present and analyze a discontinuous Galerkin method for the numerical modeling of the non-linear fully-coupled thermo-hydro-mechanic problem. We propose a high-order symmetric weighted interior penalty scheme that supports general polytopal grids and is robust with respect to strong heteorgeneities in the model coefficients. We focus on the treatment of the non-linear convective transport term in the energy conservation equation and we propose suitable stabilization techniques that make the scheme robust for advection-dominated regimes. The stability analysis of the problem and the convergence of the fixed-point linearization strategy are addressed theoretically under mild requirements on the problem's data. A complete set of numerical simulations is presented in order to assess the convergence and robustness properties of the proposed method."], "authors": "Stefano Bonetti"},
{"Title": "A generalized nonstandard finite difference method for a class of autonomous dynamical systems and its applications", "abs": ["In this work, a class of continuous-time autonomous dynamical systems describing many important phenomena and processes arising in real-world applications is considered. We apply the nonstandard finite difference (NSFD) methodology proposed by Mickens to design a generalized NSFD method for the dynamical system models under consideration. This method is constructed based on a novel non-local approximation for the right-side functions of the dynamical systems. It is proved by rigorous mathematical analyses that the NSFD method is dynamically consistent with respect to positivity, asymptotic stability and three classes of conservation laws, including direct conservation, generalized conservation and sub-conservation laws. Furthermore, the NSFD method is easy to be implemented and can be applied to solve a broad range of mathematical models arising in real-life. Finally, a set of numerical experiments is performed to illustrate the theoretical findings and to show advantages of the proposed NSFD method."], "authors": "Manh Tuan Hoang"},
{"Title": "Homogeneous algorithms and solvable problems on cones", "abs": ["We consider linear problems in the worst case setting. That is, given a linear operator and a pool of admissible linear measurements, we want to approximate the values of the operator uniformly on a convex and balanced set by means of algorithms that use at most $n$ such measurements. It is known that, in general, linear algorithms do not yield an optimal approximation. However, as we show in this paper, an optimal approximation can always be obtained with a homogeneous algorithm. This is of interest to us for two reasons. First, the homogeneity allows us to extend any error bound on the unit ball to the full input space. Second, homogeneous algorithms are better suited to tackle problems on cones, a scenario that is far less understood than the classical situation of balls. We illustrate our results by several examples."], "authors": "David Krieg"},
{"Title": "On full linear convergence and optimal complexity of adaptive FEM with inexact solver", "abs": ["The ultimate goal of any numerical scheme for partial differential equations (PDEs) is to compute an approximation of user-prescribed accuracy at quasi-minimal computational time. To this end, algorithmically, the standard adaptive finite element method (AFEM) integrates an inexact solver and nested iterations with discerning stopping criteria balancing the different error components. The analysis ensuring optimal convergence order of AFEM with respect to the overall computational cost critically hinges on the concept of R-linear convergence of a suitable quasi-error quantity. This work tackles several shortcomings of previous approaches by introducing a new proof strategy. First, the algorithm requires several fine-tuned parameters in order to make the underlying analysis work. A redesign of the standard line of reasoning and the introduction of a summability criterion for R-linear convergence allows us to remove restrictions on those parameters. Second, the usual assumption of a (quasi-)Pythagorean identity is replaced by the generalized notion of quasi-orthogonality from [Feischl, Math. Comp., 91 (2022)]. Importantly, this paves the way towards extending the analysis to general inf-sup stable problems beyond the energy minimization setting. Numerical experiments investigate the choice of the adaptivity parameters."], "authors": "Philipp Bringmann"},
{"Title": "Quadrature Rules on Triangles and Tetrahedra for Multidimensional Summation-By-Parts Operators", "abs": ["Multidimensional diagonal-norm summation-by-parts (SBP) operators with collocated volume and facet nodes, known as diagonal-$ \\mathsf{E} $ operators, are attractive for entropy-stable discretizations from an efficiency standpoint. However, there is a limited number of such operators, and those currently in existence often have a relatively high node count for a given polynomial order due to a scarcity of suitable quadrature rules. We present several new symmetric positive-weight quadrature rules on triangles and tetrahedra that are suitable for construction of diagonal-$ \\mathsf{E} $ SBP operators. For triangles, quadrature rules of degree one through twenty with facet nodes that correspond to the Legendre-Gauss-Lobatto (LGL) and Legendre-Gauss (LG) quadrature rules are derived. For tetrahedra, quadrature rules of degree one through ten are presented along with the corresponding facet quadrature rules. All of the quadrature rules are provided in a supplementary data repository. The quadrature rules are used to construct novel SBP diagonal-$ \\mathsf{E} $ operators, whose accuracy and maximum timestep restrictions are studied numerically."], "authors": "Zelalem Arega Worku"},
{"Title": "Quasi-optimal Discontinuous Galerkin discretisations of the $p$-Dirichlet problem", "abs": ["The classical arguments employed when obtaining error estimates of Finite Element (FE) discretisations of elliptic problems lead to more restrictive assumptions on the regularity of the exact solution when applied to non-conforming methods. The so-called minimal regularity estimates available in the literature relax some of these assumptions, but are not truly of -minimal regularity-, since a data oscillation term appears in the error estimate. Employing an approach based on a smoothing operator, we derive for the first time error estimates for Discontinuous Galerkin (DG) type discretisations of non-linear problems with $(p,\\delta)$-structure that only assume the natural $W^{1,p}$-regularity of the exact solution, and which do not contain any oscillation terms."], "authors": "J. Blechta"},
{"Title": "Efficient iterative methods for hyperparameter estimation in large-scale linear inverse problems", "abs": ["We study Bayesian methods for large-scale linear inverse problems, focusing on the challenging task of hyperparameter estimation. Typical hierarchical Bayesian formulations that follow a Markov Chain Monte Carlo approach are possible for small problems with very few hyperparameters but are not computationally feasible for problems with a very large number of unknown parameters. In this work, we describe an empirical Bayesian (EB) method to estimate hyperparameters that maximize the marginal posterior, i.e., the probability density of the hyperparameters conditioned on the data, and then we use the estimated values to compute the posterior of the inverse parameters. For problems where the computation of the square root and inverse of prior covariance matrices are not feasible, we describe an approach based on the generalized Golub-Kahan bidiagonalization to approximate the marginal posterior and seek hyperparameters that minimize the approximate marginal posterior. Numerical results from seismic and atmospheric tomography demonstrate the accuracy, robustness, and potential benefits of the proposed approach."], "authors": "Khalil A Hall-Hooper"},
{"Title": "Anti-Gauss cubature rules with applications to Fredholm integral equations on the square", "abs": ["The purpose of this paper is to develop the anti-Gauss cubature rule for approximating integrals defined on the square whose integrand function may have algebraic singularities at the boundaries. An application of such a rule to the numerical solution of second-kind Fredholm integral equations is also explored. The stability, convergence, and conditioning of the proposed Nyström-type method are studied. The numerical solution of the resulting dense linear system is also investigated and several numerical tests are presented."], "authors": "Patricia Diaz de Alba"},
{"Title": "Sketched and Truncated Polynomial Krylov Subspace Methods: Matrix Equations", "abs": ["Thanks to its great potential in reducing both computational cost and memory requirements, combining sketching and Krylov subspace techniques has attracted a lot of attention in the recent literature on projection methods for linear systems, matrix function approximations, and eigenvalue problems. Applying this appealing strategy in the context of linear matrix equations turns out to be far more involved than a straightforward generalization. These difficulties include establishing well-posedness of the projected problem and deriving possible error estimates depending on the sketching properties. Further computational complications include the lack of a natural residual norm estimate and of an explicit basis for the generated subspace. In this paper we propose a new sketched-and-truncated polynomial Krylov subspace method for Sylvester equations that aims to address all these issues. The potential of our novel approach, in terms of both computational time and storage demand, is illustrated with numerical experiments. Comparisons with a state-of-the-art projection scheme based on rational Krylov subspaces are also included."], "authors": "Davide Palitta"},
{"Title": "Spatio-temporal Lie-Poisson discretization for incompressible magnetohydrodynamics on the sphere", "abs": ["We give a structure preserving spatio-temporal discretization for incompressible magnetohydrodynamics (MHD) on the sphere. Discretization in space is based on the theory of geometric quantization, which yields a spatially discretized analogue of the MHD equations as a finite-dimensional Lie--Poisson system on the dual of the magnetic extension Lie algebra $\\mathfrak{f}=\\mathfrak{su}(N)\\ltimes\\mathfrak{su}(N)^{*}$. We also give accompanying structure preserving time discretizations for Lie--Poisson systems on the dual of semidirect product Lie algebras of the form $\\mathfrak{f}=\\mathfrak{g}\\ltimes\\mathfrak{g^{*}}$, where $\\mathfrak{g}$ is a $J$-quadratic Lie algebra. Critically, the time integration method is free of computationally costly matrix exponentials. The full method preserves the underlying geometry, namely the Lie--Poisson structure and all the Casimirs, and nearly preserves the Hamiltonian function in the sense of backward error analysis. To showcase the method, we apply it to two models for magnetic fluids: incompressible magnetohydrodynamics and Hazeltine's model. For the latter, our simulations reveal the formation of large scale vortex condensates, indicating a backward energy cascade analogous to two-dimensional turbulence."], "authors": "Klas Modin"},
{"Title": "Finite elements for symmetric and traceless tensors in three dimensions", "abs": ["We construct a family of finite element sub-complexes of the conformal complex on tetrahedral meshes. This complex includes vector fields and symmetric and traceless tensor fields, interlinked through the conformal Killing operator, the linearized Cotton-York operator, and the divergence operator, respectively. This leads to discrete versions of transverse traceless (TT) tensors and York splits in general relativity. We provide bubble complexes and investigate supersmoothness to facilitate the construction. We show the exactness of the finite element complex on contractible domains."], "authors": "Kaibo Hu"},
{"Title": "Statistical Proper Orthogonal Decomposition for model reduction in feedback control", "abs": ["Feedback control synthesis for nonlinear, parameter-dependent fluid flow control problems is considered. The optimal feedback law requires the solution of the Hamilton-Jacobi-Bellman (HJB) PDE suffering the curse of dimensionality. This is mitigated by Model Order Reduction (MOR) techniques, where the system is projected onto a lower-dimensional subspace, over which the feedback synthesis becomes feasible. However, existing MOR methods assume at least one relaxation of generality, that is, the system should be linear, or stable, or deterministic.", "We propose a MOR method called Statistical POD (SPOD), which is inspired by the Proper Orthogonal Decomposition (POD), but extends to more general systems. Random samples of the original dynamical system are drawn, treating time and initial condition as random variables similarly to possible parameters in the model, and employing a stabilizing closed-loop control. The reduced subspace is chosen to minimize the empirical risk, which is shown to estimate the expected risk of the MOR solution with respect to the distribution of all possible outcomes of the controlled system. This reduced model is then used to compute a surrogate of the feedback control function in the Tensor Train (TT) format that is computationally fast to evaluate online. Using unstable Burgers' and Navier-Stokes equations, it is shown that the SPOD control is more accurate than Linear Quadratic Regulator or optimal control derived from a model reduced onto the standard POD basis, and faster than the direct optimal control of the original system."], "authors": "Sergey Dolgov"},
{"Title": "B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the Response of Complex Dynamical Systems to Length-Variant Multiple Input Functions", "abs": ["Deep Operator Network (DeepONet) is a neural network framework for learning nonlinear operators such as those from ordinary differential equations (ODEs) describing complex systems. Multiple-input deep neural operators (MIONet) extended DeepONet to allow multiple input functions in different Banach spaces. MIONet offers flexibility in training dataset grid spacing, without constraints on output location. However, it requires offline inputs and cannot handle varying sequence lengths in testing datasets, limiting its real-time application in dynamic complex systems. This work redesigns MIONet, integrating Long Short Term Memory (LSTM) to learn neural operators from time-dependent data. This approach overcomes data discretization constraints and harnesses LSTM's capability with variable-length, real-time data. Factors affecting learning performance, like algorithm extrapolation ability are presented. The framework is enhanced with uncertainty quantification through a novel Bayesian method, sampling from MIONet parameter distributions. Consequently, we develop the B-LSTM-MIONet, incorporating LSTM's temporal strengths with Bayesian robustness, resulting in a more precise and reliable model for noisy datasets."], "authors": "Zhihao Kong"},
{"Title": "Hybrid Intervals and Symbolic Block Matrices", "abs": ["Structured matrices with symbolic sizes appear frequently in the literature, especially in the description of algorithms for linear algebra. Recent work has treated these symbolic structured matrices themselves as computational objects, showing how to add matrices with blocks of different symbolic sizes in a general way while avoiding a combinatorial explosion of cases. The present article introduces the concept of hybrid intervals, in which points may have negative multiplicity. Various operations on hybrid intervals have compact and elegant formulations that do not require cases to handle different orders of the end points. This makes them useful to represent symbolic block matrix structures and to express arithmetic on symbolic block matrices compactly. We use these ideas to formulate symbolic block matrix addition and multiplication in a compact and uniform way."], "authors": "Mike Ghesquiere"},
{"Title": "ACL2 Proofs of Nonlinear Inequalities with Imandra", "abs": ["We present a proof-producing integration of ACL2 and Imandra for proving nonlinear inequalities. This leverages a new Imandra interface exposing its nonlinear decision procedures. The reasoning takes place over the reals, but the proofs produced are valid over the rationals and may be run in both ACL2 and ACL2(r). The ACL2 proofs Imandra constructs are extracted from Positivstellensatz refutations, a real algebraic analogue of the Nullstellensatz, and are found using convex optimization."], "authors": "Grant Passmore"},
{"Title": "Proceedings of the 18th International Workshop on the ACL2 Theorem Prover and Its Applications", "abs": ["This volume contains the proceedings of the Eighteenth International Workshop on the ACL2 Theorem Prover and Its Applications (ACL2-2023), a two-day workshop held at the University of Texas at Austin and online, on November 13-14.  These workshops provide a major technical forum for users of the ACL2 theorem prover to present research related to ACL2 and its applications."], "authors": "Alessandro Coglio"},
{"Title": "Formal Verification of Zero-Knowledge Circuits", "abs": ["Zero-knowledge circuits are sets of equality constraints over arithmetic expressions interpreted in a prime field; they are used to encode computations in cryptographic zero-knowledge proofs. We make the following contributions to the problem of ensuring that a circuit correctly encodes a computation: a formal framework for circuit correctness; an ACL2 library for prime fields; an ACL2 model of the existing R1CS (Rank-1 Constraint Systems) formalism to represent circuits, along with ACL2 and Axe tools to verify circuits of this form; a novel PFCS (Prime Field Constraint Systems) formalism to represent hierarchically structured circuits, along with an ACL2 model of it and ACL2 tools to verify circuits of this form in a compositional and scalable way; verification of circuits, ranging from simple to complex; and discovery of bugs and optimizations in existing zero-knowledge systems."], "authors": "Alessandro Coglio"},
{"Title": "Efficient Local Search for Nonlinear Real Arithmetic", "abs": ["Local search has recently been applied to SMT problems over various arithmetic theories. Among these, nonlinear real arithmetic poses special challenges due to its uncountable solution space and potential need to solve higher-degree polynomials. As a consequence, existing work on local search only considered fragments of the theory. In this work, we analyze the difficulties and propose ways to address them, resulting in an efficient search algorithm that covers the full theory of nonlinear real arithmetic. In particular, we present two algorithmic improvements: incremental computation of variable scores and temporary relaxation of equality constraints. We also discuss choice of candidate moves and a look-ahead mechanism in case when no critical moves are available. The resulting implementation is competitive on satisfiable problem instances against complete methods such as MCSAT in existing SMT solvers."], "authors": "Zhonghan Wang"},
{"Title": "Nested Integrals and Rationalizing Transformations", "abs": ["A brief overview of some computer algebra methods for computations with nested integrals is given. The focus is on nested integrals over integrands involving square roots. Rewrite rules for conversion to and from associated nested sums are discussed. We also include a short discussion comparing the holonomic systems approach and the differential field approach. For simplification to rational integrands, we give a comprehensive list of univariate rationalizing transformations, including transformations tuned to map the interval $[0,1]$ bijectively to itself."], "authors": "Clemens G. Raab"},
{"Title": "The Inverse of the Complex Gamma Function", "abs": ["We consider the functional inverse of the Gamma function in the complex plane, where it is multi-valued, and define a set of suitable branches by proposing a natural extension from the real case."], "authors": "David J. Jeffrey"},
{"Title": "Geometric Fiber Classification of Morphisms and a Geometric Approach to Cylindrical Algebraic Decomposition", "abs": ["Cylindrical Algebraic Decomposition (CAD) is a classical construction in real algebraic geometry. The original cylindrical algebraic decomposition was proposed by Collins, using the classical elimination theory. In this paper, we first study the geometric fibers cardinality classification problem of morphisms of affine varieties (over a field of characteristic 0), using a constructive version of Grothendieck's Generic Freeness Lemma and Parametric Hermite Quadratic Forms, then we show how cylindrical algebraic decomposition is related to this classification problem. This provides a new geometric view of Cylindrical Algebraic Decomposition and a new theory of Cylindrical Algebraic Decomposition is developed in this paper."], "authors": "Rizeng Chen"},
{"Title": "Data-efficient operator learning for solving high Mach number fluid flow problems", "abs": ["We consider the problem of using SciML to predict solutions of high Mach fluid flows over irregular geometries. In this setting, data is limited, and so it is desirable for models to perform well in the low-data setting. We show that Neural Basis Functions (NBF), which learns a basis of behavior modes from the data and then uses this basis to make predictions, is more effective than a basis-unaware baseline model. In addition, we identify continuing challenges in the space of predicting solutions for this type of problem."], "authors": "Noah Ford"},
{"Title": "Interleaved One-shot Semi-Persistent Scheduling for BSM Transmissions in C-V2X Networks", "abs": ["Cellular vehicle-to-everything (C-V2X) networks are regarded as one of the main pillars to enable efficient and sustainable Intelligent Transportation Systems (ITS) safety applications and services. Such services rely on the concept of exchanging periodic status updates (i.e., basic safety messages (BSMs)) between nearby vehicular users (VUEs). Hence, it is essential to ensure small inter-packet gaps (IPGs) between successive BSMs from nearby VUEs. Large IPGs, due to successive packet losses, can result in stale information at a VUE. In this paper, we study the tail behavior of the IPG and the information age (IA) distributions using C-V2X transmission mode 4 (a decentralized resource allocation method based on semi-persistent scheduling (SPS)). Specifically, we investigate improvements and trade-offs introduced by the SAE-specified concept of one-shot transmissions. We use a high-fidelity system-level simulator that closely follows the SPS process of C-V2X transmission mode 4 to evaluate the performance of the interleaved one-shot SPS transmissions. Our numerical results show that the tails of the IA and IPG complementary cumulative distribution functions (CCDFs) are significantly improved when one-shot transmissions are enabled in various simulation scenarios."], "authors": "Abdurrahman Fouda"},
{"Title": "Study of BSM Inter-Packet Gap Tails in C-V2X Networks", "abs": ["Cellular vehicle-to-everything (C-V2X) enables safety-critical connected vehicular service by exchanging basic safety messages (BSMs) among nearby vehicular users (VUEs). Timely transmission of BSMs is crucial to avoid stale information at VUEs. However, successive packet losses can lead to large inter-packet gaps (IPGs), reducing the BSMs' reliability. This paper investigates the tail behavior of IPG and information age (IA) distributions in C-V2X mode 4, a decentralized resource allocation method based on semi-persistent scheduling (SPS). We study the improvements and trade-offs introduced by SAE one-shot transmission to decrease the number of successive BSM losses at destination VUEs. The study employs high-fidelity system-level simulations that closely follow the SPS process of CV2X mode 4 to evaluate the performance of interleaved one-shot SPS transmissions. The numerical results demonstrate significant improvement in the IPG and IA tail distributions in various simulation scenarios. Additionally, we propose an accurate analytical model to characterize the IPG tail behavior of C-V2X BSM transmissions. The proposed model is validated by comparing its results with those obtained using the system-level simulations. Our validation shows that the proposed model generates analytical results that coincide with the asymptotic slopes of IPG distribution in different BSM transmission modes."], "authors": "Abdurrahman Fouda"},
{"Title": "HARQ Retransmissions in C-V2X: A BSM Latency Analysis", "abs": ["Cellular vehicular-to-everything (C-V2X) systems offer the potential for improving road safety, in part through the exchange of periodic basic safety messages (BSMs) between nearby vehicles. The reliability and latency of these messages is a key metric. Hybrid automatic repeat request (HARQ) retransmissions are one technique used to this end. However, HARQ may come at the expense of consuming the limited available wireless resources, especially in highly congested scenarios. This paper studies BSM transmission latency and reliability when HARQ retransmissions are used with the semi-persistent scheduling (SPS) in C-V2X transmission mode 4. We do so through extensive system-level simulations that closely follow the SPS process. Furthermore, we provide an analytical model for the tail behavior of the BSM latency distribution with HARQ retransmissions that is a good approximation to the simulation results. Our study reveals the impact of several deployment settings (e.g., bandwidth configurations and vehicle density)."], "authors": "Abdurrahman Fouda"},
{"Title": "Computational Hypergraph Discovery, a Gaussian Process framework for connecting the dots", "abs": ["Most scientific challenges can be framed into one of the following three levels of complexity of function approximation. Type 1: Approximate an unknown function given input/output data. Type 2: Consider a collection of variables and functions, some of which are unknown, indexed by the nodes and hyperedges of a hypergraph (a generalized graph where edges can connect more than two vertices). Given partial observations of the variables of the hypergraph (satisfying the functional dependencies imposed by its structure), approximate all the unobserved variables and unknown functions. Type 3: Expanding on Type 2, if the hypergraph structure itself is unknown, use partial observations of the variables of the hypergraph to discover its structure and approximate its unknown functions. While most Computational Science and Engineering and Scientific Machine Learning challenges can be framed as Type 1 and Type 2 problems, many scientific problems can only be categorized as Type 3. Despite their prevalence, these Type 3 challenges have been largely overlooked due to their inherent complexity. Although Gaussian Process (GP) methods are sometimes perceived as well-founded but old technology limited to Type 1 curve fitting, their scope has recently been expanded to Type 2 problems. In this paper, we introduce an interpretable GP framework for Type 3 problems, targeting the data-driven discovery and completion of computational hypergraphs. Our approach is based on a kernel generalization of Row Echelon Form reduction from linear systems to nonlinear ones and variance-based analysis. Here, variables are linked via GPs and those contributing to the highest data variance unveil the hypergraph's structure. We illustrate the scope and efficiency of the proposed approach with applications to (algebraic) equation discovery, network discovery (gene pathways, chemical, and mechanical) and raw data analysis."], "authors": "Théo Bourdais"},
{"Title": "On the stability of $θ$-methods for DDEs and PDDEs", "abs": ["In this paper, the stability of $\\theta$-methods for delay differential equations is studied based on the test equation $y'(t)=-A y(t) + B y(t-\\tau)$, where $\\tau$ is a constant delay and $A$ is a positive definite matrix. It is mainly considered the case where the matrices $A$ and $B$ are not simultaneosly diagonalizable and the concept of field of values is used to prove a sufficient condition for unconditional stability of these methods and another condition which also guarantees their stability, but according to the step size. The results obtained are also simplified for the case where the matrices $A$ and $B$ are simultaneously diagonalizable and compared with other similar works for the general case. Several numerical examples in which the theory discussed here is applied to parabolic problems given by partial delay differential equations with a diffusion term and a delayed term are presented, too."], "authors": "Alejandro Rodríguez-Fernández"},
{"Title": "Regularized Reduced Order Lippman-Schwinger-Lanczos Method for Inverse Scattering Problems in the Frequency Domain", "abs": ["Inverse scattering has a broad applicability in quantum mechanics, remote sensing, geophysical, and medical imaging. This paper presents a robust direct reduced order model (ROM) method for solving inverse scattering problems based on an efficient approximation of the resolvent operator regularizing the Lippmann-Schwinger-Lanczos (LSL) algorithm. We show that the efficiency of the method relies upon the weak dependence of the orthogonalized basis on the unknown potential in the Schrödinger equation by demonstrating that the Lanczos orthogonalization is equivalent to performing Gram-Schmidt on the ROM time snapshots. We then develop the LSL algorithm in the frequency domain with two levels of regularization. We show that the same procedure can be extended beyond the Schrödinger formulation to the Helmholtz equation, e.g., to imaging the conductivity using diffusive electromagnetic fields in conductive media with localized positive conductivity perturbations. Numerical experiments for Helmholtz and Schrödinger problems show that the proposed bi-level regularization scheme significantly improves the performance of the LSL algorithm, allowing for good reconstructions with noisy data and large data sets."], "authors": "Justin Baker"},
{"Title": "Enhanced the Fast Fractional Fourier Transform (FRFT) scheme using the closed Newton-Cotes rules", "abs": ["The paper considers the fractional Fourier transform (FRFT)--based numerical inversion of Fourier and Laplace transforms and the closed Newton Cotes quadrature rules. It is shown that the fast FRFT of a QN-long weighted sequence is the composite of two fast FRFTs: the fast FRFT of a Q-long weighted sequence and the fast FRFT of an N-long sequence. The Newton-Cotes rules, the composite fast FRFT, and non-weighted fast Fractional Fourier transform (FRFT) algorithms are applied to the Variance Gamma distribution and the Generalized Tempered Stable (GTS) distribution for illustrations. Compared to the non-weighted fast FRFT, the composite fast FRFT provides more accurate results with a small sample size, and the accuracy increases with the number of weights (Q)."], "authors": "A.H.Nzokem"},
{"Title": "Reduced-order modeling for parameterized PDEs via implicit neural representations", "abs": ["We present a new data-driven reduced-order modeling approach to efficiently solve parametrized partial differential equations (PDEs) for many-query problems. This work is inspired by the concept of implicit neural representation (INR), which models physics signals in a continuous manner and independent of spatial/temporal discretization. The proposed framework encodes PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics characterized by multiple PDE parameters. PNODE can be inferred by a hypernetwork to reduce the potential difficulties in learning PNODE due to a complex multilayer perceptron (MLP). The framework uses an INR to decode the latent dynamics and reconstruct accurate PDE solutions. Further, a physics-informed loss is also introduced to correct the prediction of unseen parameter instances. Incorporating the physics-informed loss also enables the model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A numerical experiment is performed on a two-dimensional Burgers equation with a large variation of PDE parameters. We evaluate the proposed method at a large Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to the ground truth values."], "authors": "Tianshu Wen"},
{"Title": "An hp-Adaptive Sampling Algorithm on Dispersion Relation Reconstruction for 2D Photonic Crystals", "abs": ["Computing the dispersion relation for two-dimensional photonic crystals is a notoriously challenging task: It involves solving parameterized Helmholtz eigenvalue problems with high-contrast coefficients. To resolve the challenge, we propose a novel hp-adaptive sampling scheme that can detect singular points via adaptive mesh refinement in the parameter domain, and meanwhile, allow for adaptively enriching the local polynomial spaces on the elements that do not contain singular points. In this way, we obtain an element-wise interpolation on an adaptive mesh. We derive an exponential convergence rate when the number of singular points is finite, and a first-order convergence rate otherwise. Numerical tests are provided to illustrate its performance."], "authors": "Yueqi Wang"},
{"Title": "Fourier Features for Identifying Differential Equations (FourierIdent)", "abs": ["We investigate the benefits and challenges of utilizing the frequency information in differential equation identification. Solving differential equations and Fourier analysis are closely related, yet there is limited work in exploring this connection in the identification of differential equations. Given a single realization of the differential equation perturbed by noise, we aim to identify the underlying differential equation governed by a linear combination of linear and nonlinear differential and polynomial terms in the frequency domain. This is challenging due to large magnitudes and sensitivity to noise. We introduce a Fourier feature denoising, and define the meaningful data region and the core regions of features to reduce the effect of noise in the frequency domain. We use Subspace Pursuit on the core region of the time derivative feature, and introduce a group trimming step to refine the support. We further introduce a new energy based on the core regions of features for coefficient identification. Utilizing the core regions of features serves two critical purposes: eliminating the low-response regions dominated by noise, and enhancing the accuracy in coefficient identification. The proposed method is tested on various differential equations with linear, nonlinear, and high-order derivative feature terms. Our results demonstrate the advantages of the proposed method, particularly on complex and highly corrupted datasets."], "authors": "Mengyi Tang"},
{"Title": "Eigenmatrix for unstructured sparse recovery", "abs": ["This paper considers the unstructured sparse recovery problems in a general form. Examples include rational approximation, spectral function estimation, Fourier inversion, Laplace inversion, and sparse deconvolution. The main challenges are the noise in the sample values and the unstructured nature of the sample locations. This paper proposes the eigenmatrix, a data-driven construction with desired approximate eigenvalues and eigenvectors. The eigenmatrix offers a new way for these sparse recovery problems. Numerical results are provided to demonstrate the efficiency of the proposed method."], "authors": "Lexing Ying"},
{"Title": "MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On Moving Mesh Method", "abs": ["In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate new coordinates of sampling points by solving the moving mesh PDE. This model focuses on improving the efficiency of individual sampling points. Moreover, we have developed an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with PINN to propose MS-PINN and demonstrate its effectiveness by performing error analysis under the assumptions given in this paper. Meanwhile, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments on four typical examples to verify the effectiveness of our method."], "authors": "Yu Yang"},
{"Title": "Comparing intrusive and non-intrusive polynomial chaos for a class of exponential time differencing schemes", "abs": ["We consider the numerical approximation of different ordinary differential equations (ODEs) and partial differential equations (PDEs) with periodic boundary conditions involving a one-dimensional random parameter, comparing the intrusive and non-intrusive polynomial chaos expansion (PCE) method. We demonstrate how to modify two schemes for intrusive PCE (iPCE) which are highly efficient in solving nonlinear reaction-diffusion equations: A second-order exponential time differencing scheme (ETD-RDP-IF) as well as a spectral exponential time differencing fourth-order Runge-Kutta scheme (ETDRK4). In numerical experiments, we show that these schemes show superior accuracy to simpler schemes such as the EE scheme for a range of model equations and we investigate whether they are competitive with non-intrusive PCE (niPCE) methods. We observe that the iPCE schemes are competitive with niPCE for some model equations, but that iPCE breaks down for complex pattern formation models such as the Gray-Scott system."], "authors": "Julian Clausnitzer"},
{"Title": "Stability estimates of Nyström discretizations of Helmholtz decomposition boundary integral equation formulations for the solution of Navier scattering problems in two dimensions with Dirichlet boundary conditions", "abs": ["Helmholtz decompositions of elastic fields is a common approach for the solution of Navier scattering problems. Used in the context of Boundary Integral Equations (BIE), this approach affords solutions of Navier problems via the simpler Helmholtz boundary integral operators (BIOs). Approximations of Helmholtz Dirichlet-to-Neumann (DtN) can be employed within a regularizing combined field strategy to deliver BIE formulations of the second kind for the solution of Navier scattering problems in two dimensions with Dirichlet boundary conditions, at least in the case of smooth boundaries. Unlike the case of scattering and transmission Helmholtz problems, the approximations of the DtN maps we use in the Helmholtz decomposition BIE in the Navier case require incorporation of lower order terms in their pseudodifferential asymptotic expansions. The presence of these lower order terms in the Navier regularized BIE formulations complicates the stability analysis of their Nyström discretizations in the framework of global trigonometric interpolation and the Kussmaul-Martensen kernel singularity splitting strategy. The main difficulty stems from compositions of pseudodifferential operators of opposite orders, whose Nyström discretization must be performed with care via pseudodifferential expansions beyond the principal symbol. The error analysis is significantly simpler in the case of arclength boundary parametrizations and considerably more involved in the case of general smooth parametrizations which are typically encountered in the description of one dimensional closed curves."], "authors": "Victor Dominguez"},
{"Title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse Problems", "abs": ["Incorporating prior information into inverse problems, e.g. via maximum-a-posteriori estimation, is an important technique for facilitating robust inverse problem solutions. In this paper, we devise two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions. The CG class subsumes many commonly used priors in signal and image reconstruction methods including those of sparsity-based approaches. The first method developed is an iterative algorithm, called generalized compound Gaussian least squares (G-CG-LS), that minimizes a regularized least squares objective function where the regularization enforces a CG prior. G-CG-LS is then unrolled, or unfolded, to furnish our second method, which is a novel deep regularized (DR) neural network, called DR-CG-Net, that learns the prior information. A detailed computational theory on convergence properties of G-CG-LS and thorough numerical experiments for DR-CG-Net are provided. Due to the comprehensive nature of the CG prior, these experiments show that our unrolled DR-CG-Net outperforms competitive prior art methods in tomographic imaging and compressive sensing, especially in challenging low-training scenarios."], "authors": "Carter Lyons"},
{"Title": "Applications of Moments of Dirichlet Coefficients in Elliptic Curve Families", "abs": ["The moments of the coefficients of elliptic curve L-functions are related to numerous arithmetic problems. Rosen and Silverman proved a conjecture of Nagao relating the first moment of one-parameter families satisfying Tate's conjecture to the rank of the corresponding elliptic surface over Q(T); one can also construct families of moderate rank by finding families with large first moments. Michel proved that if j(T) is not constant, then the second moment of the family is of size p^2 + O(p^(3/2)); these two moments show that for suitably small support the behavior of zeros near the central point agree with that of eigenvalues from random matrix ensembles, with the higher moments impacting the rate of convergence.", "In his thesis, Miller noticed a negative bias in the second moment of every one-parameter family of elliptic curves over the rationals whose second moment had a calculable closed-form expression, specifically the first lower order term which does not average to zero is on average negative. This Bias Conjecture is confirmed for many families; however, these are highly non-generic families whose resulting Legendre sums can be determined. Inspired by the recent successes by Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, Alexey Pozdnyakov and others in investigations of murmurations of elliptic curve coefficients with machine learning techniques, we pose a similar problem for trying to understand the Bias Conjecture. As a start to this program, we numerically investigate the Bias Conjecture for a family whose bias is positive for half the primes. Since the numerics do not offer conclusive evidence that negative bias for the other half is enough to overwhelm the positive bias, the Bias Conjecture cannot be verified for the family."], "authors": "Zoë Batterman"},
{"Title": "Discrete-to-continuum limits of optimal transport with linear growth on periodic graphs", "abs": ["We prove discrete-to-continuum convergence for dynamical optimal transport on $\\mathbb{Z}^d$-periodic graphs with energy density having linear growth at infinity. This result provides an answer to a problem left open by Gladbach, Kopfer, Maas, and Portinale (Calc Var Partial Differential Equations 62(5), 2023), where the convergence behaviour of discrete boundary-value dynamical transport problems is proved under the stronger assumption of superlinear growth. Our result extends the known literature to some important classes of examples, such as scaling limits of 1-Wasserstein transport problems. Similarly to what happens in the quadratic case, the geometry of the graph plays a crucial role in the structure of the limit cost function, as we discuss in the final part of this work, which includes some visual representations."], "authors": "Lorenzo Portinale"},
{"Title": "Consistent estimation with the use of orthogonal projections for a linear regression model with errors in the variables", "abs": ["In this paper, we construct an estimator of an errors-in-variables linear regression model. The regression model leads to a constrained total least squares problems with row and column constraints. Although this problem can be numerically solved, it is unknown whether the solution has consistency in the statistical sense. The proposed estimator can be constructed by the use of orthogonal projections and their properties, its strong consistency is naturally proved. Moreover, our asymptotic analysis proves the strong consistency of the total least squares solution of the problem with row and column constraints."], "authors": "Kensuke Aishima"},
{"Title": "A discussion on numerical shock stability of unstructured finite volume method: Riemann solvers and limiters", "abs": ["Numerical shock instability is a complexity which may occur in supersonic simulations. Riemann solver is usually the crucial factor that affects both the computation accuracy and numerical shock stability. In this paper, several classical Riemann solvers are discussed, and the intrinsic mechanism of shock instability is especially concerned. It can be found that the momentum perturbation traversing shock wave is a major reason that invokes instability. Furthermore, slope limiters used to depress oscillation across shock wave is also a key factor for computation stability. Several slope limiters can cause significant numerical errors near shock waves, and make the computation fail to converge. Extra dissipation of Riemann solvers and slope limiters can be helpful to eliminate instability, but reduces the computation accuracy. Therefore, to properly introduce numerical dissipation is critical for numerical computations. Here, pressure based shock indicator is used to show the position of shock wave and tunes the numerical dissipation. Overall, the presented methods are showing satisfactory results in both the accuracy and stability."], "authors": "Fan Zhang"},
{"Title": "Strong consistency of an estimator by the truncated singular value decomposition for an errors-in-variables regression model with collinearity", "abs": ["In this paper, we prove strong consistency of an estimator by the truncated singular value decomposition for a multivariate errors-in-variables linear regression model with collinearity. This result is an extension of Gleser's proof of the strong consistency of total least squares solutions to the case with modern rank constraints. While the usual discussion of consistency in the absence of solution uniqueness deals with the minimal norm solution, the contribution of this study is to develop a theory that shows the strong consistency of a set of solutions. The proof is based on properties of orthogonal projections, specifically properties of the Rayleigh-Ritz procedure for computing eigenvalues. This makes it suitable for targeting problems where some row vectors of the matrices do not contain noise. Therefore, this paper gives a proof for the regression model with the above condition on the row vectors, resulting in a natural generalization of the strong consistency for the standard TLS estimator."], "authors": "Kensuke Aishima"},
{"Title": "Constructing Optimal $L_{\\infty}$ Star Discrepancy Sets", "abs": ["The $L_{\\infty}$ star discrepancy is a very well-studied measure used to quantify the uniformity of a point set distribution. Constructing optimal point sets for this measure is seen as a very hard problem in the discrepancy community. Indeed, optimal point sets are, up to now, known only for $n\\leq 6$ in dimension 2 and $n \\leq 2$ for higher dimensions. We introduce in this paper mathematical programming formulations to construct point sets with as low $L_{\\infty}$ star discrepancy as possible. Firstly, we present two models to construct optimal sets and show that there always exist optimal sets with the property that no two points share a coordinate. Then, we provide possible extensions of our models to other measures, such as the extreme and periodic discrepancies. For the $L_{\\infty}$ star discrepancy, we are able to compute optimal point sets for up to 21 points in dimension 2 and for up to 8 points in dimension 3. For $d=2$ and $n\\ge 7$ points, these point sets have around a 50% lower discrepancy than the current best point sets, and show a very different structure."], "authors": "François Clément"},
{"Title": "An extended discontinuous Galerkin shock tracking method", "abs": ["In this paper, we introduce a novel high-order shock tracking method and provide a proof of concept. Our method leverages concepts from implicit shock tracking and extended discontinuous Galerkin methods, primarily designed for solving partial differential equations featuring discontinuities. To address this challenge, we solve a constrained optimization problem aiming at accurately fitting the zero iso-contour of a level set function to the discontinuities. Additionally, we discuss various robustness measures inspired by both numerical experiments and existing literature. Finally, we showcase the capabilities of our method through a series of two-dimensional problems, progressively increasing in complexity."], "authors": "Jakob Vandergrift"},
{"Title": "Modelisation of a rolling disk with Sympy", "abs": ["This paper proposes a Lagrangian approach to find the state equations of a disk rolling on a plane without friction. The approach takes advantage of a symbolic computation to simplify the reasoning."], "authors": "Luc Jaulin"},
{"Title": "An iterative equation solver with low sensitivity on the initial value", "abs": ["The objective of this publication is to reduce the sensitivity of iterative equation solvers on the initial value. To this end, at the hand of Newton's method, we exemplify how to reformulate the initial problem by means of a set of generalized moment generating functions. The approach allows to choose that very function, which is best approximated by a linear function and thus allows to set up an efficient iteration procedure. As a result of this, the number of iterations required to meet a given precision goal is significantly reduced in comparison to Newton's method especially for large deviations between the initial value and the actual root. At the hand of seven academic examples and three applications we demonstrate that the computing time of the discussed approach reveals a far lower susceptibility on the initial value when compared to results from Newton's method. This insensitivity offers the prospect to implement iterative equation solvers for applications with strict real-time requirements such as power system simulation or on-demand control algorithms on embedded systems with low computing power. We are confident that the devised methodology may be generalized to other well-established iteration algorithms."], "authors": "Alexander Herzog"},
{"Title": "Path integral molecular dynamics approximations of quantum canonical observables", "abs": ["Mean-field molecular dynamics based on path integrals is used to approximate canonical quantum observables for particle systems consisting of nuclei and electrons. A computational bottleneck is the sampling from the Gibbs density of the electron operator, which due to the fermion sign problem has a computational complexity that scales exponentially with the number of electrons. In this work we construct an algorithm that approximates the mean-field Hamiltonian by path integrals for fermions. The algorithm is based on the determinant of a matrix with components based on Brownian bridges connecting permuted electron coordinates. The computational work for $n$ electrons is $\\mathcal O(n^3)$, which reduces the computational complexity associated with the fermion sign problem. We analyze a bias resulting from this approximation and provide a computational error indicator. It remains to rigorously explain the surprisingly high accuracy."], "authors": "Xin Huang"},
{"Title": "A positivity preserving scheme for Poisson-Nernst-Planck Navier-Stokes equations and its error analysis", "abs": ["We consider in this paper a numerical approximation of Poisson-Nernst-Planck-Navier- Stokes (PNP-NS) system. We construct a decoupled semi-discrete and fully discrete scheme that enjoys the properties of positivity preserving, mass conserving, and unconditionally energy stability. Then, we establish the well-posedness and regularity of the initial and (periodic) boundary value problem of the PNP-NS system under suitable assumptions on the initial data, and carry out a rigorous convergence analysis for the fully discretized scheme. We also present some numerical results to validate the positivity-preserving property and the accuracy of our scheme."], "authors": "Ziyao Yu"},
{"Title": "Spline Upwind for space--time Isogeometric Analysis of cardiac electrophysiology", "abs": ["We present an elaboration and application of Spline Upwind (SU) stabilization method, designed in space--time Isogeometric Analysis framework, in order to make this stabilization as suitable as possible in the context of cardiac electrophysiology. Our aim is to propose a formulation as simple and efficient as possible, effectual in preventing spurious oscillations present in plain Galerkin method and also reasonable from the computational cost point of view. For these reasons we validate the method's capability with numerical experiments, focusing on accuracy and computational aspects."], "authors": "P. F. Antonietti"},
{"Title": "Computation of outer inverse of tensors based on $t$-product", "abs": ["Tensor operations play an essential role in various fields of science and engineering, including multiway data analysis. In this study, we establish a few basic properties of the range and null space of a tensor using block circulant matrices and the discrete Fourier matrix. We then discuss the outer inverse of tensors based on $t$-product with a prescribed range and kernel of third-order tensors. We address the relation of this outer inverse with other generalized inverses, such as the Moore-Penrose inverse, group inverse, and Drazin inverse. In addition, we present a few algorithms for computing the outer inverses of the tensors. In particular, a $t$-QR decomposition based algorithm is developed for computing the outer inverses."], "authors": "Ratikanta Behera"},
{"Title": "Computing Tensor Generalized bilateral inverses", "abs": ["We introduce tensor generalized bilateral inverses (TGBIs) under the Einstein tensor product as an extension of generalized bilateral inverses (GBIs) in the matrix environment. Moreover, the TBGI class includes so far considered composite generalized inverses (CGIs) for matrices and tensors. Applications of TBGIs for solving multilinear systems are presented. The characterizations and representations of TGBI were studied and verified using a specific algebraic approach. Further, a few characterizations of known CGIs (such as CMP, DMP, MPD, MPCEP, and CEPMP) are derived. The main properties of the TGBIs ware exploited and verified through numerical examples."], "authors": "Ratikanta Behera"},
{"Title": "Characterizations of Weighted Generalized Inverses", "abs": ["The main objective of this paper is to introduce unique representations and characterizations for the weighted core inverse of matrices. We also investigate various properties and representations of these inverses and their relationships with other generalized inverses. Proposed representations of the matrix weighted core inverse will help us to discuss some results associated with the reverse order law for these inverses. Furthermore,this paper introduces an extension of the concepts of generalized bilateral inverse, and $\\{1,2,3,1^k\\}$-inverse and their respective dual for complex rectangular matrices. Furthermore, we establish characterizations of EP-ness and the condition when both $W$-weighted $\\{1,2,3\\}$ and $W$-weighted $\\{1,2,3,1^k\\}$ inverses coincide. In addition, we define the dual inverses for both weighted bilateral inverses and $\\{1,2,3,1^k\\}$-inverse. Characteristics that lead to self-duality in weighted bilateral inverses are also examined."], "authors": "Bibekananda Sitha"},
{"Title": "Polynomial and rational convergence rates for Laplace problems on planar domains", "abs": ["Laplace problems on planar domains can be solved by means of least-squares expansions associated with polynomial or rational approximations. Here it is shown that, even in the context of an analytic domain with analytic boundary data, the difference in convergence rates may be huge when the domain is nonconvex. Our proofs combine the theory of the Schwarz function for analytic continuation, potential theory for polynomial and rational approximation rates, and the theory of crowding of conformal maps."], "authors": "Lloyd N. Trefethen"},
{"Title": "Homogeneous Artificial Neural Network", "abs": ["The paper proposes an artificial neural network (ANN) being a global approximator for a special class of functions, which are known as generalized homogeneous. The homogeneity means a symmetry of a function with respect to a group of transformations having topological characterization of a dilation. In this paper, a class of the so-called linear dilations is considered. A homogeneous universal approximation theorem is proven. Procedures for an upgrade of an existing ANN to a homogeneous one are developed. Theoretical results are supported by examples from the various domains (computer science, systems theory and automatic control)."], "authors": "Andrey Polyakov"},
{"Title": "On the exponential stability of uniformly damped wave equations", "abs": ["We study damped wave propagation problems phrased as abstract evolution equations in Hilbert spaces. Under some general assumptions, including a natural compatibility condition for initial values, we establish exponential decay estimates for all mild solutions using the language and tools of Hilbert complexes. This framework turns out strong enough to conduct our analysis but also general enough to include a number of interesting examples. Some of these are briefly discussed. By a slight modification of the main arguments, we also obtain corresponding decay results for numerical approximations obtained by compatible discretization strategies."], "authors": "Herbert Egger"},
{"Title": "Low-rank optimization on Tucker tensor varieties", "abs": ["In the realm of tensor optimization, low-rank tensor decomposition, particularly Tucker decomposition, stands as a pivotal technique for reducing the number of parameters and for saving storage. We embark on an exploration of Tucker tensor varieties -- the set of tensors with bounded Tucker rank -- in which the geometry is notably more intricate than the well-explored geometry of matrix varieties. We give an explicit parametrization of the tangent cone of Tucker tensor varieties and leverage its geometry to develop provable gradient-related line-search methods for optimization on Tucker tensor varieties. The search directions are computed from approximate projections of antigradient onto the tangent cone, which circumvents the calculation of intractable metric projections. To the best of our knowledge, this is the first work concerning geometry and optimization on Tucker tensor varieties. In practice, low-rank tensor optimization suffers from the difficulty of choosing a reliable rank parameter. To this end, we incorporate the established geometry and propose a Tucker rank-adaptive method that is capable of identifying an appropriate rank during iterations while the convergence is also guaranteed. Numerical experiments on tensor completion with synthetic and real-world datasets reveal that the proposed methods are in favor of recovering performance over other state-of-the-art methods. Moreover, the rank-adaptive method performs the best across various rank parameter selections and is indeed able to find an appropriate rank."], "authors": "Bin Gao"},
{"Title": "Convergence Analysis of Fractional Gradient Descent", "abs": ["Fractional derivatives are a well-studied generalization of integer order derivatives. Naturally, for optimization, it is of interest to understand the convergence properties of gradient descent using fractional derivatives. Convergence analysis of fractional gradient descent is currently limited both in the methods analyzed and the settings analyzed. This paper aims to fill in these gaps by analyzing variations of fractional gradient descent in smooth and convex, smooth and strongly convex, and smooth and non-convex settings. First, novel bounds will be established bridging fractional and integer derivatives. Then, these bounds will be applied to the aforementioned settings to prove $O(1/T)$ convergence for smooth and convex functions and linear convergence for smooth and strongly convex functions. Additionally, we prove $O(1/T)$ convergence for smooth and non-convex functions using an extended notion of smoothness that is more natural for fractional derivatives. Finally, empirical results will be presented on the potential speed up of fractional gradient descent over standard gradient descent as well as the challenges of predicting which will be faster in general."], "authors": "Ashwani Aggarwal"},
{"Title": "Accelerating Flow Simulations using Online Dynamic Mode Decomposition", "abs": ["We develop an on-the-fly reduced-order model (ROM) integrated with a flow simulation, gradually replacing a corresponding full-order model (FOM) of a physics solver. Unlike offline methods requiring a separate FOM-only simulation prior to model reduction, our approach constructs a ROM dynamically during the simulation, replacing the FOM when deemed credible. Dynamic mode decomposition (DMD) is employed for online ROM construction, with a single snapshot vector used for rank-1 updates in each iteration. Demonstrated on a flow over a cylinder with Re = 100, our hybrid FOM/ROM simulation is verified in terms of the Strouhal number, resulting in a 4.4 times speedup compared to the FOM solver."], "authors": "Seung Won Suh"},
{"Title": "A Data-Driven, Non-Linear, Parameterized Reduced Order Model of Metal 3D Printing", "abs": ["Directed energy deposition (DED) is a promising metal additive manufacturing technology capable of 3D printing metal parts with complex geometries at lower cost compared to traditional manufacturing. The technology is most effective when process parameters like laser scan speed and power are optimized for a particular geometry and alloy. To accelerate optimization, we apply a data-driven, parameterized, non-linear reduced-order model (ROM) called Gaussian Process Latent Space Dynamics Identification (GPLaSDI) to physics-based DED simulation data. With an appropriate choice of hyperparameters, GPLaSDI is an effective ROM for this application, with a worst-case error of about 8% and a speed-up of about 1,000,000x with respect to the corresponding physics-based data."], "authors": "Aaron L. Brown"},
{"Title": "Reconstructing the shape and material parameters of dissipative obstacles using an impedance model", "abs": ["In inverse scattering problems, a model that allows for the simultaneous recovery of both the domain shape and an impedance boundary condition covers a wide range of problems with impenetrable domains, including recovering the shape of sound-hard and sound-soft obstacles and obstacles with thin coatings. This work develops an optimization framework for recovering the shape and material parameters of a penetrable, dissipative obstacle in the multifrequency setting, using a constrained class of curvature-dependent impedance function models proposed by Antoine, Barucq, and Vernhet. We find that this constrained model improves the robustness of the recovery problem, compared to more general models, and provides meaningfully better obstacle recovery than simpler models. We explore the effectiveness of the model for varying levels of dissipation, for noise-corrupted data, and for limited aperture data in the numerical examples."], "authors": "Travis Askham"},
{"Title": "Generalized Gearhart-Koshy acceleration is a Krylov space method of a new type", "abs": ["The Gearhart-Koshy acceleration for the Kaczmarz method for linear systems is a line-search with the unusual property that it does not minimize the residual, but the error. Recently one of the authors generalized the this acceleration from a line-search to a search in affine subspaces.", "In this paper, we demonstrate that the affine search is a Krylov space method that is neither a CG-type nor a MINRES-type method, and we prove that it is mathematically equivalent with a more canonical Gram-Schmidt-based method. We also investigate what abstract property of the Kaczmarz method enables this type of algorithm, and we conclude with a simple numerical example."], "authors": "Markus Hegland"},
{"Title": "Spherical Designs for Function Approximation and Beyond", "abs": ["In this paper, we compare two optimization algorithms using full Hessian and approximation Hessian to obtain numerical spherical designs through their variational characterization. Based on the obtained spherical design point sets, we investigate the approximation of smooth and non-smooth functions by spherical harmonics with spherical designs. Finally, we use spherical framelets for denoising Wendland functions as an application, which shows the great potential of spherical designs in spherical data processing."], "authors": "Yuchen Xiao"},
{"Title": "An efficient solver for space-time isogeometric Galerkin methods for parabolic problems", "abs": ["In this work we focus on the preconditioning of a Galerkin space-time isogeometric discretization of the heat equation. Exploiting the tensor product structure of the basis functions in the parametric domain, we propose a preconditioner that is the sum of Kronecker products of matrices and that can be efficiently applied thanks to an extension of the classical Fast Diagonalization method. The preconditioner is robust w.r.t. the polynomial degree of the spline space and the time required for the application is almost proportional to the number of degrees-of-freedom, for a serial execution. By incorporating some information on the geometry parametrization and on the equation coefficients, we keep high efficiency with non-trivial domains and variable thermal conductivity and heat capacity coefficients."], "authors": "Gabriele Loli"},
{"Title": "Space-time least squares approximation for Schrödinger equation and efficient solver", "abs": ["In this work we present a space-time least squares isogeometric discretization of the Schrödinger equation and propose a preconditioner for the arising linear system in the parametric domain. Exploiting the tensor product structure of the basis functions, the preconditioner is written as the sum of Kronecker products of matrices. Thanks to an extension to the classical Fast Diagonalization method, the application of the preconditioner is efficient and robust w.r.t. the polynomial degree of the spline space. The time required for the application is almost proportional to the number of degrees-of-freedom, for a serial execution."], "authors": "Andrea Bressan"},
{"Title": "A Robust Hessian-based Trust Region Algorithm for Spherical Conformal Parameterizations", "abs": ["Surface parameterizations are widely applied in computer graphics, medical imaging and transformation optics. In this paper, we rigorously derive the gradient vector and Hessian matrix of the discrete conformal energy for spherical conformal parameterizations of simply connected closed surfaces of genus-$0$. In addition, we give the sparsity structure of the Hessian matrix, which leads to a robust Hessian-based trust region algorithm for the computation of spherical conformal maps. Numerical experiments demonstrate the local quadratic convergence of the proposed algorithm with low conformal distortions. We subsequently propose an application of our method to surface registrations that still maintains local quadratic convergence."], "authors": "Zhong-Heng Tan"},
{"Title": "The lowest-order Neural Approximated Virtual Element Method", "abs": ["We introduce the Neural Approximated Virtual Element Method, a novel polygonal method that relies on neural networks to eliminate the need for projection and stabilization operators in the Virtual Element Method. In this paper, we discuss its formulation and detail the strategy for training the underlying neural network. The efficacy of this new method is tested through numerical experiments on elliptic problems."], "authors": "Stefano Berrone"},
{"Title": "Energy conservative isogeometric techniques for the wave equation", "abs": ["We analyze the wave equation in mixed form, with periodic and/or Dirichlet homogeneous boundary conditions, and nonconstant coefficients that depend on the spatial variable. For the discretization, the weak form of the second equation is replaced by a strong form, written in terms of a projection operator. The system of equations is discretized with B-splines forming a De Rham complex along with suitable commutative projectors for the approximation of the second equation. The discrete scheme is energy conservative when discretized in time with a conservative method such as Crank-Nicolson. We propose a convergence analysis of the method to study the dependence with respect to the mesh size $h$, with focus on the consistency error. Numerical results show optimal convergence of the error in energy norm, and a relative error in energy conservation for long-time simulations of the order of machine precision."], "authors": "Andrea Bressan"},
{"Title": "Two-scale exponential integrators with uniform accuracy for three-dimensional charged-particle dynamics under strong magnetic field", "abs": ["The numerical simulation of three-dimensional charged-particle dynamics (CPD) under strong magnetic field is challenging. In this paper, we introduce a new methodology to design two-scale exponential integrators for three-dimensional CPD whose magnetic field's strength is inversely proportional to a dimensionless parameter $0<\\varepsilon \\ll 1$. By dealing with the transformed form of three-dimensional CPD, we linearize the magnetic field and put the rest part in a nonlinear function which can be shown to be small. Based on which and the proposed two-scale exponential integrators, a class of novel integrators is formulated. The corresponding uniform accuracy over $\\mathcal{O}(1/\\varepsilon^{\\beta})$ time interval is $\\mathcal{O}(\\varepsilon^{r\\beta} h^r)$ for the $r$-th order integrator with the time stepsize $h$, $r=1,2,3,4$ and $0<\\beta<1$. A rigorous proof of this error bound is presented and a numerical test is performed to illustrate the error behaviour of the proposed integrators."], "authors": "Bin Wang"},
{"Title": "Extension and convergence analysis of Iterative Filtering to spherical data", "abs": ["Many real-life signals are defined on spherical domains, in particular in geophysics and physics applications. In this work, we tackle the problem of extending the iterative filtering algorithm, developed for the decomposition of non-stationary signals defined in Euclidean spaces, to spherical domains. We review the properties of the classical Iterative Filtering method, present its extension, and study its convergence in the discrete setting. In particular, by leveraging the Generalized Locally Toeplitz sequence theory, we are able to characterize spectrally the operators associated with the spherical extension of Iterative Filtering, and we show a counterexample of its convergence. Finally, we propose a convergent version, called Spherical Iterative Filtering, and present numerical results of its application to spherical data."], "authors": "Giovanni Barbarino"},
{"Title": "A robust and adaptive GenEO-type domain decomposition preconditioner for $\\mathbf{H}(\\mathbf{curl})$ problems in general non-convex three-dimensional geometries", "abs": ["In this paper we develop and analyse domain decomposition methods for linear systems of equations arising from conforming finite element discretisations of positive Maxwell-type equations, namely for $\\mathbf{H}(\\mathbf{curl})$ problems. It is well known that convergence of domain decomposition methods rely heavily on the efficiency of the coarse space used in the second level. We design adaptive coarse spaces that complement a near-kernel space made from the gradient of scalar functions. The new class of preconditioner is inspired by the idea of subspace decomposition, but based on spectral coarse spaces, and is specially designed for curl-conforming discretisations of Maxwell's equations in heterogeneous media on general domains which may have holes. Our approach has wider applicability and theoretical justification than the well-known Hiptmair-Xu auxiliary space preconditioner, with results extending to the variable coefficient case and non-convex domains at the expense of a larger coarse space."], "authors": "Niall Bootland"},
{"Title": "Evaluating Lebesgue constants by Chebyshev polynomial meshes on cube, simplex and ball", "abs": ["We show that product Chebyshev polynomial meshes can be used, in a fully discrete way, to evaluate with rigorous error bounds the Lebesgue constant, i.e. the maximum of the Lebesgue function, for a class of polynomial projectors on cube, simplex and ball, including interpolation, hyperinterpolation and weighted least-squares. Several examples are presented and possible generalizations outlined. A numerical software package implementing the method is freely available online."], "authors": "L. Bialas-Ciez"},
{"Title": "Evidence of scale-free clusters of vegetation in tropical rainforests", "abs": ["Tropical rainforests exhibit a rich repertoire of spatial patterns emerging from the intricate relationship between the microscopic interaction between species. In particular, the distribution of vegetation clusters can shed much light on the underlying process regulating the ecosystem. Analyzing the distribution of vegetation clusters at different resolution scales, we show the first robust evidence of scale-invariant clusters of vegetation, suggesting the coexistence of multiple intertwined scales in the collective dynamics of tropical rainforests. We use field data and computational simulations to confirm our hypothesis, proposing a predictor that could be particularly interesting to monitor the ecological resilience of the world's 'green lungs'."], "authors": "Pablo Villegas"},
{"Title": "Automatic Time Signature Determination for New Scores Using Lyrics for Latent Rhythmic Structure", "abs": ["There has recently been a sharp increase in interest in Artificial Intelligence-Generated Content (AIGC). Despite this, musical components such as time signatures have not been studied sufficiently to form an algorithmic determination approach for new compositions, especially lyrical songs. This is likely because of the neglect of musical details, which is critical for constructing a robust framework. Specifically, time signatures establish the fundamental rhythmic structure for almost all aspects of a song, including the phrases and notes. In this paper, we propose a novel approach that only uses lyrics as input to automatically generate a fitting time signature for lyrical songs and uncover the latent rhythmic structure utilizing explainable machine learning models. In particular, we devise multiple methods that are associated with discovering lyrical patterns and creating new features that simultaneously contain lyrical, rhythmic, and statistical information. In this approach, the best of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In conclusion, our research directly generates time signatures from lyrics automatically for new scores utilizing machine learning, which is an innovative idea that approaches an understudied component of musicology and therefore contributes significantly to the future of Artificial Intelligence (AI) music generation."], "authors": "Callie C. Liao"},
{"Title": "Control of complex systems with generalized embedding and empirical dynamic modeling", "abs": ["Feedback control is ubiquitous in complex systems. Effective control requires knowledge of the dynamics informing feedback compensation to guide the system toward desired states. In many control applications this knowledge is expressed mathematically or through data-driven models, however, as complexity grows obtaining a satisfactory mathematical representation is increasingly difficult. Further, many data-driven approaches consist of abstract internal representations that may have no obvious connection to the underlying dynamics and control, or, require a-priori specification of functions to represent the dynamics. To remove these constraints we demonstrate that generalized state space embedding and prediction can provide data-driven process model representation for control of complex systems. Generalized embedding naturally encompasses multivariate dynamics enabling state space variable cross mapping for direct assessment of multivariate contributions to the dynamics. Further, state space kernel regression allows inspection of intervariable dependencies. To illustrate this an agent based model is used to generate nonlinear dynamics which are then modeled by generalized state space embedding providing state predictions to a controller regulating the system dynamics. The method is generally applicable to any dynamic system representable in a state space."], "authors": "Joseph Park"},
{"Title": "Ethics and Responsible AI Deployment", "abs": ["As Artificial Intelligence (AI) becomes more prevalent, protecting personal privacy is a critical ethical issue that must be addressed. This article explores the need for ethical AI systems that safeguard individual privacy while complying with ethical standards. By taking a multidisciplinary approach, the research examines innovative algorithmic techniques such as differential privacy, homomorphic encryption, federated learning, international regulatory frameworks, and ethical guidelines. The study concludes that these algorithms effectively enhance privacy protection while balancing the utility of AI with the need to protect personal data. The article emphasises the importance of a comprehensive approach that combines technological innovation with ethical and regulatory strategies to harness the power of AI in a way that respects and protects individual privacy."], "authors": "Petar Radanliev"},
